{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "anomaly_detection_gist.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNvO+YJXzyQi2X/rR9tFhr/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dmbk/Anomaly-Detection-System/blob/master/anomaly_detection_VAE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6uQhe8VSqXpe",
        "colab_type": "code",
        "outputId": "c695b9eb-e38f-4942-a8b9-6c37e396c318",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "pip install keras-layer-normalization"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras-layer-normalization in /usr/local/lib/python3.6/dist-packages (0.14.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from keras-layer-normalization) (1.18.3)\n",
            "Requirement already satisfied: Keras in /usr/local/lib/python3.6/dist-packages (from keras-layer-normalization) (2.3.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras->keras-layer-normalization) (3.13)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras->keras-layer-normalization) (2.10.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-layer-normalization) (1.12.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-layer-normalization) (1.0.8)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-layer-normalization) (1.1.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-layer-normalization) (1.4.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jn4T13Cd2Vwh",
        "colab_type": "code",
        "outputId": "39a336ad-e7ca-4a30-c028-d9046f6f7210",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HbKe11RPoo9K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0811e7c1-f285-4f63-a90d-c09b307298c3"
      },
      "source": [
        "\n",
        "import skimage\n",
        "import glob\n",
        "import imageio\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "from PIL import Image\n",
        "from os.path import join\n",
        "from os import listdir\n",
        "from os.path import isfile, join, isdir\n",
        "\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import keras\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.layers import Conv2DTranspose, ConvLSTM2D, BatchNormalization, TimeDistributed, Conv2D\n",
        "from keras.models import Sequential, load_model\n",
        "from keras_layer_normalization import LayerNormalization\n",
        "from keras.layers import Input, Flatten, Dense, Lambda, Reshape\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.models import Model\n",
        "from keras.datasets import mnist\n",
        "from keras.losses import binary_crossentropy\n",
        "from keras import backend as K\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import argparse\n",
        "import numpy as np\n",
        "from os.path import dirname\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import math\n",
        "class Config:\n",
        "    def __init__(self, data_dir, single_test_case, model_path, retrain=0):\n",
        "        self.DATASET_PATH = join(data_dir,\"UCSDped1/Train\")\n",
        "        self.TEST_DIR = join(data_dir,\"UCSDped1/Test/\")\n",
        "        self.SINGLE_TEST_PATH = join(self.TEST_DIR, single_test_case)\n",
        "        self.BATCH_SIZE = 4\n",
        "        self.EPOCHS = 5\n",
        "        self.MODEL_PATH = join(model_path,\"model\")\n",
        "        self.retrain = retrain\n",
        "        self.latent_dim = 128\n",
        "\n",
        "\n",
        "def get_clips_by_stride(stride, frames_list, sequence_size):\n",
        "    \"\"\" For data augmenting purposes.\n",
        "    Parameters\n",
        "    ----------\n",
        "    stride : int\n",
        "        The distance between two consecutive frames\n",
        "    frames_list : list\n",
        "        A list of sorted frames of shape 256 X 256\n",
        "    sequence_size: int\n",
        "        The size of the lstm sequence\n",
        "    Returns\n",
        "    -------\n",
        "    list\n",
        "        A list of clips , 10 frames each\n",
        "    \"\"\"\n",
        "    clips = []\n",
        "    sz = len(frames_list)\n",
        "    clip = np.zeros(shape=(sequence_size, 256, 256, 1))\n",
        "    cnt = 0\n",
        "    for start in range(0, stride):\n",
        "        for i in range(start, sz, stride):\n",
        "            clip[cnt, :, :, 0] = frames_list[i]\n",
        "            cnt = cnt + 1\n",
        "            if cnt == sequence_size:\n",
        "                clips.append(clip)\n",
        "                cnt = 0\n",
        "    return clips\n",
        "\n",
        "def get_training_set(conf):\n",
        "    \"\"\"\n",
        "    Returns\n",
        "    -------\n",
        "    list\n",
        "        A list of training sequences of shape (NUMBER_OF_SEQUENCES,SINGLE_SEQUENCE_SIZE,FRAME_WIDTH,FRAME_HEIGHT,1)\n",
        "    \"\"\"\n",
        "    clips = []\n",
        "    # loop over the training folders (Train000,Train001,..)\n",
        "    for f in sorted(listdir(conf.DATASET_PATH)):\n",
        "        directory_path = join(conf.DATASET_PATH, f)\n",
        "        if isdir(directory_path):\n",
        "            all_frames = []\n",
        "            # loop over all the images in the folder (0.tif,1.tif,..,199.tif)\n",
        "            for c in sorted(listdir(directory_path)):\n",
        "                img_path = join(directory_path, c)\n",
        "                if str(img_path)[-3:] == \"tif\":\n",
        "                    img = Image.open(img_path).resize((256, 256))\n",
        "\n",
        "                    img = np.array(img, dtype=np.float32) / 256.0\n",
        "                    all_frames.append(img)\n",
        "            # get the 10-frames sequences from the list of images after applying data augmentation\n",
        "            for stride in range(1, 3):\n",
        "                clips.extend(get_clips_by_stride(stride=stride, frames_list=all_frames, sequence_size=10))\n",
        "    return clips\n",
        "\n",
        "def kl_reconstruction_loss(true, pred):\n",
        "    # Reconstruction loss\n",
        "      #reconstruction_loss = binary_crossentropy(K.flatten(true), K.flatten(pred)) * 10 * 256 * 256\n",
        "      #reconstruction_loss = np.linalg.norm(np.subtract(true,pred))\\\n",
        "\n",
        "      reconstruction_loss = mse(K.flatten(true), K.flatten(pred)) * 10 * 256 * 256\n",
        "      #reconstruction_loss = euclidean_distance_loss(K.flatten(true), K.flatten(pred))\n",
        "      # KL divergence loss\n",
        "      kl_loss = 1 + sigma - K.square(mu) - K.exp(sigma)\n",
        "      kl_loss = K.sum(kl_loss, axis=-1)\n",
        "      kl_loss *= -0.5\n",
        "      # Total loss = 50% rec + 50% KL divergence loss\n",
        "      return K.mean(reconstruction_loss + kl_loss)\n",
        "\n",
        "def get_model(conf):\n",
        "    \"\"\"\n",
        "    Parameters\n",
        "    ----------\n",
        "    reload_model : bool\n",
        "        Load saved model or retrain it\n",
        "    \"\"\"\n",
        "    if conf.retrain == 1 and os.path.isfile(conf.MODEL_PATH):\n",
        "        vae=load_model(path, custom_objects={'LayerNormalization': LayerNormalization})\n",
        "        return vae\n",
        "    input_train = get_training_set(conf)\n",
        "    input_train = np.array(input_train)\n",
        "\n",
        "    validation_split = 0.2\n",
        "    verbosity = 1\n",
        "\n",
        "    # # =================\n",
        "    # # Encoder\n",
        "    # # =================\n",
        "    \n",
        "    # Definition\n",
        "    i       = Input(shape=(10, 256, 256, 1), name='encoder_input')\n",
        "    cx      = TimeDistributed(Conv2D(128, (11, 11), strides=4, padding=\"same\", activation='relu'))(i)\n",
        "    cx      = LayerNormalization()(cx)\n",
        "    cx      = TimeDistributed(Conv2D(64, (5, 5), strides=2, padding=\"same\", activation='relu'))(cx)\n",
        "    cx      = LayerNormalization()(cx)\n",
        "    cx      = ConvLSTM2D(64, (3, 3), padding=\"same\", return_sequences=True)(cx)\n",
        "    cx      = LayerNormalization()(cx)\n",
        "    cx      = ConvLSTM2D(32, (3, 3), padding=\"same\", return_sequences=True)(cx)\n",
        "    x       = Flatten()(cx)\n",
        "    x       = Dense(360, activation='relu')(x)\n",
        "    x       = BatchNormalization()(x)\n",
        "    mu      = Dense(conf.latent_dim, name='latent_mu')(x)\n",
        "    sigma   = Dense(conf.latent_dim, name='latent_sigma')(x)\n",
        "    \n",
        "    # Get Conv2D shape for Conv2DTranspose operation in decoder\n",
        "    conv_shape = K.int_shape(cx)\n",
        "    \n",
        "    # Define sampling with reparameterization trick\n",
        "    def sample_z(args):\n",
        "      mu, sigma = args\n",
        "      batch     = K.shape(mu)[0]\n",
        "      dim       = K.int_shape(mu)[1]\n",
        "      eps       = K.random_normal(shape=(batch, dim))\n",
        "      return mu + K.exp(sigma / 2) * eps\n",
        "    \n",
        "    # Use reparameterization trick to ....??\n",
        "    z       = Lambda(sample_z, output_shape=(conf.latent_dim, ), name='z')([mu, sigma])\n",
        "    \n",
        "    # Instantiate encoder\n",
        "    encoder = Model(i, [mu, sigma, z], name='encoder')\n",
        "    encoder.summary()\n",
        "    \n",
        "    # =================\n",
        "    # Decoder\n",
        "    # =================\n",
        "    \n",
        "    # Definition\n",
        "    d_i   = Input(shape=(conf.latent_dim, ), name='decoder_input')\n",
        "    x     = Dense(conv_shape[1] * conv_shape[2] * conv_shape[3]* conv_shape[4], activation='relu')(d_i)\n",
        "    x     = BatchNormalization()(x)\n",
        "    x     = Reshape((conv_shape[1], conv_shape[2], conv_shape[3], conv_shape[4]))(x)\n",
        "    cx    = ConvLSTM2D(32, (3, 3), padding=\"same\", return_sequences=True)(x)\n",
        "    cx    = LayerNormalization()(cx)\n",
        "    cx    = ConvLSTM2D(64, (3, 3), padding=\"same\", return_sequences=True)(cx)\n",
        "    cx    = LayerNormalization()(cx)\n",
        "    cx    = TimeDistributed(Conv2DTranspose(64, (5, 5), strides=2, padding=\"same\"))(cx)\n",
        "    cx    = LayerNormalization()(cx)\n",
        "    cx    = TimeDistributed(Conv2DTranspose(128, (11, 11), strides=4, padding=\"same\"))(cx)\n",
        "    o     = TimeDistributed(Conv2D(1, (11, 11), activation=\"sigmoid\", padding=\"same\"), name='decoder_output')(cx)\n",
        "\n",
        "    # Instantiate decoder\n",
        "    decoder = Model(d_i, o, name='decoder')\n",
        "    decoder.summary()\n",
        "    \n",
        "    # =================\n",
        "    # VAE as a whole\n",
        "    # =================\n",
        "    \n",
        "    # Instantiate VAE\n",
        "    vae_outputs = decoder(encoder(i)[2])\n",
        "    vae         = Model(i, vae_outputs, name='vae')\n",
        "    vae.summary()\n",
        "\n",
        "    def euclidean_distance_loss(y_true, y_pred):\n",
        "\n",
        "        return K.sqrt(K.sum(K.square(y_pred - y_true), axis=-1))\n",
        "    # Define loss\n",
        "\n",
        "    \n",
        "    print(vae.summary())\n",
        "    # Compile VAE\n",
        "    vae.compile(optimizer='adam', loss=kl_reconstruction_loss)\n",
        "    !mkdir training_1\n",
        "    checkpoint_path = \"training_1/cp.ckpt\"\n",
        "    checkpoint_dir = dirname(checkpoint_path)\n",
        "\n",
        "    # Create a callback that saves the model's weights\n",
        "    cp_callback = ModelCheckpoint(filepath=checkpoint_path,save_weights_only=True,verbose=1)\n",
        "\n",
        "    # Train autoencoder\n",
        "    for i in range(conf.EPOCHS/5):\n",
        "        print(\"Starting epoch: \"+str((i*5)+1))\n",
        "        vae.fit(input_train, input_train, epochs = 5, batch_size = conf.BATCH_SIZE, shuffle=False, callbacks=[cp_callback])\n",
        "        vae.save(conf.MODEL_PATH+str((i*5)+1)+\".hdf5\")\n",
        "    return vae\n",
        "\n",
        "\n",
        "def retrain_model(epochs, j):\n",
        "    if conf.retrain == 1 and os.path.isfile(conf.MODEL_PATH+str(j)+\".hdf5\"):\n",
        "        vae=load_model(conf.MODEL_PATH+str(j)+\".hdf5\", custom_objects={'LayerNormalization': LayerNormalization})\n",
        "    \n",
        "    else:\n",
        "        return\n",
        "\n",
        "    # Compile VAE\n",
        "    vae.compile(optimizer='adam', loss=kl_reconstruction_loss)\n",
        "    !mkdir training_1\n",
        "    checkpoint_path = \"training_1/cp.ckpt\"\n",
        "    checkpoint_dir = dirname(checkpoint_path)\n",
        "\n",
        "    # Create a callback that saves the model's weights\n",
        "    cp_callback = ModelCheckpoint(filepath=checkpoint_path,save_weights_only=True,verbose=1)\n",
        "\n",
        "    # Train autoencoder\n",
        "    for i in range(j, conf.EPOCHS):\n",
        "        print(\"Starting epoch: \"+str(i+1))\n",
        "        vae.fit(input_train, input_train, epochs = 1, batch_size = conf.BATCH_SIZE, shuffle=False, callbacks=[cp_callback])\n",
        "        vae.save(conf.MODEL_PATH+str(i+1)+\".hdf5\")\n",
        "\n",
        "\n",
        "\n",
        "def TEST_get_training_set(conf):\n",
        "    print(\"Starting\")\n",
        "    clips =  get_training_set(conf)\n",
        "    print(\"Total clips: %d\" % len(clips))\n",
        "    for clip in clips:\n",
        "        print(\"Sequence size: %d\" % len(clip))\n",
        "        for image in clip:\n",
        "            plt.imshow(np.uint8(image))\n",
        "            plt.show()\n",
        "\n",
        "\n",
        "\n",
        "def get_single_test(conf):\n",
        "\n",
        "    sz = 0\n",
        "    for f in sorted(listdir(conf.SINGLE_TEST_PATH)):\n",
        "        if str(join(conf.SINGLE_TEST_PATH, f))[-3:] == \"tif\":\n",
        "          sz = sz +1\n",
        "    test = np.zeros(shape=(sz, 256, 256, 1))\n",
        "    cnt = 0\n",
        "    for f in sorted(listdir(conf.SINGLE_TEST_PATH)):\n",
        "        if str(join(conf.SINGLE_TEST_PATH, f))[-3:] == \"tif\":\n",
        "            img = Image.open(join(conf.SINGLE_TEST_PATH, f)).resize((256, 256))\n",
        "            img = np.array(img, dtype=np.float32) / 256.0\n",
        "            test[cnt, :, :, 0] = img\n",
        "            cnt = cnt + 1\n",
        "    return test\n",
        "\n",
        "\n",
        "\n",
        "def evaluate(conf):\n",
        "    model = get_model(conf)\n",
        "    print(\"got model\")\n",
        "    test = get_single_test(conf)\n",
        "    print(\"got test\")\n",
        "    sz = test.shape[0] - 10\n",
        "    sequences = np.zeros((sz, 10, 256, 256, 1))\n",
        "    # apply the sliding window technique to get the sequences\n",
        "    for i in range(0, sz):\n",
        "        clip = np.zeros((10, 256, 256, 1))\n",
        "        for j in range(0, 10):\n",
        "            clip[j] = test[i + j, :, :, :]\n",
        "        sequences[i] = clip\n",
        "\n",
        "    # get the reconstruction cost of all the sequences\n",
        "    reconstructed_sequences = model.predict(sequences,batch_size=4)\n",
        "    for j in range(0, sz):\n",
        "        clip_10 = reconstructed_sequences[j]\n",
        "       #img_prev = np.reshape(clip_10[0],(256,256))*256\n",
        "        for k in range(1,2):\n",
        "            img = np.reshape(clip_10[k],(256,256))*256\n",
        "            #optical_flow(img, img_prev)\n",
        "\n",
        "    #        img_prev = img\n",
        "            #print(img)\n",
        "            #print(\"end of array\\n\")\n",
        "            cv2_imshow(img)\n",
        "            cv2.waitKey(0)\n",
        "\n",
        "    sequences_reconstruction_cost = np.array([np.linalg.norm(np.subtract(sequences[i],reconstructed_sequences[i])) for i in range(0,sz)])\n",
        "    sa = (sequences_reconstruction_cost - np.min(sequences_reconstruction_cost)) / np.max(sequences_reconstruction_cost)\n",
        "    sr = 1.0 - sa\n",
        "    plt.plot(sr)\n",
        "    plt.ylabel('regularity score Sr(t)')\n",
        "    plt.xlabel('frame t')\n",
        "    plt.show()\n",
        "    #sr = sigmoid(sr)\n",
        "    # plot the regularity scores\n",
        "    #plt.plot(sr)\n",
        "    #plt.ylabel('regularity score Sr(t)')\n",
        "    #plt.xlabel('frame t')\n",
        "    #plt.show()\n",
        "\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWcxkk6UpbgL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "# Instantiate the parser\n",
        "#parser = argparse.ArgumentParser(description='Vidasa Extended -- Anomaly Detection System')\n",
        "\n",
        "\n",
        "#parser.add_argument('--data',type=str,\n",
        " #                   help='Data directory path')\n",
        "\n",
        "#args = parser.parse_args()\n",
        "model_path = \"/content/drive/My Drive/VAE/\"\n",
        "os.makedirs(model_path, exist_ok=True)\n",
        "conf = Config(data_dir=\"/content/drive/My Drive/UCSD_Anomaly_Dataset.v1p2/\", single_test_case=\"Test022\", model_path=model_path, retrain=1)\n",
        "\n",
        "evaluate(conf)\n",
        "#TEST_get_training_set(conf)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}