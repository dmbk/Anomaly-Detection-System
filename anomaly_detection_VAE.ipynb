{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "anomaly_detection_gist.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMFDGfEHxBo9Ei/gVUu80XB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dmbk/Anomaly-Detection-System/blob/master/anomaly_detection_VAE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6uQhe8VSqXpe",
        "colab_type": "code",
        "outputId": "a89070ea-0044-488c-deb3-c95abe17262a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "pip install keras-layer-normalization"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras-layer-normalization in /usr/local/lib/python3.6/dist-packages (0.14.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from keras-layer-normalization) (1.18.3)\n",
            "Requirement already satisfied: Keras in /usr/local/lib/python3.6/dist-packages (from keras-layer-normalization) (2.3.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-layer-normalization) (1.0.8)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras->keras-layer-normalization) (3.13)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-layer-normalization) (1.4.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras->keras-layer-normalization) (2.10.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-layer-normalization) (1.1.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-layer-normalization) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jn4T13Cd2Vwh",
        "colab_type": "code",
        "outputId": "4833cab8-3836-4da1-90e4-6ddebdc576bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HbKe11RPoo9K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import skimage\n",
        "import glob\n",
        "import imageio\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "from PIL import Image\n",
        "from os.path import join\n",
        "from os import listdir\n",
        "from os.path import isfile, join, isdir\n",
        "\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import keras\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.layers import Conv2DTranspose, ConvLSTM2D, BatchNormalization, TimeDistributed, Conv2D\n",
        "from keras.models import Sequential, load_model\n",
        "from keras_layer_normalization import LayerNormalization\n",
        "from keras.layers import Input, Flatten, Dense, Lambda, Reshape\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.models import Model\n",
        "from keras.datasets import mnist\n",
        "from keras.losses import binary_crossentropy\n",
        "from keras import backend as K\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import argparse\n",
        "import numpy as np\n",
        "from os.path import dirname\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import math\n",
        "class Config:\n",
        "    def __init__(self, data_dir, single_test_case, model_path, retrain=0):\n",
        "        self.DATASET_PATH = join(data_dir,\"UCSDped1/Train\")\n",
        "        self.TEST_DIR = join(data_dir,\"UCSDped1/Test/\")\n",
        "        self.SINGLE_TEST_PATH = join(self.TEST_DIR, single_test_case)\n",
        "        self.BATCH_SIZE = 4\n",
        "        self.EPOCHS = 5\n",
        "        self.MODEL_PATH = join(model_path,\"model\")\n",
        "        self.retrain = retrain\n",
        "        self.latent_dim = 128\n",
        "\n",
        "\n",
        "def get_clips_by_stride(stride, frames_list, sequence_size):\n",
        "    \"\"\" For data augmenting purposes.\n",
        "    Parameters\n",
        "    ----------\n",
        "    stride : int\n",
        "        The distance between two consecutive frames\n",
        "    frames_list : list\n",
        "        A list of sorted frames of shape 256 X 256\n",
        "    sequence_size: int\n",
        "        The size of the lstm sequence\n",
        "    Returns\n",
        "    -------\n",
        "    list\n",
        "        A list of clips , 10 frames each\n",
        "    \"\"\"\n",
        "    clips = []\n",
        "    sz = len(frames_list)\n",
        "    clip = np.zeros(shape=(sequence_size, 256, 256, 1))\n",
        "    cnt = 0\n",
        "    for start in range(0, stride):\n",
        "        for i in range(start, sz, stride):\n",
        "            clip[cnt, :, :, 0] = frames_list[i]\n",
        "            cnt = cnt + 1\n",
        "            if cnt == sequence_size:\n",
        "                clips.append(clip)\n",
        "                cnt = 0\n",
        "    return clips\n",
        "\n",
        "def get_training_set(conf):\n",
        "    \"\"\"\n",
        "    Returns\n",
        "    -------\n",
        "    list\n",
        "        A list of training sequences of shape (NUMBER_OF_SEQUENCES,SINGLE_SEQUENCE_SIZE,FRAME_WIDTH,FRAME_HEIGHT,1)\n",
        "    \"\"\"\n",
        "    clips = []\n",
        "    # loop over the training folders (Train000,Train001,..)\n",
        "    for f in sorted(listdir(conf.DATASET_PATH)):\n",
        "        directory_path = join(conf.DATASET_PATH, f)\n",
        "        if isdir(directory_path):\n",
        "            all_frames = []\n",
        "            # loop over all the images in the folder (0.tif,1.tif,..,199.tif)\n",
        "            for c in sorted(listdir(directory_path)):\n",
        "                img_path = join(directory_path, c)\n",
        "                if str(img_path)[-3:] == \"tif\":\n",
        "                    img = Image.open(img_path).resize((256, 256))\n",
        "\n",
        "                    img = np.array(img, dtype=np.float32) / 256.0\n",
        "                    all_frames.append(img)\n",
        "            # get the 10-frames sequences from the list of images after applying data augmentation\n",
        "            for stride in range(1, 3):\n",
        "                clips.extend(get_clips_by_stride(stride=stride, frames_list=all_frames, sequence_size=10))\n",
        "    return clips\n",
        "\n",
        "def kl_reconstruction_loss(true, pred):\n",
        "    # Reconstruction loss\n",
        "      #reconstruction_loss = binary_crossentropy(K.flatten(true), K.flatten(pred)) * 10 * 256 * 256\n",
        "      #reconstruction_loss = np.linalg.norm(np.subtract(true,pred))\\\n",
        "\n",
        "      reconstruction_loss = mse(K.flatten(true), K.flatten(pred)) * 10 * 256 * 256\n",
        "      #reconstruction_loss = euclidean_distance_loss(K.flatten(true), K.flatten(pred))\n",
        "      # KL divergence loss\n",
        "      kl_loss = 1 + sigma - K.square(mu) - K.exp(sigma)\n",
        "      kl_loss = K.sum(kl_loss, axis=-1)\n",
        "      kl_loss *= -0.5\n",
        "      # Total loss = 50% rec + 50% KL divergence loss\n",
        "      return K.mean(reconstruction_loss + kl_loss)\n",
        "\n",
        "def get_model(conf):\n",
        "    \"\"\"\n",
        "    Parameters\n",
        "    ----------\n",
        "    reload_model : bool\n",
        "        Load saved model or retrain it\n",
        "    \"\"\"\n",
        "    if conf.retrain == 1 and os.path.isfile(conf.MODEL_PATH):\n",
        "        vae=load_model(path, custom_objects={'LayerNormalization': LayerNormalization})\n",
        "        return vae\n",
        "    input_train = get_training_set(conf)\n",
        "    input_train = np.array(input_train)\n",
        "\n",
        "    validation_split = 0.2\n",
        "    verbosity = 1\n",
        "\n",
        "    # # =================\n",
        "    # # Encoder\n",
        "    # # =================\n",
        "    \n",
        "    # Definition\n",
        "    i       = Input(shape=(10, 256, 256, 1), name='encoder_input')\n",
        "    cx      = TimeDistributed(Conv2D(128, (11, 11), strides=4, padding=\"same\", activation='relu'))(i)\n",
        "    cx      = LayerNormalization()(cx)\n",
        "    cx      = TimeDistributed(Conv2D(64, (5, 5), strides=2, padding=\"same\", activation='relu'))(cx)\n",
        "    cx      = LayerNormalization()(cx)\n",
        "    cx      = ConvLSTM2D(64, (3, 3), padding=\"same\", return_sequences=True)(cx)\n",
        "    cx      = LayerNormalization()(cx)\n",
        "    cx      = ConvLSTM2D(32, (3, 3), padding=\"same\", return_sequences=True)(cx)\n",
        "    x       = Flatten()(cx)\n",
        "    x       = Dense(360, activation='relu')(x)\n",
        "    x       = BatchNormalization()(x)\n",
        "    mu      = Dense(conf.latent_dim, name='latent_mu')(x)\n",
        "    sigma   = Dense(conf.latent_dim, name='latent_sigma')(x)\n",
        "    \n",
        "    # Get Conv2D shape for Conv2DTranspose operation in decoder\n",
        "    conv_shape = K.int_shape(cx)\n",
        "    \n",
        "    # Define sampling with reparameterization trick\n",
        "    def sample_z(args):\n",
        "      mu, sigma = args\n",
        "      batch     = K.shape(mu)[0]\n",
        "      dim       = K.int_shape(mu)[1]\n",
        "      eps       = K.random_normal(shape=(batch, dim))\n",
        "      return mu + K.exp(sigma / 2) * eps\n",
        "    \n",
        "    # Use reparameterization trick to ....??\n",
        "    z       = Lambda(sample_z, output_shape=(conf.latent_dim, ), name='z')([mu, sigma])\n",
        "    \n",
        "    # Instantiate encoder\n",
        "    encoder = Model(i, [mu, sigma, z], name='encoder')\n",
        "    encoder.summary()\n",
        "    \n",
        "    # =================\n",
        "    # Decoder\n",
        "    # =================\n",
        "    \n",
        "    # Definition\n",
        "    d_i   = Input(shape=(conf.latent_dim, ), name='decoder_input')\n",
        "    x     = Dense(conv_shape[1] * conv_shape[2] * conv_shape[3]* conv_shape[4], activation='relu')(d_i)\n",
        "    x     = BatchNormalization()(x)\n",
        "    x     = Reshape((conv_shape[1], conv_shape[2], conv_shape[3], conv_shape[4]))(x)\n",
        "    cx    = ConvLSTM2D(32, (3, 3), padding=\"same\", return_sequences=True)(x)\n",
        "    cx    = LayerNormalization()(cx)\n",
        "    cx    = ConvLSTM2D(64, (3, 3), padding=\"same\", return_sequences=True)(cx)\n",
        "    cx    = LayerNormalization()(cx)\n",
        "    cx    = TimeDistributed(Conv2DTranspose(64, (5, 5), strides=2, padding=\"same\"))(cx)\n",
        "    cx    = LayerNormalization()(cx)\n",
        "    cx    = TimeDistributed(Conv2DTranspose(128, (11, 11), strides=4, padding=\"same\"))(cx)\n",
        "    o     = TimeDistributed(Conv2D(1, (11, 11), activation=\"sigmoid\", padding=\"same\"), name='decoder_output')(cx)\n",
        "\n",
        "    # Instantiate decoder\n",
        "    decoder = Model(d_i, o, name='decoder')\n",
        "    decoder.summary()\n",
        "    \n",
        "    # =================\n",
        "    # VAE as a whole\n",
        "    # =================\n",
        "    \n",
        "    # Instantiate VAE\n",
        "    vae_outputs = decoder(encoder(i)[2])\n",
        "    vae         = Model(i, vae_outputs, name='vae')\n",
        "    vae.summary()\n",
        "\n",
        "    def euclidean_distance_loss(y_true, y_pred):\n",
        "\n",
        "        return K.sqrt(K.sum(K.square(y_pred - y_true), axis=-1))\n",
        "    # Define loss\n",
        "\n",
        "    \n",
        "    print(vae.summary())\n",
        "    # Compile VAE\n",
        "    vae.compile(optimizer='adam', loss=kl_reconstruction_loss)\n",
        "    !mkdir training_1\n",
        "    checkpoint_path = \"training_1/cp.ckpt\"\n",
        "    checkpoint_dir = dirname(checkpoint_path)\n",
        "\n",
        "    # Create a callback that saves the model's weights\n",
        "    cp_callback = ModelCheckpoint(filepath=checkpoint_path,save_weights_only=True,verbose=1)\n",
        "\n",
        "    # Train autoencoder\n",
        "    for i in range(conf.EPOCHS/5):\n",
        "        print(\"Starting epoch: \"+str((i*5)+1))\n",
        "        vae.fit(input_train, input_train, epochs = 5, batch_size = conf.BATCH_SIZE, shuffle=False, callbacks=[cp_callback])\n",
        "        vae.save(conf.MODEL_PATH+str((i*5)+1)+\".hdf5\")\n",
        "    return vae\n",
        "\n",
        "\n",
        "def retrain_model(epochs, j)\n",
        "    if conf.retrain == 1 and os.path.isfile(conf.MODEL_PATH+str(j)+\".hdf5\"):\n",
        "        vae=load_model(conf.MODEL_PATH+str(j)+\".hdf5\", custom_objects={'LayerNormalization': LayerNormalization})\n",
        "    \n",
        "    else:\n",
        "        return\n",
        "\n",
        "    # Compile VAE\n",
        "    vae.compile(optimizer='adam', loss=kl_reconstruction_loss)\n",
        "    !mkdir training_1\n",
        "    checkpoint_path = \"training_1/cp.ckpt\"\n",
        "    checkpoint_dir = dirname(checkpoint_path)\n",
        "\n",
        "    # Create a callback that saves the model's weights\n",
        "    cp_callback = ModelCheckpoint(filepath=checkpoint_path,save_weights_only=True,verbose=1)\n",
        "\n",
        "    # Train autoencoder\n",
        "    for i in range(j, conf.EPOCHS):\n",
        "        print(\"Starting epoch: \"+str(i+1))\n",
        "        vae.fit(input_train, input_train, epochs = 1, batch_size = conf.BATCH_SIZE, shuffle=False, callbacks=[cp_callback])\n",
        "        vae.save(conf.MODEL_PATH+str(i+1)+\".hdf5\")\n",
        "\n",
        "\n",
        "\n",
        "def TEST_get_training_set(conf):\n",
        "    print(\"Starting\")\n",
        "    clips =  get_training_set(conf)\n",
        "    print(\"Total clips: %d\" % len(clips))\n",
        "    for clip in clips:\n",
        "        print(\"Sequence size: %d\" % len(clip))\n",
        "        for image in clip:\n",
        "            plt.imshow(np.uint8(image))\n",
        "            plt.show()\n",
        "\n",
        "\n",
        "\n",
        "def get_single_test(conf):\n",
        "\n",
        "    sz = 0\n",
        "    for f in sorted(listdir(conf.SINGLE_TEST_PATH)):\n",
        "        if str(join(conf.SINGLE_TEST_PATH, f))[-3:] == \"tif\":\n",
        "          sz = sz +1\n",
        "    test = np.zeros(shape=(sz, 256, 256, 1))\n",
        "    cnt = 0\n",
        "    for f in sorted(listdir(conf.SINGLE_TEST_PATH)):\n",
        "        if str(join(conf.SINGLE_TEST_PATH, f))[-3:] == \"tif\":\n",
        "            img = Image.open(join(conf.SINGLE_TEST_PATH, f)).resize((256, 256))\n",
        "            img = np.array(img, dtype=np.float32) / 256.0\n",
        "            test[cnt, :, :, 0] = img\n",
        "            cnt = cnt + 1\n",
        "    return test\n",
        "\n",
        "\n",
        "\n",
        "def evaluate(conf):\n",
        "    model = get_model(conf)\n",
        "    print(\"got model\")\n",
        "    test = get_single_test(conf)\n",
        "    print(\"got test\")\n",
        "    sz = test.shape[0] - 10\n",
        "    sequences = np.zeros((sz, 10, 256, 256, 1))\n",
        "    # apply the sliding window technique to get the sequences\n",
        "    for i in range(0, sz):\n",
        "        clip = np.zeros((10, 256, 256, 1))\n",
        "        for j in range(0, 10):\n",
        "            clip[j] = test[i + j, :, :, :]\n",
        "        sequences[i] = clip\n",
        "\n",
        "    # get the reconstruction cost of all the sequences\n",
        "    reconstructed_sequences = model.predict(sequences,batch_size=4)\n",
        "    for j in range(0, sz):\n",
        "        clip_10 = reconstructed_sequences[j]\n",
        "       #img_prev = np.reshape(clip_10[0],(256,256))*256\n",
        "        for k in range(1,2):\n",
        "            img = np.reshape(clip_10[k],(256,256))*256\n",
        "            #optical_flow(img, img_prev)\n",
        "\n",
        "    #        img_prev = img\n",
        "            #print(img)\n",
        "            #print(\"end of array\\n\")\n",
        "            cv2_imshow(img)\n",
        "            cv2.waitKey(0)\n",
        "\n",
        "    sequences_reconstruction_cost = np.array([np.linalg.norm(np.subtract(sequences[i],reconstructed_sequences[i])) for i in range(0,sz)])\n",
        "    sa = (sequences_reconstruction_cost - np.min(sequences_reconstruction_cost)) / np.max(sequences_reconstruction_cost)\n",
        "    sr = 1.0 - sa\n",
        "    plt.plot(sr)\n",
        "    plt.ylabel('regularity score Sr(t)')\n",
        "    plt.xlabel('frame t')\n",
        "    plt.show()\n",
        "    #sr = sigmoid(sr)\n",
        "    # plot the regularity scores\n",
        "    #plt.plot(sr)\n",
        "    #plt.ylabel('regularity score Sr(t)')\n",
        "    #plt.xlabel('frame t')\n",
        "    #plt.show()\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWcxkk6UpbgL",
        "colab_type": "code",
        "outputId": "10b4bad6-a5a8-4f15-9bec-1982fdba82c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "\n",
        "# Instantiate the parser\n",
        "#parser = argparse.ArgumentParser(description='Vidasa Extended -- Anomaly Detection System')\n",
        "\n",
        "\n",
        "#parser.add_argument('--data',type=str,\n",
        " #                   help='Data directory path')\n",
        "\n",
        "#args = parser.parse_args()\n",
        "model_path = \"/content/drive/My Drive/VAE/\"\n",
        "os.makedirs(model_path, exist_ok=True)\n",
        "conf = Config(data_dir=\"/content/drive/My Drive/UCSD_Anomaly_Dataset.v1p2/\", single_test_case=\"Test022\", model_path=model_path, retrain=1)\n",
        "\n",
        "evaluate(conf)\n",
        "#TEST_get_training_set(conf)\n",
        "\n",
        "\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"encoder\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "encoder_input (InputLayer)      (None, 10, 256, 256, 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_13 (TimeDistri (None, 10, 64, 64, 1 15616       encoder_input[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "layer_normalization_19 (LayerNo (None, 10, 64, 64, 1 256         time_distributed_13[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_14 (TimeDistri (None, 10, 32, 32, 6 204864      layer_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "layer_normalization_20 (LayerNo (None, 10, 32, 32, 6 128         time_distributed_14[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv_lst_m2d_13 (ConvLSTM2D)    (None, 10, 32, 32, 6 295168      layer_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "layer_normalization_21 (LayerNo (None, 10, 32, 32, 6 128         conv_lst_m2d_13[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv_lst_m2d_14 (ConvLSTM2D)    (None, 10, 32, 32, 3 110720      layer_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "flatten_4 (Flatten)             (None, 327680)       0           conv_lst_m2d_14[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dense_7 (Dense)                 (None, 20)           6553620     flatten_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 20)           80          dense_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "latent_mu (Dense)               (None, 5)            105         batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "latent_sigma (Dense)            (None, 5)            105         batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "z (Lambda)                      (None, 5)            0           latent_mu[0][0]                  \n",
            "                                                                 latent_sigma[0][0]               \n",
            "==================================================================================================\n",
            "Total params: 7,180,790\n",
            "Trainable params: 7,180,750\n",
            "Non-trainable params: 40\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"decoder\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "decoder_input (InputLayer)   (None, 5)                 0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 327680)            1966080   \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 327680)            1310720   \n",
            "_________________________________________________________________\n",
            "reshape_4 (Reshape)          (None, 10, 32, 32, 32)    0         \n",
            "_________________________________________________________________\n",
            "conv_lst_m2d_15 (ConvLSTM2D) (None, 10, 32, 32, 32)    73856     \n",
            "_________________________________________________________________\n",
            "layer_normalization_22 (Laye (None, 10, 32, 32, 32)    64        \n",
            "_________________________________________________________________\n",
            "conv_lst_m2d_16 (ConvLSTM2D) (None, 10, 32, 32, 64)    221440    \n",
            "_________________________________________________________________\n",
            "layer_normalization_23 (Laye (None, 10, 32, 32, 64)    128       \n",
            "_________________________________________________________________\n",
            "time_distributed_15 (TimeDis (None, 10, 64, 64, 64)    102464    \n",
            "_________________________________________________________________\n",
            "layer_normalization_24 (Laye (None, 10, 64, 64, 64)    128       \n",
            "_________________________________________________________________\n",
            "time_distributed_16 (TimeDis (None, 10, 256, 256, 128) 991360    \n",
            "_________________________________________________________________\n",
            "decoder_output (TimeDistribu (None, 10, 256, 256, 1)   15489     \n",
            "=================================================================\n",
            "Total params: 4,681,729\n",
            "Trainable params: 4,026,369\n",
            "Non-trainable params: 655,360\n",
            "_________________________________________________________________\n",
            "Model: \"vae\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "encoder_input (InputLayer)   (None, 10, 256, 256, 1)   0         \n",
            "_________________________________________________________________\n",
            "encoder (Model)              [(None, 5), (None, 5), (N 7180790   \n",
            "_________________________________________________________________\n",
            "decoder (Model)              (None, 10, 256, 256, 1)   4681729   \n",
            "=================================================================\n",
            "Total params: 11,862,519\n",
            "Trainable params: 11,207,119\n",
            "Non-trainable params: 655,400\n",
            "_________________________________________________________________\n",
            "Model: \"vae\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "encoder_input (InputLayer)   (None, 10, 256, 256, 1)   0         \n",
            "_________________________________________________________________\n",
            "encoder (Model)              [(None, 5), (None, 5), (N 7180790   \n",
            "_________________________________________________________________\n",
            "decoder (Model)              (None, 10, 256, 256, 1)   4681729   \n",
            "=================================================================\n",
            "Total params: 11,862,519\n",
            "Trainable params: 11,207,119\n",
            "Non-trainable params: 655,400\n",
            "_________________________________________________________________\n",
            "None\n",
            "mkdir: cannot create directory ‘training_1’: File exists\n",
            "Train on 1088 samples, validate on 272 samples\n",
            "Epoch 1/5\n",
            "1088/1088 [==============================] - 363s 333ms/step - loss: 146.7086 - val_loss: inf\n",
            "\n",
            "Epoch 00001: saving model to training_1/cp.ckpt\n",
            "Epoch 2/5\n",
            "1088/1088 [==============================] - 356s 327ms/step - loss: 117.7496 - val_loss: inf\n",
            "\n",
            "Epoch 00002: saving model to training_1/cp.ckpt\n",
            "Epoch 3/5\n",
            "1088/1088 [==============================] - 356s 327ms/step - loss: 111.5073 - val_loss: inf\n",
            "\n",
            "Epoch 00003: saving model to training_1/cp.ckpt\n",
            "Epoch 4/5\n",
            "1088/1088 [==============================] - 357s 328ms/step - loss: 107.6957 - val_loss: inf\n",
            "\n",
            "Epoch 00004: saving model to training_1/cp.ckpt\n",
            "Epoch 5/5\n",
            "1088/1088 [==============================] - 356s 328ms/step - loss: 106.4384 - val_loss: inf\n",
            "\n",
            "Epoch 00005: saving model to training_1/cp.ckpt\n",
            "got model\n",
            "got test\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQAAAAEACAAAAAB5Gfe6AAAAVElEQVR4nO3BAQEAAACAkP6v7ggKAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGAEPAAFN9soGAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=256x256 at 0x7F491E409DD8>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-8f078096d994>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mconf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"/content/drive/My Drive/UCSD_Anomaly_Dataset.v1p2/\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msingle_test_case\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Test022\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;31m#TEST_get_training_set(conf)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-2481c5e2b979>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(conf)\u001b[0m\n\u001b[1;32m    275\u001b[0m             \u001b[0;31m#print(\"end of array\\n\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m             \u001b[0mcv2_imshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m             \u001b[0mv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[0msequences_reconstruction_cost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubtract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreconstructed_sequences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'v2' is not defined"
          ]
        }
      ]
    }
  ]
}