{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ConvLSTM_ADAE_sigmoid.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dmbk/Anomaly-Detection-System/blob/master/ConvLSTM_ADAE_sigmoid.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZeDOtMkwIqL0",
        "colab_type": "code",
        "outputId": "2e02a3e1-6a1e-4e5b-e3be-db057725faed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        }
      },
      "source": [
        "!pip install imageio\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: imageio in /usr/local/lib/python3.6/dist-packages (2.4.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from imageio) (7.0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from imageio) (1.18.2)\n",
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1qK4WayIRWG",
        "colab_type": "code",
        "outputId": "9de5dc7d-b4c6-44ba-80a1-68327f682f24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "import tensorflow as tf\n",
        "import skimage\n",
        "import glob\n",
        "import imageio\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "from PIL import Image\n",
        "from tensorflow.keras import layers\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "from IPython import display\n",
        "\n",
        "from os.path import join\n",
        "from os import listdir\n",
        "from os.path import isfile, join, isdir\n",
        "\n",
        "#import keras\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.layers import Input, GaussianNoise, Reshape, LeakyReLU, Conv2DTranspose, Conv3DTranspose, ConvLSTM2D, BatchNormalization, LayerNormalization, TimeDistributed, Conv2D, Conv3D, ZeroPadding3D, MaxPooling2D, MaxPooling3D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.models import Sequential, load_model, Model\n",
        "from keras.optimizers import RMSprop\n",
        "import matplotlib.pyplot as plt\n",
        "import argparse\n",
        "from os.path import dirname\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\t\n",
        "from keras import backend\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.backend as K\n",
        "keras = tf.keras\n",
        "\n",
        "from keras.constraints import Constraint\n",
        "tf.keras.backend.set_floatx('float32')\n",
        "import shutil\n",
        "from matplotlib import pyplot"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27gwZwBqIxav",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Config:\n",
        "    def __init__(self, data_dir_, cwdir_name_, data_set):\n",
        "        self.data_set_name = data_set\n",
        "        self.data_dir = data_dir_\n",
        "        self.data_set_dir = join(self.data_dir, data_set)\n",
        "        self.cwdir_name = cwdir_name_\n",
        "        self.cwdir = join(self.data_dir,self.cwdir_name)\n",
        "        self.run_data = join(self.cwdir, \"training_gan\")\n",
        "        self.image_dir = join(self.run_data,self.data_set_name,\"Test/\")\n",
        "        if not os.path.exists(self.cwdir):\n",
        "            os.mkdir(self.cwdir)\n",
        "            os.mkdir(self.run_data)\n",
        "    \n",
        "        if not os.path.exists(self.run_data):\n",
        "            #shutil.rmtree(self.run_data)\n",
        "            os.mkdir(self.run_data)\n",
        "            os.makedirs(self.image_dir, exist_ok=True)\n",
        "\n",
        "        self.DATASET_PATH = join(self.data_set_dir,\"Train/\")\n",
        "        self.TEST_DIR = join(self.data_set_dir,\"Test/\")\n",
        "        self.BATCH_SIZE = 4\n",
        "        self.EPOCHS = 25\n",
        "        self.GEN_MODEL_PATH = join(self.cwdir,\"model_gen_Conv2DLSTM_GAN.hdf5\")\n",
        "        self.DIS_MODEL_PATH = join(self.cwdir,\"model_dis_Conv2DLSTM_GAN.hdf5\")\n",
        "        self.GAN_MODEL_PATH = join(self.cwdir,\"model_combined_Conv2DLSTM_GAN.hdf5\")\n",
        "        \n",
        "        self.dim1 = 10\n",
        "        self.dim2 = 256\n",
        "        self.dim3 = 256\n",
        "        self.dim4 = 1\n",
        "        self.n_critic = 1\n",
        "        self.r_alpha = 0.2\n",
        "\n",
        "    def reconfig(self, new_name, batch_size = 4, epochs = 5):\n",
        "        self.cwdir_name = new_name\n",
        "        self.cwdir = join(self.data_dir, self.cwdir_name)\n",
        "        self.run_data = join(self.cwdir, \"training_gan\")\n",
        "        self.image_dir = join(self.run_data,self.data_set_name,\"Test/\")\n",
        "        if not os.path.exists(self.cwdir):\n",
        "            os.mkdir(self.cwdir)\n",
        "            os.mkdir(self.run_data)\n",
        "    \n",
        "        if os.path.exists(self.run_data):\n",
        "            shutil.rmtree(self.run_data)\n",
        "            os.mkdir(self.run_data)\n",
        "            os.makedirs(self.image_dir, exist_ok=True)\n",
        "\n",
        "        self.BATCH_SIZE = batch_size\n",
        "        self.EPOCHS = epochs\n",
        "        self.GEN_MODEL_PATH = join(self.cwdir,\"model_gen_Conv2DLSTM_GAN.hdf5\")\n",
        "        self.DIS_MODEL_PATH = join(self.cwdir,\"model_dis_Conv2DLSTM_GAN.hdf5\")\n",
        "        self.GAN_MODEL_PATH = join(self.cwdir,\"model_combined_Conv2DLSTM_GAN.hdf5\")\n",
        "\n",
        "\n",
        "class ModelContainer:\n",
        "    def __init__(self, y0, y1, y2):\n",
        "        self.generator = y0\n",
        "        self.discriminator = y1\n",
        "        self.gan = y2\n",
        " \n",
        " # clip model weights to a given hypercube\n",
        "class ClipConstraint(Constraint):\n",
        "\t# set clip value when initialized\n",
        "\tdef __init__(self, clip_value):\n",
        "\t\tself.clip_value = clip_value\n",
        "\n",
        "\t# clip model weights to hypercube\n",
        "\tdef __call__(self, weights):\n",
        "\t\treturn backend.clip(weights, -self.clip_value, self.clip_value)\n",
        "\n",
        "\t# get the config\n",
        "\tdef get_config(self):\n",
        "\t\treturn {'clip_value': self.clip_value}\n",
        " \n",
        "\n",
        "conf = Config(data_dir_=\"/content/drive/My Drive/\", cwdir_name_=\"Conv2DLSTM_ADAE\", data_set=\"UCSD_Anomaly_Dataset.v1p2/UCSDped1/\") \n",
        "physical_devices = tf.config.list_physical_devices('GPU') \n",
        "try: \n",
        "  tf.config.experimental.set_memory_growth(physical_devices[0], True) \n",
        "except: \n",
        "  # Invalid device or cannot modify virtual devices once initialized. \n",
        "  pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5IyRNft5JKae",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_clips_by_stride(stride, frames_list, sequence_size):\n",
        "\n",
        "    clips = []\n",
        "    sz = len(frames_list)\n",
        "    clip = np.zeros(shape=(sequence_size, 256, 256, 1))\n",
        "    cnt = 0\n",
        "    for start in range(0, stride):\n",
        "        for i in range(start, sz, stride):\n",
        "            clip[cnt, :, :, 0] = frames_list[i]\n",
        "            cnt = cnt + 1\n",
        "            if cnt == sequence_size:\n",
        "                clips.append(clip)\n",
        "                cnt = 0\n",
        "    return clips\n",
        "\n",
        "def get_clips_list(seq_size):\n",
        "\n",
        "    clips = []\n",
        "    # loop over the training folders (Train000,Train001,..)\n",
        "    for f in sorted(listdir(conf.DATASET_PATH)):\n",
        "        directory_path = join(conf.DATASET_PATH, f)\n",
        "        if isdir(directory_path):\n",
        "            all_frames = []\n",
        "            # loop over all the images in the folder (0.tif,1.tif,..,199.tif)\n",
        "            for c in sorted(listdir(directory_path)):\n",
        "                img_path = join(directory_path, c)\n",
        "                if str(img_path)[-3:] == \"tif\":\n",
        "                    img = Image.open(img_path).resize((256, 256))\n",
        "                    #img = np.array(img, dtype=np.float32)\n",
        "                    #img = (img - 127.5)/127.5\n",
        "                    #img = (2*(img - np.amin(img))/(np.amax(img) - np.amin(img)))-1\n",
        "                    img = np.array(img, dtype=np.float32) / 256.0\n",
        "                    all_frames.append(img)\n",
        "            # get the 32-frames sequences from the list of images after applying data augmentation\n",
        "            for stride in range(1, 3):\n",
        "                clips.extend(get_clips_by_stride(stride=stride, frames_list=all_frames, sequence_size=seq_size))\n",
        "    return clips\n",
        "\n",
        "\n",
        "def get_single_test(single_test_path, sz):\n",
        "    test = np.zeros(shape=(sz, conf.dim2, conf.dim3, conf.dim4))\n",
        "    cnt = 0\n",
        "    for f in sorted(listdir(single_test_path)):\n",
        "        if str(join(single_test_path, f))[-3:] == \"tif\":\n",
        "            img = Image.open(join(single_test_path, f)).resize((conf.dim2, conf.dim3))\n",
        "            #cv2_imshow(np.array(img,dtype=np.float32))\n",
        "            #cv2.waitKey(0)\n",
        "            img = np.array(img, dtype=np.float32) / 256\n",
        "            test[cnt, :, :, 0] = img\n",
        "            cnt = cnt + 1\n",
        "    return test\n",
        "\n",
        "def get_test_sequences(test_case_dir, sz):\n",
        "    test = get_single_test(join(conf.TEST_DIR,test_case_dir), sz)\n",
        "    print(\"Test case loaded\")\n",
        "    sz = test.shape[0] - conf.dim1\n",
        "    sequences = np.zeros((sz, conf.dim1, conf.dim2, conf.dim3, conf.dim4))\n",
        "    # apply the sliding window technique to get the sequences\n",
        "    for i in range(0, sz):\n",
        "        clip = np.zeros((conf.dim1, conf.dim2, conf.dim3, conf.dim4))\n",
        "        for j in range(0, conf.dim1):\n",
        "            clip[j] = test[i + j, :, :, :]\n",
        "        sequences[i] = clip\n",
        "    return sequences\n",
        "\n",
        "def evaluate(sequences, model, test_case_dir, gen_only):\n",
        "\n",
        "    # get the reconstruction cost of all the sequences\n",
        "    (reconstructed_sequences, reconstructed_sequences_2) = model.predict(sequences,batch_size=conf.BATCH_SIZE)\n",
        "\n",
        "    sz = sequences.shape[0]\n",
        "    if gen_only == 1:\n",
        "        os.makedirs(join(conf.image_dir,test_case_dir), exist_ok=True)\n",
        "        for i in range(0, sz):\n",
        "            #cv2_imshow(np.reshape(reconstructed_sequences[i][2],(256, 256))*256)\n",
        "            if i < 10:\n",
        "                img_num = \"00\"+str(i)\n",
        "            elif i < 100:\n",
        "                img_num = \"0\"+str(i)\n",
        "            \n",
        "            cv2.imwrite(join(conf.image_dir, test_case_dir,\"gen_\"+img_num+\".jpg\"), np.reshape(reconstructed_sequences[i][6],(256, 256))*256.0)\n",
        "\n",
        "            cv2.imwrite(join(conf.image_dir, test_case_dir,\"dis_\"+img_num+\".jpg\"), np.reshape(reconstructed_sequences_2[i][6],(256, 256))*256.0)\n",
        "            #cv2.waitKey()\n",
        "            #print((np.reshape(reconstructed_sequences_2[i][6],(256, 256))))\n",
        "            #v2_imshow(np.reshape(reconstructed_sequences_2[i][2],(256, 256))*256)\n",
        "            #cv2.waitKey()\n",
        "\n",
        "        #reconstruction_shape = (sz,10, 256, 256, 1)\n",
        "    sequences_reconstruction_cost = np.array([np.linalg.norm(np.subtract(sequences[i],reconstructed_sequences[i])) for i in range(0,sz)])\n",
        "    sa = (sequences_reconstruction_cost - np.min(sequences_reconstruction_cost)) / np.max(sequences_reconstruction_cost)\n",
        "    sr = 1.0 - sa\n",
        "\n",
        "    #print(sr.shape())\n",
        "\n",
        "    plt.plot(sr)\n",
        "    plt.ylabel('regularity score Sr(t)')\n",
        "    plt.xlabel('frame t')\n",
        "    plt.show()\n",
        "\n",
        "    sequences_reconstruction_cost_2 = np.array([np.linalg.norm(np.subtract(sequences[i],reconstructed_sequences_2[i])) for i in range(0,sz)])\n",
        "    sa_2 = (sequences_reconstruction_cost_2 - np.min(sequences_reconstruction_cost_2)) / np.max(sequences_reconstruction_cost_2)\n",
        "    sr_2 = 1.0 - sa_2\n",
        "    \n",
        "    #print(sr.shape())\n",
        "\n",
        "    plt.plot(sr_2)\n",
        "    plt.ylabel('regularity score Sr(t)')\n",
        "    plt.xlabel('frame t')\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QCP4CpApLacO",
        "colab_type": "code",
        "outputId": "253a292f-2ca4-454f-8760-ddd0857f2581",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "def get_generator():\n",
        "    #if reload_model == True and os.path.isfile(conf.GEN_MODEL_PATH):\n",
        "    #    model=load_model(conf.GEN_MODEL_PATH,custom_objects={'LayerNormalization': LayerNormalization})\n",
        "    #    return model, True\n",
        "\n",
        "    init = tf.keras.initializers.RandomNormal(stddev=0.02)\n",
        "    \n",
        "    print(\"Loading generator model\")\n",
        "    model = Sequential()\n",
        "    #model.add(GaussianNoise(0.01, input_shape=(conf.dim1, conf.dim2, conf.dim3, conf.dim4)))\n",
        "    #model.add(TimeDistributed(Conv2D(128, (11, 11), strides=4, activation=\"relu\", kernel_initializer=init, padding=\"same\"), batch_input_shape=(None, conf.dim1, conf.dim2, conf.dim3, conf.dim4)))   \n",
        "    model.add(TimeDistributed(Conv2D(128, (11, 11), strides=4, activation=\"relu\", kernel_initializer=init, padding=\"same\"), batch_input_shape=(None, conf.dim1, conf.dim2, conf.dim3, conf.dim4)))\n",
        "    model.add(LayerNormalization())\n",
        "    model.add(TimeDistributed(Conv2D(64, (5, 5), strides=2, activation=\"relu\", kernel_initializer=init, padding=\"same\")))\n",
        "    model.add(LayerNormalization())\n",
        "\n",
        "    # # # # #\n",
        "    model.add(ConvLSTM2D(64, (3, 3), kernel_initializer=init, padding=\"same\", return_sequences=True))\n",
        "    model.add(LayerNormalization())\n",
        "    model.add(ConvLSTM2D(32, (3, 3), kernel_initializer=init, padding=\"same\", return_sequences=True))\n",
        "    model.add(LayerNormalization())\n",
        "    model.add(ConvLSTM2D(64, (3, 3), kernel_initializer=init, padding=\"same\", return_sequences=True))\n",
        "    model.add(LayerNormalization())\n",
        "    # # # # #\n",
        "\n",
        "    model.add(TimeDistributed(Conv2DTranspose(64, (5, 5), strides=2, activation=\"relu\", kernel_initializer=init, padding=\"same\")))\n",
        "    model.add(LayerNormalization())\n",
        "    model.add(TimeDistributed(Conv2DTranspose(128, (11, 11), strides=4, activation=\"relu\", kernel_initializer=init, padding=\"same\")))\n",
        "    model.add(LayerNormalization())\n",
        "    model.add(TimeDistributed(Conv2D(1, (11, 11), activation=\"sigmoid\", kernel_initializer=init,  padding=\"same\")))\n",
        "\n",
        "    model.summary(line_length=150)\n",
        "    return model\n",
        "\n",
        "\n",
        "def get_discriminator():\n",
        "    init = tf.keras.initializers.RandomNormal(stddev=0.02)\n",
        "    const = ClipConstraint(0.01)\n",
        "    print(\"Loading discriminator model\")\n",
        "    model = Sequential()\n",
        "    model.add(GaussianNoise(0.01, input_shape=(conf.dim1, conf.dim2, conf.dim3, conf.dim4)))\n",
        "    #model.add(TimeDistributed(Conv2D(128, (11, 11), strides=4, activation=\"relu\", kernel_initializer=init, padding=\"same\"), batch_input_shape=(None, conf.dim1, conf.dim2, conf.dim3, conf.dim4)))   \n",
        "    model.add(TimeDistributed(Conv2D(128, (11, 11), strides=4, activation=\"relu\", kernel_initializer=init, kernel_constraint=const, padding=\"same\"), batch_input_shape=(None, conf.dim1, conf.dim2, conf.dim3, conf.dim4)))\n",
        "    model.add(LayerNormalization())\n",
        "    model.add(TimeDistributed(Conv2D(64, (5, 5), strides=2, activation=\"relu\", kernel_initializer=init, kernel_constraint=const, padding=\"same\")))\n",
        "    model.add(LayerNormalization())\n",
        "    #model.add(TimeDistributed(Conv2D(64, (3, 3), strides=1, activation=\"relu\", kernel_initializer=init, padding=\"same\")))\n",
        "    #model.add(LayerNormalization())\n",
        "    # # # # #\n",
        "\n",
        "    #model.add(TimeDistributed(Conv2D(16, (3, 3), strides=1, activation=\"relu\", kernel_initializer=init, kernel_constraint=const, padding=\"same\")))\n",
        "    #model.add(LayerNormalization())\n",
        "    #model.add(TimeDistributed(Conv2DTranspose(16, (3,3), strides=1, activation=\"relu\", kernel_initializer=init, padding=\"same\")))\n",
        "    #model.add(LayerNormalization())\n",
        "    model.add(ConvLSTM2D(64, (3, 3), kernel_initializer=init, kernel_constraint=const, padding=\"same\", return_sequences=True))\n",
        "    model.add(LayerNormalization())\n",
        "    model.add(ConvLSTM2D(32, (3, 3), kernel_initializer=init, kernel_constraint=const, padding=\"same\", return_sequences=True))\n",
        "    model.add(LayerNormalization())\n",
        "    model.add(ConvLSTM2D(64, (3, 3), kernel_initializer=init, kernel_constraint=const, padding=\"same\", return_sequences=True))\n",
        "    model.add(LayerNormalization())\n",
        "    # # # # #\n",
        "\n",
        "    #model.add(TimeDistributed(Conv2DTranspose(64, (3, 3), strides=1, activation=\"relu\", kernel_initializer=init, padding=\"same\")))\n",
        "    #model.add(LayerNormalization())\n",
        "    model.add(TimeDistributed(Conv2DTranspose(64, (5, 5), strides=2, activation=\"relu\", kernel_initializer=init, padding=\"same\")))\n",
        "    model.add(LayerNormalization())\n",
        "    model.add(TimeDistributed(Conv2DTranspose(128, (11, 11), strides=4, activation=\"relu\", kernel_initializer=init, padding=\"same\")))\n",
        "    model.add(LayerNormalization())\n",
        "    model.add(TimeDistributed(Conv2D(1, (11, 11), activation=\"sigmoid\", kernel_initializer=init, padding=\"same\")))\n",
        "\n",
        "    model.summary(line_length=150)\n",
        "    return model\n",
        "\n",
        "\n",
        "def build_model(model, image_dims):\n",
        "    input_img = Input(shape=image_dims)\n",
        "    output = model(input_img)\n",
        "    return Model(input_img,output)\n",
        "\n",
        "\n",
        "\n",
        "get_generator()\n",
        "get_discriminator()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading generator model\n",
            "Model: \"sequential\"\n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "Layer (type)                                                       Output Shape                                                Param #                \n",
            "======================================================================================================================================================\n",
            "time_distributed (TimeDistributed)                                 (None, 10, 64, 64, 128)                                     15616                  \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "layer_normalization (LayerNormalization)                           (None, 10, 64, 64, 128)                                     256                    \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "time_distributed_1 (TimeDistributed)                               (None, 10, 32, 32, 64)                                      204864                 \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "layer_normalization_1 (LayerNormalization)                         (None, 10, 32, 32, 64)                                      128                    \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "conv_lst_m2d (ConvLSTM2D)                                          (None, 10, 32, 32, 64)                                      295168                 \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "layer_normalization_2 (LayerNormalization)                         (None, 10, 32, 32, 64)                                      128                    \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "conv_lst_m2d_1 (ConvLSTM2D)                                        (None, 10, 32, 32, 32)                                      110720                 \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "layer_normalization_3 (LayerNormalization)                         (None, 10, 32, 32, 32)                                      64                     \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "conv_lst_m2d_2 (ConvLSTM2D)                                        (None, 10, 32, 32, 64)                                      221440                 \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "layer_normalization_4 (LayerNormalization)                         (None, 10, 32, 32, 64)                                      128                    \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "time_distributed_2 (TimeDistributed)                               (None, 10, 64, 64, 64)                                      102464                 \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "layer_normalization_5 (LayerNormalization)                         (None, 10, 64, 64, 64)                                      128                    \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "time_distributed_3 (TimeDistributed)                               (None, 10, 256, 256, 128)                                   991360                 \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "layer_normalization_6 (LayerNormalization)                         (None, 10, 256, 256, 128)                                   256                    \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "time_distributed_4 (TimeDistributed)                               (None, 10, 256, 256, 1)                                     15489                  \n",
            "======================================================================================================================================================\n",
            "Total params: 1,958,209\n",
            "Trainable params: 1,958,209\n",
            "Non-trainable params: 0\n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "Loading discriminator model\n",
            "Model: \"sequential_1\"\n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "Layer (type)                                                       Output Shape                                                Param #                \n",
            "======================================================================================================================================================\n",
            "gaussian_noise (GaussianNoise)                                     (None, 10, 256, 256, 1)                                     0                      \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "time_distributed_5 (TimeDistributed)                               (None, 10, 64, 64, 128)                                     15616                  \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "layer_normalization_7 (LayerNormalization)                         (None, 10, 64, 64, 128)                                     256                    \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "time_distributed_6 (TimeDistributed)                               (None, 10, 32, 32, 64)                                      204864                 \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "layer_normalization_8 (LayerNormalization)                         (None, 10, 32, 32, 64)                                      128                    \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "conv_lst_m2d_3 (ConvLSTM2D)                                        (None, 10, 32, 32, 64)                                      295168                 \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "layer_normalization_9 (LayerNormalization)                         (None, 10, 32, 32, 64)                                      128                    \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "conv_lst_m2d_4 (ConvLSTM2D)                                        (None, 10, 32, 32, 32)                                      110720                 \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "layer_normalization_10 (LayerNormalization)                        (None, 10, 32, 32, 32)                                      64                     \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "conv_lst_m2d_5 (ConvLSTM2D)                                        (None, 10, 32, 32, 64)                                      221440                 \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "layer_normalization_11 (LayerNormalization)                        (None, 10, 32, 32, 64)                                      128                    \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "time_distributed_7 (TimeDistributed)                               (None, 10, 64, 64, 64)                                      102464                 \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "layer_normalization_12 (LayerNormalization)                        (None, 10, 64, 64, 64)                                      128                    \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "time_distributed_8 (TimeDistributed)                               (None, 10, 256, 256, 128)                                   991360                 \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "layer_normalization_13 (LayerNormalization)                        (None, 10, 256, 256, 128)                                   256                    \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "time_distributed_9 (TimeDistributed)                               (None, 10, 256, 256, 1)                                     15489                  \n",
            "======================================================================================================================================================\n",
            "Total params: 1,958,209\n",
            "Trainable params: 1,958,209\n",
            "Non-trainable params: 0\n",
            "______________________________________________________________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.engine.sequential.Sequential at 0x7f8ba2321898>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1H9pUAm46jls",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create a line plot of loss for the gan and save to file\n",
        "def plot_history(d1_hist, g_hist, image_name):\n",
        "\t# plot history\n",
        "    #pyplot.plot(d1_hist, label='disc_real')\n",
        "\t#pyplot.plot(d2_hist, label='disc_fake')\n",
        "    pyplot.plot(d1_hist, label='disc_loss')\n",
        "    pyplot.plot(g_hist, label='gen')\n",
        "    pyplot.legend()\n",
        "    pyplot.savefig(image_name)\n",
        "    pyplot.close()\n",
        " \n",
        "def diff_norm(disc_x, disc_y):\n",
        "    return tf.norm(tf.math.subtract(disc_x, disc_y))\n",
        "\n",
        "def compile_gan(generator, discriminator):\n",
        "    image_dims = [conf.dim1, conf.dim2, conf.dim3, conf.dim4]\n",
        "    optimizer_1 = tf.keras.optimizers.Adam(lr=1e-7, decay=1e-5, epsilon=1e-6, beta_1=0.5)\n",
        "    built_dis = build_model(discriminator, image_dims)\n",
        "    disc_loss = diff_loss(conf.BATCH_SIZE)\n",
        "    #disc_loss = HistoricalAvgLoss(built_dis, conf.BATCH_SIZE).diff_loss\n",
        "    built_dis.compile(optimizer=optimizer_1, loss=disc_loss)\n",
        "\n",
        "    built_gen = build_model(generator, image_dims)\n",
        "    img = Input(shape=image_dims, dtype=tf.dtypes.float32)\n",
        "    #gn_layer = GaussianNoise(0.1)(img)\n",
        "    \n",
        "    reconstructed_img = built_gen(img)\n",
        "    \n",
        "    built_dis.trainable = False\n",
        "    validity = built_dis(reconstructed_img)\n",
        "    optimizer = tf.keras.optimizers.Adam(lr=1e-4, decay=1e-5, epsilon=1e-6, beta_1=0.5)\n",
        "    gan_model = Model(img, [reconstructed_img, validity])\n",
        "\n",
        "    comb_loss = combined_loss()\n",
        "    gan_model.compile(loss=[comb_loss, comb_loss],\n",
        "    loss_weights=[0.4, 1],\n",
        "    optimizer=optimizer)\n",
        "\n",
        "    return ModelContainer(built_gen, built_dis, gan_model)\n",
        "\n",
        "class HistoricalAvgLoss(object):\n",
        "  def __init__(self, model, batch_size):\n",
        "    # create tensors (initialized to zero) to hold the previous value of the\n",
        "    # weights\n",
        "    self.model = model\n",
        "    self.batch_size = batch_size\n",
        "    self.prev_weights = []\n",
        "    for w in model.get_weights():\n",
        "      self.prev_weights.append(tf.Variable(np.zeros(w.shape)))\n",
        "\n",
        "  def loss(self, y_true, y_pred):\n",
        "    err = tf.keras.losses.MSE(y_true, y_pred)\n",
        "    werr = [tf.math.reduce_mean(tf.math.abs(c - p)) for c, p in zip(self.model.get_weights(), self.prev_weights)]\n",
        "    self.prev_weights = tf.keras.backend.in_train_phase(\n",
        "        [tf.keras.backend.update(p, c) for c, p in zip(self.model.get_weights(), self.prev_weights)],\n",
        "        self.prev_weights\n",
        "    )\n",
        "    return tf.keras.backend.in_train_phase(err + tf.keras.backend.sum(werr), err)\n",
        "  def diff_loss(self, disc_true, disc_predicted):\n",
        "    loss_fake = self.loss(disc_true[:self.batch_size], disc_predicted[:self.batch_size])\n",
        "    loss_real = self.loss(disc_true[self.batch_size:], disc_predicted[self.batch_size:])\n",
        "    return loss_real - loss_fake\n",
        "\n",
        "def combined_loss():\n",
        "\n",
        "    def disc_mse_func(disc_true, disc_predicted):\n",
        "\n",
        "        #img_pred = tf.math.l2_normalize(disc_predicted)\n",
        "        loss = tf.keras.losses.MSE(disc_true, disc_predicted)\n",
        "        #mse = tf.norm(tf.math.subtract(disc_true, disc_predicted))\n",
        "        #loss = tf.math.sqrt(tf.math.reduce_sum(tf.math.abs(tf.math.subtract(disc_true, disc_predicted))))\n",
        "        #loss = (tf.math.reduce_sum(tf.math.subtract(disc_true, disc_predicted)))\n",
        "        return loss\n",
        "    return disc_mse_func\n",
        "\n",
        "def diff_loss(batch_size):\n",
        "\n",
        "    def diff_func(disc_true, disc_predicted):\n",
        "\n",
        "        loss_fake = tf.keras.losses.MSE(disc_true[:batch_size], disc_predicted[:batch_size])\n",
        "        #loss_fake = tf.math.sqrt(tf.math.reduce_sum(tf.math.abs(tf.math.subtract(disc_true[:batch_size], disc_predicted[:batch_size]))))\n",
        "        #loss_fake = (tf.math.reduce_sum(tf.math.subtract(disc_true[:batch_size], disc_predicted[:batch_size])))\n",
        "        #print(f'\\t\\tDiscriminator mse_real: {mse_real}\\n')\n",
        "\n",
        "        loss_real = tf.keras.losses.MSE(disc_true[batch_size:], disc_predicted[batch_size:])\n",
        "        #loss_real = tf.math.sqrt(tf.math.reduce_sum(tf.math.abs(tf.math.subtract(disc_true[batch_size:], disc_predicted[batch_size:]))))\n",
        "        #oss_real = (tf.math.reduce_sum(tf.math.subtract(disc_true[batch_size:], disc_predicted[batch_size:])))\n",
        "        #print(f'\\t\\tDiscriminator mse_fake: {mse_fake}\\n')\n",
        "\n",
        "        return loss_real - loss_fake \n",
        "    return diff_func\n",
        "\n",
        "def train_step(models, batch_clips, c1_hist):\n",
        "    \n",
        "    batch_noise_clips = batch_clips\n",
        "    # + tf.random.normal(shape=[conf.dim1, conf.dim2, conf.dim3, conf.dim4], stddev=0.1)\n",
        "    \n",
        "    batch_fake_clips = models.generator.predict_on_batch(batch_noise_clips)\n",
        "    \n",
        "    batch_noise_clips = tf.cast(batch_noise_clips, dtype=tf.float32)\n",
        "    batch_clips = tf.cast(batch_clips, dtype=tf.float32)\n",
        "    batch_fake_clips = tf.cast(batch_fake_clips, dtype=tf.float32)\n",
        "    \n",
        "    #disc_x = np.concatenate((batch_noise_clips, batch_fake_clips))\n",
        "    disc_x = tf.concat([batch_fake_clips, batch_noise_clips], 0)\n",
        "    #disc_y = np.concatenate((batch_clips, batch_fake_clips))\n",
        "    disc_y = tf.concat([batch_fake_clips, batch_clips], 0)\n",
        "    c1_tmp = list()\n",
        "    for _ in range(conf.n_critic):\n",
        "        d_loss = models.discriminator.train_on_batch(disc_x, disc_y)\n",
        "        #d_loss_fake = models.discriminator.train_on_batch(batch_fake_clips, batch_fake_clips)\n",
        "        #print(f'\\t\\tDiscriminator Loss: {d_loss}\\n')\n",
        "        c1_tmp.append(d_loss)\n",
        "    c1_hist.append(np.mean(c1_tmp))\n",
        "    \n",
        "    #models.gan.train_on_batch(batch_noise_clips, [batch_clips, batch_fake_clips])\n",
        "    g_loss = models.gan.train_on_batch(batch_noise_clips, [batch_clips, batch_fake_clips])\n",
        "    return  g_loss\n",
        "    \n",
        "def reconstruct_batch(model, sequences, epoch):\n",
        "\n",
        "    sz = sequences.shape[0]\n",
        "    (reconstructed_sequences, reconstructed_sequences_2) = model.predict(sequences,batch_size=conf.BATCH_SIZE)\n",
        "    path = join(conf.run_data,\"Train_Reconstructs\", str(epoch)+\"_epoch\")\n",
        "    os.makedirs(path, exist_ok=True)\n",
        "    for i in range(0, sz):\n",
        "        #cv2_imshow(np.reshape(reconstructed_sequences[i][2],(256, 256))*256)\n",
        "        if i < 10:\n",
        "            img_num = \"00\"+str(i)\n",
        "        elif i < 100:\n",
        "            img_num = \"0\"+str(i)\n",
        "            \n",
        "        cv2.imwrite(join(path,\"gen_\"+img_num+\".jpg\"), np.reshape(reconstructed_sequences[i][6],(256, 256))*256.0)\n",
        "\n",
        "        cv2.imwrite(join(path,\"dis_\"+img_num+\".jpg\"), np.reshape(reconstructed_sequences_2[i][6],(256, 256))*256.0)\n",
        "\n",
        "\n",
        "def train(test_cases):\n",
        "    discriminator = get_discriminator()\n",
        "    generator = get_generator()\n",
        "    models = compile_gan(generator, discriminator)\n",
        "    models.gan.summary()\n",
        "\n",
        "    train_dataset = tf.data.Dataset.from_tensor_slices(np.array(get_clips_list(conf.dim1))).batch(conf.BATCH_SIZE)\n",
        "    c1_hist, g_hist = list(), list()\n",
        "    #test_cases = get_test_sequences(\"Test002\", 200)\n",
        "    for epoch in range(conf.EPOCHS):\n",
        "        print(f'Epoch {epoch+1} started')\n",
        "        for batch in train_dataset:\n",
        "            \n",
        "            [total_weighted_loss, reconstruction_loss, fooling_loss] = train_step(models, batch, c1_hist)\n",
        "            \n",
        "            print(f'Epoch: {epoch+1} \\t Discriminator Loss: {fooling_loss} \\t\\t Generator Loss: {reconstruction_loss} \\t\\t Total Loss: {total_weighted_loss}')\n",
        "            g_hist.append(reconstruction_loss)\n",
        "\n",
        "        plot_history(c1_hist, g_hist, join(conf.run_data,\"plot_line_plot_loss\"+\"_ep-\"+str(epoch+1)+\".png\"))\n",
        "        models.generator.save(join(conf.run_data,\"generator\"+\"_ep-\"+str(epoch+1)+\".hdf5\"), save_format='h5')\n",
        "        models.discriminator.save(join(conf.run_data,\"discriminator\"+\"_ep-\"+str(epoch+1)+\".hdf5\"), save_format='h5')\n",
        "        models.gan.save(join(conf.run_data,\"gan\"+\"_ep-\"+str(epoch+1)+\".hdf5\"), save_format='h5')\n",
        "        reconstruct_batch(models.gan, test_cases[0:10*conf.BATCH_SIZE], epoch+1)\n",
        "\n",
        "    \n",
        "    models.generator.save(conf.GEN_MODEL_PATH,save_format='h5')\n",
        "    models.discriminator.save(conf.DIS_MODEL_PATH,save_format='h5')\n",
        "    models.gan.save(conf.GAN_MODEL_PATH, save_format='h5')\n",
        "    plot_history(c1_hist, g_hist, join(conf.cwdir,\"final_plot.png\"))\n",
        "    return models.gan\n",
        "\n",
        "\n",
        "def get_model(new_cwdir, batch_size, epochs, test_cases, reconfig=0, reload=1, model_path=conf.GAN_MODEL_PATH):\n",
        "    if reconfig == 1:\n",
        "        conf.reconfig(new_cwdir, batch_size, epochs)\n",
        "    if reload == 1 and os.path.isfile(model_path):\n",
        "        print(\"Loading the trained model\")\n",
        "        model=load_model(model_path, custom_objects={'LeakyReLU': LeakyReLU, 'ClipConstraint': ClipConstraint})\n",
        "        #model.load_weights(model_path)\n",
        "    else :\n",
        "        print(\"Loading the new model\")\n",
        "        model = train(test_cases)\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eC7JERZTIi3M",
        "colab_type": "code",
        "outputId": "e2e29794-8997-4ae6-cfe4-05a3f4e5b875",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#!rm training_gan/gan.hdf5 -rf\n",
        "#!mkdir training_gan\n",
        "test_cases_dir = \"Test002\"\n",
        "test_cases = get_test_sequences(test_cases_dir, 200)\n",
        "#model_path=\"/content/drive/My Drive/Conv2DLSTM_VanillaGAN/training_gan/gan_ep-2.hdf5\"\n",
        "model = get_model(new_cwdir=\"Conv2DLSTM_ADAE_ep50_b2_sigmoid\", batch_size=2, epochs=50, reload=1, test_cases=test_cases, reconfig=1)#, model_path=\"/content/drive/My Drive/Conv2DLSTM_ADAE/training_gan/gan_ep-1.hdf5\")\n",
        "evaluate(test_cases, model, test_cases_dir, 1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test case loaded\n",
            "Loading the new model\n",
            "Loading discriminator model\n",
            "Model: \"sequential_2\"\n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "Layer (type)                                                       Output Shape                                                Param #                \n",
            "======================================================================================================================================================\n",
            "gaussian_noise_1 (GaussianNoise)                                   (None, 10, 256, 256, 1)                                     0                      \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "time_distributed_10 (TimeDistributed)                              (None, 10, 64, 64, 128)                                     15616                  \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "layer_normalization_14 (LayerNormalization)                        (None, 10, 64, 64, 128)                                     256                    \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "time_distributed_11 (TimeDistributed)                              (None, 10, 32, 32, 64)                                      204864                 \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "layer_normalization_15 (LayerNormalization)                        (None, 10, 32, 32, 64)                                      128                    \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "conv_lst_m2d_6 (ConvLSTM2D)                                        (None, 10, 32, 32, 64)                                      295168                 \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "layer_normalization_16 (LayerNormalization)                        (None, 10, 32, 32, 64)                                      128                    \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "conv_lst_m2d_7 (ConvLSTM2D)                                        (None, 10, 32, 32, 32)                                      110720                 \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "layer_normalization_17 (LayerNormalization)                        (None, 10, 32, 32, 32)                                      64                     \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "conv_lst_m2d_8 (ConvLSTM2D)                                        (None, 10, 32, 32, 64)                                      221440                 \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "layer_normalization_18 (LayerNormalization)                        (None, 10, 32, 32, 64)                                      128                    \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "time_distributed_12 (TimeDistributed)                              (None, 10, 64, 64, 64)                                      102464                 \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "layer_normalization_19 (LayerNormalization)                        (None, 10, 64, 64, 64)                                      128                    \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "time_distributed_13 (TimeDistributed)                              (None, 10, 256, 256, 128)                                   991360                 \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "layer_normalization_20 (LayerNormalization)                        (None, 10, 256, 256, 128)                                   256                    \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "time_distributed_14 (TimeDistributed)                              (None, 10, 256, 256, 1)                                     15489                  \n",
            "======================================================================================================================================================\n",
            "Total params: 1,958,209\n",
            "Trainable params: 1,958,209\n",
            "Non-trainable params: 0\n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "Loading generator model\n",
            "Model: \"sequential_3\"\n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "Layer (type)                                                       Output Shape                                                Param #                \n",
            "======================================================================================================================================================\n",
            "time_distributed_15 (TimeDistributed)                              (None, 10, 64, 64, 128)                                     15616                  \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "layer_normalization_21 (LayerNormalization)                        (None, 10, 64, 64, 128)                                     256                    \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "time_distributed_16 (TimeDistributed)                              (None, 10, 32, 32, 64)                                      204864                 \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "layer_normalization_22 (LayerNormalization)                        (None, 10, 32, 32, 64)                                      128                    \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "conv_lst_m2d_9 (ConvLSTM2D)                                        (None, 10, 32, 32, 64)                                      295168                 \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "layer_normalization_23 (LayerNormalization)                        (None, 10, 32, 32, 64)                                      128                    \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "conv_lst_m2d_10 (ConvLSTM2D)                                       (None, 10, 32, 32, 32)                                      110720                 \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "layer_normalization_24 (LayerNormalization)                        (None, 10, 32, 32, 32)                                      64                     \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "conv_lst_m2d_11 (ConvLSTM2D)                                       (None, 10, 32, 32, 64)                                      221440                 \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "layer_normalization_25 (LayerNormalization)                        (None, 10, 32, 32, 64)                                      128                    \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "time_distributed_17 (TimeDistributed)                              (None, 10, 64, 64, 64)                                      102464                 \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "layer_normalization_26 (LayerNormalization)                        (None, 10, 64, 64, 64)                                      128                    \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "time_distributed_18 (TimeDistributed)                              (None, 10, 256, 256, 128)                                   991360                 \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "layer_normalization_27 (LayerNormalization)                        (None, 10, 256, 256, 128)                                   256                    \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "time_distributed_19 (TimeDistributed)                              (None, 10, 256, 256, 1)                                     15489                  \n",
            "======================================================================================================================================================\n",
            "Total params: 1,958,209\n",
            "Trainable params: 1,958,209\n",
            "Non-trainable params: 0\n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         [(None, 10, 256, 256, 1)] 0         \n",
            "_________________________________________________________________\n",
            "model_1 (Model)              (None, 10, 256, 256, 1)   1958209   \n",
            "_________________________________________________________________\n",
            "model (Model)                (None, 10, 256, 256, 1)   1958209   \n",
            "=================================================================\n",
            "Total params: 3,916,418\n",
            "Trainable params: 1,958,209\n",
            "Non-trainable params: 1,958,209\n",
            "_________________________________________________________________\n",
            "Epoch 1 started\n",
            "Epoch: 1 \t Discriminator Loss: 0.21768684685230255 \t\t Generator Loss: 0.1685684770345688 \t\t Total Loss: 0.38625532388687134\n",
            "Epoch: 1 \t Discriminator Loss: 0.2587859332561493 \t\t Generator Loss: 0.1585007905960083 \t\t Total Loss: 0.4172867238521576\n",
            "Epoch: 1 \t Discriminator Loss: 0.20455937087535858 \t\t Generator Loss: 0.12500423192977905 \t\t Total Loss: 0.32956361770629883\n",
            "Epoch: 1 \t Discriminator Loss: 0.19809897243976593 \t\t Generator Loss: 0.12138084322214127 \t\t Total Loss: 0.3194798231124878\n",
            "Epoch: 1 \t Discriminator Loss: 0.16871780157089233 \t\t Generator Loss: 0.11505261808633804 \t\t Total Loss: 0.2837704122066498\n",
            "Epoch: 1 \t Discriminator Loss: 0.1625032126903534 \t\t Generator Loss: 0.1194014698266983 \t\t Total Loss: 0.2819046974182129\n",
            "Epoch: 1 \t Discriminator Loss: 0.20505228638648987 \t\t Generator Loss: 0.14406761527061462 \t\t Total Loss: 0.3491199016571045\n",
            "Epoch: 1 \t Discriminator Loss: 0.21150155365467072 \t\t Generator Loss: 0.14584581553936005 \t\t Total Loss: 0.35734736919403076\n",
            "Epoch: 1 \t Discriminator Loss: 0.1728801280260086 \t\t Generator Loss: 0.12998583912849426 \t\t Total Loss: 0.30286598205566406\n",
            "Epoch: 1 \t Discriminator Loss: 0.22329261898994446 \t\t Generator Loss: 0.12373290210962296 \t\t Total Loss: 0.3470255136489868\n",
            "Epoch: 1 \t Discriminator Loss: 0.1972852647304535 \t\t Generator Loss: 0.14310312271118164 \t\t Total Loss: 0.34038838744163513\n",
            "Epoch: 1 \t Discriminator Loss: 0.1742008626461029 \t\t Generator Loss: 0.1442892849445343 \t\t Total Loss: 0.3184901475906372\n",
            "Epoch: 1 \t Discriminator Loss: 0.173989936709404 \t\t Generator Loss: 0.13324901461601257 \t\t Total Loss: 0.30723893642425537\n",
            "Epoch: 1 \t Discriminator Loss: 0.1787186563014984 \t\t Generator Loss: 0.12124001979827881 \t\t Total Loss: 0.2999586760997772\n",
            "Epoch: 1 \t Discriminator Loss: 0.1822650134563446 \t\t Generator Loss: 0.1223662868142128 \t\t Total Loss: 0.3046312928199768\n",
            "Epoch: 1 \t Discriminator Loss: 0.17107290029525757 \t\t Generator Loss: 0.1230493038892746 \t\t Total Loss: 0.29412221908569336\n",
            "Epoch: 1 \t Discriminator Loss: 0.1525861620903015 \t\t Generator Loss: 0.1165102943778038 \t\t Total Loss: 0.2690964639186859\n",
            "Epoch: 1 \t Discriminator Loss: 0.1542799025774002 \t\t Generator Loss: 0.10634754598140717 \t\t Total Loss: 0.2606274485588074\n",
            "Epoch: 1 \t Discriminator Loss: 0.16339223086833954 \t\t Generator Loss: 0.10604523122310638 \t\t Total Loss: 0.2694374620914459\n",
            "Epoch: 1 \t Discriminator Loss: 0.18689784407615662 \t\t Generator Loss: 0.11014311015605927 \t\t Total Loss: 0.2970409393310547\n",
            "Epoch: 1 \t Discriminator Loss: 0.16706188023090363 \t\t Generator Loss: 0.10577142238616943 \t\t Total Loss: 0.27283328771591187\n",
            "Epoch: 1 \t Discriminator Loss: 0.15840157866477966 \t\t Generator Loss: 0.10255476087331772 \t\t Total Loss: 0.260956346988678\n",
            "Epoch: 1 \t Discriminator Loss: 0.1724245548248291 \t\t Generator Loss: 0.09221190959215164 \t\t Total Loss: 0.26463645696640015\n",
            "Epoch: 1 \t Discriminator Loss: 0.17880186438560486 \t\t Generator Loss: 0.10012556612491608 \t\t Total Loss: 0.27892744541168213\n",
            "Epoch: 1 \t Discriminator Loss: 0.13951756060123444 \t\t Generator Loss: 0.11143447458744049 \t\t Total Loss: 0.2509520351886749\n",
            "Epoch: 1 \t Discriminator Loss: 0.15043918788433075 \t\t Generator Loss: 0.1019582599401474 \t\t Total Loss: 0.25239744782447815\n",
            "Epoch: 1 \t Discriminator Loss: 0.14430458843708038 \t\t Generator Loss: 0.09857915341854095 \t\t Total Loss: 0.24288374185562134\n",
            "Epoch: 1 \t Discriminator Loss: 0.1440591961145401 \t\t Generator Loss: 0.09013675153255463 \t\t Total Loss: 0.23419594764709473\n",
            "Epoch: 1 \t Discriminator Loss: 0.1567046046257019 \t\t Generator Loss: 0.09864763170480728 \t\t Total Loss: 0.2553522288799286\n",
            "Epoch: 1 \t Discriminator Loss: 0.14192236959934235 \t\t Generator Loss: 0.08422942459583282 \t\t Total Loss: 0.22615179419517517\n",
            "Epoch: 1 \t Discriminator Loss: 0.1377008855342865 \t\t Generator Loss: 0.08073307573795319 \t\t Total Loss: 0.21843396127223969\n",
            "Epoch: 1 \t Discriminator Loss: 0.16846667230129242 \t\t Generator Loss: 0.08827248215675354 \t\t Total Loss: 0.25673913955688477\n",
            "Epoch: 1 \t Discriminator Loss: 0.1443033218383789 \t\t Generator Loss: 0.10637716948986053 \t\t Total Loss: 0.25068050622940063\n",
            "Epoch: 1 \t Discriminator Loss: 0.14425382018089294 \t\t Generator Loss: 0.10320627689361572 \t\t Total Loss: 0.24746009707450867\n",
            "Epoch: 1 \t Discriminator Loss: 0.1462801694869995 \t\t Generator Loss: 0.09472544491291046 \t\t Total Loss: 0.24100561439990997\n",
            "Epoch: 1 \t Discriminator Loss: 0.15552131831645966 \t\t Generator Loss: 0.08550862222909927 \t\t Total Loss: 0.24102994799613953\n",
            "Epoch: 1 \t Discriminator Loss: 0.14878329634666443 \t\t Generator Loss: 0.07631459832191467 \t\t Total Loss: 0.2250978946685791\n",
            "Epoch: 1 \t Discriminator Loss: 0.14365993440151215 \t\t Generator Loss: 0.07853229343891144 \t\t Total Loss: 0.22219222784042358\n",
            "Epoch: 1 \t Discriminator Loss: 0.16265182197093964 \t\t Generator Loss: 0.08001257479190826 \t\t Total Loss: 0.2426643967628479\n",
            "Epoch: 1 \t Discriminator Loss: 0.16704674065113068 \t\t Generator Loss: 0.11039040982723236 \t\t Total Loss: 0.27743715047836304\n",
            "Epoch: 1 \t Discriminator Loss: 0.15762871503829956 \t\t Generator Loss: 0.09616522490978241 \t\t Total Loss: 0.25379395484924316\n",
            "Epoch: 1 \t Discriminator Loss: 0.16993625462055206 \t\t Generator Loss: 0.08481477946043015 \t\t Total Loss: 0.2547510266304016\n",
            "Epoch: 1 \t Discriminator Loss: 0.15392237901687622 \t\t Generator Loss: 0.07744923233985901 \t\t Total Loss: 0.23137161135673523\n",
            "Epoch: 1 \t Discriminator Loss: 0.15145890414714813 \t\t Generator Loss: 0.07238197326660156 \t\t Total Loss: 0.2238408774137497\n",
            "Epoch: 1 \t Discriminator Loss: 0.18169890344142914 \t\t Generator Loss: 0.07528828084468842 \t\t Total Loss: 0.25698718428611755\n",
            "Epoch: 1 \t Discriminator Loss: 0.14499245584011078 \t\t Generator Loss: 0.07819390296936035 \t\t Total Loss: 0.22318635880947113\n",
            "Epoch: 1 \t Discriminator Loss: 0.1358938366174698 \t\t Generator Loss: 0.07166395336389542 \t\t Total Loss: 0.2075577974319458\n",
            "Epoch: 1 \t Discriminator Loss: 0.12024136632680893 \t\t Generator Loss: 0.06264995783567429 \t\t Total Loss: 0.18289132416248322\n",
            "Epoch: 1 \t Discriminator Loss: 0.1306076943874359 \t\t Generator Loss: 0.055263154208660126 \t\t Total Loss: 0.18587085604667664\n",
            "Epoch: 1 \t Discriminator Loss: 0.15619519352912903 \t\t Generator Loss: 0.057259608060121536 \t\t Total Loss: 0.21345479786396027\n",
            "Epoch: 1 \t Discriminator Loss: 0.15374943614006042 \t\t Generator Loss: 0.06714540719985962 \t\t Total Loss: 0.22089484333992004\n",
            "Epoch: 1 \t Discriminator Loss: 0.20214787125587463 \t\t Generator Loss: 0.1005701795220375 \t\t Total Loss: 0.30271804332733154\n",
            "Epoch: 1 \t Discriminator Loss: 0.18345016241073608 \t\t Generator Loss: 0.07631312310695648 \t\t Total Loss: 0.25976330041885376\n",
            "Epoch: 1 \t Discriminator Loss: 0.17315688729286194 \t\t Generator Loss: 0.07180778682231903 \t\t Total Loss: 0.24496467411518097\n",
            "Epoch: 1 \t Discriminator Loss: 0.14162985980510712 \t\t Generator Loss: 0.060891490429639816 \t\t Total Loss: 0.20252135396003723\n",
            "Epoch: 1 \t Discriminator Loss: 0.1692756712436676 \t\t Generator Loss: 0.06715227663516998 \t\t Total Loss: 0.23642794787883759\n",
            "Epoch: 1 \t Discriminator Loss: 0.15091818571090698 \t\t Generator Loss: 0.07284627109766006 \t\t Total Loss: 0.22376444935798645\n",
            "Epoch: 1 \t Discriminator Loss: 0.1596173346042633 \t\t Generator Loss: 0.06302148103713989 \t\t Total Loss: 0.2226388156414032\n",
            "Epoch: 1 \t Discriminator Loss: 0.15543298423290253 \t\t Generator Loss: 0.08038575947284698 \t\t Total Loss: 0.2358187437057495\n",
            "Epoch: 1 \t Discriminator Loss: 0.1422596424818039 \t\t Generator Loss: 0.07930231839418411 \t\t Total Loss: 0.2215619683265686\n",
            "Epoch: 1 \t Discriminator Loss: 0.13105665147304535 \t\t Generator Loss: 0.06677062809467316 \t\t Total Loss: 0.1978272795677185\n",
            "Epoch: 1 \t Discriminator Loss: 0.15957823395729065 \t\t Generator Loss: 0.06284907460212708 \t\t Total Loss: 0.22242730855941772\n",
            "Epoch: 1 \t Discriminator Loss: 0.1573534905910492 \t\t Generator Loss: 0.07388503104448318 \t\t Total Loss: 0.23123851418495178\n",
            "Epoch: 1 \t Discriminator Loss: 0.17008186876773834 \t\t Generator Loss: 0.06901945173740387 \t\t Total Loss: 0.2391013205051422\n",
            "Epoch: 1 \t Discriminator Loss: 0.15874549746513367 \t\t Generator Loss: 0.059173841029405594 \t\t Total Loss: 0.21791933476924896\n",
            "Epoch: 1 \t Discriminator Loss: 0.16723594069480896 \t\t Generator Loss: 0.05415884777903557 \t\t Total Loss: 0.22139479219913483\n",
            "Epoch: 1 \t Discriminator Loss: 0.15573656558990479 \t\t Generator Loss: 0.06147794798016548 \t\t Total Loss: 0.21721450984477997\n",
            "Epoch: 1 \t Discriminator Loss: 0.18933555483818054 \t\t Generator Loss: 0.06944103538990021 \t\t Total Loss: 0.25877660512924194\n",
            "Epoch: 1 \t Discriminator Loss: 0.1842423677444458 \t\t Generator Loss: 0.0593581423163414 \t\t Total Loss: 0.2436005175113678\n",
            "Epoch: 1 \t Discriminator Loss: 0.18564756214618683 \t\t Generator Loss: 0.06264089047908783 \t\t Total Loss: 0.24828845262527466\n",
            "Epoch: 1 \t Discriminator Loss: 0.17125961184501648 \t\t Generator Loss: 0.054158251732587814 \t\t Total Loss: 0.2254178673028946\n",
            "Epoch: 1 \t Discriminator Loss: 0.14479130506515503 \t\t Generator Loss: 0.054503507912158966 \t\t Total Loss: 0.1992948055267334\n",
            "Epoch: 1 \t Discriminator Loss: 0.18585631251335144 \t\t Generator Loss: 0.07444090396165848 \t\t Total Loss: 0.2602972090244293\n",
            "Epoch: 1 \t Discriminator Loss: 0.15744560956954956 \t\t Generator Loss: 0.07501815259456635 \t\t Total Loss: 0.2324637621641159\n",
            "Epoch: 1 \t Discriminator Loss: 0.1355467438697815 \t\t Generator Loss: 0.05922780558466911 \t\t Total Loss: 0.1947745531797409\n",
            "Epoch: 1 \t Discriminator Loss: 0.1494418978691101 \t\t Generator Loss: 0.05320384353399277 \t\t Total Loss: 0.20264574885368347\n",
            "Epoch: 1 \t Discriminator Loss: 0.15903297066688538 \t\t Generator Loss: 0.052295487374067307 \t\t Total Loss: 0.21132846176624298\n",
            "Epoch: 1 \t Discriminator Loss: 0.1506950557231903 \t\t Generator Loss: 0.04751262068748474 \t\t Total Loss: 0.19820767641067505\n",
            "Epoch: 1 \t Discriminator Loss: 0.14696238934993744 \t\t Generator Loss: 0.04066140577197075 \t\t Total Loss: 0.1876237988471985\n",
            "Epoch: 1 \t Discriminator Loss: 0.1581575721502304 \t\t Generator Loss: 0.039389677345752716 \t\t Total Loss: 0.19754725694656372\n",
            "Epoch: 1 \t Discriminator Loss: 0.14273497462272644 \t\t Generator Loss: 0.03892280533909798 \t\t Total Loss: 0.18165777623653412\n",
            "Epoch: 1 \t Discriminator Loss: 0.1534678190946579 \t\t Generator Loss: 0.03994407504796982 \t\t Total Loss: 0.19341188669204712\n",
            "Epoch: 1 \t Discriminator Loss: 0.14121168851852417 \t\t Generator Loss: 0.04042857885360718 \t\t Total Loss: 0.18164026737213135\n",
            "Epoch: 1 \t Discriminator Loss: 0.1681481897830963 \t\t Generator Loss: 0.04624726623296738 \t\t Total Loss: 0.2143954634666443\n",
            "Epoch: 1 \t Discriminator Loss: 0.1273430436849594 \t\t Generator Loss: 0.04021751508116722 \t\t Total Loss: 0.16756056249141693\n",
            "Epoch: 1 \t Discriminator Loss: 0.12769784033298492 \t\t Generator Loss: 0.039889223873615265 \t\t Total Loss: 0.1675870716571808\n",
            "Epoch: 1 \t Discriminator Loss: 0.15188051760196686 \t\t Generator Loss: 0.038984399288892746 \t\t Total Loss: 0.1908649206161499\n",
            "Epoch: 1 \t Discriminator Loss: 0.15148049592971802 \t\t Generator Loss: 0.05443602055311203 \t\t Total Loss: 0.20591652393341064\n",
            "Epoch: 1 \t Discriminator Loss: 0.16661611199378967 \t\t Generator Loss: 0.04818947613239288 \t\t Total Loss: 0.21480558812618256\n",
            "Epoch: 1 \t Discriminator Loss: 0.14182570576667786 \t\t Generator Loss: 0.040427256375551224 \t\t Total Loss: 0.18225295841693878\n",
            "Epoch: 1 \t Discriminator Loss: 0.13703788816928864 \t\t Generator Loss: 0.03324165195226669 \t\t Total Loss: 0.17027953267097473\n",
            "Epoch: 1 \t Discriminator Loss: 0.15082374215126038 \t\t Generator Loss: 0.03308065980672836 \t\t Total Loss: 0.18390440940856934\n",
            "Epoch: 1 \t Discriminator Loss: 0.1436004936695099 \t\t Generator Loss: 0.03883511573076248 \t\t Total Loss: 0.18243560194969177\n",
            "Epoch: 1 \t Discriminator Loss: 0.13035184144973755 \t\t Generator Loss: 0.04373139888048172 \t\t Total Loss: 0.17408323287963867\n",
            "Epoch: 1 \t Discriminator Loss: 0.1528652459383011 \t\t Generator Loss: 0.03912489861249924 \t\t Total Loss: 0.19199013710021973\n",
            "Epoch: 1 \t Discriminator Loss: 0.13205787539482117 \t\t Generator Loss: 0.04174811393022537 \t\t Total Loss: 0.17380598187446594\n",
            "Epoch: 1 \t Discriminator Loss: 0.1434442549943924 \t\t Generator Loss: 0.04150381684303284 \t\t Total Loss: 0.18494807183742523\n",
            "Epoch: 1 \t Discriminator Loss: 0.1327483206987381 \t\t Generator Loss: 0.033231765031814575 \t\t Total Loss: 0.16598008573055267\n",
            "Epoch: 1 \t Discriminator Loss: 0.1284998506307602 \t\t Generator Loss: 0.03743000701069832 \t\t Total Loss: 0.1659298539161682\n",
            "Epoch: 1 \t Discriminator Loss: 0.13935387134552002 \t\t Generator Loss: 0.031605444848537445 \t\t Total Loss: 0.17095932364463806\n",
            "Epoch: 1 \t Discriminator Loss: 0.12746889889240265 \t\t Generator Loss: 0.03326103836297989 \t\t Total Loss: 0.16072994470596313\n",
            "Epoch: 1 \t Discriminator Loss: 0.1446901261806488 \t\t Generator Loss: 0.044794198125600815 \t\t Total Loss: 0.18948432803153992\n",
            "Epoch: 1 \t Discriminator Loss: 0.138773113489151 \t\t Generator Loss: 0.040905311703681946 \t\t Total Loss: 0.17967842519283295\n",
            "Epoch: 1 \t Discriminator Loss: 0.13019375503063202 \t\t Generator Loss: 0.04045059531927109 \t\t Total Loss: 0.1706443428993225\n",
            "Epoch: 1 \t Discriminator Loss: 0.13003526628017426 \t\t Generator Loss: 0.033842094242572784 \t\t Total Loss: 0.16387736797332764\n",
            "Epoch: 1 \t Discriminator Loss: 0.14300653338432312 \t\t Generator Loss: 0.03552735596895218 \t\t Total Loss: 0.1785338819026947\n",
            "Epoch: 1 \t Discriminator Loss: 0.13735832273960114 \t\t Generator Loss: 0.03533216565847397 \t\t Total Loss: 0.1726904809474945\n",
            "Epoch: 1 \t Discriminator Loss: 0.14500869810581207 \t\t Generator Loss: 0.04558107256889343 \t\t Total Loss: 0.1905897706747055\n",
            "Epoch: 1 \t Discriminator Loss: 0.14419034123420715 \t\t Generator Loss: 0.04111368581652641 \t\t Total Loss: 0.18530403077602386\n",
            "Epoch: 1 \t Discriminator Loss: 0.1329243928194046 \t\t Generator Loss: 0.03871048241853714 \t\t Total Loss: 0.17163488268852234\n",
            "Epoch: 1 \t Discriminator Loss: 0.14387936890125275 \t\t Generator Loss: 0.035901717841625214 \t\t Total Loss: 0.17978107929229736\n",
            "Epoch: 1 \t Discriminator Loss: 0.13339853286743164 \t\t Generator Loss: 0.03424932807683945 \t\t Total Loss: 0.16764786839485168\n",
            "Epoch: 1 \t Discriminator Loss: 0.12866297364234924 \t\t Generator Loss: 0.032741207629442215 \t\t Total Loss: 0.16140417754650116\n",
            "Epoch: 1 \t Discriminator Loss: 0.13827231526374817 \t\t Generator Loss: 0.03615064173936844 \t\t Total Loss: 0.174422949552536\n",
            "Epoch: 1 \t Discriminator Loss: 0.1422710120677948 \t\t Generator Loss: 0.04062199592590332 \t\t Total Loss: 0.18289300799369812\n",
            "Epoch: 1 \t Discriminator Loss: 0.13293340802192688 \t\t Generator Loss: 0.03196990117430687 \t\t Total Loss: 0.16490331292152405\n",
            "Epoch: 1 \t Discriminator Loss: 0.13055983185768127 \t\t Generator Loss: 0.03067740425467491 \t\t Total Loss: 0.16123723983764648\n",
            "Epoch: 1 \t Discriminator Loss: 0.13278484344482422 \t\t Generator Loss: 0.028818124905228615 \t\t Total Loss: 0.16160297393798828\n",
            "Epoch: 1 \t Discriminator Loss: 0.12453754991292953 \t\t Generator Loss: 0.028056537732481956 \t\t Total Loss: 0.15259408950805664\n",
            "Epoch: 1 \t Discriminator Loss: 0.12983708083629608 \t\t Generator Loss: 0.028239935636520386 \t\t Total Loss: 0.15807701647281647\n",
            "Epoch: 1 \t Discriminator Loss: 0.12167807668447495 \t\t Generator Loss: 0.0203302763402462 \t\t Total Loss: 0.14200834929943085\n",
            "Epoch: 1 \t Discriminator Loss: 0.14688654243946075 \t\t Generator Loss: 0.023881766945123672 \t\t Total Loss: 0.17076830565929413\n",
            "Epoch: 1 \t Discriminator Loss: 0.13076095283031464 \t\t Generator Loss: 0.030478453263640404 \t\t Total Loss: 0.1612394005060196\n",
            "Epoch: 1 \t Discriminator Loss: 0.13937045633792877 \t\t Generator Loss: 0.02824108675122261 \t\t Total Loss: 0.16761153936386108\n",
            "Epoch: 1 \t Discriminator Loss: 0.14080682396888733 \t\t Generator Loss: 0.03520987927913666 \t\t Total Loss: 0.176016703248024\n",
            "Epoch: 1 \t Discriminator Loss: 0.13535413146018982 \t\t Generator Loss: 0.026976272463798523 \t\t Total Loss: 0.16233040392398834\n",
            "Epoch: 1 \t Discriminator Loss: 0.12574437260627747 \t\t Generator Loss: 0.025609180331230164 \t\t Total Loss: 0.15135355293750763\n",
            "Epoch: 1 \t Discriminator Loss: 0.1402638852596283 \t\t Generator Loss: 0.022598683834075928 \t\t Total Loss: 0.16286256909370422\n",
            "Epoch: 1 \t Discriminator Loss: 0.13430723547935486 \t\t Generator Loss: 0.02411331795156002 \t\t Total Loss: 0.15842054784297943\n",
            "Epoch: 1 \t Discriminator Loss: 0.12905940413475037 \t\t Generator Loss: 0.026192963123321533 \t\t Total Loss: 0.1552523672580719\n",
            "Epoch: 1 \t Discriminator Loss: 0.12486996501684189 \t\t Generator Loss: 0.024135040119290352 \t\t Total Loss: 0.1490050107240677\n",
            "Epoch: 1 \t Discriminator Loss: 0.12167364358901978 \t\t Generator Loss: 0.024576524272561073 \t\t Total Loss: 0.1462501734495163\n",
            "Epoch: 1 \t Discriminator Loss: 0.12007351964712143 \t\t Generator Loss: 0.02120043709874153 \t\t Total Loss: 0.14127396047115326\n",
            "Epoch: 1 \t Discriminator Loss: 0.1346668004989624 \t\t Generator Loss: 0.022498618811368942 \t\t Total Loss: 0.15716542303562164\n",
            "Epoch: 1 \t Discriminator Loss: 0.12836672365665436 \t\t Generator Loss: 0.024767931550741196 \t\t Total Loss: 0.15313465893268585\n",
            "Epoch: 1 \t Discriminator Loss: 0.12250179052352905 \t\t Generator Loss: 0.020866356790065765 \t\t Total Loss: 0.14336815476417542\n",
            "Epoch: 1 \t Discriminator Loss: 0.1256060004234314 \t\t Generator Loss: 0.020886732265353203 \t\t Total Loss: 0.14649273455142975\n",
            "Epoch: 1 \t Discriminator Loss: 0.13210049271583557 \t\t Generator Loss: 0.02187171019613743 \t\t Total Loss: 0.15397220849990845\n",
            "Epoch: 1 \t Discriminator Loss: 0.13311466574668884 \t\t Generator Loss: 0.02040998265147209 \t\t Total Loss: 0.15352465212345123\n",
            "Epoch: 1 \t Discriminator Loss: 0.14836230874061584 \t\t Generator Loss: 0.028209466487169266 \t\t Total Loss: 0.1765717715024948\n",
            "Epoch: 1 \t Discriminator Loss: 0.14464294910430908 \t\t Generator Loss: 0.03329550474882126 \t\t Total Loss: 0.17793846130371094\n",
            "Epoch: 1 \t Discriminator Loss: 0.13102209568023682 \t\t Generator Loss: 0.029221083968877792 \t\t Total Loss: 0.1602431833744049\n",
            "Epoch: 1 \t Discriminator Loss: 0.13526615500450134 \t\t Generator Loss: 0.02440459281206131 \t\t Total Loss: 0.15967074036598206\n",
            "Epoch: 1 \t Discriminator Loss: 0.13580167293548584 \t\t Generator Loss: 0.026286235079169273 \t\t Total Loss: 0.16208790242671967\n",
            "Epoch: 1 \t Discriminator Loss: 0.13993652164936066 \t\t Generator Loss: 0.028379136696457863 \t\t Total Loss: 0.16831566393375397\n",
            "Epoch: 1 \t Discriminator Loss: 0.12655386328697205 \t\t Generator Loss: 0.02793586254119873 \t\t Total Loss: 0.15448972582817078\n",
            "Epoch: 1 \t Discriminator Loss: 0.13364985585212708 \t\t Generator Loss: 0.026807675138115883 \t\t Total Loss: 0.1604575365781784\n",
            "Epoch: 1 \t Discriminator Loss: 0.14108040928840637 \t\t Generator Loss: 0.04410094395279884 \t\t Total Loss: 0.18518134951591492\n",
            "Epoch: 1 \t Discriminator Loss: 0.13997796177864075 \t\t Generator Loss: 0.03055506944656372 \t\t Total Loss: 0.17053303122520447\n",
            "Epoch: 1 \t Discriminator Loss: 0.11974494159221649 \t\t Generator Loss: 0.027127105742692947 \t\t Total Loss: 0.14687204360961914\n",
            "Epoch: 1 \t Discriminator Loss: 0.12414457648992538 \t\t Generator Loss: 0.02870495244860649 \t\t Total Loss: 0.15284952521324158\n",
            "Epoch: 1 \t Discriminator Loss: 0.12013363838195801 \t\t Generator Loss: 0.026719138026237488 \t\t Total Loss: 0.1468527764081955\n",
            "Epoch: 1 \t Discriminator Loss: 0.12087880074977875 \t\t Generator Loss: 0.024233859032392502 \t\t Total Loss: 0.14511266350746155\n",
            "Epoch: 1 \t Discriminator Loss: 0.1384342908859253 \t\t Generator Loss: 0.02454473450779915 \t\t Total Loss: 0.16297902166843414\n",
            "Epoch: 1 \t Discriminator Loss: 0.12464527040719986 \t\t Generator Loss: 0.024626947939395905 \t\t Total Loss: 0.14927221834659576\n",
            "Epoch: 1 \t Discriminator Loss: 0.12659433484077454 \t\t Generator Loss: 0.02474556490778923 \t\t Total Loss: 0.15133990347385406\n",
            "Epoch: 1 \t Discriminator Loss: 0.12110444158315659 \t\t Generator Loss: 0.02251049317419529 \t\t Total Loss: 0.14361493289470673\n",
            "Epoch: 1 \t Discriminator Loss: 0.13931086659431458 \t\t Generator Loss: 0.024794692173600197 \t\t Total Loss: 0.16410556435585022\n",
            "Epoch: 1 \t Discriminator Loss: 0.11327023804187775 \t\t Generator Loss: 0.020376218482851982 \t\t Total Loss: 0.13364645838737488\n",
            "Epoch: 1 \t Discriminator Loss: 0.11145778000354767 \t\t Generator Loss: 0.02184079959988594 \t\t Total Loss: 0.1332985758781433\n",
            "Epoch: 1 \t Discriminator Loss: 0.12577596306800842 \t\t Generator Loss: 0.017544226720929146 \t\t Total Loss: 0.14332018792629242\n",
            "Epoch: 1 \t Discriminator Loss: 0.12277521193027496 \t\t Generator Loss: 0.021149594336748123 \t\t Total Loss: 0.1439248025417328\n",
            "Epoch: 1 \t Discriminator Loss: 0.12617073953151703 \t\t Generator Loss: 0.021993450820446014 \t\t Total Loss: 0.14816418290138245\n",
            "Epoch: 1 \t Discriminator Loss: 0.14657652378082275 \t\t Generator Loss: 0.02425617352128029 \t\t Total Loss: 0.17083269357681274\n",
            "Epoch: 1 \t Discriminator Loss: 0.13286426663398743 \t\t Generator Loss: 0.019101640209555626 \t\t Total Loss: 0.1519659012556076\n",
            "Epoch: 1 \t Discriminator Loss: 0.15360654890537262 \t\t Generator Loss: 0.021508222445845604 \t\t Total Loss: 0.17511476576328278\n",
            "Epoch: 1 \t Discriminator Loss: 0.14100949466228485 \t\t Generator Loss: 0.02285182848572731 \t\t Total Loss: 0.16386131942272186\n",
            "Epoch: 1 \t Discriminator Loss: 0.1277327984571457 \t\t Generator Loss: 0.019322628155350685 \t\t Total Loss: 0.14705543220043182\n",
            "Epoch: 1 \t Discriminator Loss: 0.12094362825155258 \t\t Generator Loss: 0.017808694392442703 \t\t Total Loss: 0.13875232636928558\n",
            "Epoch: 1 \t Discriminator Loss: 0.13308873772621155 \t\t Generator Loss: 0.0179741270840168 \t\t Total Loss: 0.15106286108493805\n",
            "Epoch: 1 \t Discriminator Loss: 0.1194450631737709 \t\t Generator Loss: 0.018314922228455544 \t\t Total Loss: 0.1377599835395813\n",
            "Epoch: 1 \t Discriminator Loss: 0.12617167830467224 \t\t Generator Loss: 0.021079879254102707 \t\t Total Loss: 0.14725156128406525\n",
            "Epoch: 1 \t Discriminator Loss: 0.1252903938293457 \t\t Generator Loss: 0.020399266853928566 \t\t Total Loss: 0.14568966627120972\n",
            "Epoch: 1 \t Discriminator Loss: 0.13833735883235931 \t\t Generator Loss: 0.021235976368188858 \t\t Total Loss: 0.15957333147525787\n",
            "Epoch: 1 \t Discriminator Loss: 0.12941721081733704 \t\t Generator Loss: 0.01873628981411457 \t\t Total Loss: 0.14815349876880646\n",
            "Epoch: 1 \t Discriminator Loss: 0.14258570969104767 \t\t Generator Loss: 0.02094346098601818 \t\t Total Loss: 0.163529172539711\n",
            "Epoch: 1 \t Discriminator Loss: 0.12484131008386612 \t\t Generator Loss: 0.022650571539998055 \t\t Total Loss: 0.14749188721179962\n",
            "Epoch: 1 \t Discriminator Loss: 0.12822097539901733 \t\t Generator Loss: 0.01968904584646225 \t\t Total Loss: 0.14791002869606018\n",
            "Epoch: 1 \t Discriminator Loss: 0.14453113079071045 \t\t Generator Loss: 0.023287398740649223 \t\t Total Loss: 0.16781853139400482\n",
            "Epoch: 1 \t Discriminator Loss: 0.1263476312160492 \t\t Generator Loss: 0.01943480595946312 \t\t Total Loss: 0.1457824409008026\n",
            "Epoch: 1 \t Discriminator Loss: 0.15339280664920807 \t\t Generator Loss: 0.02036779746413231 \t\t Total Loss: 0.17376060783863068\n",
            "Epoch: 1 \t Discriminator Loss: 0.1482531577348709 \t\t Generator Loss: 0.02320893481373787 \t\t Total Loss: 0.17146208882331848\n",
            "Epoch: 1 \t Discriminator Loss: 0.13218705356121063 \t\t Generator Loss: 0.02260345220565796 \t\t Total Loss: 0.1547905057668686\n",
            "Epoch: 1 \t Discriminator Loss: 0.13040576875209808 \t\t Generator Loss: 0.01895066723227501 \t\t Total Loss: 0.1493564397096634\n",
            "Epoch: 1 \t Discriminator Loss: 0.14523687958717346 \t\t Generator Loss: 0.01952735148370266 \t\t Total Loss: 0.16476422548294067\n",
            "Epoch: 1 \t Discriminator Loss: 0.12634477019309998 \t\t Generator Loss: 0.020110661163926125 \t\t Total Loss: 0.14645543694496155\n",
            "Epoch: 1 \t Discriminator Loss: 0.13598492741584778 \t\t Generator Loss: 0.02139708399772644 \t\t Total Loss: 0.15738201141357422\n",
            "Epoch: 1 \t Discriminator Loss: 0.12818053364753723 \t\t Generator Loss: 0.02068513073027134 \t\t Total Loss: 0.14886566996574402\n",
            "Epoch: 1 \t Discriminator Loss: 0.13060718774795532 \t\t Generator Loss: 0.01944696344435215 \t\t Total Loss: 0.15005415678024292\n",
            "Epoch: 1 \t Discriminator Loss: 0.1288927048444748 \t\t Generator Loss: 0.01933467760682106 \t\t Total Loss: 0.14822737872600555\n",
            "Epoch: 1 \t Discriminator Loss: 0.14724965393543243 \t\t Generator Loss: 0.019169535487890244 \t\t Total Loss: 0.16641919314861298\n",
            "Epoch: 1 \t Discriminator Loss: 0.12520723044872284 \t\t Generator Loss: 0.01802149787545204 \t\t Total Loss: 0.14322872459888458\n",
            "Epoch: 1 \t Discriminator Loss: 0.12857545912265778 \t\t Generator Loss: 0.018218930810689926 \t\t Total Loss: 0.146794393658638\n",
            "Epoch: 1 \t Discriminator Loss: 0.1449994146823883 \t\t Generator Loss: 0.02060265652835369 \t\t Total Loss: 0.16560207307338715\n",
            "Epoch: 1 \t Discriminator Loss: 0.12527035176753998 \t\t Generator Loss: 0.018543755635619164 \t\t Total Loss: 0.1438141018152237\n",
            "Epoch: 1 \t Discriminator Loss: 0.14710941910743713 \t\t Generator Loss: 0.018534433096647263 \t\t Total Loss: 0.1656438559293747\n",
            "Epoch: 1 \t Discriminator Loss: 0.1349000185728073 \t\t Generator Loss: 0.02593492902815342 \t\t Total Loss: 0.16083495318889618\n",
            "Epoch: 1 \t Discriminator Loss: 0.12324833869934082 \t\t Generator Loss: 0.019464295357465744 \t\t Total Loss: 0.14271263778209686\n",
            "Epoch: 1 \t Discriminator Loss: 0.11571717262268066 \t\t Generator Loss: 0.01954573020339012 \t\t Total Loss: 0.13526290655136108\n",
            "Epoch: 1 \t Discriminator Loss: 0.13597914576530457 \t\t Generator Loss: 0.01788201369345188 \t\t Total Loss: 0.1538611650466919\n",
            "Epoch: 1 \t Discriminator Loss: 0.13147519528865814 \t\t Generator Loss: 0.019722167402505875 \t\t Total Loss: 0.15119735896587372\n",
            "Epoch: 1 \t Discriminator Loss: 0.14198139309883118 \t\t Generator Loss: 0.023242419585585594 \t\t Total Loss: 0.16522380709648132\n",
            "Epoch: 1 \t Discriminator Loss: 0.12380628287792206 \t\t Generator Loss: 0.020785236731171608 \t\t Total Loss: 0.1445915251970291\n",
            "Epoch: 1 \t Discriminator Loss: 0.12141431868076324 \t\t Generator Loss: 0.018379542976617813 \t\t Total Loss: 0.13979385793209076\n",
            "Epoch: 1 \t Discriminator Loss: 0.12163741886615753 \t\t Generator Loss: 0.016580423340201378 \t\t Total Loss: 0.13821783661842346\n",
            "Epoch: 1 \t Discriminator Loss: 0.15386216342449188 \t\t Generator Loss: 0.021245138719677925 \t\t Total Loss: 0.17510730028152466\n",
            "Epoch: 1 \t Discriminator Loss: 0.13276898860931396 \t\t Generator Loss: 0.023367587476968765 \t\t Total Loss: 0.15613657236099243\n",
            "Epoch: 1 \t Discriminator Loss: 0.13822808861732483 \t\t Generator Loss: 0.023500073701143265 \t\t Total Loss: 0.1617281585931778\n",
            "Epoch: 1 \t Discriminator Loss: 0.12762141227722168 \t\t Generator Loss: 0.01845470629632473 \t\t Total Loss: 0.14607611298561096\n",
            "Epoch: 1 \t Discriminator Loss: 0.13550665974617004 \t\t Generator Loss: 0.017972048372030258 \t\t Total Loss: 0.1534787118434906\n",
            "Epoch: 1 \t Discriminator Loss: 0.14864394068717957 \t\t Generator Loss: 0.021483805030584335 \t\t Total Loss: 0.1701277494430542\n",
            "Epoch: 1 \t Discriminator Loss: 0.13237757980823517 \t\t Generator Loss: 0.020781632512807846 \t\t Total Loss: 0.1531592160463333\n",
            "Epoch: 1 \t Discriminator Loss: 0.13703694939613342 \t\t Generator Loss: 0.019104676321148872 \t\t Total Loss: 0.15614162385463715\n",
            "Epoch: 1 \t Discriminator Loss: 0.14014334976673126 \t\t Generator Loss: 0.020140184089541435 \t\t Total Loss: 0.16028353571891785\n",
            "Epoch: 1 \t Discriminator Loss: 0.1467626988887787 \t\t Generator Loss: 0.021193761378526688 \t\t Total Loss: 0.16795645654201508\n",
            "Epoch: 1 \t Discriminator Loss: 0.12779583036899567 \t\t Generator Loss: 0.02139490284025669 \t\t Total Loss: 0.1491907387971878\n",
            "Epoch: 1 \t Discriminator Loss: 0.1225229874253273 \t\t Generator Loss: 0.01804879680275917 \t\t Total Loss: 0.14057178795337677\n",
            "Epoch: 1 \t Discriminator Loss: 0.13309912383556366 \t\t Generator Loss: 0.018020931631326675 \t\t Total Loss: 0.15112005174160004\n",
            "Epoch: 1 \t Discriminator Loss: 0.13344062864780426 \t\t Generator Loss: 0.01887160912156105 \t\t Total Loss: 0.152312234044075\n",
            "Epoch: 1 \t Discriminator Loss: 0.14808884263038635 \t\t Generator Loss: 0.023767447099089622 \t\t Total Loss: 0.17185628414154053\n",
            "Epoch: 1 \t Discriminator Loss: 0.13221964240074158 \t\t Generator Loss: 0.0241178497672081 \t\t Total Loss: 0.15633749961853027\n",
            "Epoch: 1 \t Discriminator Loss: 0.1309119462966919 \t\t Generator Loss: 0.01889866217970848 \t\t Total Loss: 0.14981061220169067\n",
            "Epoch: 1 \t Discriminator Loss: 0.13865897059440613 \t\t Generator Loss: 0.019443877041339874 \t\t Total Loss: 0.1581028401851654\n",
            "Epoch: 1 \t Discriminator Loss: 0.1478462815284729 \t\t Generator Loss: 0.018248144537210464 \t\t Total Loss: 0.16609442234039307\n",
            "Epoch: 1 \t Discriminator Loss: 0.1346641331911087 \t\t Generator Loss: 0.019308626651763916 \t\t Total Loss: 0.15397275984287262\n",
            "Epoch: 1 \t Discriminator Loss: 0.13292333483695984 \t\t Generator Loss: 0.020670881494879723 \t\t Total Loss: 0.1535942107439041\n",
            "Epoch: 1 \t Discriminator Loss: 0.13012634217739105 \t\t Generator Loss: 0.01917780004441738 \t\t Total Loss: 0.14930413663387299\n",
            "Epoch: 1 \t Discriminator Loss: 0.13570816814899445 \t\t Generator Loss: 0.02007788047194481 \t\t Total Loss: 0.15578605234622955\n",
            "Epoch: 1 \t Discriminator Loss: 0.1327739953994751 \t\t Generator Loss: 0.01798093691468239 \t\t Total Loss: 0.1507549285888672\n",
            "Epoch: 1 \t Discriminator Loss: 0.14562349021434784 \t\t Generator Loss: 0.021384095773100853 \t\t Total Loss: 0.16700758039951324\n",
            "Epoch: 1 \t Discriminator Loss: 0.12856754660606384 \t\t Generator Loss: 0.019605154171586037 \t\t Total Loss: 0.14817270636558533\n",
            "Epoch: 1 \t Discriminator Loss: 0.12215612083673477 \t\t Generator Loss: 0.017021123319864273 \t\t Total Loss: 0.13917724788188934\n",
            "Epoch: 1 \t Discriminator Loss: 0.1551540642976761 \t\t Generator Loss: 0.018828237429261208 \t\t Total Loss: 0.17398230731487274\n",
            "Epoch: 1 \t Discriminator Loss: 0.1260140985250473 \t\t Generator Loss: 0.021303366869688034 \t\t Total Loss: 0.14731746912002563\n",
            "Epoch: 1 \t Discriminator Loss: 0.12358961254358292 \t\t Generator Loss: 0.01822173222899437 \t\t Total Loss: 0.141811341047287\n",
            "Epoch: 1 \t Discriminator Loss: 0.13946574926376343 \t\t Generator Loss: 0.01867752894759178 \t\t Total Loss: 0.1581432819366455\n",
            "Epoch: 1 \t Discriminator Loss: 0.12716808915138245 \t\t Generator Loss: 0.01785743422806263 \t\t Total Loss: 0.14502552151679993\n",
            "Epoch: 1 \t Discriminator Loss: 0.16563907265663147 \t\t Generator Loss: 0.023391347378492355 \t\t Total Loss: 0.18903042376041412\n",
            "Epoch: 1 \t Discriminator Loss: 0.1388794630765915 \t\t Generator Loss: 0.026158297434449196 \t\t Total Loss: 0.16503776609897614\n",
            "Epoch: 1 \t Discriminator Loss: 0.12914039194583893 \t\t Generator Loss: 0.019856054335832596 \t\t Total Loss: 0.14899644255638123\n",
            "Epoch: 1 \t Discriminator Loss: 0.12505286931991577 \t\t Generator Loss: 0.01715983636677265 \t\t Total Loss: 0.14221270382404327\n",
            "Epoch: 1 \t Discriminator Loss: 0.14708001911640167 \t\t Generator Loss: 0.02118794247508049 \t\t Total Loss: 0.16826796531677246\n",
            "Epoch: 1 \t Discriminator Loss: 0.13246992230415344 \t\t Generator Loss: 0.02200356498360634 \t\t Total Loss: 0.15447348356246948\n",
            "Epoch: 1 \t Discriminator Loss: 0.12729039788246155 \t\t Generator Loss: 0.019410420209169388 \t\t Total Loss: 0.14670081436634064\n",
            "Epoch: 1 \t Discriminator Loss: 0.12487731873989105 \t\t Generator Loss: 0.01647050678730011 \t\t Total Loss: 0.14134782552719116\n",
            "Epoch: 1 \t Discriminator Loss: 0.1614580750465393 \t\t Generator Loss: 0.020538534969091415 \t\t Total Loss: 0.18199661374092102\n",
            "Epoch: 1 \t Discriminator Loss: 0.14269930124282837 \t\t Generator Loss: 0.018646027892827988 \t\t Total Loss: 0.16134533286094666\n",
            "Epoch: 1 \t Discriminator Loss: 0.155194491147995 \t\t Generator Loss: 0.02203965187072754 \t\t Total Loss: 0.17723414301872253\n",
            "Epoch: 1 \t Discriminator Loss: 0.1404561549425125 \t\t Generator Loss: 0.02241605892777443 \t\t Total Loss: 0.16287221014499664\n",
            "Epoch: 1 \t Discriminator Loss: 0.1553141325712204 \t\t Generator Loss: 0.0218195803463459 \t\t Total Loss: 0.177133709192276\n",
            "Epoch: 1 \t Discriminator Loss: 0.13218705356121063 \t\t Generator Loss: 0.019492601975798607 \t\t Total Loss: 0.1516796499490738\n",
            "Epoch: 1 \t Discriminator Loss: 0.14174646139144897 \t\t Generator Loss: 0.01780286803841591 \t\t Total Loss: 0.15954932570457458\n",
            "Epoch: 1 \t Discriminator Loss: 0.15468594431877136 \t\t Generator Loss: 0.020278755575418472 \t\t Total Loss: 0.17496469616889954\n",
            "Epoch: 1 \t Discriminator Loss: 0.13072404265403748 \t\t Generator Loss: 0.020215872675180435 \t\t Total Loss: 0.1509399116039276\n",
            "Epoch: 1 \t Discriminator Loss: 0.13782835006713867 \t\t Generator Loss: 0.019309010356664658 \t\t Total Loss: 0.15713736414909363\n",
            "Epoch: 1 \t Discriminator Loss: 0.13184385001659393 \t\t Generator Loss: 0.01808319427073002 \t\t Total Loss: 0.1499270498752594\n",
            "Epoch: 1 \t Discriminator Loss: 0.13104338943958282 \t\t Generator Loss: 0.01775212213397026 \t\t Total Loss: 0.14879551529884338\n",
            "Epoch: 1 \t Discriminator Loss: 0.14541828632354736 \t\t Generator Loss: 0.01968136802315712 \t\t Total Loss: 0.16509965062141418\n",
            "Epoch: 1 \t Discriminator Loss: 0.1310899555683136 \t\t Generator Loss: 0.01873340643942356 \t\t Total Loss: 0.1498233675956726\n",
            "Epoch: 1 \t Discriminator Loss: 0.12473789602518082 \t\t Generator Loss: 0.0169279333204031 \t\t Total Loss: 0.14166583120822906\n",
            "Epoch: 1 \t Discriminator Loss: 0.12980778515338898 \t\t Generator Loss: 0.015954764559864998 \t\t Total Loss: 0.14576254785060883\n",
            "Epoch: 1 \t Discriminator Loss: 0.16381646692752838 \t\t Generator Loss: 0.02081049606204033 \t\t Total Loss: 0.184626966714859\n",
            "Epoch: 1 \t Discriminator Loss: 0.14758147299289703 \t\t Generator Loss: 0.02159154787659645 \t\t Total Loss: 0.16917301714420319\n",
            "Epoch: 1 \t Discriminator Loss: 0.15661582350730896 \t\t Generator Loss: 0.02201184630393982 \t\t Total Loss: 0.17862766981124878\n",
            "Epoch: 1 \t Discriminator Loss: 0.13772249221801758 \t\t Generator Loss: 0.02036074362695217 \t\t Total Loss: 0.1580832302570343\n",
            "Epoch: 1 \t Discriminator Loss: 0.15277865529060364 \t\t Generator Loss: 0.01949298568069935 \t\t Total Loss: 0.17227163910865784\n",
            "Epoch: 1 \t Discriminator Loss: 0.12490393966436386 \t\t Generator Loss: 0.01864812895655632 \t\t Total Loss: 0.14355206489562988\n",
            "Epoch: 1 \t Discriminator Loss: 0.12454919517040253 \t\t Generator Loss: 0.018030453473329544 \t\t Total Loss: 0.14257964491844177\n",
            "Epoch: 1 \t Discriminator Loss: 0.14427348971366882 \t\t Generator Loss: 0.018692433834075928 \t\t Total Loss: 0.16296592354774475\n",
            "Epoch: 1 \t Discriminator Loss: 0.13716664910316467 \t\t Generator Loss: 0.018717745319008827 \t\t Total Loss: 0.15588440001010895\n",
            "Epoch: 1 \t Discriminator Loss: 0.13755477964878082 \t\t Generator Loss: 0.02115046977996826 \t\t Total Loss: 0.15870524942874908\n",
            "Epoch: 1 \t Discriminator Loss: 0.1358843594789505 \t\t Generator Loss: 0.01812940463423729 \t\t Total Loss: 0.1540137678384781\n",
            "Epoch: 1 \t Discriminator Loss: 0.14821277558803558 \t\t Generator Loss: 0.019109712913632393 \t\t Total Loss: 0.16732248663902283\n",
            "Epoch: 1 \t Discriminator Loss: 0.13072624802589417 \t\t Generator Loss: 0.01851050928235054 \t\t Total Loss: 0.1492367535829544\n",
            "Epoch: 1 \t Discriminator Loss: 0.12816345691680908 \t\t Generator Loss: 0.018552253022789955 \t\t Total Loss: 0.14671571552753448\n",
            "Epoch: 1 \t Discriminator Loss: 0.12940721213817596 \t\t Generator Loss: 0.016818348318338394 \t\t Total Loss: 0.14622555673122406\n",
            "Epoch: 1 \t Discriminator Loss: 0.16014257073402405 \t\t Generator Loss: 0.019578296691179276 \t\t Total Loss: 0.17972086369991302\n",
            "Epoch: 1 \t Discriminator Loss: 0.13017292320728302 \t\t Generator Loss: 0.018920112401247025 \t\t Total Loss: 0.14909303188323975\n",
            "Epoch: 1 \t Discriminator Loss: 0.15629658102989197 \t\t Generator Loss: 0.019634170457720757 \t\t Total Loss: 0.17593075335025787\n",
            "Epoch: 1 \t Discriminator Loss: 0.13324376940727234 \t\t Generator Loss: 0.02214016392827034 \t\t Total Loss: 0.15538392961025238\n",
            "Epoch: 1 \t Discriminator Loss: 0.1286444514989853 \t\t Generator Loss: 0.02385110966861248 \t\t Total Loss: 0.15249556303024292\n",
            "Epoch: 1 \t Discriminator Loss: 0.12348900735378265 \t\t Generator Loss: 0.025744784623384476 \t\t Total Loss: 0.14923378825187683\n",
            "Epoch: 1 \t Discriminator Loss: 0.14215557277202606 \t\t Generator Loss: 0.023769617080688477 \t\t Total Loss: 0.16592518985271454\n",
            "Epoch: 1 \t Discriminator Loss: 0.16525928676128387 \t\t Generator Loss: 0.02536039613187313 \t\t Total Loss: 0.19061967730522156\n",
            "Epoch: 1 \t Discriminator Loss: 0.15641413629055023 \t\t Generator Loss: 0.02684207819402218 \t\t Total Loss: 0.18325620889663696\n",
            "Epoch: 1 \t Discriminator Loss: 0.15170055627822876 \t\t Generator Loss: 0.024795129895210266 \t\t Total Loss: 0.17649568617343903\n",
            "Epoch: 1 \t Discriminator Loss: 0.1435128003358841 \t\t Generator Loss: 0.023913487792015076 \t\t Total Loss: 0.16742628812789917\n",
            "Epoch: 1 \t Discriminator Loss: 0.1327868402004242 \t\t Generator Loss: 0.02634965442121029 \t\t Total Loss: 0.15913648903369904\n",
            "Epoch: 1 \t Discriminator Loss: 0.15478506684303284 \t\t Generator Loss: 0.026505598798394203 \t\t Total Loss: 0.1812906712293625\n",
            "Epoch: 1 \t Discriminator Loss: 0.13865742087364197 \t\t Generator Loss: 0.02224619686603546 \t\t Total Loss: 0.16090361773967743\n",
            "Epoch: 1 \t Discriminator Loss: 0.13661789894104004 \t\t Generator Loss: 0.021741976961493492 \t\t Total Loss: 0.15835987031459808\n",
            "Epoch: 1 \t Discriminator Loss: 0.14838045835494995 \t\t Generator Loss: 0.020352963358163834 \t\t Total Loss: 0.1687334179878235\n",
            "Epoch: 1 \t Discriminator Loss: 0.14744657278060913 \t\t Generator Loss: 0.019553160294890404 \t\t Total Loss: 0.1669997274875641\n",
            "Epoch: 1 \t Discriminator Loss: 0.13408537209033966 \t\t Generator Loss: 0.020560450851917267 \t\t Total Loss: 0.15464583039283752\n",
            "Epoch: 1 \t Discriminator Loss: 0.12734250724315643 \t\t Generator Loss: 0.018464606255292892 \t\t Total Loss: 0.14580711722373962\n",
            "Epoch: 1 \t Discriminator Loss: 0.1429215967655182 \t\t Generator Loss: 0.01822083629667759 \t\t Total Loss: 0.16114243865013123\n",
            "Epoch: 1 \t Discriminator Loss: 0.14604255557060242 \t\t Generator Loss: 0.018875567242503166 \t\t Total Loss: 0.16491812467575073\n",
            "Epoch: 1 \t Discriminator Loss: 0.13760966062545776 \t\t Generator Loss: 0.0221231821924448 \t\t Total Loss: 0.159732848405838\n",
            "Epoch: 1 \t Discriminator Loss: 0.12947577238082886 \t\t Generator Loss: 0.019841279834508896 \t\t Total Loss: 0.14931705594062805\n",
            "Epoch: 1 \t Discriminator Loss: 0.12932512164115906 \t\t Generator Loss: 0.018201256170868874 \t\t Total Loss: 0.14752638339996338\n",
            "Epoch: 1 \t Discriminator Loss: 0.15199795365333557 \t\t Generator Loss: 0.018166786059737206 \t\t Total Loss: 0.17016473412513733\n",
            "Epoch: 1 \t Discriminator Loss: 0.13088616728782654 \t\t Generator Loss: 0.01959805004298687 \t\t Total Loss: 0.15048421919345856\n",
            "Epoch: 1 \t Discriminator Loss: 0.1257147192955017 \t\t Generator Loss: 0.01826164871454239 \t\t Total Loss: 0.1439763605594635\n",
            "Epoch: 1 \t Discriminator Loss: 0.14338451623916626 \t\t Generator Loss: 0.017896318808197975 \t\t Total Loss: 0.16128084063529968\n",
            "Epoch: 1 \t Discriminator Loss: 0.13667038083076477 \t\t Generator Loss: 0.017978426069021225 \t\t Total Loss: 0.1546488106250763\n",
            "Epoch: 1 \t Discriminator Loss: 0.14458981156349182 \t\t Generator Loss: 0.02067434974014759 \t\t Total Loss: 0.16526415944099426\n",
            "Epoch: 1 \t Discriminator Loss: 0.13106603920459747 \t\t Generator Loss: 0.023052310571074486 \t\t Total Loss: 0.1541183441877365\n",
            "Epoch: 1 \t Discriminator Loss: 0.12773311138153076 \t\t Generator Loss: 0.020936595275998116 \t\t Total Loss: 0.14866970479488373\n",
            "Epoch: 1 \t Discriminator Loss: 0.13178397715091705 \t\t Generator Loss: 0.017261523753404617 \t\t Total Loss: 0.14904549717903137\n",
            "Epoch: 1 \t Discriminator Loss: 0.16309751570224762 \t\t Generator Loss: 0.01944025792181492 \t\t Total Loss: 0.18253777921199799\n",
            "Epoch: 1 \t Discriminator Loss: 0.14829032123088837 \t\t Generator Loss: 0.02203129604458809 \t\t Total Loss: 0.17032161355018616\n",
            "Epoch: 1 \t Discriminator Loss: 0.16398867964744568 \t\t Generator Loss: 0.023987513035535812 \t\t Total Loss: 0.1879761964082718\n",
            "Epoch: 1 \t Discriminator Loss: 0.13504719734191895 \t\t Generator Loss: 0.022444989532232285 \t\t Total Loss: 0.15749219059944153\n",
            "Epoch: 1 \t Discriminator Loss: 0.12669137120246887 \t\t Generator Loss: 0.020585857331752777 \t\t Total Loss: 0.14727723598480225\n",
            "Epoch: 1 \t Discriminator Loss: 0.14259327948093414 \t\t Generator Loss: 0.018934478983283043 \t\t Total Loss: 0.16152775287628174\n",
            "Epoch: 1 \t Discriminator Loss: 0.14066554605960846 \t\t Generator Loss: 0.01755167730152607 \t\t Total Loss: 0.15821722149848938\n",
            "Epoch: 1 \t Discriminator Loss: 0.15413884818553925 \t\t Generator Loss: 0.022080708295106888 \t\t Total Loss: 0.17621955275535583\n",
            "Epoch: 1 \t Discriminator Loss: 0.14615002274513245 \t\t Generator Loss: 0.02597624994814396 \t\t Total Loss: 0.17212627828121185\n",
            "Epoch: 1 \t Discriminator Loss: 0.14152154326438904 \t\t Generator Loss: 0.02393072471022606 \t\t Total Loss: 0.1654522716999054\n",
            "Epoch: 1 \t Discriminator Loss: 0.14606896042823792 \t\t Generator Loss: 0.01899031363427639 \t\t Total Loss: 0.16505926847457886\n",
            "Epoch: 1 \t Discriminator Loss: 0.14659373462200165 \t\t Generator Loss: 0.027968596667051315 \t\t Total Loss: 0.17456233501434326\n",
            "Epoch: 1 \t Discriminator Loss: 0.1345558613538742 \t\t Generator Loss: 0.025759205222129822 \t\t Total Loss: 0.16031506657600403\n",
            "Epoch: 1 \t Discriminator Loss: 0.12372477352619171 \t\t Generator Loss: 0.018705129623413086 \t\t Total Loss: 0.1424299031496048\n",
            "Epoch: 1 \t Discriminator Loss: 0.12467612326145172 \t\t Generator Loss: 0.01669393852353096 \t\t Total Loss: 0.14137005805969238\n",
            "Epoch: 1 \t Discriminator Loss: 0.17603078484535217 \t\t Generator Loss: 0.022582922130823135 \t\t Total Loss: 0.198613703250885\n",
            "Epoch: 1 \t Discriminator Loss: 0.16290786862373352 \t\t Generator Loss: 0.02217148244380951 \t\t Total Loss: 0.18507935106754303\n",
            "Epoch: 1 \t Discriminator Loss: 0.15377244353294373 \t\t Generator Loss: 0.021668553352355957 \t\t Total Loss: 0.17544099688529968\n",
            "Epoch: 1 \t Discriminator Loss: 0.1347842961549759 \t\t Generator Loss: 0.023007601499557495 \t\t Total Loss: 0.1577918976545334\n",
            "Epoch: 1 \t Discriminator Loss: 0.1275898963212967 \t\t Generator Loss: 0.018856022506952286 \t\t Total Loss: 0.14644591510295868\n",
            "Epoch: 1 \t Discriminator Loss: 0.11538094282150269 \t\t Generator Loss: 0.015875544399023056 \t\t Total Loss: 0.13125649094581604\n",
            "Epoch: 1 \t Discriminator Loss: 0.11313255876302719 \t\t Generator Loss: 0.01542479358613491 \t\t Total Loss: 0.12855735421180725\n",
            "Epoch: 1 \t Discriminator Loss: 0.17788659036159515 \t\t Generator Loss: 0.020982876420021057 \t\t Total Loss: 0.1988694667816162\n",
            "Epoch: 1 \t Discriminator Loss: 0.1660657376050949 \t\t Generator Loss: 0.021235406398773193 \t\t Total Loss: 0.1873011440038681\n",
            "Epoch: 1 \t Discriminator Loss: 0.15869900584220886 \t\t Generator Loss: 0.022194908931851387 \t\t Total Loss: 0.1808939129114151\n",
            "Epoch: 1 \t Discriminator Loss: 0.1443464159965515 \t\t Generator Loss: 0.02461288310587406 \t\t Total Loss: 0.16895930469036102\n",
            "Epoch: 1 \t Discriminator Loss: 0.13712985813617706 \t\t Generator Loss: 0.01935853809118271 \t\t Total Loss: 0.15648838877677917\n",
            "Epoch: 1 \t Discriminator Loss: 0.14797349274158478 \t\t Generator Loss: 0.017467215657234192 \t\t Total Loss: 0.16544070839881897\n",
            "Epoch: 1 \t Discriminator Loss: 0.1508861929178238 \t\t Generator Loss: 0.018430635333061218 \t\t Total Loss: 0.169316828250885\n",
            "Epoch: 1 \t Discriminator Loss: 0.14020220935344696 \t\t Generator Loss: 0.019292905926704407 \t\t Total Loss: 0.15949511528015137\n",
            "Epoch: 1 \t Discriminator Loss: 0.14594462513923645 \t\t Generator Loss: 0.019866349175572395 \t\t Total Loss: 0.1658109724521637\n",
            "Epoch: 1 \t Discriminator Loss: 0.1452665627002716 \t\t Generator Loss: 0.01839417591691017 \t\t Total Loss: 0.16366073489189148\n",
            "Epoch: 1 \t Discriminator Loss: 0.14870533347129822 \t\t Generator Loss: 0.01951562985777855 \t\t Total Loss: 0.16822096705436707\n",
            "Epoch: 1 \t Discriminator Loss: 0.14615276455879211 \t\t Generator Loss: 0.019597651436924934 \t\t Total Loss: 0.1657504141330719\n",
            "Epoch: 1 \t Discriminator Loss: 0.14824220538139343 \t\t Generator Loss: 0.019506387412548065 \t\t Total Loss: 0.1677486002445221\n",
            "Epoch: 1 \t Discriminator Loss: 0.14770588278770447 \t\t Generator Loss: 0.020822197198867798 \t\t Total Loss: 0.16852807998657227\n",
            "Epoch: 1 \t Discriminator Loss: 0.14601103961467743 \t\t Generator Loss: 0.020128801465034485 \t\t Total Loss: 0.16613984107971191\n",
            "Epoch: 1 \t Discriminator Loss: 0.14818120002746582 \t\t Generator Loss: 0.019035091623663902 \t\t Total Loss: 0.16721628606319427\n",
            "Epoch: 1 \t Discriminator Loss: 0.13817408680915833 \t\t Generator Loss: 0.02048603817820549 \t\t Total Loss: 0.1586601287126541\n",
            "Epoch: 1 \t Discriminator Loss: 0.139041006565094 \t\t Generator Loss: 0.018362700939178467 \t\t Total Loss: 0.15740370750427246\n",
            "Epoch: 1 \t Discriminator Loss: 0.15462449193000793 \t\t Generator Loss: 0.018694592639803886 \t\t Total Loss: 0.17331908643245697\n",
            "Epoch: 1 \t Discriminator Loss: 0.14163801074028015 \t\t Generator Loss: 0.018703307956457138 \t\t Total Loss: 0.1603413224220276\n",
            "Epoch: 1 \t Discriminator Loss: 0.14902697503566742 \t\t Generator Loss: 0.020515019074082375 \t\t Total Loss: 0.16954199969768524\n",
            "Epoch: 1 \t Discriminator Loss: 0.14394217729568481 \t\t Generator Loss: 0.018979739397764206 \t\t Total Loss: 0.16292192041873932\n",
            "Epoch: 1 \t Discriminator Loss: 0.1481037735939026 \t\t Generator Loss: 0.018611455336213112 \t\t Total Loss: 0.16671523451805115\n",
            "Epoch: 1 \t Discriminator Loss: 0.14905360341072083 \t\t Generator Loss: 0.019526785239577293 \t\t Total Loss: 0.16858038306236267\n",
            "Epoch: 1 \t Discriminator Loss: 0.1464112102985382 \t\t Generator Loss: 0.020277364179491997 \t\t Total Loss: 0.16668857634067535\n",
            "Epoch: 1 \t Discriminator Loss: 0.13852201402187347 \t\t Generator Loss: 0.018824700266122818 \t\t Total Loss: 0.157346710562706\n",
            "Epoch: 1 \t Discriminator Loss: 0.14765727519989014 \t\t Generator Loss: 0.019652649760246277 \t\t Total Loss: 0.1673099249601364\n",
            "Epoch: 1 \t Discriminator Loss: 0.1536390781402588 \t\t Generator Loss: 0.019096380099654198 \t\t Total Loss: 0.17273545265197754\n",
            "Epoch: 1 \t Discriminator Loss: 0.13729560375213623 \t\t Generator Loss: 0.019716590642929077 \t\t Total Loss: 0.1570121943950653\n",
            "Epoch: 1 \t Discriminator Loss: 0.13090865314006805 \t\t Generator Loss: 0.017328273504972458 \t\t Total Loss: 0.1482369303703308\n",
            "Epoch: 1 \t Discriminator Loss: 0.12605221569538116 \t\t Generator Loss: 0.0155800087377429 \t\t Total Loss: 0.14163222908973694\n",
            "Epoch: 1 \t Discriminator Loss: 0.15745809674263 \t\t Generator Loss: 0.017287585884332657 \t\t Total Loss: 0.17474567890167236\n",
            "Epoch: 1 \t Discriminator Loss: 0.136734738945961 \t\t Generator Loss: 0.01688404008746147 \t\t Total Loss: 0.15361878275871277\n",
            "Epoch: 1 \t Discriminator Loss: 0.1524403840303421 \t\t Generator Loss: 0.01810048148036003 \t\t Total Loss: 0.17054086923599243\n",
            "Epoch: 1 \t Discriminator Loss: 0.16722193360328674 \t\t Generator Loss: 0.018989913165569305 \t\t Total Loss: 0.18621185421943665\n",
            "Epoch: 1 \t Discriminator Loss: 0.14172501862049103 \t\t Generator Loss: 0.02052822895348072 \t\t Total Loss: 0.1622532457113266\n",
            "Epoch: 1 \t Discriminator Loss: 0.1396520882844925 \t\t Generator Loss: 0.01800685003399849 \t\t Total Loss: 0.15765893459320068\n",
            "Epoch: 1 \t Discriminator Loss: 0.15587063133716583 \t\t Generator Loss: 0.017470013350248337 \t\t Total Loss: 0.17334064841270447\n",
            "Epoch: 1 \t Discriminator Loss: 0.148379385471344 \t\t Generator Loss: 0.0179392471909523 \t\t Total Loss: 0.1663186252117157\n",
            "Epoch: 1 \t Discriminator Loss: 0.15870721638202667 \t\t Generator Loss: 0.02032867819070816 \t\t Total Loss: 0.17903590202331543\n",
            "Epoch: 1 \t Discriminator Loss: 0.14771443605422974 \t\t Generator Loss: 0.020391838625073433 \t\t Total Loss: 0.16810627281665802\n",
            "Epoch: 1 \t Discriminator Loss: 0.140555739402771 \t\t Generator Loss: 0.018341243267059326 \t\t Total Loss: 0.15889698266983032\n",
            "Epoch: 1 \t Discriminator Loss: 0.15983808040618896 \t\t Generator Loss: 0.017435643821954727 \t\t Total Loss: 0.1772737205028534\n",
            "Epoch: 1 \t Discriminator Loss: 0.14621153473854065 \t\t Generator Loss: 0.01865673065185547 \t\t Total Loss: 0.16486826539039612\n",
            "Epoch: 1 \t Discriminator Loss: 0.13752049207687378 \t\t Generator Loss: 0.022391892969608307 \t\t Total Loss: 0.1599123775959015\n",
            "Epoch: 1 \t Discriminator Loss: 0.1581941545009613 \t\t Generator Loss: 0.020465314388275146 \t\t Total Loss: 0.17865946888923645\n",
            "Epoch: 1 \t Discriminator Loss: 0.1500246375799179 \t\t Generator Loss: 0.018036220222711563 \t\t Total Loss: 0.16806085407733917\n",
            "Epoch: 1 \t Discriminator Loss: 0.14944054186344147 \t\t Generator Loss: 0.023281574249267578 \t\t Total Loss: 0.17272211611270905\n",
            "Epoch: 1 \t Discriminator Loss: 0.1485070288181305 \t\t Generator Loss: 0.019904812797904015 \t\t Total Loss: 0.16841183602809906\n",
            "Epoch: 1 \t Discriminator Loss: 0.1542951464653015 \t\t Generator Loss: 0.020006254315376282 \t\t Total Loss: 0.1743014007806778\n",
            "Epoch: 1 \t Discriminator Loss: 0.1465510129928589 \t\t Generator Loss: 0.02103053405880928 \t\t Total Loss: 0.16758154332637787\n",
            "Epoch: 1 \t Discriminator Loss: 0.15495562553405762 \t\t Generator Loss: 0.01981411501765251 \t\t Total Loss: 0.17476974427700043\n",
            "Epoch: 1 \t Discriminator Loss: 0.14830747246742249 \t\t Generator Loss: 0.020517267286777496 \t\t Total Loss: 0.16882473230361938\n",
            "Epoch: 1 \t Discriminator Loss: 0.14939379692077637 \t\t Generator Loss: 0.02214304730296135 \t\t Total Loss: 0.17153684794902802\n",
            "Epoch: 1 \t Discriminator Loss: 0.1462586671113968 \t\t Generator Loss: 0.019152317196130753 \t\t Total Loss: 0.16541098058223724\n",
            "Epoch: 1 \t Discriminator Loss: 0.1547938734292984 \t\t Generator Loss: 0.022405017167329788 \t\t Total Loss: 0.1771988868713379\n",
            "Epoch: 1 \t Discriminator Loss: 0.1506783664226532 \t\t Generator Loss: 0.023737061768770218 \t\t Total Loss: 0.17441542446613312\n",
            "Epoch: 1 \t Discriminator Loss: 0.14820460975170135 \t\t Generator Loss: 0.020552515983581543 \t\t Total Loss: 0.1687571257352829\n",
            "Epoch: 1 \t Discriminator Loss: 0.14929476380348206 \t\t Generator Loss: 0.020001491531729698 \t\t Total Loss: 0.1692962497472763\n",
            "Epoch: 1 \t Discriminator Loss: 0.1558944582939148 \t\t Generator Loss: 0.024780483916401863 \t\t Total Loss: 0.1806749403476715\n",
            "Epoch: 1 \t Discriminator Loss: 0.138071671128273 \t\t Generator Loss: 0.020647117868065834 \t\t Total Loss: 0.1587187945842743\n",
            "Epoch: 1 \t Discriminator Loss: 0.13357073068618774 \t\t Generator Loss: 0.01893382892012596 \t\t Total Loss: 0.152504563331604\n",
            "Epoch: 1 \t Discriminator Loss: 0.12701483070850372 \t\t Generator Loss: 0.017816193401813507 \t\t Total Loss: 0.14483103156089783\n",
            "Epoch: 1 \t Discriminator Loss: 0.1594352424144745 \t\t Generator Loss: 0.017147492617368698 \t\t Total Loss: 0.17658273875713348\n",
            "Epoch: 1 \t Discriminator Loss: 0.14168290793895721 \t\t Generator Loss: 0.02051568403840065 \t\t Total Loss: 0.16219858825206757\n",
            "Epoch: 1 \t Discriminator Loss: 0.14307643473148346 \t\t Generator Loss: 0.020850952714681625 \t\t Total Loss: 0.16392739117145538\n",
            "Epoch: 1 \t Discriminator Loss: 0.1599101424217224 \t\t Generator Loss: 0.019159741699695587 \t\t Total Loss: 0.1790698766708374\n",
            "Epoch: 1 \t Discriminator Loss: 0.15330341458320618 \t\t Generator Loss: 0.02178383432328701 \t\t Total Loss: 0.17508724331855774\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}