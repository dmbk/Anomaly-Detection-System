{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TEST_AAE.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dmbk/Anomaly-Detection-System/blob/master/TEST_AAE_PED1_bg.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVE526Rfl8ed",
        "colab_type": "code",
        "outputId": "0897645b-8cbe-4d89-fd49-0fc95d875483",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "!pip install imageio\n",
        "!pip install qpsolvers\n",
        "#!pip install tensorflow_datasets\n",
        "!pip install keras-layer-normalization\n",
        "from google.colab import drive\n",
        "#!pip install alive-progress\n",
        "drive.mount('/content/drive', force_remount=True)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: imageio in /usr/local/lib/python3.6/dist-packages (2.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from imageio) (1.18.3)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from imageio) (7.0.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drSah6JgmAU_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "\n",
        "import skimage\n",
        "import glob\n",
        "import imageio\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "from PIL import Image\n",
        "from os.path import join\n",
        "from os import listdir\n",
        "from os.path import isfile, join, isdir\n",
        "\n",
        "#import keras\n",
        "import argparse\n",
        "from os.path import dirname\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\t\n",
        "import statistics\n",
        "import shutil\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import time\n",
        "#from progress.bar import IncrementalBar\n",
        "\n",
        "import numpy as np\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Input, Dense, Reshape, Flatten\n",
        "from keras.layers import Conv2DTranspose, ConvLSTM2D, BatchNormalization, TimeDistributed, Conv2D, Dropout, Activation, InputLayer\n",
        "from keras.optimizers import Adam\n",
        "from keras_layer_normalization import LayerNormalization\n",
        "from keras.models import load_model\n",
        "import csv\n",
        "from scipy.interpolate import make_interp_spline, BSpline\n",
        "\n",
        "from scipy.signal import savgol_filter"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bJ798qPmI9L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_single_test(single_test_path):\n",
        "    \n",
        "    sz = 0\n",
        "    for f in sorted(listdir(single_test_path)):\n",
        "        if str(join(single_test_path, f))[-3:] == \"tif\":\n",
        "          sz = sz +1\n",
        "    test = np.zeros(shape=(sz, conf.dim2, conf.dim3, conf.dim4))\n",
        "    cnt = 0\n",
        "    for f in sorted(listdir(single_test_path)):\n",
        "        if str(join(single_test_path, f))[-3:] == \"tif\":\n",
        "            #print(\"img path: \"+join(single_test_path, f))\n",
        "            img = Image.open(join(single_test_path, f)).resize((conf.dim2, conf.dim3))\n",
        "            #cv2_imshow(np.array(img,dtype=np.float32))\n",
        "            #cv2.waitKey(0)\n",
        "            img = np.array(img, dtype=np.float32) / 256\n",
        "            test[cnt, :, :, 0] = img\n",
        "            cnt = cnt + 1\n",
        "    return test\n",
        "\n",
        "def get_test_sequences(test_case_dir):\n",
        "    test = get_single_test(join(conf.TEST_DIR,test_case_dir))\n",
        "    print(\"Test case loaded\")\n",
        "    sz = test.shape[0] - conf.dim1\n",
        "    sequences = np.zeros((sz, conf.dim1, conf.dim2, conf.dim3, conf.dim4))\n",
        "    # apply the sliding window technique to get the sequences\n",
        "    for i in range(0, sz):\n",
        "        clip = np.zeros((conf.dim1, conf.dim2, conf.dim3, conf.dim4))\n",
        "        for j in range(0, conf.dim1):\n",
        "            clip[j] = test[i + j, :, :, :]\n",
        "        sequences[i] = clip\n",
        "    return sequences\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UkgtzofEvwlU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Config:\n",
        "    def __init__(self, data_dir_, cwdir_name_, data_set):\n",
        "        self.data_set_name = data_set\n",
        "        self.data_dir = data_dir_\n",
        "        self.data_set_dir = join(self.data_dir, data_set)\n",
        "        self.cwdir_name = cwdir_name_\n",
        "        self.cwdir = join(self.data_dir,self.cwdir_name)\n",
        "        self.run_data = join(self.cwdir, \"training_dir\")\n",
        "        self.image_dir = join(self.run_data,self.data_set_name,\"Test/\")\n",
        "        if not os.path.exists(self.cwdir):\n",
        "            os.mkdir(self.cwdir)\n",
        "            os.mkdir(self.run_data)\n",
        "    \n",
        "        if not os.path.exists(self.run_data):\n",
        "            #shutil.rmtree(self.run_data)\n",
        "            os.mkdir(self.run_data)\n",
        "            os.makedirs(self.image_dir, exist_ok=True)\n",
        "\n",
        "        self.DATASET_PATH = join(self.data_set_dir,\"Train/\")\n",
        "        self.TEST_DIR = join(self.data_set_dir,\"Test/\")\n",
        "        self.BATCH_SIZE = 2\n",
        "        self.EPOCHS = 50\n",
        "        self.GEN_MODEL_PATH = join(self.cwdir,\"model_gen_Conv2DLSTM_AAE\")\n",
        "        self.DIS_MODEL_PATH = join(self.cwdir,\"model_dis_Conv2DLSTM_AAE\")\n",
        "        self.DEC_MODEL_PATH = join(self.cwdir,\"model_dec_Conv2DLSTM_AAE\")\n",
        "\n",
        "        self.retrain = 0\n",
        "        self.dim1 = 10\n",
        "        self.dim2 = 256\n",
        "        self.dim3 = 256\n",
        "        self.dim4 = 1\n",
        "        self.latent_dim = 327680\n",
        "\n",
        "\n",
        "    def reconfig(self, new_name, batch_size = 4, epochs = 5, retrain = 0):\n",
        "        self.cwdir_name = new_name\n",
        "        self.cwdir = join(self.data_dir, self.cwdir_name)\n",
        "        self.run_data = join(self.cwdir, \"training_dir\")\n",
        "        self.image_dir = join(self.run_data,self.data_set_name,\"Test/\")\n",
        "\n",
        "        self.BATCH_SIZE = batch_size\n",
        "        self.EPOCHS = epochs\n",
        "        self.GEN_MODEL_PATH = join(self.cwdir,\"model_gen_Conv2DLSTM_AAE\")\n",
        "        self.DIS_MODEL_PATH = join(self.cwdir,\"model_dis_Conv2DLSTM_AAE\")\n",
        "        self.DEC_MODEL_PATH = join(self.cwdir,\"model_dec_Conv2DLSTM_AAE\")\n",
        "\n",
        "        self.retrain = retrain\n",
        "        if retrain == 0:\n",
        "            print(\"Configuring train from scratch\")\n",
        "            if not os.path.exists(self.cwdir):\n",
        "                os.mkdir(self.cwdir)\n",
        "                os.mkdir(self.run_data)\n",
        "    \n",
        "            if os.path.exists(self.run_data):\n",
        "                shutil.rmtree(self.run_data)\n",
        "                os.mkdir(self.run_data)\n",
        "                os.makedirs(self.image_dir, exist_ok=True)\n",
        "\n",
        "\n",
        "conf = Config(data_dir_=\"/content/drive/My Drive/\", cwdir_name_=\"Conv2DLSTM_AAE_PED1\", data_set=\"UCSD_Anomaly_Dataset.v1p2/UCSDped1/\") \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQZhjkL1NycS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "# insert at 1, 0 is the script path (or '' in REPL)\n",
        "sys.path.insert(1, '/content/drive/My Drive/Persistence1D/python')\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from persistence1d import RunPersistence\n",
        "from reconstruct1d import RunReconstruction\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UDjBu8hyrfnZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TestVideoFile_ped1 = list((36,2))\n",
        "TestVideoFile_ped1 = [[60,152], [50,175], [91,200], [31,168], [5,90], [1,100], [1,175], [1,94], [1,48], [1,140],   [70,165],   [130,200],   [1,156],   [1,200],   [138,200],   [123,200],   [1,47],   [54,120],    [64,138],    [45,175],    [31,200],    [16,107],    [8,165],    [50,171],    [40,135],    [77,144],    [10,122],    [105,200],    [1,15],    [175,200],    [1,180],    [1,52],  [5,165],    [1,121],    [86,200],   [15,108]]\n",
        "\n",
        "def persistence(InputData, dt, id, color, threshold_abs):\n",
        "    #~ Compute the extrema of the given data and their persistence.\n",
        "    ExtremaAndPersistence = RunPersistence(InputData)\n",
        "\n",
        "    #~ Keep only those extrema with a persistence larger than 0.5.\n",
        "    FilteredIndices = [t[0] for t in ExtremaAndPersistence if t[1] >= 0.1]\n",
        "\n",
        "    #~ This simple call is all you need to reconstruct a smooth function containing only the filtered extrema\n",
        "    SmoothData = RunReconstruction(InputData, FilteredIndices, 'biharmonic', 0.0000001)\n",
        "\n",
        "    #~ Plot original and smoothed data\n",
        "    fig, ax = plt.subplots()\n",
        "    ax.plot(range(0, len(InputData)), InputData, label=\"Original Data\")\n",
        "    ax.plot(range(0, len(SmoothData)), SmoothData, label=\"Smooth Data\")\n",
        "    ExtremaIndices = [t[0] for t in ExtremaAndPersistence]\n",
        "    ax.plot(ExtremaIndices, InputData[ExtremaIndices], marker='.', linestyle='')\n",
        "    ax.plot(FilteredIndices, InputData[FilteredIndices], marker='*', linestyle='')\n",
        "    ax.set(xlabel='data index', ylabel='data value')\n",
        "    #ax.set_aspect(1.0/ax.get_data_ratio()*0.2)\n",
        "    plt.axvspan(TestVideoFile_ped1[id-1][0], TestVideoFile_ped1[id-1][1], alpha=0.5, color=color)\n",
        "    #plt.axhline(y=threshold_abs,linewidth=1, color='blue') \n",
        "\n",
        "    if dt == 1 and id == 5:\n",
        "        plt.axvspan(140, 200, alpha=0.5, color=color)\n",
        "    elif dt == 1 and id == 6:\n",
        "        plt.axvspan(110, 200, alpha=0.5, color=color) \n",
        "    elif dt == 1 and id == 29:\n",
        "        plt.axvspan(45, 113, alpha=0.5, color=color)\n",
        "    elif dt == 1 and id == 32:\n",
        "        plt.axvspan(65, 115, alpha=0.5, color=color)\n",
        "\n",
        "    ax.grid()\n",
        "    plt.legend()    \n",
        "    plt.show()\n",
        "    return plt\n",
        "\n",
        "threshold = 0.3\n",
        "def fill_gt_ped1(sr, id, color, threshold_abs):\n",
        "    #plt.xlim((conf.dim1,len(sr)+conf.dim1))\n",
        "    sr = np.reshape(sr, (sr.shape[0],))\n",
        "    print(sr.shape)\n",
        "    #zeros = np.zeros((conf.dim1,))\n",
        "    #print(zeros.shape)\n",
        "    #plt.plot(np.concatenate((zeros, sr)))\n",
        "    persistence(sr, 1, id, color, threshold_abs)\n",
        "    yhat = savgol_filter(sr, 51, 3)\n",
        "    persistence(yhat, 1, id, color, threshold_abs)\n",
        "    #plt.plot(sr)  \n",
        "    return \n",
        "\n",
        "    #plt.plot(yhat, color='red')\n",
        "    plt.axvspan(TestVideoFile_ped1[id-1][0], TestVideoFile_ped1[id-1][1], alpha=0.5, color=color)\n",
        "    #plt.axhline(y=threshold_abs,linewidth=1, color='blue')\n",
        "    if id == 5:\n",
        "        plt.axvspan(140, 200, alpha=0.5, color=color)\n",
        "    elif id == 6:\n",
        "        plt.axvspan(110, 200, alpha=0.5, color=color) \n",
        "    elif id == 29:\n",
        "        plt.axvspan(45, 113, alpha=0.5, color=color)\n",
        "    elif id == 32:\n",
        "        plt.axvspan(65, 115, alpha=0.5, color=color)\n",
        "\n",
        "\n",
        "    plt.ylabel('regularity score sr_ae(t)')\n",
        "    plt.xlabel('frame t')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "\n",
        "TestVideoFile_ped2 = list((12,2))\n",
        "TestVideoFile_ped2 = [[61,180],[95,180],[1,146],[31,180],[1,129],[1,159],[46,180],[1,180],[1,120],[1,150],[1,180],[88,180]]\n",
        "\n",
        "def fill_gt_ped2(sr, id, color, threshold_abs):\n",
        "    #plt.xlim((conf.dim1,len(sr)+conf.dim1))\n",
        "    sr = np.reshape(sr, (sr.shape[0],))\n",
        "    #plt.plot(np.concatenate((np.zeros((conf.dim1,)), sr)))\n",
        "    persistence(sr, 2, id, color, threshold_abs)\n",
        "    yhat = savgol_filter(sr, 51, 3)\n",
        "    persistence(yhat, 2, id, color, threshold_abs)\n",
        "    return \n",
        "\n",
        "    #plt.plot(sr)\n",
        "\n",
        "    #plt.plot(yhat, color='red')\n",
        "    plt.axvspan(TestVideoFile_ped2[id-1][0], TestVideoFile_ped2[id-1][1], alpha=0.5, color=color)\n",
        "    #plt.axhline(y=threshold_abs,linewidth=1, color='blue')\n",
        "    plt.ylabel('regularity score sr_ae(t)')\n",
        "    plt.xlabel('frame t')\n",
        "    plt.show()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GAXfjsTem0oM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_model_aae():\n",
        "  \n",
        "    model_enc = load_model(conf.cwdir+\"/model_gen_Conv2DLSTM_AAEep100\",custom_objects={'LayerNormalization': LayerNormalization})\n",
        "    model_dec = load_model(conf.cwdir+\"/model_dec_Conv2DLSTM_AAEep100\",custom_objects={'LayerNormalization': LayerNormalization})\n",
        "    model_disc = load_model(conf.cwdir+\"/model_dis_Conv2DLSTM_AAEep100\",custom_objects={'LayerNormalization': LayerNormalization})\n",
        "\n",
        "    #model_enc = load_model(\"/content/drive/My Drive/model_gen_Conv2DLSTM_AAEep100\",custom_objects={'LayerNormalization': LayerNormalization})\n",
        "    #model_dec = load_model(\"/content/drive/My Drive/model_dec_Conv2DLSTM_AAEep100\",custom_objects={'LayerNormalization': LayerNormalization})\n",
        "    #model_disc = load_model(\"/content/drive/My Drive/model_dis_Conv2DLSTM_AAEep100\",custom_objects={'LayerNormalization': LayerNormalization})\n",
        "\n",
        "    model_ae = Sequential()\n",
        "    model_ae.add(model_enc)\n",
        "    model_ae.add(model_dec)\n",
        "    \n",
        "    model_enc_disc = Sequential()\n",
        "    model_enc_disc.add(model_enc)\n",
        "    model_enc_disc.add(model_disc)\n",
        "    \n",
        "    return model_enc, model_dec, model_disc, model_ae, model_enc_disc\n",
        "\n",
        "model_enc, model_dec, model_disc, model_ae, model_enc_disc = build_model_aae()\n",
        "\n",
        "model_enc.summary()\n",
        "model_dec.summary()\n",
        "model_disc.summary()\n",
        "model_ae.summary()\n",
        "model_enc_disc.summary()\n",
        "\n",
        "model_disc.compile(optimizer=Adam(lr=1e-4), loss=\"binary_crossentropy\")\n",
        "model_enc_disc.compile(optimizer=Adam(lr=1e-4), loss=\"binary_crossentropy\")\n",
        "model_ae.compile(optimizer=Adam(lr=1e-4, decay=1e-5, epsilon=1e-6), loss=\"mse\")\n",
        "#\"/content/drive/My Drive/UCSD_Anomaly_Dataset.v1p2/model.hdf5\"\n",
        "\n",
        "#model_ae = load_model(\"/content/drive/My Drive/VAE/model1.hdf5\",custom_objects={'LayerNormalization': LayerNormalization})\n",
        "\n",
        "def evaluate_dis(sequences, model, id, dt):\n",
        "    fooling_loss = model.predict(sequences,batch_size=conf.BATCH_SIZE)\n",
        "    sa = (fooling_loss - np.min(fooling_loss)) / (np.max(fooling_loss))\n",
        "    sr = 1.0 - sa\n",
        "\n",
        "    with open(join(\"/content/drive/My Drive/\", 'sr_score.csv'), mode='a') as f:\n",
        "        writer = csv.writer(f)\n",
        "        writer.writerow([float(x[0]) for x in sr])\n",
        "        f.close()\n",
        "\n",
        "    threshold_abs = threshold# np.min(sr)+ (np.max(sr) - np.min(sr)) * threshold\n",
        "    if dt == 1:\n",
        "        fill_gt_ped1(sr, id, 'red', threshold_abs)\n",
        "    elif dt == 2:\n",
        "        fill_gt_ped2(sr, id, 'red', threshold_abs)\n",
        "    #plt.plot(sr)\n",
        "    #plt.ylabel('regularity score sr_dis(t)')\n",
        "    #plt.xlabel('frame t')\n",
        "    #plt.show()\n",
        "\n",
        "def get_clips(test):\n",
        "    sz = test.shape[0] - conf.dim1\n",
        "    sequences = np.zeros((sz, conf.dim1, conf.dim2, conf.dim3))\n",
        "    # apply the sliding window technique to get the sequences\n",
        "    for i in range(0, sz):\n",
        "        clip = np.zeros((conf.dim1, conf.dim2, conf.dim3))\n",
        "        for j in range(0, conf.dim1):\n",
        "            clip[j] = test[i + j, :, :]\n",
        "        sequences[i] = clip\n",
        "    return sequences\n",
        "\n",
        "\n",
        "def mask_array(bg_list):\n",
        "\n",
        "    for p in range(0, bg_list.shape[0]):\n",
        "        for r in range(256):\n",
        "            for c in range(256):\n",
        "                if bg_list[p][r][c] > 0:\n",
        "                    bg_list[p][r][c] = 1\n",
        "                else:\n",
        "                    bg_list[p][r][c] = 0\n",
        "\n",
        "    bg_list[0, :, :] = 0\n",
        "    return bg_list\n",
        "\n",
        "def evaluate_ae(sequences, model, id, dt, bg_list=[], mask=1):\n",
        "  \n",
        "    sz = len(sequences)\n",
        "\n",
        "    reconstructed_sequences = model.predict(sequences,batch_size=conf.BATCH_SIZE)\n",
        "    #print(bg_list[10])\n",
        "\n",
        "    masked_bg = mask_array(bg_list)\n",
        "    bg_clips = get_clips(masked_bg)\n",
        "\n",
        "    sequences = np.reshape(sequences, (sequences.shape[0], sequences.shape[1], sequences.shape[2], sequences.shape[3]))\n",
        "    reconstructed_sequences = np.reshape(reconstructed_sequences, (reconstructed_sequences.shape[0], reconstructed_sequences.shape[1], reconstructed_sequences.shape[2], reconstructed_sequences.shape[3]))\n",
        "\n",
        "    if mask == 1:\n",
        "        print(\"==============With BG Masked==============\")\n",
        "        sq_masked = np.multiply(sequences, bg_clips)\n",
        "        rec_masked = np.multiply(reconstructed_sequences, bg_clips)\n",
        "    else:\n",
        "        print(\"==============Without BG Masked==============\")\n",
        "        sq_masked = sequences\n",
        "        rec_masked = reconstructed_sequences\n",
        "\n",
        "    sequences_reconstruction_cost = np.array([np.linalg.norm(np.subtract(sq_masked[i], rec_masked[i])) for i in range(0,sz)])\n",
        "    sa = (sequences_reconstruction_cost - np.min(sequences_reconstruction_cost)) / (np.max(sequences_reconstruction_cost))\n",
        "\n",
        "    \n",
        "    sr = 1 - sa\n",
        "    threshold_abs = threshold#np.min(sr)+ (np.max(sr) - np.min(sr)) * threshold\n",
        "    if dt == 1:\n",
        "        fill_gt_ped1(sr, id, 'yellow', threshold_abs)\n",
        "    elif dt == 2:\n",
        "        fill_gt_ped2(sr, id, 'yellow', threshold_abs)\n",
        "    #plt.plot(sr)\n",
        "    #plt.ylabel('regularity score sr_ae(t)')\n",
        "    #plt.xlabel('frame t')\n",
        "    #plt.show()\n",
        "    \n",
        "\n",
        "def load_input_data_list():\n",
        "    path = join(\"/content/drive/My Drive/\", 'sr_score.csv')\n",
        "    InputDataList = LoadData(path)\n",
        "    return InputDataList\n",
        "\n",
        "\n",
        "def get_persistance(InputData):\n",
        "  #~ This simple call is all you need to compute the extrema of the given data and their persistence.\n",
        "  ExtremaAndPersistence = RunPersistence(InputData)\n",
        "\n",
        "  #~ Keep only those extrema with a persistence larger than 10.\n",
        "  Filtered = [t for t in ExtremaAndPersistence if ExtremaAndPersistence[1] > 50]\n",
        "  print(ExtremaAndPersistence)\n",
        "  print(Filtered)\n",
        "  #~ Sort the list of extrema by persistence.\n",
        "  #Sorted = sorted(Filtered, key=lambda ExtremumAndPersistence: ExtremumAndPersistence[1])\n",
        "\n",
        "  return Filtered\n",
        "\n",
        "\n",
        "conf.reconfig(new_name=\"Conv2DLSTM_AAE_PED1\", batch_size=4, epochs=100, retrain=1)\n",
        "\n",
        "def get_background_subtr(test_case):\n",
        "    print(\"BGS show\")\n",
        "    subtractor = cv2.createBackgroundSubtractorMOG2(history=100, varThreshold=50, detectShadows=True)\n",
        "    bg_list = []\n",
        "    for frame in test_case:\n",
        "        frame = np.reshape(frame, (256, 256))*256\n",
        "        mask = subtractor.apply(frame)\n",
        "        kernel = np.ones((3,3), np.uint8) \n",
        "        fg_mask = cv2.erode(mask, kernel, iterations=2)\n",
        "        #fg_mask = fg_mask/255.0\n",
        "        #cv2_imshow(fg_mask)\n",
        "        #print(fg_mask)\n",
        "        bg_list.append(fg_mask)\n",
        "        #key = cv2.waitKey(30)\n",
        "        #if key == 27:\n",
        "        #    break\n",
        "    #cv2.destroyAllWindows()\n",
        "    #print(bg_list)\n",
        "    return np.array(bg_list)\n",
        "\n",
        "\n",
        "def show_bgs(test_case_dir):\n",
        "    test = get_single_test(join(conf.TEST_DIR,test_case_dir))\n",
        "    return get_background_subtr(test)\n",
        "\n",
        "\n",
        "\n",
        "#print(bg_list[10])\n",
        "for i in range(1,37):\n",
        "  if i < 10:\n",
        "    img_num = \"00\"+str(i)\n",
        "  elif i < 100:\n",
        "    img_num = \"0\"+str(i)\n",
        "  else:\n",
        "    img_num = str(i) \n",
        "\n",
        "  #if img_num == \"017\":\n",
        "  #  continue\n",
        "\n",
        "  bg_list = show_bgs(\"Test\"+img_num)\n",
        "  test_cases_dir = \"Test\"+img_num\n",
        "  test_cases = get_test_sequences(test_cases_dir)\n",
        "  print(\"Test\"+img_num+\" data set loaded\")\n",
        "  #evaluate_dis(test_cases, model_enc_disc, i, 1)\n",
        "  #sorted_sr = get_persistance(np.array([x[0] for x in sr_dis], dtype=float))\n",
        "  #print(sorted_sr)\n",
        "  #break\n",
        "  evaluate_ae(test_cases, model_ae, i, 1, bg_list, 1)\n",
        "  evaluate_ae(test_cases, model_ae, i, 1, bg_list, 0)\n",
        "  #sr_comb = (sr_dis + sr_ae)*0.5\n",
        "  #sr_comb = []\n",
        "\n",
        "  continue\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}