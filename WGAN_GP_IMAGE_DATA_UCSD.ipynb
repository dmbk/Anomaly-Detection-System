{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "WGAN_GP_IMAGE_DATA_UCSD.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPlTZ24rWNaYM5u+2FBJ/y6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dmbk/Anomaly-Detection-System/blob/master/WGAN_GP_IMAGE_DATA_UCSD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBLtnudvoG99",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from __future__ import print_function, division\n",
        "\n",
        "from keras.datasets import mnist\n",
        "from keras.layers.merge import _Merge\n",
        "from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
        "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
        "from keras.models import Sequential, Model\n",
        "from keras.optimizers import RMSprop\n",
        "from functools import partial\n",
        "\n",
        "import keras.backend as K\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import sys\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "class RandomWeightedAverage(_Merge):\n",
        "    \"\"\"Provides a (random) weighted average between real and generated image samples\"\"\"\n",
        "    def _merge_function(self, inputs):\n",
        "        alpha = K.random_uniform((32, 1, 1, 1))\n",
        "        return (alpha * inputs[0]) + ((1 - alpha) * inputs[1])\n",
        "\n",
        "class WGANGP():\n",
        "    def __init__(self):\n",
        "        self.DATASET_PATH = \"/content/drive/My Drive/UCSD_Anomaly_Dataset.v1p2/UCSDped1/Train/\"\n",
        "        self.img_rows = 256\n",
        "        self.img_cols = 256\n",
        "        self.channels = 1\n",
        "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
        "        self.latent_dim = 100\n",
        "\n",
        "        # Following parameter and optimizer set as recommended in paper\n",
        "        self.n_critic = 5\n",
        "        optimizer = RMSprop(lr=0.00005)\n",
        "\n",
        "        # Build the generator and critic\n",
        "        self.generator = self.build_generator()\n",
        "        self.critic = self.build_critic()\n",
        "\n",
        "        #-------------------------------\n",
        "        # Construct Computational Graph\n",
        "        #       for the Critic\n",
        "        #-------------------------------\n",
        "\n",
        "        # Freeze generator's layers while training critic\n",
        "        self.generator.trainable = False\n",
        "\n",
        "        # Image input (real sample)\n",
        "        real_img = Input(shape=self.img_shape)\n",
        "\n",
        "        # Noise input\n",
        "        z_disc = Input(shape=(self.latent_dim,))\n",
        "        # Generate image based of noise (fake sample)\n",
        "        fake_img = self.generator(z_disc)\n",
        "\n",
        "        # Discriminator determines validity of the real and fake images\n",
        "        fake = self.critic(fake_img)\n",
        "        valid = self.critic(real_img)\n",
        "\n",
        "        # Construct weighted average between real and fake images\n",
        "        interpolated_img = RandomWeightedAverage()([real_img, fake_img])\n",
        "        # Determine validity of weighted sample\n",
        "        validity_interpolated = self.critic(interpolated_img)\n",
        "\n",
        "        # Use Python partial to provide loss function with additional\n",
        "        # 'averaged_samples' argument\n",
        "        partial_gp_loss = partial(self.gradient_penalty_loss,\n",
        "                          averaged_samples=interpolated_img)\n",
        "        partial_gp_loss.__name__ = 'gradient_penalty' # Keras requires function names\n",
        "\n",
        "        self.critic_model = Model(inputs=[real_img, z_disc],\n",
        "                            outputs=[valid, fake, validity_interpolated])\n",
        "        self.critic_model.compile(loss=[self.wasserstein_loss,\n",
        "                                              self.wasserstein_loss,\n",
        "                                              partial_gp_loss],\n",
        "                                        optimizer=optimizer,\n",
        "                                        loss_weights=[1, 1, 10])\n",
        "        #-------------------------------\n",
        "        # Construct Computational Graph\n",
        "        #         for Generator\n",
        "        #-------------------------------\n",
        "\n",
        "        # For the generator we freeze the critic's layers\n",
        "        self.critic.trainable = False\n",
        "        self.generator.trainable = True\n",
        "\n",
        "        # Sampled noise for input to generator\n",
        "        z_gen = Input(shape=(self.latent_dim,))\n",
        "        # Generate images based of noise\n",
        "        img = self.generator(z_gen)\n",
        "        # Discriminator determines validity\n",
        "        valid = self.critic(img)\n",
        "        # Defines generator model\n",
        "        self.generator_model = Model(z_gen, valid)\n",
        "        self.generator_model.compile(loss=self.wasserstein_loss, optimizer=optimizer)\n",
        "\n",
        "    \n",
        "    def load_training_data(self):\n",
        "\n",
        "        all_frames_merged = []\n",
        "        # loop over the training folders (Train000,Train001,..)\n",
        "        for f in sorted(listdir(self.DATASET_PATH)):\n",
        "            directory_path = join(self.DATASET_PATH, f)\n",
        "            if isdir(directory_path):\n",
        "\n",
        "                # loop over all the images in the folder (0.tif,1.tif,..,199.tif)\n",
        "                for c in sorted(listdir(directory_path)):\n",
        "                    img_path = join(directory_path, c)\n",
        "                    if str(img_path)[-3:] == \"tif\":\n",
        "                        img = Image.open(img_path).resize((256, 256))\n",
        "                        img = np.array(img, dtype=np.float32)\n",
        "                        img = (img - 127.5)/127.5\n",
        "                        #img = (2*(img - np.amin(img))/(np.amax(img) - np.amin(img)))-1\n",
        "                        #img = np.array(img, dtype=np.float32) / 256.0\n",
        "                        all_frames_merged.append(img)\n",
        "             \n",
        "        return all_frames_merged\n",
        "    \n",
        "    \n",
        "\n",
        "    def gradient_penalty_loss(self, y_true, y_pred, averaged_samples):\n",
        "\n",
        "        gradients = K.gradients(y_pred, averaged_samples)[0]\n",
        "        # compute the euclidean norm by squaring ...\n",
        "        gradients_sqr = K.square(gradients)\n",
        "        #   ... summing over the rows ...\n",
        "        gradients_sqr_sum = K.sum(gradients_sqr,\n",
        "                                  axis=np.arange(1, len(gradients_sqr.shape)))\n",
        "        #   ... and sqrt\n",
        "        gradient_l2_norm = K.sqrt(gradients_sqr_sum)\n",
        "        # compute lambda * (1 - ||grad||)^2 still for each single sample\n",
        "        gradient_penalty = K.square(1 - gradient_l2_norm)\n",
        "        # return the mean as loss over all the batch samples\n",
        "        return K.mean(gradient_penalty)\n",
        "\n",
        "\n",
        "    def wasserstein_loss(self, y_true, y_pred):\n",
        "        return K.mean(y_true * y_pred)\n",
        "\n",
        "    def build_generator(self):\n",
        "\n",
        "        model = Sequential()\n",
        "\n",
        "        model.add(Dense(128 * 16 * 16, activation=\"relu\", input_dim=self.latent_dim))\n",
        "        model.add(Reshape((16, 16, 128)))\n",
        "        model.add(UpSampling2D())\n",
        "        model.add(Conv2D(128, kernel_size=4, padding=\"same\"))\n",
        "        model.add(BatchNormalization(momentum=0.8))\n",
        "        model.add(Activation(\"relu\"))\n",
        "        model.add(UpSampling2D())\n",
        "        model.add(Conv2D(64, kernel_size=4, padding=\"same\"))\n",
        "        model.add(BatchNormalization(momentum=0.8))\n",
        "        model.add(Activation(\"relu\"))\n",
        "        model.add(UpSampling2D())\n",
        "        model.add(Conv2D(32, kernel_size=4, padding=\"same\"))\n",
        "        model.add(BatchNormalization(momentum=0.8))\n",
        "        model.add(Activation(\"relu\"))\n",
        "        model.add(UpSampling2D())\n",
        "        model.add(Conv2D(16, kernel_size=4, padding=\"same\"))\n",
        "        model.add(BatchNormalization(momentum=0.8))\n",
        "        model.add(Activation(\"relu\"))\n",
        "        model.add(Conv2D(self.channels, kernel_size=4, padding=\"same\"))\n",
        "        model.add(Activation(\"tanh\"))\n",
        "\n",
        "        model.summary()\n",
        "\n",
        "        noise = Input(shape=(self.latent_dim,))\n",
        "        img = model(noise)\n",
        "\n",
        "        return Model(noise, img)\n",
        "\n",
        "    def build_critic(self):\n",
        "\n",
        "        model = Sequential()\n",
        "\n",
        "        model.add(Conv2D(16, kernel_size=3, strides=2, input_shape=self.img_shape, padding=\"same\"))\n",
        "        model.add(LeakyReLU(alpha=0.2))\n",
        "        model.add(Dropout(0.25))\n",
        "        model.add(Conv2D(32, kernel_size=3, strides=2, padding=\"same\"))\n",
        "        model.add(ZeroPadding2D(padding=((0,1),(0,1))))\n",
        "        model.add(BatchNormalization(momentum=0.8))\n",
        "        model.add(LeakyReLU(alpha=0.2))\n",
        "        model.add(Dropout(0.25))\n",
        "        model.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n",
        "        model.add(BatchNormalization(momentum=0.8))\n",
        "        model.add(LeakyReLU(alpha=0.2))\n",
        "        model.add(Dropout(0.25))\n",
        "        model.add(Conv2D(128, kernel_size=3, strides=1, padding=\"same\"))\n",
        "        model.add(BatchNormalization(momentum=0.8))\n",
        "        model.add(LeakyReLU(alpha=0.2))\n",
        "        model.add(Dropout(0.25))\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(1))\n",
        "\n",
        "        model.summary()\n",
        "\n",
        "        img = Input(shape=self.img_shape)\n",
        "        validity = model(img)\n",
        "\n",
        "        return Model(img, validity)\n",
        "\n",
        "    def train(self, epochs, batch_size, sample_interval=50):\n",
        "\n",
        "        # Load the dataset\n",
        "        X_train = self.load_training_data()\n",
        "\n",
        "        # Rescale -1 to 1\n",
        "        #X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
        "        X_train = np.expand_dims(X_train, axis=3)\n",
        "\n",
        "        # Adversarial ground truths\n",
        "        valid = -np.ones((batch_size, 1))\n",
        "        fake =  np.ones((batch_size, 1))\n",
        "        dummy = np.zeros((batch_size, 1)) # Dummy gt for gradient penalty\n",
        "        for epoch in range(epochs):\n",
        "\n",
        "            for _ in range(self.n_critic):\n",
        "\n",
        "                # ---------------------\n",
        "                #  Train Discriminator\n",
        "                # ---------------------\n",
        "\n",
        "                # Select a random batch of images\n",
        "                idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
        "                imgs = X_train[idx]\n",
        "                # Sample generator input\n",
        "                noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n",
        "                # Train the critic\n",
        "                d_loss = self.critic_model.train_on_batch([imgs, noise],\n",
        "                                                                [valid, fake, dummy])\n",
        "\n",
        "            # ---------------------\n",
        "            #  Train Generator\n",
        "            # ---------------------\n",
        "\n",
        "            g_loss = self.generator_model.train_on_batch(noise, valid)\n",
        "\n",
        "            # Plot the progress\n",
        "            print (\"%d [D loss: %f] [G loss: %f]\" % (epoch, d_loss[0], g_loss))\n",
        "\n",
        "            # If at save interval => save generated image samples\n",
        "            if epoch % sample_interval == 0:\n",
        "                self.sample_images(epoch)\n",
        "\n",
        "    def sample_images(self, epoch):\n",
        "        r, c = 5, 5\n",
        "        noise = np.random.normal(0, 1, (r * c, self.latent_dim))\n",
        "        gen_imgs = self.generator.predict(noise)\n",
        "\n",
        "        # Rescale images 0 - 1\n",
        "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
        "\n",
        "        fig, axs = plt.subplots(r, c)\n",
        "        cnt = 0\n",
        "        for i in range(r):\n",
        "            for j in range(c):\n",
        "                axs[i,j].imshow(gen_imgs[cnt, :,:,0], cmap='gray')\n",
        "                axs[i,j].axis('off')\n",
        "                cnt += 1\n",
        "        fig.savefig(\"images/mnist_%d.png\" % epoch)\n",
        "        plt.close()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7L0dBTruhsy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "66878618-3ee6-42e0-8e13-cd734656b630"
      },
      "source": [
        "if __name__ == '__main__':\n",
        "    wgan = WGANGP()\n",
        "    #wgan.train(epochs=30000, batch_size=32, sample_interval=100)\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_5 (Dense)              (None, 32768)             3309568   \n",
            "_________________________________________________________________\n",
            "reshape_3 (Reshape)          (None, 16, 16, 128)       0         \n",
            "_________________________________________________________________\n",
            "up_sampling2d_5 (UpSampling2 (None, 32, 32, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_15 (Conv2D)           (None, 32, 32, 128)       262272    \n",
            "_________________________________________________________________\n",
            "batch_normalization_11 (Batc (None, 32, 32, 128)       512       \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 32, 32, 128)       0         \n",
            "_________________________________________________________________\n",
            "up_sampling2d_6 (UpSampling2 (None, 64, 64, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_16 (Conv2D)           (None, 64, 64, 64)        131136    \n",
            "_________________________________________________________________\n",
            "batch_normalization_12 (Batc (None, 64, 64, 64)        256       \n",
            "_________________________________________________________________\n",
            "activation_8 (Activation)    (None, 64, 64, 64)        0         \n",
            "_________________________________________________________________\n",
            "up_sampling2d_7 (UpSampling2 (None, 128, 128, 64)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_17 (Conv2D)           (None, 128, 128, 32)      32800     \n",
            "_________________________________________________________________\n",
            "batch_normalization_13 (Batc (None, 128, 128, 32)      128       \n",
            "_________________________________________________________________\n",
            "activation_9 (Activation)    (None, 128, 128, 32)      0         \n",
            "_________________________________________________________________\n",
            "up_sampling2d_8 (UpSampling2 (None, 256, 256, 32)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_18 (Conv2D)           (None, 256, 256, 16)      8208      \n",
            "_________________________________________________________________\n",
            "batch_normalization_14 (Batc (None, 256, 256, 16)      64        \n",
            "_________________________________________________________________\n",
            "activation_10 (Activation)   (None, 256, 256, 16)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_19 (Conv2D)           (None, 256, 256, 1)       257       \n",
            "_________________________________________________________________\n",
            "activation_11 (Activation)   (None, 256, 256, 1)       0         \n",
            "=================================================================\n",
            "Total params: 3,745,201\n",
            "Trainable params: 3,744,721\n",
            "Non-trainable params: 480\n",
            "_________________________________________________________________\n",
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_20 (Conv2D)           (None, 128, 128, 16)      160       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_9 (LeakyReLU)    (None, 128, 128, 16)      0         \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 128, 128, 16)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_21 (Conv2D)           (None, 64, 64, 32)        4640      \n",
            "_________________________________________________________________\n",
            "zero_padding2d_3 (ZeroPaddin (None, 65, 65, 32)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_15 (Batc (None, 65, 65, 32)        128       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_10 (LeakyReLU)   (None, 65, 65, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 65, 65, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_22 (Conv2D)           (None, 33, 33, 64)        18496     \n",
            "_________________________________________________________________\n",
            "batch_normalization_16 (Batc (None, 33, 33, 64)        256       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_11 (LeakyReLU)   (None, 33, 33, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 33, 33, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_23 (Conv2D)           (None, 33, 33, 128)       73856     \n",
            "_________________________________________________________________\n",
            "batch_normalization_17 (Batc (None, 33, 33, 128)       512       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_12 (LeakyReLU)   (None, 33, 33, 128)       0         \n",
            "_________________________________________________________________\n",
            "dropout_12 (Dropout)         (None, 33, 33, 128)       0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 139392)            0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 1)                 139393    \n",
            "=================================================================\n",
            "Total params: 237,441\n",
            "Trainable params: 236,993\n",
            "Non-trainable params: 448\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJC2kyAotDz6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "2aa58a9a-d603-4e39-a3ee-d6f080723d88"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}