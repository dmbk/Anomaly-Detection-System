{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TEST_AAE.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP7c8VWGmB+5RpYVJNN7jTE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dmbk/Anomaly-Detection-System/blob/master/TEST_AAE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVE526Rfl8ed",
        "colab_type": "code",
        "outputId": "d3fdfccc-5ea7-4373-db13-692a6e5c55c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        }
      },
      "source": [
        "!pip install imageio\n",
        "!pip install qpsolvers\n",
        "#!pip install tensorflow_datasets\n",
        "!pip install keras-layer-normalization\n",
        "from google.colab import drive\n",
        "#!pip install alive-progress\n",
        "drive.mount('/content/drive', force_remount=True)\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: imageio in /usr/local/lib/python3.6/dist-packages (2.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from imageio) (1.18.3)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from imageio) (7.0.0)\n",
            "Requirement already satisfied: qpsolvers in /usr/local/lib/python3.6/dist-packages (1.1)\n",
            "Requirement already satisfied: quadprog in /usr/local/lib/python3.6/dist-packages (from qpsolvers) (0.1.7)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.6/dist-packages (from quadprog->qpsolvers) (0.29.16)\n",
            "Requirement already satisfied: keras-layer-normalization in /usr/local/lib/python3.6/dist-packages (0.14.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from keras-layer-normalization) (1.18.3)\n",
            "Requirement already satisfied: Keras in /usr/local/lib/python3.6/dist-packages (from keras-layer-normalization) (2.3.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-layer-normalization) (1.12.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-layer-normalization) (1.4.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras->keras-layer-normalization) (3.13)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-layer-normalization) (1.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras->keras-layer-normalization) (2.10.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-layer-normalization) (1.1.0)\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drSah6JgmAU_",
        "colab_type": "code",
        "outputId": "ae5b1453-af56-4dd6-a30e-ceb2b143686c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "\n",
        "import skimage\n",
        "import glob\n",
        "import imageio\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "from PIL import Image\n",
        "from os.path import join\n",
        "from os import listdir\n",
        "from os.path import isfile, join, isdir\n",
        "\n",
        "#import keras\n",
        "import argparse\n",
        "from os.path import dirname\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\t\n",
        "import statistics\n",
        "import shutil\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import time\n",
        "#from progress.bar import IncrementalBar\n",
        "\n",
        "import numpy as np\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Input, Dense, Reshape, Flatten\n",
        "from keras.layers import Conv2DTranspose, ConvLSTM2D, BatchNormalization, TimeDistributed, Conv2D, Dropout, Activation, InputLayer\n",
        "from keras.optimizers import Adam\n",
        "from keras_layer_normalization import LayerNormalization\n",
        "from keras.models import load_model\n",
        "import csv"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bJ798qPmI9L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_single_test(single_test_path):\n",
        "    \n",
        "    sz = 0\n",
        "    for f in sorted(listdir(single_test_path)):\n",
        "        if str(join(single_test_path, f))[-3:] == \"tif\":\n",
        "          sz = sz +1\n",
        "    test = np.zeros(shape=(sz, conf.dim2, conf.dim3, conf.dim4))\n",
        "    cnt = 0\n",
        "    for f in sorted(listdir(single_test_path)):\n",
        "        if str(join(single_test_path, f))[-3:] == \"tif\":\n",
        "            #print(\"img path: \"+join(single_test_path, f))\n",
        "            img = Image.open(join(single_test_path, f)).resize((conf.dim2, conf.dim3))\n",
        "            #cv2_imshow(np.array(img,dtype=np.float32))\n",
        "            #cv2.waitKey(0)\n",
        "            img = np.array(img, dtype=np.float32) / 256\n",
        "            test[cnt, :, :, 0] = img\n",
        "            cnt = cnt + 1\n",
        "    return test\n",
        "\n",
        "def get_test_sequences(test_case_dir):\n",
        "    test = get_single_test(join(conf.TEST_DIR,test_case_dir))\n",
        "    print(\"Test case loaded\")\n",
        "    sz = test.shape[0] - conf.dim1\n",
        "    sequences = np.zeros((sz, conf.dim1, conf.dim2, conf.dim3, conf.dim4))\n",
        "    # apply the sliding window technique to get the sequences\n",
        "    for i in range(0, sz):\n",
        "        clip = np.zeros((conf.dim1, conf.dim2, conf.dim3, conf.dim4))\n",
        "        for j in range(0, conf.dim1):\n",
        "            clip[j] = test[i + j, :, :, :]\n",
        "        sequences[i] = clip\n",
        "    return sequences\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UkgtzofEvwlU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Config:\n",
        "    def __init__(self, data_dir_, cwdir_name_, data_set):\n",
        "        self.data_set_name = data_set\n",
        "        self.data_dir = data_dir_\n",
        "        self.data_set_dir = join(self.data_dir, data_set)\n",
        "        self.cwdir_name = cwdir_name_\n",
        "        self.cwdir = join(self.data_dir,self.cwdir_name)\n",
        "        self.run_data = join(self.cwdir, \"training_dir\")\n",
        "        self.image_dir = join(self.run_data,self.data_set_name,\"Test/\")\n",
        "        if not os.path.exists(self.cwdir):\n",
        "            os.mkdir(self.cwdir)\n",
        "            os.mkdir(self.run_data)\n",
        "    \n",
        "        if not os.path.exists(self.run_data):\n",
        "            #shutil.rmtree(self.run_data)\n",
        "            os.mkdir(self.run_data)\n",
        "            os.makedirs(self.image_dir, exist_ok=True)\n",
        "\n",
        "        self.DATASET_PATH = join(self.data_set_dir,\"Train/\")\n",
        "        self.TEST_DIR = join(self.data_set_dir,\"Test/\")\n",
        "        self.BATCH_SIZE = 2\n",
        "        self.EPOCHS = 50\n",
        "        self.GEN_MODEL_PATH = join(self.cwdir,\"model_gen_Conv2DLSTM_AAE\")\n",
        "        self.DIS_MODEL_PATH = join(self.cwdir,\"model_dis_Conv2DLSTM_AAE\")\n",
        "        self.DEC_MODEL_PATH = join(self.cwdir,\"model_dec_Conv2DLSTM_AAE\")\n",
        "\n",
        "        self.retrain = 0\n",
        "        self.dim1 = 10\n",
        "        self.dim2 = 256\n",
        "        self.dim3 = 256\n",
        "        self.dim4 = 1\n",
        "        self.latent_dim = 327680\n",
        "\n",
        "\n",
        "    def reconfig(self, new_name, batch_size = 4, epochs = 5, retrain = 0):\n",
        "        self.cwdir_name = new_name\n",
        "        self.cwdir = join(self.data_dir, self.cwdir_name)\n",
        "        self.run_data = join(self.cwdir, \"training_dir\")\n",
        "        self.image_dir = join(self.run_data,self.data_set_name,\"Test/\")\n",
        "\n",
        "        self.BATCH_SIZE = batch_size\n",
        "        self.EPOCHS = epochs\n",
        "        self.GEN_MODEL_PATH = join(self.cwdir,\"model_gen_Conv2DLSTM_AAE\")\n",
        "        self.DIS_MODEL_PATH = join(self.cwdir,\"model_dis_Conv2DLSTM_AAE\")\n",
        "        self.DEC_MODEL_PATH = join(self.cwdir,\"model_dec_Conv2DLSTM_AAE\")\n",
        "\n",
        "        self.retrain = retrain\n",
        "        if retrain == 0:\n",
        "            print(\"Configuring train from scratch\")\n",
        "            if not os.path.exists(self.cwdir):\n",
        "                os.mkdir(self.cwdir)\n",
        "                os.mkdir(self.run_data)\n",
        "    \n",
        "            if os.path.exists(self.run_data):\n",
        "                shutil.rmtree(self.run_data)\n",
        "                os.mkdir(self.run_data)\n",
        "                os.makedirs(self.image_dir, exist_ok=True)\n",
        "\n",
        "\n",
        "conf = Config(data_dir_=\"/content/drive/My Drive/\", cwdir_name_=\"Conv2DLSTM_AAE_PED1\", data_set=\"UCSD_Anomaly_Dataset.v1p2/UCSDped1/\") \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dzdc2hrlftUv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from persistence1d import RunPersistence\n",
        "from reconstruct1d import RunReconstruction\n",
        "from examples_visualize import Visualize\n",
        "\n",
        "\"\"\"\n",
        "The file exemplifies different use cases for Reconstruct1D:\n",
        "\n",
        "* Loading data from file\n",
        "* Generating data in memory with different shapes and noise\n",
        "* Running Persistence1D to obtain minima/maxima and their persistence\n",
        "* Filtering minima/maxima by their persistence\n",
        "* Running Reconstruct1D with the filtered set of extrema to obtain a smoothed version of the input data.\n",
        "   Notably, this new data contains only the filtered minima/maxima.\n",
        "* Creating a smooth function using user-defined minima/maxima and data values.\n",
        "* Influence of the biharmonic or triharmonic smoothing setting\n",
        "* Influence of the Data Weight parameter\n",
        "* Increasing the output's resolution to obtain smoother results\n",
        "* Visualizing the (filtered) list of minima/maxima together with the input/smoothed data\n",
        "\"\"\"\n",
        "\n",
        "def LoadData():\n",
        "    InputDataList = []\n",
        "    with open('sr_score.csv', newline='') as csvfile:\n",
        "      reader = csv.reader(csvfile, delimiter=',')\n",
        "      for row in reader:\n",
        "          row = np.array(reader, dtype=float)\n",
        "          InputDataList.append(row)        \n",
        "    return InputDataList\n",
        "\n",
        "\n",
        "def IncreaseDataResolution(InputData, SuperSample):\n",
        "    #~ Increase resolution by straightforward linear interpolation between original samples.\n",
        "    #~ This yields the same topology. The smoothed output will be smoother.\n",
        "    if (SuperSample > 1):\n",
        "        from scipy.interpolate import interp1d\n",
        "        x = np.linspace(0, len(InputData)-1, num = len(InputData), endpoint=True)\n",
        "        f = interp1d(x, InputData)\n",
        "        xnew = np.linspace(0, len(InputData)-1, num = len(InputData) + SuperSample*(len(InputData)-1), endpoint=True)\n",
        "        InputData = f(xnew)\n",
        "    return InputData\n",
        "\n",
        "\n",
        "def FilterExtremaByPersistence(ExtremaAndPersistence, Threshhold):\n",
        "    FilteredExtremaAndPersistence = [t for t in ExtremaAndPersistence if t[1] > Threshhold]\n",
        "    return FilteredExtremaAndPersistence\n",
        "\n",
        "\n",
        "def ComputeExtremaAndPersistence(InputData):\n",
        "    #~ This simple call is all you need to compute the extrema of the given data and their persistence.\n",
        "    ExtremaAndPersistence = RunPersistence(InputData)\n",
        "    return ExtremaAndPersistence\n",
        "\n",
        "\n",
        "def smoothen(InputDataList):\n",
        "\n",
        "    if not InputDataList:\n",
        "        InputDataList = LoadData()\n",
        "    for(j,InputData) in enumerate(InputDatList):\n",
        "        Extrema = ComputeExtremaAndPersistence(InputData)\n",
        "        for (i, PersistenceThreshold) in enumerate([0.5]):\n",
        "            Filtered = FilterExtremaByPersistence(Extrema, PersistenceThreshold)\n",
        "            SmoothData = RunReconstruction(InputData, [t[0] for t in Filtered], 'biharmonic', 0)\n",
        "            Visualize(SmoothData, Filtered, None, 'extrema data fat', DataLabel=\"Smoothed Data with Persistence Threshold %g\" % PersistenceThreshold, SaveFilename=\"Reconstruct1D_Test_%d.png\" % j)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GAXfjsTem0oM",
        "colab_type": "code",
        "outputId": "75f7a5f6-5b5d-4a21-fba9-9d5fc09a223f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "def build_model_aae():\n",
        "  \n",
        "    model_enc = load_model(conf.cwdir+\"/model_gen_Conv2DLSTM_AAEep50\",custom_objects={'LayerNormalization': LayerNormalization})\n",
        "    model_dec = load_model(conf.cwdir+\"/model_dec_Conv2DLSTM_AAEep50\",custom_objects={'LayerNormalization': LayerNormalization})\n",
        "    model_disc = load_model(conf.cwdir+\"/model_dis_Conv2DLSTM_AAEep50\",custom_objects={'LayerNormalization': LayerNormalization})\n",
        "\n",
        "    #model_enc = load_model(\"/content/drive/My Drive/model_gen_Conv2DLSTM_AAEep100\",custom_objects={'LayerNormalization': LayerNormalization})\n",
        "    #model_dec = load_model(\"/content/drive/My Drive/model_dec_Conv2DLSTM_AAEep100\",custom_objects={'LayerNormalization': LayerNormalization})\n",
        "    #model_disc = load_model(\"/content/drive/My Drive/model_dis_Conv2DLSTM_AAEep100\",custom_objects={'LayerNormalization': LayerNormalization})\n",
        "\n",
        "    model_ae = Sequential()\n",
        "    model_ae.add(model_enc)\n",
        "    model_ae.add(model_dec)\n",
        "    \n",
        "    model_enc_disc = Sequential()\n",
        "    model_enc_disc.add(model_enc)\n",
        "    model_enc_disc.add(model_disc)\n",
        "    \n",
        "    return model_enc, model_dec, model_disc, model_ae, model_enc_disc\n",
        "\n",
        "model_enc, model_dec, model_disc, model_ae, model_enc_disc = build_model_aae()\n",
        "\n",
        "model_enc.summary()\n",
        "model_dec.summary()\n",
        "model_disc.summary()\n",
        "model_ae.summary()\n",
        "model_enc_disc.summary()\n",
        "\n",
        "model_disc.compile(optimizer=Adam(lr=1e-4), loss=\"binary_crossentropy\")\n",
        "model_enc_disc.compile(optimizer=Adam(lr=1e-4), loss=\"binary_crossentropy\")\n",
        "model_ae.compile(optimizer=Adam(lr=1e-4, decay=1e-5, epsilon=1e-6), loss=\"mse\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def evaluate_dis(sequences, model):\n",
        "    fooling_loss = model.predict(sequences,batch_size=conf.BATCH_SIZE)\n",
        "    sr = (fooling_loss - np.min(fooling_loss)) / (np.max(fooling_loss) - np.min(fooling_loss))\n",
        "    #sr = 1.0 - sa\n",
        "\n",
        "    with open(join(\"/content/drive/My Drive/\", 'sr_score.csv'), mode='a') as f:\n",
        "        writer = csv.writer(f)\n",
        "        writer.writerow(sr)\n",
        "        f.close()\n",
        "\n",
        "    plt.plot(sr)\n",
        "    plt.ylabel('regularity score sr_dis(t)')\n",
        "    plt.xlabel('frame t')\n",
        "    plt.show()\n",
        "    return sr\n",
        "\n",
        "def evaluate_ae(sequences, model):\n",
        "  \n",
        "    sz = len(sequences)\n",
        "\n",
        "    reconstructed_sequences = model.predict(sequences,batch_size=conf.BATCH_SIZE)\n",
        "\n",
        "    sequences_reconstruction_cost = np.array([np.linalg.norm(np.subtract(sequences[i],reconstructed_sequences[i])) for i in range(0,sz)])\n",
        "    sr = (sequences_reconstruction_cost - np.min(sequences_reconstruction_cost)) / (np.max(sequences_reconstruction_cost) - np.min(sequences_reconstruction_cost))\n",
        "    plt.plot(sr)\n",
        "    plt.ylabel('regularity score sr_ae(t)')\n",
        "    plt.xlabel('frame t')\n",
        "    plt.show()\n",
        "    return sr\n",
        "\n",
        "\n",
        "conf.reconfig(new_name=\"Conv2DLSTM_AAE_PED1\", batch_size=4, epochs=100, retrain=1)\n",
        "\n",
        "for i in range(1,37):\n",
        "  if i < 10:\n",
        "    img_num = \"00\"+str(i)\n",
        "  elif i < 100:\n",
        "    img_num = \"0\"+str(i)\n",
        "  else:\n",
        "    img_num = str(i) \n",
        "\n",
        "  if img_num == \"017\":\n",
        "    continue\n",
        "  test_cases_dir = \"Test\"+img_num\n",
        "  test_cases = get_test_sequences(test_cases_dir)\n",
        "  print(\"Test\"+img_num+\" data set loaded\")\n",
        "  sr_dis = evaluate_dis(test_cases, model_enc_disc)\n",
        "  smoothen([sr_dis])\n",
        "  #sr_ae = evaluate_ae(test_cases, model_enc_disc)\n",
        "  #sr_comb = (sr_dis + sr_ae)*0.5\n",
        "  #sr_comb = []\n",
        "\n",
        "\n",
        "  #for (item1, item2) in zip(sr_dis, sr_ae):\n",
        "  #  sr_comb.append((item1+item2)*0.5)\n",
        "  #plt.plot(sr_comb)\n",
        "  #plt.ylabel('regularity score sr_comb(t)')\n",
        "  #plt.xlabel('frame t')\n",
        "  #plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py:341: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
            "  warnings.warn('No training configuration found in save file: '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "time_distributed_7 (TimeDist (None, 10, 64, 64, 128)   15616     \n",
            "_________________________________________________________________\n",
            "layer_normalization_9 (Layer (None, 10, 64, 64, 128)   256       \n",
            "_________________________________________________________________\n",
            "time_distributed_8 (TimeDist (None, 10, 32, 32, 64)    204864    \n",
            "_________________________________________________________________\n",
            "layer_normalization_10 (Laye (None, 10, 32, 32, 64)    128       \n",
            "_________________________________________________________________\n",
            "conv_lst_m2d_5 (ConvLSTM2D)  (None, 10, 32, 32, 64)    295168    \n",
            "_________________________________________________________________\n",
            "layer_normalization_11 (Laye (None, 10, 32, 32, 64)    128       \n",
            "_________________________________________________________________\n",
            "conv_lst_m2d_6 (ConvLSTM2D)  (None, 10, 32, 32, 32)    110720    \n",
            "_________________________________________________________________\n",
            "layer_normalization_12 (Laye (None, 10, 32, 32, 32)    64        \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 327680)            0         \n",
            "=================================================================\n",
            "Total params: 626,944\n",
            "Trainable params: 626,944\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "reshape_3 (Reshape)          (None, 10, 32, 32, 32)    0         \n",
            "_________________________________________________________________\n",
            "conv_lst_m2d_7 (ConvLSTM2D)  (None, 10, 32, 32, 32)    73856     \n",
            "_________________________________________________________________\n",
            "layer_normalization_13 (Laye (None, 10, 32, 32, 32)    64        \n",
            "_________________________________________________________________\n",
            "conv_lst_m2d_8 (ConvLSTM2D)  (None, 10, 32, 32, 64)    221440    \n",
            "_________________________________________________________________\n",
            "layer_normalization_14 (Laye (None, 10, 32, 32, 64)    128       \n",
            "_________________________________________________________________\n",
            "time_distributed_9 (TimeDist (None, 10, 64, 64, 64)    102464    \n",
            "_________________________________________________________________\n",
            "layer_normalization_15 (Laye (None, 10, 64, 64, 64)    128       \n",
            "_________________________________________________________________\n",
            "time_distributed_10 (TimeDis (None, 10, 256, 256, 128) 991360    \n",
            "_________________________________________________________________\n",
            "layer_normalization_16 (Laye (None, 10, 256, 256, 128) 256       \n",
            "_________________________________________________________________\n",
            "time_distributed_11 (TimeDis (None, 10, 256, 256, 1)   15489     \n",
            "=================================================================\n",
            "Total params: 1,405,185\n",
            "Trainable params: 1,405,185\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "reshape_4 (Reshape)          (None, 10, 32, 32, 32)    0         \n",
            "_________________________________________________________________\n",
            "time_distributed_12 (TimeDis (None, 10, 16, 16, 16)    4624      \n",
            "_________________________________________________________________\n",
            "max_pooling3d_2 (MaxPooling3 (None, 5, 8, 8, 16)       0         \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 5120)              0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 5120)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 5121      \n",
            "=================================================================\n",
            "Total params: 9,745\n",
            "Trainable params: 0\n",
            "Non-trainable params: 9,745\n",
            "_________________________________________________________________\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "sequential_5 (Sequential)    (None, 327680)            626944    \n",
            "_________________________________________________________________\n",
            "sequential_6 (Sequential)    (None, 10, 256, 256, 1)   1405185   \n",
            "=================================================================\n",
            "Total params: 2,032,129\n",
            "Trainable params: 2,032,129\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "sequential_5 (Sequential)    (None, 327680)            626944    \n",
            "_________________________________________________________________\n",
            "sequential_7 (Sequential)    (None, 1)                 9745      \n",
            "=================================================================\n",
            "Total params: 636,689\n",
            "Trainable params: 626,944\n",
            "Non-trainable params: 9,745\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}