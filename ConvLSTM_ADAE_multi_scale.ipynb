{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ConvLSTM_ADAE_multi_scale.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dmbk/Anomaly-Detection-System/blob/master/ConvLSTM_ADAE_multi_scale.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZeDOtMkwIqL0",
        "colab_type": "code",
        "outputId": "abb0084a-936d-49c6-a3eb-33f465c5d6b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        }
      },
      "source": [
        "!pip install imageio\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: imageio in /usr/local/lib/python3.6/dist-packages (2.4.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from imageio) (7.0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from imageio) (1.18.2)\n",
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1qK4WayIRWG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7ce576df-7f15-450a-e98e-c26374472953"
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "import tensorflow as tf\n",
        "import skimage\n",
        "import glob\n",
        "import imageio\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "from PIL import Image\n",
        "from tensorflow.keras import layers\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "from IPython import display\n",
        "\n",
        "from os.path import join\n",
        "from os import listdir\n",
        "from os.path import isfile, join, isdir\n",
        "\n",
        "#import keras\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.layers import Input, Add, Activation, GaussianNoise, Reshape, LeakyReLU, Conv2DTranspose, Conv3DTranspose, ConvLSTM2D, BatchNormalization, LayerNormalization, TimeDistributed, Conv2D, Conv3D, ZeroPadding3D, MaxPooling2D, MaxPooling3D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.models import Sequential, load_model, Model\n",
        "from keras.optimizers import RMSprop\n",
        "import matplotlib.pyplot as plt\n",
        "import argparse\n",
        "from os.path import dirname\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\t\n",
        "from keras import backend\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.backend as K\n",
        "keras = tf.keras\n",
        "import statistics\n",
        "\n",
        "from keras.constraints import Constraint\n",
        "tf.keras.backend.set_floatx('float32')\n",
        "import shutil\n",
        "from matplotlib import pyplot"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27gwZwBqIxav",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Config:\n",
        "    def __init__(self, data_dir_, cwdir_name_, data_set):\n",
        "        self.data_set_name = data_set\n",
        "        self.data_dir = data_dir_\n",
        "        self.data_set_dir = join(self.data_dir, data_set)\n",
        "        self.cwdir_name = cwdir_name_\n",
        "        self.cwdir = join(self.data_dir,self.cwdir_name)\n",
        "        self.run_data = join(self.cwdir, \"training_gan\")\n",
        "        self.image_dir = join(self.run_data,self.data_set_name,\"Test/\")\n",
        "        if not os.path.exists(self.cwdir):\n",
        "            os.mkdir(self.cwdir)\n",
        "            os.mkdir(self.run_data)\n",
        "    \n",
        "        if not os.path.exists(self.run_data):\n",
        "            #shutil.rmtree(self.run_data)\n",
        "            os.mkdir(self.run_data)\n",
        "            os.makedirs(self.image_dir, exist_ok=True)\n",
        "\n",
        "        self.curr_epoch = 0\n",
        "        self.DATASET_PATH = join(self.data_set_dir,\"Train/\")\n",
        "        self.TEST_DIR = join(self.data_set_dir,\"Test/\")\n",
        "        self.BATCH_SIZE = 4\n",
        "        self.EPOCHS = 25\n",
        "        self.GEN_MODEL_PATH = join(self.cwdir,\"model_gen_Conv2DLSTM_GAN.hdf5\")\n",
        "        self.DIS_MODEL_PATH = join(self.cwdir,\"model_dis_Conv2DLSTM_GAN.hdf5\")\n",
        "        self.GAN_MODEL_PATH = join(self.cwdir,\"model_combined_Conv2DLSTM_GAN.hdf5\")\n",
        "        self.retrain = 0\n",
        "        self.curr_epoch = 1\n",
        "        self.dim1 = 10\n",
        "        self.dim2 = 256\n",
        "        self.dim3 = 256\n",
        "        self.dim4 = 1\n",
        "        self.n_critic = 1\n",
        "        self.r_alpha = 0.2\n",
        "\n",
        "    def reconfig(self, new_name, batch_size = 4, epochs = 5, retrain = 0, curr_epoch = 0):\n",
        "        self.cwdir_name = new_name\n",
        "        self.cwdir = join(self.data_dir, self.cwdir_name)\n",
        "        self.run_data = join(self.cwdir, \"training_gan\")\n",
        "        self.image_dir = join(self.run_data,self.data_set_name,\"Test/\")\n",
        "        \n",
        "        self.BATCH_SIZE = batch_size\n",
        "        self.EPOCHS = epochs\n",
        "        self.GEN_MODEL_PATH = join(self.cwdir,\"model_gen_Conv2DLSTM_GAN.hdf5\")\n",
        "        self.DIS_MODEL_PATH = join(self.cwdir,\"model_dis_Conv2DLSTM_GAN.hdf5\")\n",
        "        self.GAN_MODEL_PATH = join(self.cwdir,\"model_combined_Conv2DLSTM_GAN.hdf5\")\n",
        "        self.curr_epoch = 0\n",
        "        self.retrain = retrain\n",
        "        if retrain == 0:\n",
        "            print(\"Configuring train from scratch\")\n",
        "            if not os.path.exists(self.cwdir):\n",
        "                os.mkdir(self.cwdir)\n",
        "                os.mkdir(self.run_data)\n",
        "    \n",
        "            if os.path.exists(self.run_data):\n",
        "                shutil.rmtree(self.run_data)\n",
        "                os.mkdir(self.run_data)\n",
        "                os.makedirs(self.image_dir, exist_ok=True)\n",
        "        else:\n",
        "            print(\"Configuring retrain mode\\n\")\n",
        "            self.final_gen_path = join(self.run_data, \"generator_ep-\"+str(curr_epoch)+\".hdf5\")\n",
        "            self.final_disc_path = join(self.run_data, \"discriminator_ep-\"+str(curr_epoch)+\".hdf5\")\n",
        "            self.final_gan_path = join(self.run_data, \"gan_ep-\"+str(curr_epoch)+\".hdf5\")\n",
        "            self.curr_epoch = curr_epoch\n",
        "            print(\"Last epoch saved : \"+str(curr_epoch))\n",
        "\n",
        "class ModelContainer:\n",
        "    def __init__(self, y0, y1, y2):\n",
        "        self.generator = y0\n",
        "        self.discriminator = y1\n",
        "        self.gan = y2\n",
        " \n",
        " # clip model weights to a given hypercube\n",
        "class ClipConstraint(Constraint):\n",
        "\t# set clip value when initialized\n",
        "\tdef __init__(self, clip_value):\n",
        "\t\tself.clip_value = clip_value\n",
        "\n",
        "\t# clip model weights to hypercube\n",
        "\tdef __call__(self, weights):\n",
        "\t\treturn backend.clip(weights, -self.clip_value, self.clip_value)\n",
        "\n",
        "\t# get the config\n",
        "\tdef get_config(self):\n",
        "\t\treturn {'clip_value': self.clip_value}\n",
        " \n",
        "\n",
        "conf = Config(data_dir_=\"/content/drive/My Drive/\", cwdir_name_=\"Conv2DLSTM_ADAE\", data_set=\"UCSD_Anomaly_Dataset.v1p2/UCSDped1/\") \n",
        "physical_devices = tf.config.list_physical_devices('GPU') \n",
        "try: \n",
        "  tf.config.experimental.set_memory_growth(physical_devices[0], True) \n",
        "except: \n",
        "  # Invalid device or cannot modify virtual devices once initialized. \n",
        "  pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5IyRNft5JKae",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_clips_by_stride(stride, frames_list, sequence_size):\n",
        "\n",
        "    clips = []\n",
        "    sz = len(frames_list)\n",
        "    clip = np.zeros(shape=(sequence_size, 256, 256, 1))\n",
        "    cnt = 0\n",
        "    for start in range(0, stride):\n",
        "        for i in range(start, sz, stride):\n",
        "            clip[cnt, :, :, 0] = frames_list[i]\n",
        "            cnt = cnt + 1\n",
        "            if cnt == sequence_size:\n",
        "                clips.append(clip)\n",
        "                cnt = 0\n",
        "    return clips\n",
        "\n",
        "def get_clips_list(seq_size):\n",
        "\n",
        "    clips = []\n",
        "    # loop over the training folders (Train000,Train001,..)\n",
        "    for f in sorted(listdir(conf.DATASET_PATH)):\n",
        "        directory_path = join(conf.DATASET_PATH, f)\n",
        "        if isdir(directory_path):\n",
        "            all_frames = []\n",
        "            # loop over all the images in the folder (0.tif,1.tif,..,199.tif)\n",
        "            for c in sorted(listdir(directory_path)):\n",
        "                img_path = join(directory_path, c)\n",
        "                if str(img_path)[-3:] == \"tif\":\n",
        "                    img = Image.open(img_path).resize((256, 256))\n",
        "                    img = np.array(img, dtype=np.float32)\n",
        "                    img = (img - 127.5)/127.5\n",
        "                    #img = (2*(img - np.amin(img))/(np.amax(img) - np.amin(img)))-1\n",
        "                    #img = np.array(img, dtype=np.float32) / 256.0\n",
        "                    all_frames.append(img)\n",
        "            # get the 32-frames sequences from the list of images after applying data augmentation\n",
        "            for stride in range(1, 3):\n",
        "                clips.extend(get_clips_by_stride(stride=stride, frames_list=all_frames, sequence_size=seq_size))\n",
        "    return clips\n",
        "\n",
        "\n",
        "def get_single_test(single_test_path, sz):\n",
        "    test = np.zeros(shape=(sz, conf.dim2, conf.dim3, conf.dim4))\n",
        "    cnt = 0\n",
        "    for f in sorted(listdir(single_test_path)):\n",
        "        if str(join(single_test_path, f))[-3:] == \"tif\":\n",
        "            img = Image.open(join(single_test_path, f)).resize((conf.dim2, conf.dim3))\n",
        "            #cv2_imshow(np.array(img,dtype=np.float32))\n",
        "            #cv2.waitKey(0)\n",
        "            img = np.array(img, dtype=np.float32) / 256\n",
        "            test[cnt, :, :, 0] = img\n",
        "            cnt = cnt + 1\n",
        "    return test\n",
        "\n",
        "def get_test_sequences(test_case_dir, sz):\n",
        "    test = get_single_test(join(conf.TEST_DIR,test_case_dir), sz)\n",
        "    print(\"Test case loaded\")\n",
        "    sz = test.shape[0] - conf.dim1\n",
        "    sequences = np.zeros((sz, conf.dim1, conf.dim2, conf.dim3, conf.dim4))\n",
        "    # apply the sliding window technique to get the sequences\n",
        "    for i in range(0, sz):\n",
        "        clip = np.zeros((conf.dim1, conf.dim2, conf.dim3, conf.dim4))\n",
        "        for j in range(0, conf.dim1):\n",
        "            clip[j] = test[i + j, :, :, :]\n",
        "        sequences[i] = clip\n",
        "    return sequences\n",
        "\n",
        "def convert_images_back(image):\n",
        "    #return np.reshape(image,(256, 256))*256.0\n",
        "    return np.reshape(image,(256, 256))*127.5 + 127.5\n",
        "\n",
        "def evaluate(sequences, model, test_case_dir, gen_only):\n",
        "\n",
        "    # get the reconstruction cost of all the sequences\n",
        "    (reconstructed_sequences, reconstructed_sequences_2) = model.predict(sequences,batch_size=conf.BATCH_SIZE)\n",
        "\n",
        "    sz = sequences.shape[0]\n",
        "    print(\"Test size:\"+str(sz))\n",
        "    if gen_only == 1:\n",
        "        os.makedirs(join(conf.image_dir,test_case_dir), exist_ok=True)\n",
        "        for i in range(0, sz):\n",
        "            #print(\"sz \"+str(i)+\"\\n\")\n",
        "            #cv2_imshow(np.reshape(reconstructed_sequences[i][2],(256, 256))*256)\n",
        "            if i < 10:\n",
        "                img_num = \"00\"+str(i)\n",
        "            elif i < 100:\n",
        "                img_num = \"0\"+str(i)\n",
        "            else:\n",
        "                img_num = str(i)    \n",
        "        \n",
        "            cv2.imwrite(join(conf.image_dir, test_case_dir,\"gen_\"+img_num+\".jpg\"), convert_images_back(reconstructed_sequences[i][6]))\n",
        "\n",
        "            cv2.imwrite(join(conf.image_dir, test_case_dir,\"dis_\"+img_num+\".jpg\"), convert_images_back(reconstructed_sequences_2[i][6]))\n",
        "            #cv2.waitKey()\n",
        "            #print((np.reshape(reconstructed_sequences_2[i][6],(256, 256))))\n",
        "            #v2_imshow(np.reshape(reconstructed_sequences_2[i][2],(256, 256))*256)\n",
        "            #cv2.waitKey()\n",
        "\n",
        "        #reconstruction_shape = (sz,10, 256, 256, 1)\n",
        "    sequences_reconstruction_cost = np.array([np.linalg.norm(np.subtract(sequences[i],reconstructed_sequences[i])) for i in range(0,sz)])\n",
        "    sa = (sequences_reconstruction_cost - np.min(sequences_reconstruction_cost)) / np.max(sequences_reconstruction_cost)\n",
        "    sr = 1.0 - sa\n",
        "\n",
        "    #print(sr.shape())\n",
        "\n",
        "    plt.plot(sr)\n",
        "    plt.ylabel('regularity score Sr(t)')\n",
        "    plt.xlabel('frame t')\n",
        "    plt.show()\n",
        "\n",
        "    sequences_reconstruction_cost_2 = np.array([np.linalg.norm(np.subtract(sequences[i],reconstructed_sequences_2[i])) for i in range(0,sz)])\n",
        "    sa_2 = (sequences_reconstruction_cost_2 - np.min(sequences_reconstruction_cost_2)) / np.max(sequences_reconstruction_cost_2)\n",
        "    sr_2 = 1.0 - sa_2\n",
        "    \n",
        "    #print(sr.shape())\n",
        "\n",
        "    plt.plot(sr_2)\n",
        "    plt.ylabel('regularity score Sr(t)')\n",
        "    plt.xlabel('frame t')\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QCP4CpApLacO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1eb1867d-1580-4be8-9c16-b85197f625b6"
      },
      "source": [
        "\n",
        "def get_generator():\n",
        "    if conf.retrain == 1 and os.path.isfile(conf.final_gen_path):\n",
        "        model=load_model(conf.final_gen_path, custom_objects={'LayerNormalization': LayerNormalization})\n",
        "        return model\n",
        "\n",
        "    init = tf.keras.initializers.RandomNormal(stddev=0.02)\n",
        "    \n",
        "    print(\"Loading generator model\")\n",
        "    model = Sequential()\n",
        "    #model.add(GaussianNoise(0.01, input_shape=(conf.dim1, conf.dim2, conf.dim3, conf.dim4)))\n",
        "    #model.add(TimeDistributed(Conv2D(128, (11, 11), strides=4, activation=\"relu\", kernel_initializer=init, padding=\"same\"), batch_input_shape=(None, conf.dim1, conf.dim2, conf.dim3, conf.dim4)))   \n",
        "    model.add(TimeDistributed(Conv2D(128, (11, 11), strides=4, activation=\"relu\", kernel_initializer=init, padding=\"same\"), batch_input_shape=(None, conf.dim1, conf.dim2, conf.dim3, conf.dim4)))\n",
        "    model.add(LayerNormalization())\n",
        "    model.add(TimeDistributed(Conv2D(64, (5, 5), strides=2, activation=\"relu\", kernel_initializer=init, padding=\"same\")))\n",
        "    model.add(LayerNormalization())\n",
        "\n",
        "    # # # # #\n",
        "    model.add(ConvLSTM2D(64, (3, 3), kernel_initializer=init, padding=\"same\", return_sequences=True))\n",
        "    model.add(LayerNormalization())\n",
        "    model.add(ConvLSTM2D(32, (3, 3), kernel_initializer=init, padding=\"same\", return_sequences=True))\n",
        "    model.add(LayerNormalization())\n",
        "    model.add(ConvLSTM2D(64, (3, 3), kernel_initializer=init, padding=\"same\", return_sequences=True))\n",
        "    model.add(LayerNormalization())\n",
        "    # # # # #\n",
        "\n",
        "    model.add(TimeDistributed(Conv2DTranspose(64, (5, 5), strides=2, activation=\"relu\", kernel_initializer=init, padding=\"same\")))\n",
        "    model.add(LayerNormalization())\n",
        "    model.add(TimeDistributed(Conv2DTranspose(128, (11, 11), strides=4, activation=\"relu\", kernel_initializer=init, padding=\"same\")))\n",
        "    model.add(LayerNormalization())\n",
        "    model.add(TimeDistributed(Conv2D(1, (11, 11), activation=\"tanh\", kernel_initializer=init,  padding=\"same\")))\n",
        "\n",
        "    model.summary(line_length=150)\n",
        "    return model\n",
        "\n",
        "\n",
        "def get_discriminator():\n",
        "    if conf.retrain == 1 and os.path.isfile(conf.final_disc_path):\n",
        "        model=load_model(conf.final_disc_path, custom_objects={'LayerNormalization': LayerNormalization, 'ClipConstraint': ClipConstraint})\n",
        "        return model\n",
        "\n",
        "    init = tf.keras.initializers.RandomNormal(stddev=0.02)\n",
        "    const = ClipConstraint(0.01)\n",
        "    print(\"Loading discriminator model\")\n",
        "    model = Sequential()\n",
        "    model.add(GaussianNoise(0.01, input_shape=(conf.dim1, conf.dim2, conf.dim3, conf.dim4)))\n",
        "    #model.add(TimeDistributed(Conv2D(128, (11, 11), strides=4, activation=\"relu\", kernel_initializer=init, padding=\"same\"), batch_input_shape=(None, conf.dim1, conf.dim2, conf.dim3, conf.dim4)))   \n",
        "    model.add(TimeDistributed(Conv2D(128, (11, 11), strides=4, activation=\"relu\", kernel_initializer=init, kernel_constraint=const, padding=\"same\"), batch_input_shape=(None, conf.dim1, conf.dim2, conf.dim3, conf.dim4)))\n",
        "    model.add(LayerNormalization())\n",
        "    model.add(TimeDistributed(Conv2D(64, (5, 5), strides=2, activation=\"relu\", kernel_initializer=init, kernel_constraint=const, padding=\"same\")))\n",
        "    model.add(LayerNormalization())\n",
        "    #model.add(TimeDistributed(Conv2D(64, (3, 3), strides=1, activation=\"relu\", kernel_initializer=init, padding=\"same\")))\n",
        "    #model.add(LayerNormalization())\n",
        "    # # # # #\n",
        "\n",
        "    #model.add(TimeDistributed(Conv2D(16, (3, 3), strides=1, activation=\"relu\", kernel_initializer=init, kernel_constraint=const, padding=\"same\")))\n",
        "    #model.add(LayerNormalization())\n",
        "    #model.add(TimeDistributed(Conv2DTranspose(16, (3,3), strides=1, activation=\"relu\", kernel_initializer=init, padding=\"same\")))\n",
        "    #model.add(LayerNormalization())\n",
        "    model.add(ConvLSTM2D(64, (3, 3), kernel_initializer=init, kernel_constraint=const, padding=\"same\", return_sequences=True))\n",
        "    model.add(LayerNormalization())\n",
        "    model.add(ConvLSTM2D(32, (3, 3), kernel_initializer=init, kernel_constraint=const, padding=\"same\", return_sequences=True))\n",
        "    model.add(LayerNormalization())\n",
        "    model.add(ConvLSTM2D(64, (3, 3), kernel_initializer=init, kernel_constraint=const, padding=\"same\", return_sequences=True))\n",
        "    model.add(LayerNormalization())\n",
        "    # # # # #\n",
        "\n",
        "    #model.add(TimeDistributed(Conv2DTranspose(64, (3, 3), strides=1, activation=\"relu\", kernel_initializer=init, padding=\"same\")))\n",
        "    #model.add(LayerNormalization())\n",
        "    model.add(TimeDistributed(Conv2DTranspose(64, (5, 5), strides=2, activation=\"relu\", kernel_initializer=init, padding=\"same\")))\n",
        "    model.add(LayerNormalization())\n",
        "    model.add(TimeDistributed(Conv2DTranspose(128, (11, 11), strides=4, activation=\"relu\", kernel_initializer=init, padding=\"same\")))\n",
        "    model.add(LayerNormalization())\n",
        "    model.add(TimeDistributed(Conv2D(1, (11, 11), activation=\"tanh\", kernel_initializer=init, padding=\"same\")))\n",
        "\n",
        "    model.summary(line_length=150)\n",
        "    return model\n",
        "\n",
        "def get_generator_skip_conn():\n",
        "    if conf.retrain == 1 and os.path.isfile(conf.final_gen_path):\n",
        "        model=load_model(conf.final_gen_path, custom_objects={'LayerNormalization': LayerNormalization})\n",
        "        return model\n",
        "\n",
        "    init = tf.keras.initializers.RandomNormal(stddev=0.02)\n",
        "    \n",
        "    print(\"Loading generator model\")\n",
        "    input_shape=(conf.dim1, conf.dim2, conf.dim3, conf.dim4)\n",
        "    X_input = Input(input_shape)\n",
        "    model = Sequential()\n",
        "    \n",
        "    X = TimeDistributed(Conv2D(128, (11, 11), strides=4, kernel_initializer=init, padding=\"same\"))(X_input)\n",
        "    X = LayerNormalization()(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    X = TimeDistributed(Conv2D(64, (5, 5), strides=2, kernel_initializer=init, padding=\"same\"))(X)\n",
        "    X = LayerNormalization()(X)\n",
        "    X = Activation('relu')(X)\n",
        "    X_skip_conn1 = X\n",
        "    # # # # #\n",
        "    X = ConvLSTM2D(64, (3, 3), kernel_initializer=init, padding=\"same\", return_sequences=True)(X)\n",
        "    X = LayerNormalization()(X)\n",
        "    X = ConvLSTM2D(32, (3, 3), kernel_initializer=init, padding=\"same\", return_sequences=True)(X)\n",
        "    X = LayerNormalization()(X)\n",
        "    X = ConvLSTM2D(64, (3, 3), kernel_initializer=init, padding=\"same\", return_sequences=True)(X)\n",
        "    X = LayerNormalization()(X)\n",
        "    # # # # #\n",
        "    X = Add()([X, X_skip_conn1])\n",
        "    X = TimeDistributed(Conv2DTranspose(64, (5, 5), strides=2, kernel_initializer=init, padding=\"same\"))(X)\n",
        "    X = LayerNormalization()(X)\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    X = TimeDistributed(Conv2DTranspose(128, (11, 11), strides=4, kernel_initializer=init, padding=\"same\"))(X)\n",
        "    X = LayerNormalization()(X)\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    X = TimeDistributed(Conv2D(1, (11, 11), activation=\"tanh\", kernel_initializer=init,  padding=\"same\"))(X)\n",
        "\n",
        "    model = Model(inputs = X_input, outputs = X, name='Generator')\n",
        "    model.summary(line_length=150)\n",
        "    return model\n",
        "\n",
        "\n",
        "def get_discriminator_skip_conn():\n",
        "    if conf.retrain == 1 and os.path.isfile(conf.final_disc_path):\n",
        "        model=load_model(conf.final_disc_path, custom_objects={'LayerNormalization': LayerNormalization, 'ClipConstraint': ClipConstraint})\n",
        "        return model\n",
        "\n",
        "    init = tf.keras.initializers.RandomNormal(stddev=0.02)\n",
        "    const = ClipConstraint(0.01)\n",
        "    print(\"Loading discriminator model\")\n",
        "    input_shape=(conf.dim1, conf.dim2, conf.dim3, conf.dim4)\n",
        "    X_input = Input(input_shape)\n",
        "    model = Sequential()\n",
        "    \n",
        "    X = TimeDistributed(Conv2D(128, (11, 11), strides=4, kernel_initializer=init, kernel_constraint=const, padding=\"same\"))(X_input)\n",
        "    X = LayerNormalization()(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    X = TimeDistributed(Conv2D(64, (5, 5), strides=2, kernel_initializer=init, kernel_constraint=const, padding=\"same\"))(X)\n",
        "    X = LayerNormalization()(X)\n",
        "    X = Activation('relu')(X)\n",
        "    X_skip_conn1 = X\n",
        "\n",
        "    # # # # #\n",
        "    X = ConvLSTM2D(64, (3, 3), kernel_initializer=init, kernel_constraint=const, padding=\"same\", return_sequences=True)(X)\n",
        "    X = LayerNormalization()(X)\n",
        "    X = ConvLSTM2D(32, (3, 3), kernel_initializer=init, kernel_constraint=const, padding=\"same\", return_sequences=True)(X)\n",
        "    X = LayerNormalization()(X)\n",
        "    X = ConvLSTM2D(16, (3, 3), kernel_initializer=init, kernel_constraint=const, padding=\"same\", return_sequences=True)(X)\n",
        "    X = LayerNormalization()(X)\n",
        "    X = ConvLSTM2D(32, (3, 3), kernel_initializer=init, kernel_constraint=const, padding=\"same\", return_sequences=True)(X)\n",
        "    X = LayerNormalization()(X)\n",
        "    X = ConvLSTM2D(64, (3, 3), kernel_initializer=init, kernel_constraint=const, padding=\"same\", return_sequences=True)(X)\n",
        "    X = LayerNormalization()(X)\n",
        "    # # # # #\n",
        "\n",
        "    X = Add()([X, X_skip_conn1])\n",
        "    X = TimeDistributed(Conv2DTranspose(64, (5, 5), strides=2, kernel_initializer=init, kernel_constraint=const, padding=\"same\"))(X)\n",
        "    X = LayerNormalization()(X)\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    X = TimeDistributed(Conv2DTranspose(128, (11, 11), strides=4, kernel_initializer=init, kernel_constraint=const, padding=\"same\"))(X)\n",
        "    X = LayerNormalization()(X)\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    X = TimeDistributed(Conv2D(1, (11, 11), activation=\"tanh\", kernel_initializer=init, kernel_constraint=const,  padding=\"same\"))(X)\n",
        "\n",
        "    model = Model(inputs = X_input, outputs = X, name='Discriminator')\n",
        "    model.summary(line_length=150)\n",
        "    return model\n",
        "\n",
        "def get_gen_dis_multiscale():\n",
        "    if conf.retrain == 1 and os.path.isfile(conf.final_gen_path):\n",
        "        model_gen=load_model(conf.final_gen_path, custom_objects={'LayerNormalization': LayerNormalization})\n",
        "        model_disc=load_model(conf.final_disc_path, custom_objects={'LayerNormalization': LayerNormalization, 'ClipConstraint': ClipConstraint})\n",
        "        return model_gen, model_disc\n",
        "\n",
        "    init = tf.keras.initializers.RandomNormal(stddev=0.02)\n",
        "    \n",
        "    print(\"Loading generator model\")\n",
        "    #input_shape=(conf.dim1, conf.dim2, conf.dim3, conf.dim4)\n",
        "    #X_input = tf.keras.layers.InputLayer(batch_size=conf.BATCH_SIZE, input_shape=input_shape)\n",
        "    #X_input = Input(input_shape=input_shape)\n",
        "\n",
        "    input_shape=(conf.dim1, conf.dim2, conf.dim3, conf.dim4)\n",
        "    X_input = Input(input_shape)\n",
        "    model_gen = Sequential()\n",
        "    \n",
        "    X = TimeDistributed(Conv2D(128, (11, 11), strides=4, kernel_initializer=init, padding=\"same\"))(X_input)\n",
        "    X = LayerNormalization()(X)\n",
        "    X = Activation('relu')(X)\n",
        "    X_skip_conn1 = X\n",
        "\n",
        "    X = TimeDistributed(Conv2D(64, (5, 5), strides=2, kernel_initializer=init, padding=\"same\", name=\"conv2\"))(X)\n",
        "    X = LayerNormalization()(X)\n",
        "    X = Activation('relu')(X)\n",
        "    X_skip_conn2 = X\n",
        "\n",
        "    # # # # #\n",
        "    X = ConvLSTM2D(64, (3, 3), kernel_initializer=init, padding=\"same\", return_sequences=True)(X)\n",
        "    X = LayerNormalization()(X)\n",
        "    X = ConvLSTM2D(32, (3, 3), kernel_initializer=init, padding=\"same\", return_sequences=True)(X)\n",
        "    X = LayerNormalization()(X)\n",
        "    X = ConvLSTM2D(64, (3, 3), kernel_initializer=init, padding=\"same\", return_sequences=True)(X)\n",
        "    X = LayerNormalization()(X)\n",
        "    # # # # #\n",
        "    X_skip_conn3 = X\n",
        "\n",
        "\n",
        "    X = TimeDistributed(Conv2DTranspose(64, (5, 5), strides=2, kernel_initializer=init, padding=\"same\", name=\"convT3\"))(X)\n",
        "    X = LayerNormalization()(X)\n",
        "    X = Activation('relu')(X)\n",
        "    X_skip_conn4 = X\n",
        "\n",
        "    \n",
        "    X = TimeDistributed(Conv2DTranspose(128, (11, 11), strides=4, kernel_initializer=init, padding=\"same\", name=\"convT4\"))(X)\n",
        "    X = LayerNormalization()(X)\n",
        "    X = Activation('relu')(X)\n",
        "    #X_skip_conn4 = X\n",
        "\n",
        "\n",
        "    X = TimeDistributed(Conv2D(1, (11, 11), activation=\"tanh\", kernel_initializer=init,  padding=\"same\", name=\"convT5\"))(X)\n",
        "\n",
        "    model_gen = Model(inputs = X_input, outputs = X, name='Generator')\n",
        "    model_gen.summary(line_length=150)\n",
        "\n",
        "\n",
        "    print(\"Loading discriminator model\")\n",
        "\n",
        "    init = tf.keras.initializers.RandomNormal(stddev=0.02)\n",
        "    const = ClipConstraint(0.01)\n",
        "\n",
        "    #input_shape=(conf.dim1, conf.dim2, conf.dim3, conf.dim4)\n",
        "    #X_input = Input(input_shape)\n",
        "    #X_input = tf.keras.layers.InputLayer(batch_size=conf.BATCH_SIZE, input_tensor=X)\n",
        "    model_disc = Sequential()\n",
        "    print(\"test\")\n",
        "    X = TimeDistributed(Conv2D(128, (11, 11), strides=4, kernel_initializer=init, padding=\"same\"))(X)\n",
        "    print(\"test1\")\n",
        "    X = LayerNormalization()(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "\n",
        "    X = tf.concat([X, X_skip_conn4], 4)\n",
        "    X = TimeDistributed(Conv2D(64, (5, 5), strides=2, kernel_initializer=init, kernel_constraint=const, padding=\"same\"))(X)\n",
        "    X = LayerNormalization()(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    X = tf.concat([X, X_skip_conn3], 4)\n",
        "    # # # # #\n",
        "    X = ConvLSTM2D(64, (3, 3), kernel_initializer=init, kernel_constraint=const, padding=\"same\", return_sequences=True)(X)\n",
        "    X = LayerNormalization()(X)\n",
        "    X = ConvLSTM2D(32, (3, 3), kernel_initializer=init, kernel_constraint=const, padding=\"same\", return_sequences=True)(X)\n",
        "    X = LayerNormalization()(X)\n",
        "    X = ConvLSTM2D(64, (3, 3), kernel_initializer=init, kernel_constraint=const, padding=\"same\", return_sequences=True)(X)\n",
        "    X = LayerNormalization()(X)\n",
        "    # # # # #\n",
        "\n",
        "    X = tf.concat([X, X_skip_conn2], 4)\n",
        "    X = TimeDistributed(Conv2DTranspose(64, (5, 5), strides=2, kernel_initializer=init, kernel_constraint=const, padding=\"same\"))(X)\n",
        "    X = LayerNormalization()(X)\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    X = tf.concat([X, X_skip_conn1], 4)\n",
        "    X = TimeDistributed(Conv2DTranspose(128, (11, 11), strides=4, kernel_initializer=init, kernel_constraint=const, padding=\"same\"))(X)\n",
        "    X = LayerNormalization()(X)\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    X = TimeDistributed(Conv2D(1, (11, 11), activation=\"tanh\", kernel_initializer=init, kernel_constraint=const,  padding=\"same\"))(X)\n",
        "\n",
        "    model_disc = Model(inputs = X_input, outputs = X, name='Discriminator')\n",
        "    model_disc.summary(line_length=150)\n",
        "\n",
        "    return mode_gen, model_disc \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def build_model(model, image_dims):\n",
        "    input_img = Input(shape=image_dims)\n",
        "    output = model(input_img)\n",
        "    return Model(input_img,output)\n",
        "\n",
        "\n",
        "get_gen_dis_multiscale()\n",
        "#get_generator_skip_conn()\n",
        "#get_discriminator_skip_conn()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading generator model\n",
            "Model: \"Generator\"\n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "Layer (type)                                                       Output Shape                                                Param #                \n",
            "======================================================================================================================================================\n",
            "input_13 (InputLayer)                                              [(None, 10, 256, 256, 1)]                                   0                      \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "time_distributed_41 (TimeDistributed)                              (None, 10, 64, 64, 128)                                     15616                  \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "layer_normalization_54 (LayerNormalization)                        (None, 10, 64, 64, 128)                                     256                    \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "activation_30 (Activation)                                         (None, 10, 64, 64, 128)                                     0                      \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "time_distributed_42 (TimeDistributed)                              (None, 10, 32, 32, 64)                                      204864                 \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "layer_normalization_55 (LayerNormalization)                        (None, 10, 32, 32, 64)                                      128                    \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "activation_31 (Activation)                                         (None, 10, 32, 32, 64)                                      0                      \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "conv_lst_m2d_24 (ConvLSTM2D)                                       (None, 10, 32, 32, 64)                                      295168                 \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "layer_normalization_56 (LayerNormalization)                        (None, 10, 32, 32, 64)                                      128                    \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "conv_lst_m2d_25 (ConvLSTM2D)                                       (None, 10, 32, 32, 32)                                      110720                 \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "layer_normalization_57 (LayerNormalization)                        (None, 10, 32, 32, 32)                                      64                     \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "conv_lst_m2d_26 (ConvLSTM2D)                                       (None, 10, 32, 32, 64)                                      221440                 \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "layer_normalization_58 (LayerNormalization)                        (None, 10, 32, 32, 64)                                      128                    \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "time_distributed_43 (TimeDistributed)                              (None, 10, 64, 64, 64)                                      102464                 \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "layer_normalization_59 (LayerNormalization)                        (None, 10, 64, 64, 64)                                      128                    \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "activation_32 (Activation)                                         (None, 10, 64, 64, 64)                                      0                      \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "time_distributed_44 (TimeDistributed)                              (None, 10, 256, 256, 128)                                   991360                 \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "layer_normalization_60 (LayerNormalization)                        (None, 10, 256, 256, 128)                                   256                    \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "activation_33 (Activation)                                         (None, 10, 256, 256, 128)                                   0                      \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "time_distributed_45 (TimeDistributed)                              (None, 10, 256, 256, 1)                                     15489                  \n",
            "======================================================================================================================================================\n",
            "Total params: 1,958,209\n",
            "Trainable params: 1,958,209\n",
            "Non-trainable params: 0\n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "Loading discriminator model\n",
            "test\n",
            "test1\n",
            "Model: \"Discriminator\"\n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "Layer (type)                                     Output Shape                     Param #           Connected to                                      \n",
            "======================================================================================================================================================\n",
            "input_13 (InputLayer)                            [(None, 10, 256, 256, 1)]        0                                                                   \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "time_distributed_41 (TimeDistributed)            (None, 10, 64, 64, 128)          15616             input_13[0][0]                                    \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "layer_normalization_54 (LayerNormalization)      (None, 10, 64, 64, 128)          256               time_distributed_41[0][0]                         \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "activation_30 (Activation)                       (None, 10, 64, 64, 128)          0                 layer_normalization_54[0][0]                      \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "time_distributed_42 (TimeDistributed)            (None, 10, 32, 32, 64)           204864            activation_30[0][0]                               \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "layer_normalization_55 (LayerNormalization)      (None, 10, 32, 32, 64)           128               time_distributed_42[0][0]                         \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "activation_31 (Activation)                       (None, 10, 32, 32, 64)           0                 layer_normalization_55[0][0]                      \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "conv_lst_m2d_24 (ConvLSTM2D)                     (None, 10, 32, 32, 64)           295168            activation_31[0][0]                               \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "layer_normalization_56 (LayerNormalization)      (None, 10, 32, 32, 64)           128               conv_lst_m2d_24[0][0]                             \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "conv_lst_m2d_25 (ConvLSTM2D)                     (None, 10, 32, 32, 32)           110720            layer_normalization_56[0][0]                      \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "layer_normalization_57 (LayerNormalization)      (None, 10, 32, 32, 32)           64                conv_lst_m2d_25[0][0]                             \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "conv_lst_m2d_26 (ConvLSTM2D)                     (None, 10, 32, 32, 64)           221440            layer_normalization_57[0][0]                      \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "layer_normalization_58 (LayerNormalization)      (None, 10, 32, 32, 64)           128               conv_lst_m2d_26[0][0]                             \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "time_distributed_43 (TimeDistributed)            (None, 10, 64, 64, 64)           102464            layer_normalization_58[0][0]                      \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "layer_normalization_59 (LayerNormalization)      (None, 10, 64, 64, 64)           128               time_distributed_43[0][0]                         \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "activation_32 (Activation)                       (None, 10, 64, 64, 64)           0                 layer_normalization_59[0][0]                      \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "time_distributed_44 (TimeDistributed)            (None, 10, 256, 256, 128)        991360            activation_32[0][0]                               \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "layer_normalization_60 (LayerNormalization)      (None, 10, 256, 256, 128)        256               time_distributed_44[0][0]                         \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "activation_33 (Activation)                       (None, 10, 256, 256, 128)        0                 layer_normalization_60[0][0]                      \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "time_distributed_45 (TimeDistributed)            (None, 10, 256, 256, 1)          15489             activation_33[0][0]                               \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "time_distributed_46 (TimeDistributed)            (None, 10, 64, 64, 128)          15616             time_distributed_45[0][0]                         \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "layer_normalization_61 (LayerNormalization)      (None, 10, 64, 64, 128)          256               time_distributed_46[0][0]                         \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "activation_34 (Activation)                       (None, 10, 64, 64, 128)          0                 layer_normalization_61[0][0]                      \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "tf_op_layer_concat_6 (TensorFlowOpLayer)         [(None, 10, 64, 64, 192)]        0                 activation_34[0][0]                               \n",
            "                                                                                                    activation_32[0][0]                               \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "time_distributed_47 (TimeDistributed)            (None, 10, 32, 32, 64)           307264            tf_op_layer_concat_6[0][0]                        \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "layer_normalization_62 (LayerNormalization)      (None, 10, 32, 32, 64)           128               time_distributed_47[0][0]                         \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "activation_35 (Activation)                       (None, 10, 32, 32, 64)           0                 layer_normalization_62[0][0]                      \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "tf_op_layer_concat_7 (TensorFlowOpLayer)         [(None, 10, 32, 32, 128)]        0                 activation_35[0][0]                               \n",
            "                                                                                                    layer_normalization_58[0][0]                      \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "conv_lst_m2d_27 (ConvLSTM2D)                     (None, 10, 32, 32, 64)           442624            tf_op_layer_concat_7[0][0]                        \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "layer_normalization_63 (LayerNormalization)      (None, 10, 32, 32, 64)           128               conv_lst_m2d_27[0][0]                             \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "conv_lst_m2d_28 (ConvLSTM2D)                     (None, 10, 32, 32, 32)           110720            layer_normalization_63[0][0]                      \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "layer_normalization_64 (LayerNormalization)      (None, 10, 32, 32, 32)           64                conv_lst_m2d_28[0][0]                             \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "conv_lst_m2d_29 (ConvLSTM2D)                     (None, 10, 32, 32, 64)           221440            layer_normalization_64[0][0]                      \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "layer_normalization_65 (LayerNormalization)      (None, 10, 32, 32, 64)           128               conv_lst_m2d_29[0][0]                             \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "tf_op_layer_concat_8 (TensorFlowOpLayer)         [(None, 10, 32, 32, 128)]        0                 layer_normalization_65[0][0]                      \n",
            "                                                                                                    activation_31[0][0]                               \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "time_distributed_48 (TimeDistributed)            (None, 10, 64, 64, 64)           204864            tf_op_layer_concat_8[0][0]                        \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "layer_normalization_66 (LayerNormalization)      (None, 10, 64, 64, 64)           128               time_distributed_48[0][0]                         \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "activation_36 (Activation)                       (None, 10, 64, 64, 64)           0                 layer_normalization_66[0][0]                      \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "tf_op_layer_concat_9 (TensorFlowOpLayer)         [(None, 10, 64, 64, 192)]        0                 activation_36[0][0]                               \n",
            "                                                                                                    activation_30[0][0]                               \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "time_distributed_49 (TimeDistributed)            (None, 10, 256, 256, 128)        2973824           tf_op_layer_concat_9[0][0]                        \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "layer_normalization_67 (LayerNormalization)      (None, 10, 256, 256, 128)        256               time_distributed_49[0][0]                         \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "activation_37 (Activation)                       (None, 10, 256, 256, 128)        0                 layer_normalization_67[0][0]                      \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "time_distributed_50 (TimeDistributed)            (None, 10, 256, 256, 1)          15489             activation_37[0][0]                               \n",
            "======================================================================================================================================================\n",
            "Total params: 6,251,138\n",
            "Trainable params: 6,251,138\n",
            "Non-trainable params: 0\n",
            "______________________________________________________________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1H9pUAm46jls",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create a line plot of loss for the gan and save to file\n",
        "def plot_history(d1_hist, g_hist, image_name):\n",
        "\t# plot history\n",
        "    #pyplot.plot(d1_hist, label='disc_real')\n",
        "\t#pyplot.plot(d2_hist, label='disc_fake')\n",
        "    pyplot.plot(d1_hist, label='disc_loss')\n",
        "    pyplot.plot(g_hist, label='gen')\n",
        "    pyplot.legend()\n",
        "    pyplot.savefig(image_name)\n",
        "    pyplot.close()\n",
        " \n",
        "def diff_norm(disc_x, disc_y):\n",
        "    return tf.norm(tf.math.subtract(disc_x, disc_y))\n",
        "\n",
        "def compile_gan(generator, discriminator):\n",
        "    image_dims = [conf.dim1, conf.dim2, conf.dim3, conf.dim4]\n",
        "    optimizer_1 = tf.keras.optimizers.Adam(lr=1e-4, decay=1e-5, epsilon=1e-6, beta_1=0.5)\n",
        "    built_dis = build_model(discriminator, image_dims)\n",
        "    disc_loss = diff_loss(conf.BATCH_SIZE)\n",
        "    #disc_loss = HistoricalAvgLoss(built_dis, conf.BATCH_SIZE).diff_loss\n",
        "    built_dis.compile(optimizer=optimizer_1, loss=disc_loss)\n",
        "\n",
        "    built_gen = build_model(generator, image_dims)\n",
        "    img = Input(shape=image_dims, dtype=tf.dtypes.float32)\n",
        "    #gn_layer = GaussianNoise(0.1)(img)\n",
        "    \n",
        "    reconstructed_img = built_gen(img)\n",
        "    \n",
        "    built_dis.trainable = False\n",
        "    validity = built_dis(reconstructed_img)\n",
        "    optimizer = tf.keras.optimizers.Adam(lr=1e-4, decay=1e-5, epsilon=1e-6, beta_1=0.5)\n",
        "    gan_model = Model(img, [reconstructed_img, validity])\n",
        "\n",
        "    comb_loss = combined_loss()\n",
        "    gan_model.compile(loss=[comb_loss, comb_loss],\n",
        "    loss_weights=[1, 1],\n",
        "    optimizer=optimizer)\n",
        "\n",
        "    return ModelContainer(built_gen, built_dis, gan_model)\n",
        "\n",
        "class HistoricalAvgLoss(object):\n",
        "  def __init__(self, model, batch_size):\n",
        "    # create tensors (initialized to zero) to hold the previous value of the\n",
        "    # weights\n",
        "    self.model = model\n",
        "    self.batch_size = batch_size\n",
        "    self.prev_weights = []\n",
        "    for w in model.get_weights():\n",
        "      self.prev_weights.append(tf.Variable(np.zeros(w.shape)))\n",
        "\n",
        "  def loss(self, y_true, y_pred):\n",
        "    err = tf.keras.losses.MSE(y_true, y_pred)\n",
        "    werr = [tf.math.reduce_mean(tf.math.abs(c - p)) for c, p in zip(self.model.get_weights(), self.prev_weights)]\n",
        "    self.prev_weights = tf.keras.backend.in_train_phase(\n",
        "        [tf.keras.backend.update(p, c) for c, p in zip(self.model.get_weights(), self.prev_weights)],\n",
        "        self.prev_weights\n",
        "    )\n",
        "    return tf.keras.backend.in_train_phase(err + tf.keras.backend.sum(werr), err)\n",
        "  def diff_loss(self, disc_true, disc_predicted):\n",
        "    loss_fake = self.loss(disc_true[:self.batch_size], disc_predicted[:self.batch_size])\n",
        "    loss_real = self.loss(disc_true[self.batch_size:], disc_predicted[self.batch_size:])\n",
        "    return loss_real + (1/loss_fake)\n",
        "\n",
        "def combined_loss():\n",
        "\n",
        "    def gen_loss_func(disc_true, disc_predicted):\n",
        "        #true_flattened = flatten_over_batch(disc_true)\n",
        "        #predicted_flattened = flatten_over_batch(disc_predicted)\n",
        "\n",
        "        #loss = tf.math.log(tf.norm(tf.math.abs(tf.math.subtract(true_flattened, predicted_flattened)), ord='euclidean', axis=None, keepdims=None, name=None))\n",
        "        #loss = tf.math.reduce_max([tf.match.reduce_sum(x) for x  in tf.math.abs(tf.math.subtract(true_flattened, predicted_flattened))])\n",
        "        #img_pred = tf.math.l2_normalize(disc_predicted)\n",
        "        loss = tf.keras.losses.MSE(disc_true, disc_predicted)\n",
        "        #mse = tf.norm(tf.math.subtract(disc_true, disc_predicted))\n",
        "        #loss = tf.math.sqrt(tf.math.reduce_sum(tf.math.abs(tf.math.subtract(disc_true, disc_predicted))))\n",
        "        #loss = (tf.math.reduce_sum(tf.math.subtract(disc_true, disc_predicted)))\n",
        "        return loss\n",
        "    return gen_loss_func\n",
        "\n",
        "def flatten_over_batch(sequence_batch):\n",
        "    shape = sequence_batch.get_shape().as_list()       \n",
        "    dim = np.prod(shape[1:])\n",
        "    flattened_over_batch = tf.reshape(sequence_batch, [-1, dim])\n",
        "    return flattened_over_batch\n",
        "\n",
        "\n",
        "def diff_loss(batch_size):\n",
        "\n",
        "    def diff_func(disc_true, disc_predicted):\n",
        "        true_flattened = flatten_over_batch(disc_true)\n",
        "        predicted_flattened = flatten_over_batch(disc_predicted)\n",
        "\n",
        "        #gx_minus_dgx = tf.math.log(tf.norm(tf.math.abs(tf.math.subtract(true_flattened[:batch_size], predicted_flattened[:batch_size])), ord='euclidean', axis=None, keepdims=None, name=None))\n",
        "        gx_minus_dgx = tf.keras.losses.MSE(true_flattened[:batch_size], predicted_flattened[:batch_size])\n",
        "        \n",
        "        #loss_fake = tf.math.reduce_max([tf.match.reduce_sum(x) for x  in tf.math.abs(tf.math.subtract(true_flattened[:batch_size], predicted_flattened[:batch_size]))])\n",
        "        #x_minus_gx = tf.math.log(tf.norm(tf.math.abs(tf.math.subtract(true_flattened[batch_size:], true_flattened[:batch_size])), ord='euclidean', axis=None, keepdims=None, name=None))\n",
        "        x_minus_gx = tf.keras.losses.MSE(true_flattened[batch_size:], true_flattened[:batch_size])\n",
        "        \n",
        "        #loss_fake = tf.keras.losses.MSE(disc_true[:batch_size], disc_predicted[:batch_size])\n",
        "        #loss_fake = tf.math.sqrt(tf.math.reduce_sum(tf.math.abs(tf.math.subtract(disc_true[:batch_size], disc_predicted[:batch_size]))))\n",
        "        #loss_fake = (tf.math.reduce_sum(tf.math.subtract(disc_true[:batch_size], disc_predicted[:batch_size])))\n",
        "        #print(f'\\t\\tDiscriminator mse_real: {mse_real}\\n')\n",
        "        #x_minus_dx = tf.math.log(tf.norm(tf.math.abs(tf.math.subtract(true_flattened[batch_size:], predicted_flattened[batch_size:])), ord='euclidean', axis=None, keepdims=None, name=None))\n",
        "        x_minus_dx = tf.keras.losses.MSE(true_flattened[batch_size:], predicted_flattened[batch_size:])\n",
        "        \n",
        "        #loss_real = tf.math.reduce_max([tf.match.reduce_sum(x) for x  in tf.math.abs(tf.math.subtract(true_flattened[batch_size:], predicted_flattened[batch_size:]))])\n",
        "        #loss_real = tf.keras.losses.MSE(disc_true[batch_size:], disc_predicted[batch_size:])\n",
        "        #loss_real = tf.math.sqrt(tf.math.reduce_sum(tf.math.abs(tf.math.subtract(disc_true[batch_size:], disc_predicted[batch_size:]))))\n",
        "        #loss_real = (tf.math.reduce_sum(tf.math.subtract(disc_true[batch_size:], disc_predicted[batch_size:])))\n",
        "        #print(f'\\t\\tDiscriminator mse_fake: {mse_fake}\\n')\n",
        "        term2 = tf.math.multiply(gx_minus_dgx, x_minus_gx)\n",
        "        #return tf.math.add(tf.math.divide(loss_real, 2.0), tf.math.divide(1.0,tf.math.add(2.0,loss_fake)))\n",
        "        return x_minus_dx - term2\n",
        "    return diff_func\n",
        "\n",
        "def train_step(models, batch_clips, c1_hist):\n",
        "    \n",
        "    batch_noise_clips = batch_clips\n",
        "    # + tf.random.normal(shape=[conf.dim1, conf.dim2, conf.dim3, conf.dim4], stddev=0.1)\n",
        "    \n",
        "    batch_fake_clips = models.generator.predict_on_batch(batch_noise_clips)\n",
        "    \n",
        "    batch_noise_clips = tf.cast(batch_noise_clips, dtype=tf.float32)\n",
        "    batch_clips = tf.cast(batch_clips, dtype=tf.float32)\n",
        "    batch_fake_clips = tf.cast(batch_fake_clips, dtype=tf.float32)\n",
        "    \n",
        "    #disc_x = np.concatenate((batch_noise_clips, batch_fake_clips))\n",
        "    disc_x = tf.concat([batch_fake_clips, batch_noise_clips], 0)\n",
        "    #disc_y = np.concatenate((batch_clips, batch_fake_clips))\n",
        "    disc_y = tf.concat([batch_fake_clips, batch_clips], 0)\n",
        "    c1_tmp = list()\n",
        "    for _ in range(conf.n_critic):\n",
        "        d_loss = models.discriminator.train_on_batch(disc_x, disc_y)\n",
        "        #d_loss_fake = models.discriminator.train_on_batch(batch_fake_clips, batch_fake_clips)\n",
        "        #print(f'\\t\\tDiscriminator Loss: {d_loss}\\n')\n",
        "        c1_tmp.append(d_loss)\n",
        "    c1_hist.append(np.mean(c1_tmp))\n",
        "    \n",
        "    #models.gan.train_on_batch(batch_noise_clips, [batch_clips, batch_fake_clips])\n",
        "    g_loss = models.gan.train_on_batch(batch_noise_clips, [batch_clips, batch_fake_clips])\n",
        "    return  g_loss\n",
        "    \n",
        "def reconstruct_batch(model, sequences, epoch):\n",
        "\n",
        "    sz = sequences.shape[0]\n",
        "    (reconstructed_sequences, reconstructed_sequences_2) = model.predict(sequences,batch_size=conf.BATCH_SIZE)\n",
        "    path = join(conf.run_data,\"Train_Reconstructs\", str(epoch)+\"_epoch\")\n",
        "    os.makedirs(path, exist_ok=True)\n",
        "    for i in range(0, sz):\n",
        "        #cv2_imshow(np.reshape(reconstructed_sequences[i][2],(256, 256))*256)\n",
        "        if i < 10:\n",
        "            img_num = \"00\"+str(i)\n",
        "        elif i < 100:\n",
        "            img_num = \"0\"+str(i)\n",
        "        else:\n",
        "            img_num = str(i)\n",
        "        cv2.imwrite(join(path,\"gen_\"+img_num+\".jpg\"), convert_images_back(reconstructed_sequences[i][6]))\n",
        "\n",
        "        cv2.imwrite(join(path,\"dis_\"+img_num+\".jpg\"), convert_images_back(reconstructed_sequences_2[i][6]))\n",
        "\n",
        "\n",
        "def train(test_cases):\n",
        "    generator, discriminator = get_gen_dis_multiscale()\n",
        "    #generator = get_generator()\n",
        "    models = compile_gan(generator, discriminator)\n",
        "    models.gan.summary()\n",
        "\n",
        "    train_dataset = tf.data.Dataset.from_tensor_slices(np.array(get_clips_list(conf.dim1))).batch(conf.BATCH_SIZE)\n",
        "    c1_hist, g_hist = list(), list()\n",
        "    #test_cases = get_test_sequences(\"Test002\", 200)\n",
        "    for epoch in range(conf.curr_epoch, conf.EPOCHS+1):\n",
        "        print(f'Epoch {epoch+1} started')\n",
        "        for batch in train_dataset:\n",
        "            \n",
        "            [total_weighted_loss, reconstruction_loss, fooling_loss] = train_step(models, batch, c1_hist)\n",
        "            \n",
        "            #print(f'Epoch: {epoch+1} \\t Discriminator Loss: {fooling_loss} \\t\\t Generator Loss: {reconstruction_loss} \\t\\t Total Loss: {total_weighted_loss}')\n",
        "            g_hist.append(reconstruction_loss)\n",
        "            \n",
        "        gen_loss_acc = statistics.mean(g_hist)\n",
        "        disc_loss_acc = statistics.mean(c1_hist)\n",
        "        print(f'Epoch: {epoch+1} \\t Discriminator Loss: {disc_loss_acc} \\t\\t Generator Loss: {gen_loss_acc}')\n",
        "        plot_history(c1_hist, g_hist, join(conf.run_data,\"plot_line_plot_loss\"+\"_ep-\"+str(epoch+1)+\".png\"))\n",
        "        models.generator.save(join(conf.run_data,\"generator\"+\"_ep-\"+str(epoch+1)+\".hdf5\"), save_format='h5')\n",
        "        models.discriminator.save(join(conf.run_data,\"discriminator\"+\"_ep-\"+str(epoch+1)+\".hdf5\"), save_format='h5')\n",
        "        models.gan.save(join(conf.run_data,\"gan\"+\"_ep-\"+str(epoch+1)+\".hdf5\"), save_format='h5')\n",
        "        reconstruct_batch(models.gan, test_cases[0:10*conf.BATCH_SIZE], epoch+1)\n",
        "\n",
        "    \n",
        "    models.generator.save(conf.GEN_MODEL_PATH,save_format='h5')\n",
        "    models.discriminator.save(conf.DIS_MODEL_PATH,save_format='h5')\n",
        "    models.gan.save(conf.GAN_MODEL_PATH, save_format='h5')\n",
        "    plot_history(c1_hist, g_hist, join(conf.cwdir,\"final_plot.png\"))\n",
        "    return models.gan\n",
        "\n",
        "\n",
        "\n",
        "def get_model(new_cwdir, batch_size, epochs, test_cases, reconfig=0, reload=1, model_path=conf.GAN_MODEL_PATH, retrain=0, curr_epoch=0):\n",
        "    if reconfig == 1:\n",
        "        conf.reconfig(new_cwdir, batch_size, epochs, retrain, curr_epoch)\n",
        "    if reload == 1 and os.path.isfile(model_path):\n",
        "        print(\"Loading the trained model\")\n",
        "        model=load_model(model_path, custom_objects={'LeakyReLU': LeakyReLU, 'ClipConstraint': ClipConstraint, 'gen_loss_func': combined_loss(), 'diff_func': diff_loss(conf.BATCH_SIZE)})\n",
        "        #model.load_weights(model_path)\n",
        "    else :\n",
        "        print(\"Loading the new model\")\n",
        "        model = train(test_cases)\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eC7JERZTIi3M",
        "colab_type": "code",
        "outputId": "b90d540d-ff8c-4310-e363-4fa86314f988",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        }
      },
      "source": [
        "#!rm training_gan/gan.hdf5 -rf\n",
        "#!mkdir training_gan\n",
        "\n",
        "\n",
        "test_cases_dir = \"Test008\"\n",
        "test_cases = get_test_sequences(test_cases_dir, 200)\n",
        "#model_path=\"/content/drive/My Drive/Conv2DLSTM_VanillaGAN/training_gan/gan_ep-2.hdf5\"tf.math.divide\n",
        "model = get_model(new_cwdir=\"Conv2DLSTM_ADAE_multi_scale\", batch_size=2, epochs=50, reload=1, test_cases=test_cases, reconfig=1, retrain=1, curr_epoch=39, model_path=\"/content/drive/My Drive/Conv2DLSTM_ADAE_ep50_b2_tanh/training_gan/gan_ep-10.hdf5\")\n",
        "evaluate(test_cases, model, test_cases_dir, 1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test case loaded\n",
            "Configuring retrain mode\n",
            "\n",
            "Last epoch saved : 39\n",
            "Loading the trained model\n",
            "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
            "Test size:190\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nLEEAsAQBwBIEAEsQAKwAsafPSlcLmyUAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}