{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ConvLSTM_GAN.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNxrFr5XqqVGRc36fvSuLP3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dmbk/Anomaly-Detection-System/blob/master/ConvLSTM_GAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZeDOtMkwIqL0",
        "colab_type": "code",
        "outputId": "aa40700a-c634-4499-ef36-2c0049782d47",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 186
        }
      },
      "source": [
        "!pip install imageio\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: imageio in /usr/local/lib/python3.6/dist-packages (2.4.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from imageio) (6.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from imageio) (1.17.5)\n",
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1qK4WayIRWG",
        "colab_type": "code",
        "outputId": "823ee779-bca2-44d9-a5e9-18df0fd6f0f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "import tensorflow as tf\n",
        "import glob\n",
        "import imageio\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "from PIL import Image\n",
        "from tensorflow.keras import layers\n",
        "import time\n",
        "\n",
        "from IPython import display\n",
        "\n",
        "from os.path import join\n",
        "from os import listdir\n",
        "from os.path import isfile, join, isdir\n",
        "\n",
        "#import keras\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.layers import Input, Conv2DTranspose, Conv3DTranspose, ConvLSTM2D, BatchNormalization, LayerNormalization, TimeDistributed, Conv2D, Conv3D, MaxPool3D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import argparse\n",
        "from os.path import dirname\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "\n",
        "tf.keras.backend.set_floatx('float32')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27gwZwBqIxav",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Config:\n",
        "    def __init__(self, data_dir):\n",
        "        self.DATASET_PATH = join(data_dir,\"UCSDped1/Train/\")\n",
        "        self.TEST_DIR = join(data_dir,\"UCSDped1/Test/\")\n",
        "        self.BATCH_SIZE = 4\n",
        "        self.EPOCHS = 5\n",
        "        self.GEN_MODEL_PATH = join(data_dir,\"model_gen_ConvLSTM_GAN.hdf5\")\n",
        "        self.DIS_MODEL_PATH = join(data_dir,\"model_dis_ConvLSTM_GAN.hdf5\")\n",
        "        self.GAN_MODEL_PATH = join(data_dir,\"model_combined_ConvLSTM_GAN.hdf5\")\n",
        "        self.dim1 = 10\n",
        "        self.dim2 = 256\n",
        "        self.dim3 = 256\n",
        "        self.dim4 = 1\n",
        "\n",
        "conf = Config(data_dir=\"/content/drive/My Drive/UCSD_Anomaly_Dataset.v1p2/\") \n",
        "physical_devices = tf.config.list_physical_devices('GPU') \n",
        "try: \n",
        "  tf.config.experimental.set_memory_growth(physical_devices[0], True) \n",
        "except: \n",
        "  # Invalid device or cannot modify virtual devices once initialized. \n",
        "  pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5IyRNft5JKae",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_clips_by_stride(stride, frames_list, sequence_size):\n",
        "    \"\"\" For data augmenting purposes.\n",
        "    Parameters\n",
        "    ----------\n",
        "    stride : int\n",
        "        The distance between two consecutive frames\n",
        "    frames_list : list\n",
        "        A list of sorted frames of shape 256 X 256\n",
        "    sequence_size: int\n",
        "        The size of the lstm sequence\n",
        "    Returns\n",
        "    -------\n",
        "    list\n",
        "        A list of clips , 32 frames each\n",
        "    \"\"\"\n",
        "    clips = []\n",
        "    sz = len(frames_list)\n",
        "    clip = np.zeros(shape=(sequence_size, 256, 256, 1))\n",
        "    cnt = 0\n",
        "    for start in range(0, stride):\n",
        "        for i in range(start, sz, stride):\n",
        "            clip[cnt, :, :, 0] = frames_list[i]\n",
        "            cnt = cnt + 1\n",
        "            if cnt == sequence_size:\n",
        "                clips.append(clip)\n",
        "                cnt = 0\n",
        "    return clips\n",
        "\n",
        "def get_clips_list(seq_size):\n",
        "    \"\"\"\n",
        "    seq_size :int \n",
        "        The sequence size of individual clip\n",
        "    Returns\n",
        "    -------\n",
        "    list\n",
        "        A list of training sequences of shape (NUMBER_OF_SEQUENCES,SINGLE_SEQUENCE_SIZE,FRAME_WIDTH,FRAME_HEIGHT,1)\n",
        "    \"\"\"\n",
        "    clips = []\n",
        "    # loop over the training folders (Train000,Train001,..)\n",
        "    for f in sorted(listdir(conf.DATASET_PATH)):\n",
        "        directory_path = join(conf.DATASET_PATH, f)\n",
        "        if isdir(directory_path):\n",
        "            all_frames = []\n",
        "            # loop over all the images in the folder (0.tif,1.tif,..,199.tif)\n",
        "            for c in sorted(listdir(directory_path)):\n",
        "                img_path = join(directory_path, c)\n",
        "                if str(img_path)[-3:] == \"tif\":\n",
        "                    img = Image.open(img_path).resize((256, 256))\n",
        "\n",
        "                    img = np.array(img, dtype=np.float32) / 256.0\n",
        "                    all_frames.append(img)\n",
        "            # get the 32-frames sequences from the list of images after applying data augmentation\n",
        "            for stride in range(1, 4):\n",
        "                clips.extend(get_clips_by_stride(stride=stride, frames_list=all_frames, sequence_size=seq_size))\n",
        "    return clips\n",
        "\n",
        "\n",
        "def get_single_test(single_test_path, sz):\n",
        "    test = np.zeros(shape=(sz, conf.dim2, conf.dim3, conf.dim4))\n",
        "    cnt = 0\n",
        "    for f in sorted(listdir(single_test_path)):\n",
        "        if str(join(single_test_path, f))[-3:] == \"tif\":\n",
        "            img = Image.open(join(single_test_path, f)).resize((conf.dim2, conf.dim3))\n",
        "            #cv2_imshow(np.array(img,dtype=np.float32))\n",
        "            #cv2.waitKey(0)\n",
        "            img = np.array(img, dtype=np.float32) / 256\n",
        "            test[cnt, :, :, 0] = img\n",
        "            cnt = cnt + 1\n",
        "    return test\n",
        "\n",
        "def evaluate(test_case_dir, model, sz):\n",
        "\n",
        "    test = get_single_test(join(conf.TEST_DIR,test_case_dir), sz)\n",
        "    print(\"Test case loaded\")\n",
        "    sz = test.shape[0] - conf.dim1\n",
        "    sequences = np.zeros((sz, conf.dim1, conf.dim2, conf.dim3, conf.dim4))\n",
        "    # apply the sliding window technique to get the sequences\n",
        "    for i in range(0, sz):\n",
        "        clip = np.zeros((conf.dim1, conf.dim2, conf.dim3, conf.dim4))\n",
        "        for j in range(0, conf.dim1):\n",
        "            clip[j] = test[i + j, :, :, :]\n",
        "        sequences[i] = clip\n",
        "\n",
        "    #sz_10x = sequences.shape[0] - conf.dim1\n",
        "    #sequences_10x = np.zeros((sz_10x, conf.dim1, conf.dim2, conf.dim3, conf.dim4, conf.dim5))\n",
        "    #count = 0\n",
        "    #for k in range(0, sz_10x):\n",
        "    #    clip_10x = np.zeros((conf.dim1, conf.dim2, conf.dim3, conf.dim4, conf.dim5))\n",
        "    #    for l in range(0, conf.dim1):\n",
        "    #        clip_10x[l] = sequences[k + l, :, :, :, :] \n",
        "    #    sequences_10x[k] = clip_10x\n",
        "\n",
        "    # get the reconstruction cost of all the sequences\n",
        "    reconstructed_sequences = model.predict(sequences,batch_size=conf.BATCH_SIZE)\n",
        "    sr = reconstructed_sequences\n",
        "    #for i in range(0, sz):\n",
        "    #    cv2_imshow(np.reshape(reconstructed_sequences[i][0],(256, 256))*256)\n",
        "    #    cv2.waitKey()\n",
        "\n",
        "    #reconstruction shape = (10, 16, 256, 256, 1)\n",
        "    #sequences_reconstruction_cost = np.array([np.linalg.norm(np.subtract(sequences[i],reconstructed_sequences[i])) for i in range(0,sz)])\n",
        "    #sa = (sequences_reconstruction_cost - np.min(sequences_reconstruction_cost)) / np.max(sequences_reconstruction_cost)\n",
        "    #sr = 1.0 - sa\n",
        "    #print(sr.shape())\n",
        "    \n",
        "    plt.plot(sr)\n",
        "    plt.ylabel('regularity score Sr(t)')\n",
        "    plt.xlabel('frame t')\n",
        "    plt.show()\n",
        "    #sr = sigmoid(sr)\n",
        "    # plot the regularity scores\n",
        "    plt.plot(sr)\n",
        "    plt.ylabel('regularity score Sr(t)')\n",
        "    plt.xlabel('frame t')\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QCP4CpApLacO",
        "colab_type": "code",
        "outputId": "1349ec9f-a411-4b31-cab8-51de93463d59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "def get_generator(reload_model=True):\n",
        "    if reload_model == True and os.path.isfile(conf.GEN_MODEL_PATH):\n",
        "        model=load_model(conf.GEN_MODEL_PATH,custom_objects={'LayerNormalization': LayerNormalization})\n",
        "        return model, True\n",
        "    print(\"Loading generator model\")\n",
        "    seq = Sequential()\n",
        "    seq.add(TimeDistributed(Conv2D(64, (11, 11), strides=(4,4), padding=\"same\"), batch_input_shape=(None, conf.dim1, conf.dim2, conf.dim3, conf.dim4)))   \n",
        "    seq.add(LayerNormalization())\n",
        "    seq.add(TimeDistributed(Conv2D(32, (5, 5), strides=(2,2), padding=\"same\")))\n",
        "    seq.add(LayerNormalization())\n",
        "\n",
        "    # # # # #\n",
        "    seq.add(ConvLSTM2D(64,(3, 3), padding=\"same\", return_sequences=True))\n",
        "    seq.add(LayerNormalization())\n",
        "    seq.add(ConvLSTM2D(32, (3, 3), padding=\"same\", return_sequences=True))\n",
        "    seq.add(LayerNormalization())\n",
        "    seq.add(ConvLSTM2D(64, (3, 3), padding=\"same\", return_sequences=True))\n",
        "    seq.add(LayerNormalization())\n",
        "    # # # # #\n",
        "\n",
        "    seq.add(TimeDistributed(Conv2DTranspose(32, (5, 5), strides=(2,2), padding=\"same\")))\n",
        "    seq.add(LayerNormalization())\n",
        "    seq.add(TimeDistributed(Conv2DTranspose(64, (11, 11), strides=(4,4), padding=\"same\")))\n",
        "    seq.add(LayerNormalization())\n",
        "    seq.add(TimeDistributed(Conv2D(1, (11, 11), activation=\"sigmoid\", padding=\"same\")))\n",
        "    optimizer = tf.keras.optimizers.RMSprop(lr=0.002, clipvalue=1.0, decay=1e-8)\n",
        "    seq.compile(optimizer=optimizer, loss='binary_crossentropy')\n",
        "    seq.summary(line_length=150)\n",
        "    return seq, False\n",
        "\n",
        "def get_discriminator(reload_model = True):\n",
        "\n",
        "    if reload_model == True and os.path.isfile(conf.DIS_MODEL_PATH):\n",
        "        model=load_model(conf.DIS_MODEL_PATH,custom_objects={'LayerNormalization': LayerNormalization})\n",
        "        return model, True\n",
        "    model = Sequential()\n",
        "    ## convolutional layers\n",
        "    model.add(Conv3D(filters=8, kernel_size=(3, 3, 3), activation='relu', data_format=\"channels_last\", padding=\"same\", batch_input_shape=(None, conf.dim1, conf.dim2, conf.dim3, conf.dim4)))\n",
        "    model.add(Conv3D(filters=16, kernel_size=(3, 3, 3), activation='relu', padding=\"same\"))\n",
        "    model.add(MaxPool3D(pool_size=(2, 2, 2)))\n",
        "\n",
        "    model.add(Conv3D(filters=32, kernel_size=(3, 3, 3), activation='relu', padding=\"same\"))\n",
        "    model.add(Conv3D(filters=64, kernel_size=(3, 3, 3), activation='relu', padding=\"same\"))\n",
        "    model.add(MaxPool3D(pool_size=(2, 2, 2)))\n",
        "\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Flatten())\n",
        "\n",
        "    ## MLP architecture with dense layers : 512 -> 128->1\n",
        "    ## add dropouts to avoid overfitting / perform regularization\n",
        "    model.add(Dense(units=128, activation='relu'))\n",
        "    model.add(Dropout(0.4))    \n",
        "    model.add(Dense(units=1, activation='sigmoid'))\n",
        "    optimizer = tf.keras.optimizers.RMSprop(lr=0.002, clipvalue=1.0, decay=1e-8)\n",
        "    #model.compile(optimizer=optimizer, loss='binary_crossentropy')\n",
        "    model.compile(loss='binary_crossentropy', optimizer=optimizer,metrics=['accuracy'])\n",
        "    model.summary(line_length=150)\n",
        "    return model, False\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#https://medium.com/analytics-vidhya/implementing-a-gan-in-keras-d6c36bc6ab5f   \n",
        "#https://www.dlology.com/blog/how-to-do-novelty-detection-in-keras-with-generative-adversarial-network/\n",
        "#https://arxiv.org/pdf/1802.09088.pdf\n",
        "get_generator(False)\n",
        "get_discriminator(False)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading generator model\n",
            "Model: \"sequential\"\n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "Layer (type)                                                       Output Shape                                                Param #                \n",
            "======================================================================================================================================================\n",
            "time_distributed (TimeDistributed)                                 (None, 10, 64, 64, 64)                                      7808                   \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "layer_normalization (LayerNormalization)                           (None, 10, 64, 64, 64)                                      128                    \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "time_distributed_1 (TimeDistributed)                               (None, 10, 32, 32, 32)                                      51232                  \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "layer_normalization_1 (LayerNormalization)                         (None, 10, 32, 32, 32)                                      64                     \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "conv_lst_m2d (ConvLSTM2D)                                          (None, 10, 32, 32, 64)                                      221440                 \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "layer_normalization_2 (LayerNormalization)                         (None, 10, 32, 32, 64)                                      128                    \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "conv_lst_m2d_1 (ConvLSTM2D)                                        (None, 10, 32, 32, 32)                                      110720                 \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "layer_normalization_3 (LayerNormalization)                         (None, 10, 32, 32, 32)                                      64                     \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "conv_lst_m2d_2 (ConvLSTM2D)                                        (None, 10, 32, 32, 64)                                      221440                 \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "layer_normalization_4 (LayerNormalization)                         (None, 10, 32, 32, 64)                                      128                    \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "time_distributed_2 (TimeDistributed)                               (None, 10, 64, 64, 32)                                      51232                  \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "layer_normalization_5 (LayerNormalization)                         (None, 10, 64, 64, 32)                                      64                     \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "time_distributed_3 (TimeDistributed)                               (None, 10, 256, 256, 64)                                    247872                 \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "layer_normalization_6 (LayerNormalization)                         (None, 10, 256, 256, 64)                                    128                    \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "time_distributed_4 (TimeDistributed)                               (None, 10, 256, 256, 1)                                     7745                   \n",
            "======================================================================================================================================================\n",
            "Total params: 920,193\n",
            "Trainable params: 920,193\n",
            "Non-trainable params: 0\n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "Model: \"sequential_1\"\n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "Layer (type)                                                       Output Shape                                                Param #                \n",
            "======================================================================================================================================================\n",
            "conv3d (Conv3D)                                                    (None, 10, 256, 256, 8)                                     224                    \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "conv3d_1 (Conv3D)                                                  (None, 10, 256, 256, 16)                                    3472                   \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "max_pooling3d (MaxPooling3D)                                       (None, 5, 128, 128, 16)                                     0                      \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "conv3d_2 (Conv3D)                                                  (None, 5, 128, 128, 32)                                     13856                  \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "conv3d_3 (Conv3D)                                                  (None, 5, 128, 128, 64)                                     55360                  \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "max_pooling3d_1 (MaxPooling3D)                                     (None, 2, 64, 64, 64)                                       0                      \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "batch_normalization (BatchNormalization)                           (None, 2, 64, 64, 64)                                       256                    \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "flatten (Flatten)                                                  (None, 524288)                                              0                      \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "dense (Dense)                                                      (None, 128)                                                 67108992               \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "dropout (Dropout)                                                  (None, 128)                                                 0                      \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "dense_1 (Dense)                                                    (None, 1)                                                   129                    \n",
            "======================================================================================================================================================\n",
            "Total params: 67,182,289\n",
            "Trainable params: 67,182,161\n",
            "Non-trainable params: 128\n",
            "______________________________________________________________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tensorflow.python.keras.engine.sequential.Sequential at 0x7f34db475668>,\n",
              " False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1H9pUAm46jls",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "def train(generator, discriminator):\n",
        "    discriminator.trainable = False\n",
        "    optimizer = tf.keras.optimizers.RMSprop(lr=0.002, clipvalue=1.0, decay=1e-8)\n",
        "    gan_input = Input(shape=(conf.dim1, conf.dim2, conf.dim3, conf.dim4))\n",
        "    fake_image = generator(gan_input)\n",
        "    \n",
        "    gan_output = discriminator(fake_image)\n",
        "    \n",
        "    gan = tf.keras.Model(gan_input, gan_output)\n",
        "    gan.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
        "    \n",
        "    train_dataset = tf.data.Dataset.from_tensor_slices(np.array(get_clips_list(conf.dim1))).batch(conf.BATCH_SIZE)\n",
        "    for epoch in range(conf.EPOCHS):\n",
        "        for batch in train_dataset:\n",
        "            noise = batch + np.random.normal(0, 1, size=(conf.BATCH_SIZE, conf.dim1, conf.dim2, conf.dim3, conf.dim4))\n",
        "            fake_x = generator.predict(noise)\n",
        "    \n",
        "            real_x = batch\n",
        "            \n",
        "            x = np.concatenate((real_x, fake_x))\n",
        "    \n",
        "            disc_y = np.zeros(2*conf.BATCH_SIZE)\n",
        "            disc_y[:conf.BATCH_SIZE] = 0.9\n",
        "    \n",
        "            d_loss = discriminator.train_on_batch(x, disc_y)\n",
        "    \n",
        "            y_gen = np.ones(conf.BATCH_SIZE)\n",
        "            g_loss = gan.train_on_batch(noise, y_gen)\n",
        "        gan.reset_states()\n",
        "        print(f'Epoch: {epoch} \\t Discriminator Loss: {d_loss} \\t\\t Generator Loss: {g_loss}')\n",
        "    \n",
        "    generator.save(conf.GEN_MODEL_PATH,save_format='h5')\n",
        "    discriminator.save(conf.DIS_MODEL_PATH,save_format='h5')\n",
        "    gan.save(conf.GAN_MODEL_PATH, save_format='h5')\n",
        "    return gan"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eC7JERZTIi3M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 560
        },
        "outputId": "061b43dc-1afa-4dad-a1c1-6677bf6db727"
      },
      "source": [
        "\n",
        "if os.path.isfile(conf.GAN_MODEL_PATH):\n",
        "    model=load_model(conf.GAN_MODEL_PATH,custom_objects={'LayerNormalization': LayerNormalization})\n",
        "else :\n",
        "    discriminator, loaded_dis = get_discriminator()\n",
        "    generator, loaded_gen= get_generator()\n",
        "    model = train(generator, discriminator)\n",
        "\n",
        "evaluate(\"Test002\", model, 200)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test case loaded\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}