{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyP1LEd3tBLApqR10lcys4ba",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dmbk/Anomaly-Detection-System/blob/master/Hybrid_Model_v1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9WVi4y0rl3Ru",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install keras-layer-normalization\n",
        "!pip install imageio"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pbQptbyLlopp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-yt5wqYh2zQ",
        "colab_type": "code",
        "outputId": "94d7a6eb-ec24-43b1-9d13-e52d95bd7afc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "import tensorflow as tf\n",
        "import glob\n",
        "import imageio\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "from PIL import Image\n",
        "from tensorflow.keras import layers\n",
        "import time\n",
        "\n",
        "from IPython import display\n",
        "\n",
        "from os.path import join\n",
        "from os import listdir\n",
        "from os.path import isfile, join, isdir\n",
        "\n",
        "#import keras\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.layers import Conv2DTranspose, ConvLSTM2D, BatchNormalization, TimeDistributed, Conv2D, Conv3D, LayerNormalization, MaxPool3D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import argparse\n",
        "from os.path import dirname\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EvWhoWymim4I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Config:\n",
        "    def __init__(self, data_dir):\n",
        "        self.DATASET_PATH = join(data_dir,\"UCSDped1/Train\")\n",
        "        self.SINGLE_TEST_PATH = join(data_dir,\"UCSDped1/Test/Test018\")\n",
        "        self.BATCH_SIZE = 4\n",
        "        self.EPOCHS = 50\n",
        "        self.GEN_MODEL_PATH = join(data_dir,\"model_gen.hdf5\")\n",
        "        self.DIS_MODEL_PATH = join(data_dir,\"model_dis.hdf5\")\n",
        "\n",
        "conf = Config(data_dir=\"/content/drive/My Drive/UCSD_Anomaly_Dataset.v1p2/\") \n",
        "physical_devices = tf.config.list_physical_devices('GPU') \n",
        "try: \n",
        "  tf.config.experimental.set_memory_growth(physical_devices[0], True) \n",
        "except: \n",
        "  # Invalid device or cannot modify virtual devices once initialized. \n",
        "  pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8P2fxTYglGV9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_clips_by_stride(stride, frames_list, sequence_size):\n",
        "    \"\"\" For data augmenting purposes.\n",
        "    Parameters\n",
        "    ----------\n",
        "    stride : int\n",
        "        The distance between two consecutive frames\n",
        "    frames_list : list\n",
        "        A list of sorted frames of shape 256 X 256\n",
        "    sequence_size: int\n",
        "        The size of the lstm sequence\n",
        "    Returns\n",
        "    -------\n",
        "    list\n",
        "        A list of clips , 10 frames each\n",
        "    \"\"\"\n",
        "    clips = []\n",
        "    sz = len(frames_list)\n",
        "    clip = np.zeros(shape=(sequence_size, 256, 256, 1))\n",
        "    cnt = 0\n",
        "    for start in range(0, stride):\n",
        "        for i in range(start, sz, stride):\n",
        "            clip[cnt, :, :, 0] = frames_list[i]\n",
        "            cnt = cnt + 1\n",
        "            if cnt == sequence_size:\n",
        "                clips.append(clip)\n",
        "                cnt = 0\n",
        "    return clips\n",
        "\n",
        "def get_training_set():\n",
        "    \"\"\"\n",
        "    Returns\n",
        "    -------\n",
        "    list\n",
        "        A list of training sequences of shape (NUMBER_OF_SEQUENCES,SINGLE_SEQUENCE_SIZE,FRAME_WIDTH,FRAME_HEIGHT,1)\n",
        "    \"\"\"\n",
        "    clips = []\n",
        "    # loop over the training folders (Train000,Train001,..)\n",
        "    for f in sorted(listdir(conf.DATASET_PATH)):\n",
        "        directory_path = join(conf.DATASET_PATH, f)\n",
        "        if isdir(directory_path):\n",
        "            all_frames = []\n",
        "            # loop over all the images in the folder (0.tif,1.tif,..,199.tif)\n",
        "            for c in sorted(listdir(directory_path)):\n",
        "                img_path = join(directory_path, c)\n",
        "                if str(img_path)[-3:] == \"tif\":\n",
        "                    img = Image.open(img_path).resize((256, 256))\n",
        "\n",
        "                    img = np.array(img, dtype=np.float32) / 256.0\n",
        "                    all_frames.append(img)\n",
        "            # get the 10-frames sequences from the list of images after applying data augmentation\n",
        "            for stride in range(1, 3):\n",
        "                clips.extend(get_clips_by_stride(stride=stride, frames_list=all_frames, sequence_size=10))\n",
        "    return clips\n",
        "\n",
        "def get_single_test():\n",
        "    sz = 200\n",
        "    test = np.zeros(shape=(sz, 256, 256, 1))\n",
        "    cnt = 0\n",
        "    for f in sorted(listdir(conf.SINGLE_TEST_PATH)):\n",
        "        if str(join(conf.SINGLE_TEST_PATH, f))[-3:] == \"tif\":\n",
        "            img = Image.open(join(conf.SINGLE_TEST_PATH, f)).resize((256, 256))\n",
        "            img = np.array(img, dtype=np.float32) / 256.0\n",
        "            test[cnt, :, :, 0] = img\n",
        "            cnt = cnt + 1\n",
        "    return test\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-SXZUmPq07B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_generator_model():\n",
        "    \"\"\"\n",
        "    Parameters\n",
        "    ----------\n",
        "    reload_model : bool\n",
        "        Load saved model or retrain it\n",
        "    \"\"\"\n",
        "    seq = Sequential()\n",
        "    seq.add(TimeDistributed(Conv2D(128, (11, 11), strides=4, padding=\"same\"), batch_input_shape=(None, 10, 256, 256, 1)))\n",
        "    seq.add(LayerNormalization())\n",
        "    seq.add(TimeDistributed(Conv2D(64, (5, 5), strides=2, padding=\"same\")))\n",
        "    seq.add(LayerNormalization())\n",
        "    # # # # #\n",
        "    seq.add(ConvLSTM2D(64, (3, 3), padding=\"same\", return_sequences=True))\n",
        "    seq.add(LayerNormalization())\n",
        "    seq.add(ConvLSTM2D(32, (3, 3), padding=\"same\", return_sequences=True))\n",
        "    seq.add(LayerNormalization())\n",
        "    seq.add(ConvLSTM2D(64, (3, 3), padding=\"same\", return_sequences=True))\n",
        "    seq.add(LayerNormalization())\n",
        "    # # # # #\n",
        "    seq.add(TimeDistributed(Conv2DTranspose(64, (5, 5), strides=2, padding=\"same\")))\n",
        "    seq.add(LayerNormalization())\n",
        "    seq.add(TimeDistributed(Conv2DTranspose(128, (11, 11), strides=4, padding=\"same\")))\n",
        "    seq.add(LayerNormalization())\n",
        "    seq.add(TimeDistributed(Conv2D(1, (11, 11), activation=\"sigmoid\", padding=\"same\")))\n",
        "\n",
        "    return seq\n",
        "\n",
        "def get_discriminator_model():\n",
        "    ## input layer\n",
        "    input_layer = tf.keras.Input(shape=(10, 256, 256, 1), batch_size=conf.BATCH_SIZE)\n",
        "\n",
        "    ## convolutional layers\n",
        "    conv_layer1 = Conv3D(filters=8, kernel_size=(3, 3, 3), activation='relu', data_format=\"channels_last\", padding=\"same\")(input_layer)\n",
        "    conv_layer2 = Conv3D(filters=16, kernel_size=(3, 3, 3), activation='relu', padding=\"same\")(conv_layer1)\n",
        "\n",
        "    ## add max pooling to obtain the most imformatic features\n",
        "    pooling_layer1 = MaxPool3D(pool_size=(2, 2, 2))(conv_layer2)\n",
        "\n",
        "    conv_layer3 = Conv3D(filters=32, kernel_size=(3, 3, 3), activation='relu', padding=\"same\")(pooling_layer1)\n",
        "    conv_layer4 = Conv3D(filters=64, kernel_size=(3, 3, 3), activation='relu', padding=\"same\")(conv_layer3)\n",
        "    pooling_layer2 = MaxPool3D(pool_size=(2, 2, 2))(conv_layer4)\n",
        "\n",
        "    conv_layer5 = Conv3D(filters=16, kernel_size=(3, 3, 3), activation='relu', padding=\"same\")(pooling_layer2)\n",
        "    conv_layer6 = Conv3D(filters=8, kernel_size=(3, 3, 3), activation='relu', padding=\"same\")(conv_layer5)\n",
        "    pooling_layer3 = MaxPool3D(pool_size=(2, 2, 2))(conv_layer6)\n",
        "    ## perform batch normalization on the convolution outputs before feeding it to MLP architecture\n",
        "    pooling_layer3 = BatchNormalization()(pooling_layer3)\n",
        "    flatten_layer = Flatten()(pooling_layer3)\n",
        "\n",
        "    ## create an MLP architecture with dense layers : 4096 -> 512 -> 128->1\n",
        "    ## add dropouts to avoid overfitting / perform regularization\n",
        "    dense_layer1 = Dense(units=2048, activation='relu')(flatten_layer)\n",
        "    dense_layer1 = Dropout(0.4)(dense_layer1)\n",
        "    dense_layer2 = Dense(units=512, activation='relu')(dense_layer1)\n",
        "    dense_layer2 = Dropout(0.4)(dense_layer2)\n",
        "    dense_layer3 = Dense(units=265, activation='relu')(dense_layer2)\n",
        "    dense_layer3 = Dropout(0.4)(dense_layer3)\n",
        "    output_layer = Dense(units=1, activation='softmax')(dense_layer3)\n",
        "    ## define the model with input layer and output layer\n",
        "    model = tf.keras.Model(inputs=input_layer, outputs=output_layer)\n",
        "    return model\n",
        "\n",
        "def get_discriminator_model_v1():\n",
        "    model = Sequential()\n",
        "    ## convolutional layers\n",
        "    model.add(Conv3D(filters=8, kernel_size=(3, 3, 3), activation='relu', data_format=\"channels_last\", padding=\"same\", batch_input_shape=(None, 10, 256, 256, 1)))\n",
        "    model.add(Conv3D(filters=16, kernel_size=(3, 3, 3), activation='relu', padding=\"same\"))\n",
        "\n",
        "    ## add max pooling to obtain the most imformatic features\n",
        "    model.add(MaxPool3D(pool_size=(2, 2, 2)))\n",
        "\n",
        "    model.add(Conv3D(filters=32, kernel_size=(3, 3, 3), activation='relu', padding=\"same\"))\n",
        "    model.add(Conv3D(filters=64, kernel_size=(3, 3, 3), activation='relu', padding=\"same\"))\n",
        "    model.add(MaxPool3D(pool_size=(2, 2, 2)))\n",
        "\n",
        "    model.add(Conv3D(filters=16, kernel_size=(3, 3, 3), activation='relu', padding=\"same\"))\n",
        "    model.add(Conv3D(filters=8, kernel_size=(3, 3, 3), activation='relu', padding=\"same\"))\n",
        "    model.add(MaxPool3D(pool_size=(2, 2, 2)))\n",
        "    ## perform batch normalization on the convolution outputs before feeding it to MLP architecture\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Flatten())\n",
        "\n",
        "    ## create an MLP architecture with dense layers : 4096 -> 512 -> 128->1\n",
        "    ## add dropouts to avoid overfitting / perform regularization\n",
        "    model.add(Dense(units=2048, activation='relu'))\n",
        "    model.add(Dropout(0.4))\n",
        "    model.add(Dense(units=512, activation='relu'))\n",
        "    model.add(Dropout(0.4))\n",
        "    model.add(Dense(units=128, activation='relu'))\n",
        "    model.add(Dropout(0.4))\n",
        "    model.add(Dense(units=1, activation='sigmoid'))\n",
        "    \n",
        "    return model\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g54Be7BfRVUQ",
        "colab_type": "code",
        "outputId": "c0c7b5c0-2682-4b5f-d466-45d237ebf2f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "generator = get_generator_model()\n",
        "print(\"Generator Summary===============================================>>\")\n",
        "generator.summary()\n",
        "discriminator = get_discriminator_model_v1()\n",
        "print(\"Discriminator Summary===============================================>>\")\n",
        "discriminator.summary()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Generator Summary===============================================>>\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "time_distributed (TimeDistri (None, 10, 64, 64, 128)   15616     \n",
            "_________________________________________________________________\n",
            "layer_normalization (LayerNo (None, 10, 64, 64, 128)   256       \n",
            "_________________________________________________________________\n",
            "time_distributed_1 (TimeDist (None, 10, 32, 32, 64)    204864    \n",
            "_________________________________________________________________\n",
            "layer_normalization_1 (Layer (None, 10, 32, 32, 64)    128       \n",
            "_________________________________________________________________\n",
            "conv_lst_m2d (ConvLSTM2D)    (None, 10, 32, 32, 64)    295168    \n",
            "_________________________________________________________________\n",
            "layer_normalization_2 (Layer (None, 10, 32, 32, 64)    128       \n",
            "_________________________________________________________________\n",
            "conv_lst_m2d_1 (ConvLSTM2D)  (None, 10, 32, 32, 32)    110720    \n",
            "_________________________________________________________________\n",
            "layer_normalization_3 (Layer (None, 10, 32, 32, 32)    64        \n",
            "_________________________________________________________________\n",
            "conv_lst_m2d_2 (ConvLSTM2D)  (None, 10, 32, 32, 64)    221440    \n",
            "_________________________________________________________________\n",
            "layer_normalization_4 (Layer (None, 10, 32, 32, 64)    128       \n",
            "_________________________________________________________________\n",
            "time_distributed_2 (TimeDist (None, 10, 64, 64, 64)    102464    \n",
            "_________________________________________________________________\n",
            "layer_normalization_5 (Layer (None, 10, 64, 64, 64)    128       \n",
            "_________________________________________________________________\n",
            "time_distributed_3 (TimeDist (None, 10, 256, 256, 128) 991360    \n",
            "_________________________________________________________________\n",
            "layer_normalization_6 (Layer (None, 10, 256, 256, 128) 256       \n",
            "_________________________________________________________________\n",
            "time_distributed_4 (TimeDist (None, 10, 256, 256, 1)   15489     \n",
            "=================================================================\n",
            "Total params: 1,958,209\n",
            "Trainable params: 1,958,209\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Discriminator Summary===============================================>>\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv3d (Conv3D)              (None, 10, 256, 256, 8)   224       \n",
            "_________________________________________________________________\n",
            "conv3d_1 (Conv3D)            (None, 10, 256, 256, 16)  3472      \n",
            "_________________________________________________________________\n",
            "max_pooling3d (MaxPooling3D) (None, 5, 128, 128, 16)   0         \n",
            "_________________________________________________________________\n",
            "conv3d_2 (Conv3D)            (None, 5, 128, 128, 32)   13856     \n",
            "_________________________________________________________________\n",
            "conv3d_3 (Conv3D)            (None, 5, 128, 128, 64)   55360     \n",
            "_________________________________________________________________\n",
            "max_pooling3d_1 (MaxPooling3 (None, 2, 64, 64, 64)     0         \n",
            "_________________________________________________________________\n",
            "conv3d_4 (Conv3D)            (None, 2, 64, 64, 16)     27664     \n",
            "_________________________________________________________________\n",
            "conv3d_5 (Conv3D)            (None, 2, 64, 64, 8)      3464      \n",
            "_________________________________________________________________\n",
            "max_pooling3d_2 (MaxPooling3 (None, 1, 32, 32, 8)      0         \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 1, 32, 32, 8)      32        \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 8192)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 2048)              16779264  \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 512)               1049088   \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 128)               65664     \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 17,998,217\n",
            "Trainable params: 17,998,201\n",
            "Non-trainable params: 16\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1CWt9umOv6lD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wuzBCu040Z36",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def discriminator_loss(real_output, fake_output):\n",
        "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
        "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
        "    total_loss = real_loss + fake_loss\n",
        "    return total_loss\n",
        "\n",
        "\n",
        "def generator_loss(fake_output):\n",
        "    return cross_entropy(tf.ones_like(fake_output), fake_output)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iluCW6d00-_v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "generator_optimizer = tf.optimizers.Adam(1e-4, decay=1e-5, epsilon=1e-6)\n",
        "discriminator_optimizer = tf.optimizers.Adam(1e-4, decay=1e-5, epsilon=1e-6)\n",
        "#tf.keras.optimizers.Adam\n",
        "#checkpoint_dir = './training_checkpoints'\n",
        "#heckpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "#checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
        "#                                discriminator_optimizer=discriminator_optimizer,\n",
        "#                                 generator=generator,\n",
        "#                                 discriminator=discriminator)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkNki2mqQqLl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def train_step(images):\n",
        "    #noise = tf.random.normal([BATCH_SIZE, noise_dim])\n",
        "    \n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "        generated_images = generator(images, training=True)\n",
        "        \n",
        "        real_output = discriminator(images, training=True)\n",
        "        \n",
        "        fake_output = discriminator(generated_images, training=True)\n",
        "        \n",
        "        gen_loss = generator_loss(fake_output)\n",
        "        disc_loss = discriminator_loss(real_output, fake_output)\n",
        "        \n",
        "\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4A5t2BAgRgpJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_generator():\n",
        "    \n",
        "    test = get_single_test()\n",
        "    sz = test.shape[0] - 10\n",
        "    sequences = np.zeros((sz, 10, 256, 256, 1))\n",
        "    # apply the sliding window technique to get the sequences\n",
        "    for i in range(0, sz):\n",
        "        clip = np.zeros((10, 256, 256, 1))\n",
        "        for j in range(0, 10):\n",
        "            clip[j] = test[i + j, :, :, :]\n",
        "        sequences[i] = clip\n",
        "\n",
        "    # get the reconstruction cost of all the sequences\n",
        "    reconstructed_sequences = generator.predict(sequences,batch_size=4)\n",
        "\n",
        "    sequences_reconstruction_cost = np.array([np.linalg.norm(np.subtract(sequences[i],reconstructed_sequences[i])) for i in range(0,sz)])\n",
        "    sa = (sequences_reconstruction_cost - np.min(sequences_reconstruction_cost)) / np.max(sequences_reconstruction_cost)\n",
        "    sr = 1.0 - sa\n",
        "\n",
        "    # plot the regularity scores\n",
        "    plt.plot(sr)\n",
        "    plt.ylabel('regularity score Sr(t)')\n",
        "    plt.xlabel('frame t')\n",
        "    plt.show()\n",
        "    return reconstructed_sequences\n",
        "\n",
        "def test_discriminator(reconstructed_sequences):\n",
        "    sz = test.shape[0] - 10\n",
        "    final_output = discriminator.predict(reconstructed_sequences,batch_size=4)\n",
        "\n",
        "    plt.plot(final_output)\n",
        "    plt.ylabel('Anomalous probability(t)')\n",
        "    plt.xlabel('frame t')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def train(dataset, epochs):\n",
        "  for epoch in range(epochs):\n",
        "    start = time.time()\n",
        "    \n",
        "    for image_batch in dataset:\n",
        "      train_step(image_batch)\n",
        "    \n",
        "    # Produce images for the GIF as we go\n",
        "    display.clear_output(wait=True)\n",
        "\n",
        "    print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
        "\n",
        "  generator.save(conf.GEN_MODEL_PATH,save_format='h5')\n",
        "  discriminator.save(conf.DIS_MODEL_PATH,save_format='h5')\n",
        "  # Generate after the final epoch\n",
        "  display.clear_output(wait=True)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47A6nxhTRgwn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset = tf.data.Dataset.from_tensor_slices(np.array(get_training_set())).batch(conf.BATCH_SIZE)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_t346URNjWrM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for data in train_dataset:\n",
        "    print(data)\n",
        "    break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGxtkBifR6hX",
        "colab_type": "code",
        "outputId": "e2f6fc29-66e0-4623-f6eb-ab9deb3a9fd7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "\n",
        "train(train_dataset, conf.EPOCHS)\n",
        "reconstructed_images = test_generator()\n",
        "test_discriminator(reconstructed_images)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Time for epoch 3 is 589.9900367259979 sec\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}