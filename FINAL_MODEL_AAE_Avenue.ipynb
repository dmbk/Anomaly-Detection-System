{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FINAL_MODEL_AAE_Avenue.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dmbk/Anomaly-Detection-System/blob/master/FINAL_MODEL_AAE_Avenue.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mOpwOqr0OL6R",
        "colab_type": "code",
        "outputId": "78370e35-de9c-4cd6-c43a-9cd77a51be9b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        }
      },
      "source": [
        "!pip install imageio\n",
        "!pip install progress\n",
        "#!pip install tensorflow_datasets\n",
        "!pip install keras-layer-normalization\n",
        "from google.colab import drive\n",
        "#!pip install alive-progress\n",
        "drive.mount('/content/drive', force_remount=True)\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: imageio in /usr/local/lib/python3.6/dist-packages (2.4.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from imageio) (7.0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from imageio) (1.18.3)\n",
            "Requirement already satisfied: progress in /usr/local/lib/python3.6/dist-packages (1.5)\n",
            "Requirement already satisfied: keras-layer-normalization in /usr/local/lib/python3.6/dist-packages (0.14.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from keras-layer-normalization) (1.18.3)\n",
            "Requirement already satisfied: Keras in /usr/local/lib/python3.6/dist-packages (from keras-layer-normalization) (2.3.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras->keras-layer-normalization) (2.10.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras->keras-layer-normalization) (3.13)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-layer-normalization) (1.0.8)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-layer-normalization) (1.1.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-layer-normalization) (1.4.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-layer-normalization) (1.12.0)\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-eFt6lxCTi3Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "\n",
        "import skimage\n",
        "import glob\n",
        "import imageio\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "from PIL import Image\n",
        "from os.path import join\n",
        "from os import listdir\n",
        "from os.path import isfile, join, isdir\n",
        "\n",
        "#import keras\n",
        "import argparse\n",
        "from os.path import dirname\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\t\n",
        "import statistics\n",
        "import shutil\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import time\n",
        "from progress.bar import IncrementalBar\n",
        "\n",
        "import numpy as np\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Input, Dense, Reshape, Flatten\n",
        "from keras.layers import Conv2DTranspose, ConvLSTM2D, BatchNormalization, TimeDistributed, Conv2D, Dropout, Activation, InputLayer, MaxPool3D\n",
        "from keras.optimizers import Adam\n",
        "from keras_layer_normalization import LayerNormalization\n",
        "from keras.models import load_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "571xSlFJUBaB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Config:\n",
        "    def __init__(self, data_dir_, cwdir_name_, data_set):\n",
        "        self.data_set_name = data_set\n",
        "        self.data_dir = data_dir_\n",
        "        self.data_set_dir = join(self.data_dir, data_set)\n",
        "        self.cwdir_name = cwdir_name_\n",
        "        self.cwdir = join(self.data_dir,self.cwdir_name)\n",
        "        self.run_data = join(self.cwdir, \"training_dir\")\n",
        "        self.image_dir = join(self.run_data,self.data_set_name,\"testing_videos/\")\n",
        "        if not os.path.exists(self.cwdir):\n",
        "            os.mkdir(self.cwdir)\n",
        "            os.mkdir(self.run_data)\n",
        "    \n",
        "        if not os.path.exists(self.run_data):\n",
        "            #shutil.rmtree(self.run_data)\n",
        "            os.mkdir(self.run_data)\n",
        "            os.makedirs(self.image_dir, exist_ok=True)\n",
        "\n",
        "        self.DATASET_PATH = join(self.data_set_dir,\"training_videos/\")\n",
        "        self.TEST_DIR = join(self.data_set_dir,\"testing_videos/\")\n",
        "        self.BATCH_SIZE = 2\n",
        "        self.EPOCHS = 50\n",
        "        self.GEN_MODEL_PATH = join(self.cwdir,\"model_gen_Conv2DLSTM_AAE\")\n",
        "        self.DIS_MODEL_PATH = join(self.cwdir,\"model_dis_Conv2DLSTM_AAE\")\n",
        "        self.DEC_MODEL_PATH = join(self.cwdir,\"model_dec_Conv2DLSTM_AAE\")\n",
        "\n",
        "        self.retrain = 0\n",
        "        self.dim1 = 10\n",
        "        self.dim2 = 256\n",
        "        self.dim3 = 256\n",
        "        self.dim4 = 1\n",
        "        self.latent_dim = 327680\n",
        "        self.curr_epoch = 0\n",
        "\n",
        "    def reconfig(self, new_name, batch_size = 4, epochs = 5, retrain = 0, curr_epoch = 0):\n",
        "        self.cwdir_name = new_name\n",
        "        self.cwdir = join(self.data_dir, self.cwdir_name)\n",
        "        self.run_data = join(self.cwdir, \"training_dir\")\n",
        "        self.image_dir = join(self.run_data,self.data_set_name,\"testing_videos/\")\n",
        "\n",
        "        self.BATCH_SIZE = batch_size\n",
        "        self.EPOCHS = epochs\n",
        "        self.GEN_MODEL_PATH = join(self.cwdir,\"model_gen_Conv2DLSTM_AAE\")\n",
        "        self.DIS_MODEL_PATH = join(self.cwdir,\"model_dis_Conv2DLSTM_AAE\")\n",
        "        self.DEC_MODEL_PATH = join(self.cwdir,\"model_dec_Conv2DLSTM_AAE\")\n",
        "\n",
        "        self.retrain = retrain\n",
        "        if retrain == 0:\n",
        "            print(\"Configuring train from scratch\")\n",
        "            if not os.path.exists(self.cwdir):\n",
        "                os.mkdir(self.cwdir)\n",
        "                os.mkdir(self.run_data)\n",
        "    \n",
        "            if os.path.exists(self.run_data):\n",
        "                shutil.rmtree(self.run_data)\n",
        "                os.mkdir(self.run_data)\n",
        "                os.makedirs(self.image_dir, exist_ok=True)\n",
        "        else:\n",
        "            if not os.path.exists(self.cwdir):\n",
        "                os.mkdir(self.cwdir)\n",
        "                os.mkdir(self.run_data)\n",
        "                os.makedirs(self.image_dir, exist_ok=True)\n",
        "\n",
        "        self.curr_epoch = curr_epoch\n",
        "\n",
        "conf = Config(data_dir_=\"/content/drive/My Drive/\", cwdir_name_=\"Conv2DLSTM_AAE_Avenue\", data_set=\"AVDT/\") \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wEre58ljoxbK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def normalize_img(img):\n",
        "    img = np.array(img, dtype=np.float32) / 256.0\n",
        "    return img\n",
        "\n",
        "\n",
        "def get_clips_by_stride(stride, frames_list, sequence_size):\n",
        "\n",
        "    clips = []\n",
        "    sz = len(frames_list)\n",
        "    clip = np.zeros(shape=(sequence_size, 256, 256, 1))\n",
        "    cnt = 0\n",
        "    for start in range(0, stride):\n",
        "        for i in range(start, sz, stride):\n",
        "            clip[cnt, :, :, 0] = frames_list[i]\n",
        "            cnt = cnt + 1\n",
        "            if cnt == sequence_size:\n",
        "                clips.append(clip)\n",
        "                cnt = 0\n",
        "    return clips\n",
        "\n",
        "def get_clips_list(seq_size):\n",
        "\n",
        "    clips = []\n",
        "    # loop over the training folders (Train000,Train001,..)\n",
        "    for f in sorted(listdir(conf.DATASET_PATH)):\n",
        "        directory_path = join(conf.DATASET_PATH, f)\n",
        "        if isdir(directory_path):\n",
        "            all_frames = []\n",
        "            # loop over all the images in the folder (0.tif,1.tif,..,199.tif)\n",
        "            for c in sorted(listdir(directory_path)):\n",
        "                img_path = join(directory_path, c)\n",
        "                if str(img_path)[-3:] == \"tif\":\n",
        "                    img = Image.open(img_path).resize((256, 256))\n",
        "\n",
        "                    img = normalize_img(img)\n",
        "                    all_frames.append(img)\n",
        "            # get the 32-frames sequences from the list of images after applying data augmentation\n",
        "            for stride in range(1, 3):\n",
        "                clips.extend(get_clips_by_stride(stride=stride, frames_list=all_frames, sequence_size=seq_size))\n",
        "    \n",
        "    #print(np.array(clips).shape)\n",
        "    return np.array(clips)\n",
        "\n",
        "\n",
        "def cap_video(file_path):\n",
        "\n",
        "    cap = cv2.VideoCapture(file_path)\n",
        "    if (cap.isOpened()== False):\n",
        "        print(\"Error opening video stream or file\")\n",
        "\n",
        "    frames = []\n",
        "    while(cap.isOpened()):\n",
        "        ret, frame = cap.read()\n",
        "        if ret == True:\n",
        "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "            frame = cv2.resize(frame, (256, 256))\n",
        "            frame = np.array(frame, dtype=np.float32) / 256.0\n",
        "            frames.append(frame)\n",
        "        else: \n",
        "            break\n",
        "    cap.release()\n",
        "    cv2.destroyAllWindows()\n",
        "    return frames\n",
        "\n",
        "def get_video_list():\n",
        "    return  [join(conf.DATASET_PATH, x) for x in sorted(listdir(conf.DATASET_PATH))]\n",
        "        \n",
        "\n",
        "def get_clips_list_from_video(seq_size):\n",
        "\n",
        "    clips = []\n",
        "    for f in get_video_list():\n",
        "        print(\"Loading video \"+f)\n",
        "        all_frames = []\n",
        "        if(os.path.isfile(f)):\n",
        "            all_frames = cap_video(f) \n",
        "            print(np.array(all_frames).shape)\n",
        "        for stride in range(1, 2):\n",
        "            strided = get_clips_by_stride(stride=stride, frames_list=all_frames, sequence_size=seq_size)\n",
        "            #print(np.array(strided).shape)\n",
        "            clips.extend(strided)\n",
        "\n",
        "    return np.array(clips)\n",
        "\n",
        "def get_test_sequences_from_video(test_case):\n",
        "    test = np.array(cap_video(join(conf.TEST_DIR,test_case)))\n",
        "    test = np.resize(test, (test.shape[0], conf.dim2, conf.dim3, conf.dim4))\n",
        "\n",
        "    print(\"Test case loaded\")\n",
        "    sz = test.shape[0] - conf.dim1\n",
        "    sequences = np.zeros((sz, conf.dim1, conf.dim2, conf.dim3, conf.dim4))\n",
        "    # apply the sliding window technique to get the sequences\n",
        "    for i in range(0, sz):\n",
        "        clip = np.zeros((conf.dim1, conf.dim2, conf.dim3, conf.dim4))\n",
        "        for j in range(0, conf.dim1):\n",
        "            clip[j] = test[i + j, :, :, :]\n",
        "        sequences[i] = clip\n",
        "    return np.array(sequences)\n",
        "\n",
        "\n",
        "def get_single_test(single_test_path):\n",
        "\n",
        "    sz = 0\n",
        "    for f in sorted(listdir(single_test_path)):\n",
        "        if str(join(single_test_path, f))[-3:] == \"tif\":\n",
        "          sz = sz +1\n",
        "\n",
        "    test = np.zeros(shape=(sz, conf.dim2, conf.dim3, conf.dim4))\n",
        "    cnt = 0\n",
        "    for f in sorted(listdir(single_test_path)):\n",
        "        if str(join(single_test_path, f))[-3:] == \"tif\":\n",
        "            img = Image.open(join(single_test_path, f)).resize((conf.dim2, conf.dim3))\n",
        "            #cv2_imshow(np.array(img,dtype=np.float32))\n",
        "            #cv2.waitKey(0)\n",
        "            img = normalize_img(img)\n",
        "            test[cnt, :, :, 0] = img\n",
        "            cnt = cnt + 1\n",
        "    return test\n",
        "\n",
        "def get_test_sequences(test_case_dir):\n",
        "    test = get_single_test(join(conf.TEST_DIR,test_case_dir))\n",
        "    print(\"Test case loaded\")\n",
        "    sz = test.shape[0] - conf.dim1\n",
        "    sequences = np.zeros((sz, conf.dim1, conf.dim2, conf.dim3, conf.dim4))\n",
        "    # apply the sliding window technique to get the sequences\n",
        "    for i in range(0, sz):\n",
        "        clip = np.zeros((conf.dim1, conf.dim2, conf.dim3, conf.dim4))\n",
        "        for j in range(0, conf.dim1):\n",
        "            clip[j] = test[i + j, :, :, :]\n",
        "        sequences[i] = clip\n",
        "    return sequences\n",
        "\n",
        "def convert_images_back(image):\n",
        "    return np.reshape(image,(256, 256))*256.0\n",
        "    #print(image.shape)\n",
        "    #return np.reshape(image[:, :, 0],(image.shape[0], image.shape[1]))*127.5 + 127.5\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0RiNsbLXHTb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8183a992-1a12-4d30-c6cb-1cacf37f19e1"
      },
      "source": [
        "def build_model_enc(path=\"\"):\n",
        "    if conf.retrain == 1 and os.path.isfile(path):\n",
        "        print(\"Loading enc from :\"+path)\n",
        "        model_gen=load_model(path, custom_objects={'LayerNormalization': LayerNormalization})\n",
        "        return model_gen\n",
        "    seq = Sequential()\n",
        "    seq.add(TimeDistributed(Conv2D(128, (11, 11), strides=4, activation=\"relu\", padding=\"same\"), batch_input_shape=(None, 10, 256, 256, 1)))\n",
        "    seq.add(LayerNormalization())\n",
        "    seq.add(TimeDistributed(Conv2D(64, (5, 5), strides=2, activation=\"relu\", padding=\"same\")))\n",
        "    seq.add(LayerNormalization())\n",
        "    # # # # #\n",
        "    seq.add(ConvLSTM2D(64, (3, 3), padding=\"same\", return_sequences=True))\n",
        "    seq.add(LayerNormalization())\n",
        "    seq.add(ConvLSTM2D(32, (3, 3), padding=\"same\", return_sequences=True))\n",
        "    seq.add(LayerNormalization())\n",
        "    seq.add(Flatten())\n",
        "    seq.summary(line_length=150)\n",
        "    return  seq\n",
        "\n",
        "def build_model_dec(path=\"\"):\n",
        "    if conf.retrain == 1 and os.path.isfile(path):\n",
        "        print(\"Loading dec from :\"+path)\n",
        "        model_gen=load_model(path, custom_objects={'LayerNormalization': LayerNormalization})\n",
        "        return model_gen\n",
        "    seq = Sequential()\n",
        "    seq.add(Reshape((10, 32, 32, 32), input_shape=(conf.latent_dim,)))\n",
        "    seq.add(ConvLSTM2D(32, (3, 3), padding=\"same\", return_sequences=True))\n",
        "    seq.add(LayerNormalization())\n",
        "    seq.add(ConvLSTM2D(64, (3, 3), padding=\"same\", return_sequences=True))\n",
        "    seq.add(LayerNormalization())\n",
        "    # # # # #\n",
        "    seq.add(TimeDistributed(Conv2DTranspose(64, (5, 5), strides=2, activation=\"relu\", padding=\"same\")))\n",
        "    seq.add(LayerNormalization())\n",
        "    seq.add(TimeDistributed(Conv2DTranspose(128, (11, 11), strides=4, activation=\"relu\", padding=\"same\")))\n",
        "    seq.add(LayerNormalization())\n",
        "    seq.add(TimeDistributed(Conv2D(1, (11, 11), activation=\"sigmoid\", padding=\"same\")))\n",
        "    seq.summary(line_length=150)\n",
        "    return seq\n",
        "\n",
        "def build_model_disc(path=\"\"):\n",
        "    if conf.retrain == 1 and os.path.isfile(path):\n",
        "        print(\"Loading disc from :\"+path)\n",
        "        model_gen=load_model(path, custom_objects={'LayerNormalization': LayerNormalization})\n",
        "        return model_gen\n",
        "    seq = Sequential()\n",
        "    model = Sequential()\n",
        "    seq.add(Reshape((10, 32, 32, 32), input_shape=(conf.latent_dim,)))\n",
        "    seq.add(TimeDistributed(Conv2D(16, (3, 3), strides=2, activation=\"relu\", padding=\"same\")))\n",
        "    seq.add(MaxPool3D(pool_size=(2, 2, 2), strides=2, padding='valid'))\n",
        "    seq.add(Flatten())\n",
        "    seq.add(Dropout(0.4))\n",
        "    seq.add(Dense(1, activation=\"sigmoid\"))\n",
        "    seq.summary(line_length=150)\n",
        "    return seq\n",
        "\n",
        "build_model_enc()\n",
        "build_model_dec()\n",
        "build_model_disc()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "Layer (type)                                                       Output Shape                                                Param #                \n",
            "======================================================================================================================================================\n",
            "time_distributed_1 (TimeDistributed)                               (None, 10, 64, 64, 128)                                     15616                  \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "layer_normalization_1 (LayerNormalization)                         (None, 10, 64, 64, 128)                                     256                    \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "time_distributed_2 (TimeDistributed)                               (None, 10, 32, 32, 64)                                      204864                 \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "layer_normalization_2 (LayerNormalization)                         (None, 10, 32, 32, 64)                                      128                    \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "conv_lst_m2d_1 (ConvLSTM2D)                                        (None, 10, 32, 32, 64)                                      295168                 \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "layer_normalization_3 (LayerNormalization)                         (None, 10, 32, 32, 64)                                      128                    \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "conv_lst_m2d_2 (ConvLSTM2D)                                        (None, 10, 32, 32, 32)                                      110720                 \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "layer_normalization_4 (LayerNormalization)                         (None, 10, 32, 32, 32)                                      64                     \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)                                                (None, 327680)                                              0                      \n",
            "======================================================================================================================================================\n",
            "Total params: 626,944\n",
            "Trainable params: 626,944\n",
            "Non-trainable params: 0\n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "Model: \"sequential_2\"\n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "Layer (type)                                                       Output Shape                                                Param #                \n",
            "======================================================================================================================================================\n",
            "reshape_1 (Reshape)                                                (None, 10, 32, 32, 32)                                      0                      \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "conv_lst_m2d_3 (ConvLSTM2D)                                        (None, 10, 32, 32, 32)                                      73856                  \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "layer_normalization_5 (LayerNormalization)                         (None, 10, 32, 32, 32)                                      64                     \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "conv_lst_m2d_4 (ConvLSTM2D)                                        (None, 10, 32, 32, 64)                                      221440                 \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "layer_normalization_6 (LayerNormalization)                         (None, 10, 32, 32, 64)                                      128                    \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "time_distributed_3 (TimeDistributed)                               (None, 10, 64, 64, 64)                                      102464                 \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "layer_normalization_7 (LayerNormalization)                         (None, 10, 64, 64, 64)                                      128                    \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "time_distributed_4 (TimeDistributed)                               (None, 10, 256, 256, 128)                                   991360                 \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "layer_normalization_8 (LayerNormalization)                         (None, 10, 256, 256, 128)                                   256                    \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "time_distributed_5 (TimeDistributed)                               (None, 10, 256, 256, 1)                                     15489                  \n",
            "======================================================================================================================================================\n",
            "Total params: 1,405,185\n",
            "Trainable params: 1,405,185\n",
            "Non-trainable params: 0\n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "Model: \"sequential_3\"\n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "Layer (type)                                                       Output Shape                                                Param #                \n",
            "======================================================================================================================================================\n",
            "reshape_2 (Reshape)                                                (None, 10, 32, 32, 32)                                      0                      \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "time_distributed_6 (TimeDistributed)                               (None, 10, 16, 16, 16)                                      4624                   \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "max_pooling3d_1 (MaxPooling3D)                                     (None, 5, 8, 8, 16)                                         0                      \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "flatten_2 (Flatten)                                                (None, 5120)                                                0                      \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)                                                (None, 5120)                                                0                      \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "dense_1 (Dense)                                                    (None, 1)                                                   5121                   \n",
            "======================================================================================================================================================\n",
            "Total params: 9,745\n",
            "Trainable params: 9,745\n",
            "Non-trainable params: 0\n",
            "______________________________________________________________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.engine.sequential.Sequential at 0x7f3245b145f8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0prEtmaLqGVG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_model_aae(enc_path, dec_path, disc_path):\n",
        "    model_enc = build_model_enc(enc_path)\n",
        "    model_dec = build_model_dec(dec_path)\n",
        "    model_disc = build_model_disc(disc_path)\n",
        "    \n",
        "    model_ae = Sequential()\n",
        "    model_ae.add(model_enc)\n",
        "    model_ae.add(model_dec)\n",
        "    \n",
        "    model_enc_disc = Sequential()\n",
        "    model_enc_disc.add(model_enc)\n",
        "    model_enc_disc.add(model_disc)\n",
        "    \n",
        "    model_enc.summary()\n",
        "    model_dec.summary()\n",
        "    model_disc.summary()\n",
        "    model_ae.summary()\n",
        "    model_enc_disc.summary()\n",
        "\n",
        "    model_disc.compile(optimizer=Adam(lr=1e-4), loss=\"binary_crossentropy\")\n",
        "    model_enc_disc.compile(optimizer=Adam(lr=1e-4), loss=\"binary_crossentropy\")\n",
        "    model_ae.compile(optimizer=Adam(lr=1e-4, decay=1e-5, epsilon=1e-6), loss=\"mse\")\n",
        "    \n",
        "    return model_enc, model_dec, model_disc, model_ae, model_enc_disc\n",
        "\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6GvNOR9piRHx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "def reconstruct_batch(model, sequences, epoch, folder_name):\n",
        "\n",
        "    sz = sequences.shape[0]\n",
        "    #InX = Input(shape=sequences.shape[1:]) \n",
        "    #tmpModel = Model(inputs=InX, outputs=model.get_layer(\"convTD5\").output)\n",
        "    reconstructed_sequences = model.predict(sequences,batch_size=conf.BATCH_SIZE)\n",
        "\n",
        "    path = join(conf.run_data,folder_name, str(epoch)+\"_epoch\")\n",
        "    os.makedirs(path, exist_ok=True)\n",
        "    for i in range(0, sz):\n",
        "        #cv2_imshow(np.reshape(reconstructed_sequences[i][2],(256, 256))*256)\n",
        "        if i < 10:\n",
        "            img_num = \"00\"+str(i)\n",
        "        elif i < 100:\n",
        "            img_num = \"0\"+str(i)\n",
        "        else:\n",
        "            img_num = str(i)\n",
        "        print(\"Reconstructing : \"+ str(reconstructed_sequences.shape))\n",
        "        cv2.imwrite(join(path,\"gen_\"+img_num+\".jpg\"), convert_images_back(reconstructed_sequences[i][6]))\n",
        "        \n",
        "def settrainable(model, toset):\n",
        "    for layer in model.layers:\n",
        "        layer.trainable = toset\n",
        "    model.trainable = toset\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def evaluate_gen(sequences, model, test_case_dir, epoch=conf.EPOCHS):\n",
        "\n",
        "    reconstructed_sequences = model.predict(sequences,batch_size=conf.BATCH_SIZE)\n",
        "    \n",
        "    sz = sequences.shape[0]\n",
        "    \n",
        "    print(\"Test size:\"+str(sz))\n",
        "   \n",
        "    os.makedirs(join(conf.image_dir,test_case_dir,\"epoch_\"+str(epoch)), exist_ok=True)\n",
        "    for i in range(0, sz):\n",
        "        #print(\"sz \"+str(i)+\"\\n\")\n",
        "        #cv2_imshow(np.reshape(reconstructed_sequences[i][2],(256, 256))*256)\n",
        "        if i < 10:\n",
        "            img_num = \"00\"+str(i)\n",
        "        elif i < 100:\n",
        "            img_num = \"0\"+str(i)\n",
        "        else:\n",
        "            img_num = str(i)    \n",
        "        \n",
        "        cv2.imwrite(join(conf.image_dir, test_case_dir, \"epoch_\"+str(epoch),\"gen_\"+img_num+\".jpg\"), convert_images_back(reconstructed_sequences[i][6]))\n",
        "\n",
        "\n",
        "def evaluate_dis(sequences, model, test_case_dir, epoch=conf.EPOCHS):\n",
        "    sr = model.predict(sequences,batch_size=conf.BATCH_SIZE)\n",
        "\n",
        "    plt.plot(sr)\n",
        "    plt.ylabel('regularity score Sr(t)')\n",
        "    plt.xlabel('frame t')\n",
        "    plt.savefig(join(conf.image_dir, test_case_dir, \"epoch_\"+str(epoch),\"regularity_score.jpg\"))\n",
        "    plt.show()\n",
        "\n",
        "def plot_history(d1_hist, d2_hist, d3_hist, image_name):\n",
        "\t# plot history\n",
        "\tplt.plot(d1_hist, label='ae_loss')\n",
        "\tplt.plot(d2_hist, label='disc_loss')\n",
        "\tplt.plot(d3_hist, label='enc_disc_loss')\n",
        "\tplt.legend()\n",
        "\tplt.savefig(image_name)\n",
        "\tplt.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8GzbHa0avadq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f7ccc709-b95d-4085-c020-687827fb58fb"
      },
      "source": [
        "import csv\n",
        "\n",
        "\n",
        "test_case= \"11.avi\"\n",
        "test_cases = get_test_sequences_from_video(test_case)\n",
        "print(\"Test data set loaded: \"+ str(test_cases.shape))\n",
        "conf.reconfig(new_name=\"Conv2DLSTM_AAE_Avenue\", batch_size=2, epochs=100, retrain=1, curr_epoch=0)\n",
        "x_train = get_clips_list_from_video(conf.dim1)\n",
        "\n",
        "print(\"Train data set loaded: \"+str(x_train.shape))\n",
        "\n",
        "\n",
        "model_enc, model_dec, model_disc, model_ae, model_enc_disc = build_model_aae(enc_path=conf.GEN_MODEL_PATH+str(\"ep\"+str(conf.curr_epoch+1)), dec_path=conf.DEC_MODEL_PATH+str(\"ep\"+str(conf.curr_epoch+1)), disc_path=conf.DIS_MODEL_PATH+str(\"ep\"+str(conf.curr_epoch+1)))\n",
        "\n",
        "\n",
        "batchsize = conf.BATCH_SIZE\n",
        "\n",
        "\n",
        "for epochnumber in range(conf.curr_epoch, conf.EPOCHS):\n",
        "    print(\"Epoch \"+str(epochnumber+1))\n",
        "    d1_hist, d2_hist, d3_hist = list(), list(), list()\n",
        "    with open(join(conf.run_data, 'loss_val.csv'), mode='a') as csv_file:\n",
        "        fieldnames = ['epoch_num', 'batch_num', 'ae_loss', 'disc_loss', 'enc_disc_loss']\n",
        "        writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
        "        writer.writeheader()\n",
        "        for i in range(int(len(x_train) / batchsize)):\n",
        "            print(\"================Starting batch \"+str(i)+\"===============\")\n",
        "            settrainable(model_ae, True)\n",
        "            settrainable(model_enc, True)\n",
        "            settrainable(model_dec, True)\n",
        "        \n",
        "            batch = x_train[i*batchsize:i*batchsize+batchsize]\n",
        "            ae_loss = model_ae.train_on_batch(batch, batch)\n",
        "            print(\"AE trained \")\n",
        "            \n",
        "            settrainable(model_disc, True)\n",
        "            batchpred = model_enc.predict(batch)\n",
        "            fakepred = np.random.standard_normal((batchsize, conf.latent_dim))\n",
        "            #fakepred = np.random.normal(loc=0.0, scale=0.2, size=(batchsize, conf.latent_dim))\n",
        "            discbatch_x = np.concatenate([batchpred, fakepred])\n",
        "            discbatch_y = np.concatenate([np.zeros(batchsize), np.ones(batchsize)])\n",
        "            disc_loss = model_disc.train_on_batch(discbatch_x, discbatch_y)\n",
        "            print(\"Discriminator trained \")\n",
        "            settrainable(model_enc_disc, True)\n",
        "            settrainable(model_enc, True)\n",
        "            settrainable(model_disc, False)\n",
        "            enc_disc_loss = model_enc_disc.train_on_batch(batch, np.ones(batchsize))\n",
        "            print(\"Encoder trained \")\n",
        "            #print(\"ae_loss:\"+str(ae_loss)+\", disc_loss:\"+str(disc_loss)+\", enc_disc_loss:\"+str(enc_disc_loss))\n",
        "            d1_hist.append(ae_loss)\n",
        "            d2_hist.append(disc_loss)\n",
        "            d3_hist.append(enc_disc_loss)\n",
        "\n",
        "            writer.writerow({'epoch_num': epochnumber, 'batch_num': i, 'ae_loss': ae_loss, 'disc_loss': disc_loss, 'enc_disc_loss': enc_disc_loss})\n",
        "        csv_file.close()\n",
        "    plot_history(d1_hist, d2_hist, d3_hist, join(conf.run_data,\"plot_ep_\"+str(epochnumber+1)))\n",
        "    model_enc.save(conf.GEN_MODEL_PATH+str(\"ep\"+str(epochnumber+1)))\n",
        "    model_dec.save(conf.DEC_MODEL_PATH+str(\"ep\"+str(epochnumber+1)))\n",
        "    model_disc.save(conf.DIS_MODEL_PATH+str(\"ep\"+str(epochnumber+1)))\n",
        "    print(\"All models saved for epoch \"+str(epochnumber+1))\n",
        "    print(\"Reconstructing Gen \")\n",
        "    evaluate_gen(test_cases, model_ae, test_case, epochnumber+1)\n",
        "    #print(\"Reconstructing Dis\")\n",
        "    #evaluate_dis(test_cases, model_enc_disc, test_case, epochnumber+1)\n",
        "    #print (\"Reconstruction Loss:\", model_ae.evaluate(x_train, x_train, verbose=0, batch_size=conf.BATCH_SIZE))\n",
        "    #print (\"Adverserial Loss:\", model_enc_disc.evaluate(x_train, np.ones(len(x_train)), verbose=0, batch_size=conf.BATCH_SIZE))\n",
        "\n",
        "\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test case loaded\n",
            "Test data set loaded: (462, 10, 256, 256, 1)\n",
            "Loading video /content/drive/My Drive/AVDT/training_videos/01.avi\n",
            "(1364, 256, 256)\n",
            "Loading video /content/drive/My Drive/AVDT/training_videos/02.avi\n",
            "(1511, 256, 256)\n",
            "Loading video /content/drive/My Drive/AVDT/training_videos/03.avi\n",
            "(1487, 256, 256)\n",
            "Loading video /content/drive/My Drive/AVDT/training_videos/04.avi\n",
            "(1511, 256, 256)\n",
            "Loading video /content/drive/My Drive/AVDT/training_videos/05.avi\n",
            "(815, 256, 256)\n",
            "Loading video /content/drive/My Drive/AVDT/training_videos/06.avi\n",
            "(1511, 256, 256)\n",
            "Loading video /content/drive/My Drive/AVDT/training_videos/07.avi\n",
            "(1099, 256, 256)\n",
            "Loading video /content/drive/My Drive/AVDT/training_videos/08.avi\n",
            "(1017, 256, 256)\n",
            "Loading video /content/drive/My Drive/AVDT/training_videos/09.avi\n",
            "(1391, 256, 256)\n",
            "Loading video /content/drive/My Drive/AVDT/training_videos/10.avi\n",
            "(1223, 256, 256)\n",
            "Loading video /content/drive/My Drive/AVDT/training_videos/11.avi\n",
            "(781, 256, 256)\n",
            "Loading video /content/drive/My Drive/AVDT/training_videos/12.avi\n",
            "(145, 256, 256)\n",
            "Loading video /content/drive/My Drive/AVDT/training_videos/13.avi\n",
            "(366, 256, 256)\n",
            "Loading video /content/drive/My Drive/AVDT/training_videos/14.avi\n",
            "(510, 256, 256)\n",
            "Loading video /content/drive/My Drive/AVDT/training_videos/15.avi\n",
            "(353, 256, 256)\n",
            "Loading video /content/drive/My Drive/AVDT/training_videos/16.avi\n",
            "(244, 256, 256)\n",
            "Train data set loaded: (1527, 10, 256, 256, 1)\n",
            "Model: \"sequential_5\"\n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "Layer (type)                                                       Output Shape                                                Param #                \n",
            "======================================================================================================================================================\n",
            "time_distributed_7 (TimeDistributed)                               (None, 10, 64, 64, 128)                                     15616                  \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "layer_normalization_9 (LayerNormalization)                         (None, 10, 64, 64, 128)                                     256                    \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "time_distributed_8 (TimeDistributed)                               (None, 10, 32, 32, 64)                                      204864                 \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "layer_normalization_10 (LayerNormalization)                        (None, 10, 32, 32, 64)                                      128                    \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "conv_lst_m2d_5 (ConvLSTM2D)                                        (None, 10, 32, 32, 64)                                      295168                 \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "layer_normalization_11 (LayerNormalization)                        (None, 10, 32, 32, 64)                                      128                    \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "conv_lst_m2d_6 (ConvLSTM2D)                                        (None, 10, 32, 32, 32)                                      110720                 \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "layer_normalization_12 (LayerNormalization)                        (None, 10, 32, 32, 32)                                      64                     \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "flatten_3 (Flatten)                                                (None, 327680)                                              0                      \n",
            "======================================================================================================================================================\n",
            "Total params: 626,944\n",
            "Trainable params: 626,944\n",
            "Non-trainable params: 0\n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "Model: \"sequential_6\"\n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "Layer (type)                                                       Output Shape                                                Param #                \n",
            "======================================================================================================================================================\n",
            "reshape_3 (Reshape)                                                (None, 10, 32, 32, 32)                                      0                      \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "conv_lst_m2d_7 (ConvLSTM2D)                                        (None, 10, 32, 32, 32)                                      73856                  \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "layer_normalization_13 (LayerNormalization)                        (None, 10, 32, 32, 32)                                      64                     \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "conv_lst_m2d_8 (ConvLSTM2D)                                        (None, 10, 32, 32, 64)                                      221440                 \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "layer_normalization_14 (LayerNormalization)                        (None, 10, 32, 32, 64)                                      128                    \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "time_distributed_9 (TimeDistributed)                               (None, 10, 64, 64, 64)                                      102464                 \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "layer_normalization_15 (LayerNormalization)                        (None, 10, 64, 64, 64)                                      128                    \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "time_distributed_10 (TimeDistributed)                              (None, 10, 256, 256, 128)                                   991360                 \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "layer_normalization_16 (LayerNormalization)                        (None, 10, 256, 256, 128)                                   256                    \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "time_distributed_11 (TimeDistributed)                              (None, 10, 256, 256, 1)                                     15489                  \n",
            "======================================================================================================================================================\n",
            "Total params: 1,405,185\n",
            "Trainable params: 1,405,185\n",
            "Non-trainable params: 0\n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "Model: \"sequential_7\"\n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "Layer (type)                                                       Output Shape                                                Param #                \n",
            "======================================================================================================================================================\n",
            "reshape_4 (Reshape)                                                (None, 10, 32, 32, 32)                                      0                      \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "time_distributed_12 (TimeDistributed)                              (None, 10, 16, 16, 16)                                      4624                   \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "max_pooling3d_2 (MaxPooling3D)                                     (None, 5, 8, 8, 16)                                         0                      \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "flatten_4 (Flatten)                                                (None, 5120)                                                0                      \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)                                                (None, 5120)                                                0                      \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "dense_2 (Dense)                                                    (None, 1)                                                   5121                   \n",
            "======================================================================================================================================================\n",
            "Total params: 9,745\n",
            "Trainable params: 9,745\n",
            "Non-trainable params: 0\n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "time_distributed_7 (TimeDist (None, 10, 64, 64, 128)   15616     \n",
            "_________________________________________________________________\n",
            "layer_normalization_9 (Layer (None, 10, 64, 64, 128)   256       \n",
            "_________________________________________________________________\n",
            "time_distributed_8 (TimeDist (None, 10, 32, 32, 64)    204864    \n",
            "_________________________________________________________________\n",
            "layer_normalization_10 (Laye (None, 10, 32, 32, 64)    128       \n",
            "_________________________________________________________________\n",
            "conv_lst_m2d_5 (ConvLSTM2D)  (None, 10, 32, 32, 64)    295168    \n",
            "_________________________________________________________________\n",
            "layer_normalization_11 (Laye (None, 10, 32, 32, 64)    128       \n",
            "_________________________________________________________________\n",
            "conv_lst_m2d_6 (ConvLSTM2D)  (None, 10, 32, 32, 32)    110720    \n",
            "_________________________________________________________________\n",
            "layer_normalization_12 (Laye (None, 10, 32, 32, 32)    64        \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 327680)            0         \n",
            "=================================================================\n",
            "Total params: 626,944\n",
            "Trainable params: 626,944\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "reshape_3 (Reshape)          (None, 10, 32, 32, 32)    0         \n",
            "_________________________________________________________________\n",
            "conv_lst_m2d_7 (ConvLSTM2D)  (None, 10, 32, 32, 32)    73856     \n",
            "_________________________________________________________________\n",
            "layer_normalization_13 (Laye (None, 10, 32, 32, 32)    64        \n",
            "_________________________________________________________________\n",
            "conv_lst_m2d_8 (ConvLSTM2D)  (None, 10, 32, 32, 64)    221440    \n",
            "_________________________________________________________________\n",
            "layer_normalization_14 (Laye (None, 10, 32, 32, 64)    128       \n",
            "_________________________________________________________________\n",
            "time_distributed_9 (TimeDist (None, 10, 64, 64, 64)    102464    \n",
            "_________________________________________________________________\n",
            "layer_normalization_15 (Laye (None, 10, 64, 64, 64)    128       \n",
            "_________________________________________________________________\n",
            "time_distributed_10 (TimeDis (None, 10, 256, 256, 128) 991360    \n",
            "_________________________________________________________________\n",
            "layer_normalization_16 (Laye (None, 10, 256, 256, 128) 256       \n",
            "_________________________________________________________________\n",
            "time_distributed_11 (TimeDis (None, 10, 256, 256, 1)   15489     \n",
            "=================================================================\n",
            "Total params: 1,405,185\n",
            "Trainable params: 1,405,185\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "reshape_4 (Reshape)          (None, 10, 32, 32, 32)    0         \n",
            "_________________________________________________________________\n",
            "time_distributed_12 (TimeDis (None, 10, 16, 16, 16)    4624      \n",
            "_________________________________________________________________\n",
            "max_pooling3d_2 (MaxPooling3 (None, 5, 8, 8, 16)       0         \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 5120)              0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 5120)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 5121      \n",
            "=================================================================\n",
            "Total params: 9,745\n",
            "Trainable params: 9,745\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "sequential_5 (Sequential)    (None, 327680)            626944    \n",
            "_________________________________________________________________\n",
            "sequential_6 (Sequential)    (None, 10, 256, 256, 1)   1405185   \n",
            "=================================================================\n",
            "Total params: 2,032,129\n",
            "Trainable params: 2,032,129\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "sequential_5 (Sequential)    (None, 327680)            626944    \n",
            "_________________________________________________________________\n",
            "sequential_7 (Sequential)    (None, 1)                 9745      \n",
            "=================================================================\n",
            "Total params: 636,689\n",
            "Trainable params: 636,689\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1\n",
            "================Starting batch 0===============\n",
            "AE trained \n",
            "Discriminator trained \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:297: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
            "  'Discrepancy between trainable weights and collected trainable'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Encoder trained \n",
            "================Starting batch 1===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 2===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 3===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 4===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 5===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 6===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 7===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 8===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 9===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 10===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 11===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 12===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 13===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 14===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 15===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 16===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 17===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 18===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 19===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 20===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 21===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 22===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 23===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 24===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 25===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 26===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 27===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 28===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 29===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 30===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 31===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 32===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 33===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 34===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 35===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 36===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 37===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 38===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 39===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 40===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 41===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 42===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 43===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 44===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 45===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 46===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 47===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 48===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 49===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 50===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 51===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 52===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 53===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 54===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 55===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 56===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 57===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 58===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 59===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 60===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 61===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 62===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 63===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 64===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 65===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 66===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 67===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 68===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 69===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 70===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 71===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 72===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 73===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 74===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 75===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 76===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 77===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 78===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 79===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 80===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 81===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 82===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 83===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 84===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 85===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 86===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 87===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 88===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 89===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 90===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 91===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 92===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 93===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 94===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 95===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 96===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 97===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 98===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 99===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 100===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 101===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 102===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 103===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 104===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 105===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 106===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 107===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 108===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 109===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 110===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 111===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 112===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 113===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 114===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 115===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 116===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 117===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 118===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 119===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 120===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 121===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 122===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 123===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 124===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 125===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 126===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 127===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 128===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 129===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 130===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 131===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 132===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 133===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 134===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 135===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 136===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 137===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 138===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 139===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 140===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 141===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 142===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 143===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 144===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 145===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 146===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 147===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 148===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 149===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 150===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 151===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 152===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 153===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 154===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 155===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 156===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 157===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 158===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 159===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 160===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 161===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 162===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 163===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 164===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 165===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 166===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 167===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 168===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 169===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 170===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 171===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 172===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 173===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 174===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 175===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 176===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 177===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 178===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 179===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 180===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 181===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 182===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 183===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 184===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 185===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 186===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 187===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 188===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 189===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 190===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 191===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 192===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 193===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 194===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 195===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 196===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 197===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 198===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 199===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 200===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 201===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 202===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 203===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 204===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 205===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 206===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 207===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 208===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 209===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 210===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 211===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 212===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 213===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 214===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 215===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 216===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 217===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 218===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 219===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 220===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 221===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 222===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 223===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 224===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 225===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 226===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 227===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 228===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 229===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 230===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 231===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 232===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 233===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 234===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 235===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 236===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 237===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 238===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 239===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 240===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 241===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 242===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 243===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 244===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 245===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 246===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 247===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 248===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 249===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 250===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 251===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 252===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 253===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 254===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 255===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 256===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 257===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 258===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 259===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 260===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 261===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 262===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 263===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 264===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 265===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 266===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 267===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 268===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 269===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 270===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 271===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 272===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 273===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 274===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 275===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 276===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 277===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 278===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 279===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 280===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 281===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 282===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 283===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 284===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 285===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 286===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 287===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 288===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 289===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 290===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 291===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 292===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 293===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 294===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 295===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 296===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 297===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 298===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 299===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 300===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 301===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 302===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 303===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 304===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 305===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 306===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 307===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 308===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 309===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 310===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 311===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 312===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 313===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 314===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 315===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 316===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 317===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 318===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 319===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 320===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 321===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 322===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 323===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 324===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 325===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 326===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 327===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 328===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 329===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 330===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 331===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 332===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 333===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 334===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 335===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 336===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 337===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 338===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 339===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 340===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 341===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 342===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 343===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 344===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 345===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 346===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 347===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 348===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 349===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 350===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 351===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 352===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 353===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 354===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 355===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 356===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 357===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 358===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 359===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 360===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 361===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 362===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 363===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 364===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 365===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 366===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 367===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 368===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 369===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 370===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 371===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 372===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 373===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 374===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 375===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 376===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 377===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 378===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 379===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 380===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 381===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 382===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 383===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 384===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 385===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 386===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 387===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 388===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 389===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 390===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 391===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 392===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 393===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 394===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 395===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 396===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 397===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 398===============\n",
            "AE trained \n",
            "Discriminator trained \n",
            "Encoder trained \n",
            "================Starting batch 399===============\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-90fdb61f28c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatchsize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatchsize\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbatchsize\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             \u001b[0mae_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_ae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"AE trained \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1512\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1514\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1516\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3790\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3791\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3792\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3793\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3794\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1603\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1604\u001b[0m     \"\"\"\n\u001b[0;32m-> 1605\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1607\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1643\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1644\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1645\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1647\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}