{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "WGAN_as_Discriminator.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNGU+7wc91dg7PmeAoW1BAb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dmbk/Anomaly-Detection-System/blob/master/WGAN_as_Discriminator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yPgCpkKW9bHP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "81d95c0e-af9c-4e4b-e3a3-4eeb49f91585"
      },
      "source": [
        "!pip install imageio\n",
        "\n",
        "from google.colab import drive\n",
        "#!pip install alive-progress\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: imageio in /usr/local/lib/python3.6/dist-packages (2.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from imageio) (1.18.3)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from imageio) (7.0.0)\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5NkfyIC3X4_G",
        "colab_type": "code",
        "outputId": "389ca4a9-99fb-4659-cb4d-9b0ebfecc88a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from __future__ import print_function, division\n",
        "\n",
        "from keras.datasets import mnist\n",
        "from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
        "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
        "from keras.models import Sequential, Model\n",
        "from keras.optimizers import RMSprop\n",
        "\n",
        "import PIL\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "import keras.backend as K\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from os.path import join\n",
        "from os import listdir\n",
        "from os.path import isfile, join, isdir\n",
        "\n",
        "\n",
        "import sys\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "class WGAN():\n",
        "    def __init__(self, retrain=1, model_path=\"\", curr_epoch=0):\n",
        "\n",
        "        self.retrain = retrain\n",
        "        self.MODEL_PATH = model_path\n",
        "        self.curr_epoch = curr_epoch\n",
        "        os.makedirs(self.MODEL_PATH, exist_ok=True)\n",
        "\n",
        "        self.img_rows = 256\n",
        "        self.img_cols = 256\n",
        "        self.channels = 1\n",
        "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
        "        self.latent_dim = 100\n",
        "\n",
        "        # Following parameter and optimizer set as recommended in paper\n",
        "        self.n_critic = 5\n",
        "        self.clip_value = 0.01\n",
        "        optimizer = RMSprop(lr=0.00005)\n",
        "\n",
        "        # Build and compile the critic\n",
        "        self.critic = self.build_critic()\n",
        "        self.critic.compile(loss=self.wasserstein_loss,\n",
        "            optimizer=optimizer,\n",
        "            metrics=['accuracy'])\n",
        "\n",
        "        # Build the generator\n",
        "        self.generator = self.build_generator()\n",
        "\n",
        "        # The generator takes noise as input and generated imgs\n",
        "        z = Input(shape=(self.latent_dim,))\n",
        "        img = self.generator(z)\n",
        "\n",
        "        # For the combined model we will only train the generator\n",
        "        self.critic.trainable = False\n",
        "\n",
        "        # The critic takes generated images as input and determines validity\n",
        "        valid = self.critic(img)\n",
        "\n",
        "        # The combined model  (stacked generator and critic)\n",
        "        self.combined = Model(z, valid)\n",
        "        self.combined.compile(loss=self.wasserstein_loss,\n",
        "            optimizer=optimizer,\n",
        "            metrics=['accuracy'])\n",
        "\n",
        "    def wasserstein_loss(self, y_true, y_pred):\n",
        "        return K.mean(y_true * y_pred)\n",
        "\n",
        "    def build_generator(self):\n",
        "        if self.retrain == 1 and os.path.isfile(join(self.MODEL_PATH,str(\"model_gen_ep\")+str(self.curr_epoch))):\n",
        "            print(\"Loading generator from :\"+join(self.MODEL_PATH,str(\"model_gen_ep\")+str(self.curr_epoch)))\n",
        "            model_gen=load_model(join(self.MODEL_PATH,str(\"model_gen_ep\")+str(self.curr_epoch)))\n",
        "            return model_gen\n",
        "\n",
        "        model = Sequential()\n",
        "\n",
        "        model.add(Dense(128 * 8 *8, activation=\"relu\", input_dim=self.latent_dim))\n",
        "        model.add(Reshape((8, 8, 128)))\n",
        "        model.add(UpSampling2D())\n",
        "        model.add(Conv2D(128, kernel_size=4, padding=\"same\"))\n",
        "        model.add(BatchNormalization(momentum=0.8))\n",
        "        model.add(Activation(\"relu\"))\n",
        "        model.add(UpSampling2D())\n",
        "\n",
        "        model.add(Conv2D(64, kernel_size=4, padding=\"same\"))\n",
        "        model.add(BatchNormalization(momentum=0.8))\n",
        "        model.add(Activation(\"relu\"))\n",
        "        model.add(UpSampling2D())\n",
        "\n",
        "        model.add(Conv2D(32, kernel_size=4, padding=\"same\"))\n",
        "        model.add(BatchNormalization(momentum=0.8))\n",
        "        model.add(Activation(\"relu\"))\n",
        "        model.add(UpSampling2D())\n",
        "\n",
        "        model.add(Conv2D(16, kernel_size=4, padding=\"same\"))\n",
        "        model.add(BatchNormalization(momentum=0.8))\n",
        "        model.add(Activation(\"relu\"))\n",
        "        model.add(UpSampling2D())\n",
        "\n",
        "        model.add(Conv2D(8, kernel_size=4, padding=\"same\"))\n",
        "        model.add(BatchNormalization(momentum=0.8))\n",
        "        model.add(Activation(\"relu\"))\n",
        "        model.add(Conv2D(self.channels, kernel_size=4, padding=\"same\"))\n",
        "        model.add(Activation(\"tanh\"))\n",
        "\n",
        "        model.summary()\n",
        "\n",
        "        noise = Input(shape=(self.latent_dim,))\n",
        "        img = model(noise)\n",
        "\n",
        "        return Model(noise, img)\n",
        "\n",
        "    def build_critic(self):\n",
        "        if self.retrain == 1 and os.path.isfile(join(self.MODEL_PATH,str(\"model_crit_ep\")+str(self.curr_epoch))):\n",
        "            print(\"Loading critic from :\"+ join(self.MODEL_PATH,str(\"model_crit_ep\")+str(self.curr_epoch)))\n",
        "            model_crit=load_model(join(self.MODEL_PATH,str(\"model_crit_ep\")+str(self.curr_epoch)))\n",
        "            return model_crit\n",
        "\n",
        "        model = Sequential()\n",
        "\n",
        "        model.add(Conv2D(16, kernel_size=11, strides=4, input_shape=self.img_shape, padding=\"same\"))\n",
        "        model.add(LeakyReLU(alpha=0.2))\n",
        "        model.add(Dropout(0.25))\n",
        "        model.add(Conv2D(32, kernel_size=5, strides=4, padding=\"same\"))\n",
        "        model.add(ZeroPadding2D(padding=((0,1),(0,1))))\n",
        "        model.add(BatchNormalization(momentum=0.8))\n",
        "        model.add(LeakyReLU(alpha=0.2))\n",
        "        model.add(Dropout(0.25))\n",
        "        model.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n",
        "        model.add(BatchNormalization(momentum=0.8))\n",
        "        model.add(LeakyReLU(alpha=0.2))\n",
        "        model.add(Dropout(0.25))\n",
        "        model.add(Conv2D(128, kernel_size=3, strides=1, padding=\"same\"))\n",
        "        model.add(BatchNormalization(momentum=0.8))\n",
        "        model.add(LeakyReLU(alpha=0.2))\n",
        "        model.add(Dropout(0.25))\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(1))\n",
        "\n",
        "        model.summary()\n",
        "\n",
        "        img = Input(shape=self.img_shape)\n",
        "        validity = model(img)\n",
        "\n",
        "        return Model(img, validity)\n",
        "\n",
        "    def get_frames_list(self):\n",
        "\n",
        "        all_frames = []\n",
        "        # loop over the training folders (Train000,Train001,..)\n",
        "        for f in sorted(listdir(self.DATASET_PATH)):\n",
        "            directory_path = join(self.DATASET_PATH, f)\n",
        "            if isdir(directory_path):\n",
        "            \n",
        "                # loop over all the images in the folder (0.tif,1.tif,..,199.tif)\n",
        "                for c in sorted(listdir(directory_path)):\n",
        "                    img_path = join(directory_path, c)\n",
        "                    if str(img_path)[-3:] == \"tif\":\n",
        "                        img = Image.open(img_path).resize((256, 256))\n",
        "\n",
        "                        img = normalize_img(img)\n",
        "                        all_frames.append(img)\n",
        "       \n",
        "        return np.array(all_frames, dtype=np.float32)\n",
        "\n",
        "    def train(self, epochs, batch_size=128, sample_interval=50):\n",
        "\n",
        "        # Load the dataset\n",
        "        X_train = self.get_frames_list()\n",
        "\n",
        "        # Rescale -1 to 1\n",
        "        X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
        "        X_train = np.expand_dims(X_train, axis=3)\n",
        "\n",
        "        # Adversarial ground truths\n",
        "        valid = -np.ones((batch_size, 1))\n",
        "        fake = np.ones((batch_size, 1))\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "\n",
        "            for _ in range(self.n_critic):\n",
        "\n",
        "                # ---------------------\n",
        "                #  Train Discriminator\n",
        "                # ---------------------\n",
        "\n",
        "                # Select a random batch of images\n",
        "                idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
        "                imgs = X_train[idx]\n",
        "                \n",
        "                # Sample noise as generator input\n",
        "                noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n",
        "\n",
        "                # Generate a batch of new images\n",
        "                gen_imgs = self.generator.predict(noise)\n",
        "\n",
        "                # Train the critic\n",
        "                d_loss_real = self.critic.train_on_batch(imgs, valid)\n",
        "                d_loss_fake = self.critic.train_on_batch(gen_imgs, fake)\n",
        "                d_loss = 0.5 * np.add(d_loss_fake, d_loss_real)\n",
        "\n",
        "                # Clip critic weights\n",
        "                for l in self.critic.layers:\n",
        "                    weights = l.get_weights()\n",
        "                    weights = [np.clip(w, -self.clip_value, self.clip_value) for w in weights]\n",
        "                    l.set_weights(weights)\n",
        "\n",
        "\n",
        "            # ---------------------\n",
        "            #  Train Generator\n",
        "            # ---------------------\n",
        "\n",
        "            g_loss = self.combined.train_on_batch(noise, valid)\n",
        "\n",
        "            # Plot the progress\n",
        "            print (\"%d [D loss: %f] [G loss: %f]\" % (epoch, 1 - d_loss[0], 1 - g_loss[0]))\n",
        "\n",
        "            # If at save interval => save generated image samples\n",
        "            if epoch % sample_interval == 0:\n",
        "                self.sample_images(epoch)\n",
        "                self.critic.save(join(self.MODEL_PATH,str(\"model_crit_ep\")+str(epoch+1)))\n",
        "                self.generator.save(join(self.MODEL_PATH,str(\"model_gen_ep\")+str(epoch+1)))\n",
        "\n",
        "    def sample_images(self, epoch):\n",
        "        r, c = 5, 5\n",
        "        noise = np.random.normal(0, 1, (r * c, self.latent_dim))\n",
        "        gen_imgs = self.generator.predict(noise)\n",
        "\n",
        "        # Rescale images 0 - 1\n",
        "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
        "\n",
        "        fig, axs = plt.subplots(r, c)\n",
        "        cnt = 0\n",
        "        for i in range(r):\n",
        "            for j in range(c):\n",
        "                axs[i,j].imshow(gen_imgs[cnt, :,:,0], cmap='gray')\n",
        "                axs[i,j].axis('off')\n",
        "                cnt += 1\n",
        "        fig.savefig(\"images/mnist_%d.png\" % epoch)\n",
        "        plt.close()\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    wgan = WGAN(retrain=1, model_path=\"/content/drive/My Drive/CRITIC_PED1\", curr_epoch=0)\n",
        "    wgan.train(epochs=4000, batch_size=32, sample_interval=50)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_15\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_65 (Conv2D)           (None, 64, 64, 16)        1952      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_29 (LeakyReLU)   (None, 64, 64, 16)        0         \n",
            "_________________________________________________________________\n",
            "dropout_29 (Dropout)         (None, 64, 64, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_66 (Conv2D)           (None, 16, 16, 32)        12832     \n",
            "_________________________________________________________________\n",
            "zero_padding2d_8 (ZeroPaddin (None, 17, 17, 32)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_51 (Batc (None, 17, 17, 32)        128       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_30 (LeakyReLU)   (None, 17, 17, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_30 (Dropout)         (None, 17, 17, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_67 (Conv2D)           (None, 9, 9, 64)          18496     \n",
            "_________________________________________________________________\n",
            "batch_normalization_52 (Batc (None, 9, 9, 64)          256       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_31 (LeakyReLU)   (None, 9, 9, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_31 (Dropout)         (None, 9, 9, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_68 (Conv2D)           (None, 9, 9, 128)         73856     \n",
            "_________________________________________________________________\n",
            "batch_normalization_53 (Batc (None, 9, 9, 128)         512       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_32 (LeakyReLU)   (None, 9, 9, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_32 (Dropout)         (None, 9, 9, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_8 (Flatten)          (None, 10368)             0         \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 1)                 10369     \n",
            "=================================================================\n",
            "Total params: 118,401\n",
            "Trainable params: 117,953\n",
            "Non-trainable params: 448\n",
            "_________________________________________________________________\n",
            "Model: \"sequential_16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_16 (Dense)             (None, 8192)              827392    \n",
            "_________________________________________________________________\n",
            "reshape_8 (Reshape)          (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "up_sampling2d_30 (UpSampling (None, 16, 16, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_69 (Conv2D)           (None, 16, 16, 128)       262272    \n",
            "_________________________________________________________________\n",
            "batch_normalization_54 (Batc (None, 16, 16, 128)       512       \n",
            "_________________________________________________________________\n",
            "activation_37 (Activation)   (None, 16, 16, 128)       0         \n",
            "_________________________________________________________________\n",
            "up_sampling2d_31 (UpSampling (None, 32, 32, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_70 (Conv2D)           (None, 32, 32, 64)        131136    \n",
            "_________________________________________________________________\n",
            "batch_normalization_55 (Batc (None, 32, 32, 64)        256       \n",
            "_________________________________________________________________\n",
            "activation_38 (Activation)   (None, 32, 32, 64)        0         \n",
            "_________________________________________________________________\n",
            "up_sampling2d_32 (UpSampling (None, 64, 64, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_71 (Conv2D)           (None, 64, 64, 32)        32800     \n",
            "_________________________________________________________________\n",
            "batch_normalization_56 (Batc (None, 64, 64, 32)        128       \n",
            "_________________________________________________________________\n",
            "activation_39 (Activation)   (None, 64, 64, 32)        0         \n",
            "_________________________________________________________________\n",
            "up_sampling2d_33 (UpSampling (None, 128, 128, 32)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_72 (Conv2D)           (None, 128, 128, 16)      8208      \n",
            "_________________________________________________________________\n",
            "batch_normalization_57 (Batc (None, 128, 128, 16)      64        \n",
            "_________________________________________________________________\n",
            "activation_40 (Activation)   (None, 128, 128, 16)      0         \n",
            "_________________________________________________________________\n",
            "up_sampling2d_34 (UpSampling (None, 256, 256, 16)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_73 (Conv2D)           (None, 256, 256, 8)       2056      \n",
            "_________________________________________________________________\n",
            "batch_normalization_58 (Batc (None, 256, 256, 8)       32        \n",
            "_________________________________________________________________\n",
            "activation_41 (Activation)   (None, 256, 256, 8)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_74 (Conv2D)           (None, 256, 256, 1)       129       \n",
            "_________________________________________________________________\n",
            "activation_42 (Activation)   (None, 256, 256, 1)       0         \n",
            "=================================================================\n",
            "Total params: 1,264,985\n",
            "Trainable params: 1,264,489\n",
            "Non-trainable params: 496\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-93d635373b04>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0mwgan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWGAN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"/content/drive/My Drive/CRITIC_PED1\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurr_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m     \u001b[0mwgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-10-93d635373b04>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, epochs, batch_size, sample_interval)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;31m# Load the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_frames_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;31m# Rescale -1 to 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-93d635373b04>\u001b[0m in \u001b[0;36mget_frames_list\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0mall_frames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0;31m# loop over the training folders (Train000,Train001,..)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDATASET_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m             \u001b[0mdirectory_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDATASET_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'WGAN' object has no attribute 'DATASET_PATH'"
          ]
        }
      ]
    }
  ]
}