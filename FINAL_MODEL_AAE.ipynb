{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FINAL_MODEL_AAE.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOzpvPSrtvanf6BsFVu6kHV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dmbk/Anomaly-Detection-System/blob/master/FINAL_MODEL_AAE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mOpwOqr0OL6R",
        "colab_type": "code",
        "outputId": "ef58b9db-d672-44c6-800a-0c80fcb602e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        }
      },
      "source": [
        "!pip install imageio\n",
        "!pip install progress\n",
        "#!pip install tensorflow_datasets\n",
        "!pip install keras-layer-normalization\n",
        "from google.colab import drive\n",
        "#!pip install alive-progress\n",
        "drive.mount('/content/drive', force_remount=True)\n"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: imageio in /usr/local/lib/python3.6/dist-packages (2.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from imageio) (1.18.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from imageio) (7.0.0)\n",
            "Requirement already satisfied: progress in /usr/local/lib/python3.6/dist-packages (1.5)\n",
            "Requirement already satisfied: keras-layer-normalization in /usr/local/lib/python3.6/dist-packages (0.14.0)\n",
            "Requirement already satisfied: Keras in /usr/local/lib/python3.6/dist-packages (from keras-layer-normalization) (2.3.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from keras-layer-normalization) (1.18.2)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-layer-normalization) (1.1.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras->keras-layer-normalization) (3.13)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-layer-normalization) (1.4.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-layer-normalization) (1.12.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras->keras-layer-normalization) (2.10.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-layer-normalization) (1.0.8)\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-eFt6lxCTi3Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "\n",
        "import skimage\n",
        "import glob\n",
        "import imageio\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "from PIL import Image\n",
        "from os.path import join\n",
        "from os import listdir\n",
        "from os.path import isfile, join, isdir\n",
        "\n",
        "#import keras\n",
        "import argparse\n",
        "from os.path import dirname\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\t\n",
        "import statistics\n",
        "import shutil\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import time\n",
        "from progress.bar import IncrementalBar\n",
        "\n",
        "import numpy as np\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Input, Dense, Reshape, Flatten\n",
        "from keras.layers import Conv2DTranspose, ConvLSTM2D, BatchNormalization, TimeDistributed, Conv2D, Dropout, Activation, InputLayer\n",
        "from keras.optimizers import Adam\n",
        "from keras_layer_normalization import LayerNormalization\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "571xSlFJUBaB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Config:\n",
        "    def __init__(self, data_dir_, cwdir_name_, data_set):\n",
        "        self.data_set_name = data_set\n",
        "        self.data_dir = data_dir_\n",
        "        self.data_set_dir = join(self.data_dir, data_set)\n",
        "        self.cwdir_name = cwdir_name_\n",
        "        self.cwdir = join(self.data_dir,self.cwdir_name)\n",
        "        self.run_data = join(self.cwdir, \"training_dir\")\n",
        "        self.image_dir = join(self.run_data,self.data_set_name,\"Test/\")\n",
        "        if not os.path.exists(self.cwdir):\n",
        "            os.mkdir(self.cwdir)\n",
        "            os.mkdir(self.run_data)\n",
        "    \n",
        "        if not os.path.exists(self.run_data):\n",
        "            #shutil.rmtree(self.run_data)\n",
        "            os.mkdir(self.run_data)\n",
        "            os.makedirs(self.image_dir, exist_ok=True)\n",
        "\n",
        "        self.DATASET_PATH = join(self.data_set_dir,\"Train/\")\n",
        "        self.TEST_DIR = join(self.data_set_dir,\"Test/\")\n",
        "        self.BATCH_SIZE = 2\n",
        "        self.EPOCHS = 50\n",
        "        self.GEN_MODEL_PATH = join(self.cwdir,\"model_gen_Conv2DLSTM_AAE\")\n",
        "        self.DIS_MODEL_PATH = join(self.cwdir,\"model_dis_Conv2DLSTM_AAE\")\n",
        "        self.DEC_MODEL_PATH = join(self.cwdir,\"model_dec_Conv2DLSTM_AAE\")\n",
        "\n",
        "        self.retrain = 0\n",
        "        self.dim1 = 10\n",
        "        self.dim2 = 256\n",
        "        self.dim3 = 256\n",
        "        self.dim4 = 1\n",
        "        self.latent_dim = 163840\n",
        "\n",
        "\n",
        "    def reconfig(self, new_name, batch_size = 4, epochs = 5, retrain = 0):\n",
        "        self.cwdir_name = new_name\n",
        "        self.cwdir = join(self.data_dir, self.cwdir_name)\n",
        "        self.run_data = join(self.cwdir, \"training_dir\")\n",
        "        self.image_dir = join(self.run_data,self.data_set_name,\"Test/\")\n",
        "\n",
        "        self.BATCH_SIZE = batch_size\n",
        "        self.EPOCHS = epochs\n",
        "        self.GEN_MODEL_PATH = join(self.cwdir,\"model_gen_Conv2DLSTM_AAE\")\n",
        "        self.DIS_MODEL_PATH = join(self.cwdir,\"model_dis_Conv2DLSTM_AAE\")\n",
        "        self.DEC_MODEL_PATH = join(self.cwdir,\"model_dec_Conv2DLSTM_AAE\")\n",
        "\n",
        "        self.retrain = retrain\n",
        "        if retrain == 0:\n",
        "            print(\"Configuring train from scratch\")\n",
        "            if not os.path.exists(self.cwdir):\n",
        "                os.mkdir(self.cwdir)\n",
        "                os.mkdir(self.run_data)\n",
        "    \n",
        "            if os.path.exists(self.run_data):\n",
        "                shutil.rmtree(self.run_data)\n",
        "                os.mkdir(self.run_data)\n",
        "                os.makedirs(self.image_dir, exist_ok=True)\n",
        "\n",
        "\n",
        "conf = Config(data_dir_=\"/content/drive/My Drive/\", cwdir_name_=\"Conv2DLSTM_AAE\", data_set=\"UCSD_Anomaly_Dataset.v1p2/UCSDped1/\") \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wEre58ljoxbK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_clips_by_stride(stride, frames_list, sequence_size):\n",
        "\n",
        "    clips = []\n",
        "    sz = len(frames_list)\n",
        "    clip = np.zeros(shape=(sequence_size, 256, 256, 1))\n",
        "    cnt = 0\n",
        "    for start in range(0, stride):\n",
        "        for i in range(start, sz, stride):\n",
        "            clip[cnt, :, :, 0] = frames_list[i]\n",
        "            cnt = cnt + 1\n",
        "            if cnt == sequence_size:\n",
        "                clips.append(clip)\n",
        "                cnt = 0\n",
        "    return clips\n",
        "\n",
        "def get_clips_list(seq_size):\n",
        "\n",
        "    clips = []\n",
        "    # loop over the training folders (Train000,Train001,..)\n",
        "    for f in sorted(listdir(conf.DATASET_PATH)):\n",
        "        directory_path = join(conf.DATASET_PATH, f)\n",
        "        if isdir(directory_path):\n",
        "            all_frames = []\n",
        "            # loop over all the images in the folder (0.tif,1.tif,..,199.tif)\n",
        "            for c in sorted(listdir(directory_path)):\n",
        "                img_path = join(directory_path, c)\n",
        "                if str(img_path)[-3:] == \"tif\":\n",
        "                    img = Image.open(img_path).resize((256, 256))\n",
        "\n",
        "                    img = np.array(img, dtype=np.float32) / 256.0\n",
        "                    all_frames.append(img)\n",
        "            # get the 32-frames sequences from the list of images after applying data augmentation\n",
        "            for stride in range(1, 3):\n",
        "                clips.extend(get_clips_by_stride(stride=stride, frames_list=all_frames, sequence_size=seq_size))\n",
        "    \n",
        "    #print(np.array(clips).shape)\n",
        "    return np.array(clips)\n",
        "\n",
        "\n",
        "def get_single_test(single_test_path, sz):\n",
        "    test = np.zeros(shape=(sz, conf.dim2, conf.dim3, conf.dim4))\n",
        "    cnt = 0\n",
        "    for f in sorted(listdir(single_test_path)):\n",
        "        if str(join(single_test_path, f))[-3:] == \"tif\":\n",
        "            img = Image.open(join(single_test_path, f)).resize((conf.dim2, conf.dim3))\n",
        "            #cv2_imshow(np.array(img,dtype=np.float32))\n",
        "            #cv2.waitKey(0)\n",
        "            img = np.array(img, dtype=np.float32) / 256\n",
        "            test[cnt, :, :, 0] = img\n",
        "            cnt = cnt + 1\n",
        "    return test\n",
        "\n",
        "def get_test_sequences(test_case_dir, sz):\n",
        "    test = get_single_test(join(conf.TEST_DIR,test_case_dir), sz)\n",
        "    print(\"Test case loaded\")\n",
        "    sz = test.shape[0] - conf.dim1\n",
        "    sequences = np.zeros((sz, conf.dim1, conf.dim2, conf.dim3, conf.dim4))\n",
        "    # apply the sliding window technique to get the sequences\n",
        "    for i in range(0, sz):\n",
        "        clip = np.zeros((conf.dim1, conf.dim2, conf.dim3, conf.dim4))\n",
        "        for j in range(0, conf.dim1):\n",
        "            clip[j] = test[i + j, :, :, :]\n",
        "        sequences[i] = clip\n",
        "    return sequences\n",
        "\n",
        "def convert_images_back(image):\n",
        "    return np.reshape(image,(256, 256))*256.0\n",
        "    #print(image.shape)\n",
        "    #return np.reshape(image[:, :, 0],(image.shape[0], image.shape[1]))*127.5 + 127.5\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0RiNsbLXHTb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_model_enc():\n",
        "    if conf.retrain == 1 and os.path.isfile(conf.GEN_MODEL_PATH+\".hdf5\"):\n",
        "        model_gen=load_model(conf.GEN_MODEL_PATH)\n",
        "        return model_gen\n",
        "    seq = Sequential()\n",
        "    seq.add(TimeDistributed(Conv2D(128, (11, 11), strides=4, padding=\"same\"), batch_input_shape=(None, 10, 256, 256, 1)))\n",
        "    seq.add(LayerNormalization())\n",
        "    seq.add(TimeDistributed(Conv2D(64, (5, 5), strides=2, padding=\"same\")))\n",
        "    seq.add(LayerNormalization())\n",
        "    # # # # #\n",
        "    seq.add(ConvLSTM2D(64, (3, 3), padding=\"same\", return_sequences=True))\n",
        "    seq.add(LayerNormalization())\n",
        "    seq.add(ConvLSTM2D(32, (3, 3), padding=\"same\", return_sequences=True))\n",
        "    seq.add(LayerNormalization())\n",
        "    seq.add(ConvLSTM2D(16, (3, 3), padding=\"same\", return_sequences=True))\n",
        "    seq.add(LayerNormalization())\n",
        "    seq.add(Flatten())\n",
        "    seq.summary(line_length=150)\n",
        "    return  seq\n",
        "\n",
        "def build_model_dec():\n",
        "    if conf.retrain == 1 and os.path.isfile(conf.DEC_MODEL_PATH+\".hdf5\"):\n",
        "        model_gen=load_model(conf.DEC_MODEL_PATH)\n",
        "        return model_gen\n",
        "    seq = Sequential()\n",
        "    seq.add(Reshape((10, 32, 32, 16), input_shape=(conf.latent_dim,)))\n",
        "    seq.add(ConvLSTM2D(16, (3, 3), padding=\"same\", return_sequences=True))\n",
        "    seq.add(LayerNormalization())\n",
        "    seq.add(ConvLSTM2D(32, (3, 3), padding=\"same\", return_sequences=True))\n",
        "    seq.add(LayerNormalization())\n",
        "    seq.add(ConvLSTM2D(64, (3, 3), padding=\"same\", return_sequences=True))\n",
        "    seq.add(LayerNormalization())\n",
        "    # # # # #\n",
        "    seq.add(TimeDistributed(Conv2DTranspose(64, (5, 5), strides=2, padding=\"same\")))\n",
        "    seq.add(LayerNormalization())\n",
        "    seq.add(TimeDistributed(Conv2DTranspose(128, (11, 11), strides=4, padding=\"same\")))\n",
        "    seq.add(LayerNormalization())\n",
        "    seq.add(TimeDistributed(Conv2D(1, (11, 11), activation=\"sigmoid\", padding=\"same\")))\n",
        "    seq.summary(line_length=150)\n",
        "    return seq\n",
        "\n",
        "def build_model_disc():\n",
        "    if conf.retrain == 1 and os.path.isfile(conf.DIS_MODEL_PATH+\".hdf5\"):\n",
        "        model_gen=load_model(conf.DIS_MODEL_PATH)\n",
        "        return model_gen\n",
        "    seq = Sequential()\n",
        "    model = Sequential()\n",
        "    seq.add(Reshape((10, 32, 32, 16), input_shape=(conf.latent_dim,)))\n",
        "    seq.add(TimeDistributed(Conv2D(16, (3, 3), strides=2, padding=\"same\")))\n",
        "    seq.add(LayerNormalization())\n",
        "    seq.add(TimeDistributed(Conv2D(32, (3, 3), strides=2, padding=\"same\")))\n",
        "    seq.add(LayerNormalization())\n",
        "    seq.add(TimeDistributed(Conv2D(64, (3,3), strides=4, padding=\"same\")))\n",
        "    seq.add(LayerNormalization())\n",
        "    seq.add(TimeDistributed(Conv2D(128, (3,3), strides=4, padding=\"same\")))\n",
        "    seq.add(LayerNormalization())\n",
        "    \n",
        "    seq.add(Flatten())\n",
        "    seq.add(Dense(512, activation=\"relu\"))\n",
        "    seq.add(Dropout(0.4))\n",
        "    seq.add(Dense(256, activation=\"relu\"))\n",
        "    seq.add(Dropout(0.4))\n",
        "    seq.add(Dense(128, activation=\"relu\"))\n",
        "    seq.add(Dropout(0.4))\n",
        "    seq.add(Dense(64, activation=\"relu\"))\n",
        "    #model.add(ke.layers.Dense(32, activation=\"relu\", input_shape=(20480,)))\n",
        "    #model.add(ke.layers.Dense(32, activation=\"relu\"))\n",
        "    seq.add(Dense(1, activation=\"sigmoid\"))\n",
        "    seq.summary(line_length=150)\n",
        "    return seq\n",
        "\n",
        "#build_model_enc()\n",
        "#build_model_dec()\n",
        "#build_model_disc()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0prEtmaLqGVG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "19f890d0-28b7-4619-e326-51dd5684ce17"
      },
      "source": [
        "def build_model_aae():\n",
        "    model_enc = build_model_enc()\n",
        "    model_dec = build_model_dec()\n",
        "    model_disc = build_model_disc()\n",
        "    \n",
        "    model_ae = Sequential()\n",
        "    model_ae.add(model_enc)\n",
        "    model_ae.add(model_dec)\n",
        "    \n",
        "    model_enc_disc = Sequential()\n",
        "    model_enc_disc.add(model_enc)\n",
        "    model_enc_disc.add(model_disc)\n",
        "    \n",
        "    return model_enc, model_dec, model_disc, model_ae, model_enc_disc\n",
        "\n",
        "model_enc, model_dec, model_disc, model_ae, model_enc_disc = build_model_aae()\n",
        "\n",
        "model_enc.summary()\n",
        "model_dec.summary()\n",
        "model_disc.summary()\n",
        "model_ae.summary()\n",
        "model_enc_disc.summary()\n",
        "\n",
        "model_disc.compile(optimizer=Adam(lr=1e-4), loss=\"binary_crossentropy\")\n",
        "model_enc_disc.compile(optimizer=Adam(lr=1e-4), loss=\"binary_crossentropy\")\n",
        "model_ae.compile(optimizer=Adam(lr=1e-4, decay=1e-5, epsilon=1e-6), loss=\"mse\")\n"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_29\"\n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "Layer (type)                                                       Output Shape                                                Param #                \n",
            "======================================================================================================================================================\n",
            "time_distributed_57 (TimeDistributed)                              (None, 10, 64, 64, 128)                                     15616                  \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "layer_normalization_97 (LayerNormalization)                        (None, 10, 64, 64, 128)                                     256                    \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "time_distributed_58 (TimeDistributed)                              (None, 10, 32, 32, 64)                                      204864                 \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "layer_normalization_98 (LayerNormalization)                        (None, 10, 32, 32, 64)                                      128                    \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "conv_lst_m2d_49 (ConvLSTM2D)                                       (None, 10, 32, 32, 64)                                      295168                 \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "layer_normalization_99 (LayerNormalization)                        (None, 10, 32, 32, 64)                                      128                    \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "conv_lst_m2d_50 (ConvLSTM2D)                                       (None, 10, 32, 32, 32)                                      110720                 \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "layer_normalization_100 (LayerNormalization)                       (None, 10, 32, 32, 32)                                      64                     \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "conv_lst_m2d_51 (ConvLSTM2D)                                       (None, 10, 32, 32, 16)                                      27712                  \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "layer_normalization_101 (LayerNormalization)                       (None, 10, 32, 32, 16)                                      32                     \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "flatten_13 (Flatten)                                               (None, 163840)                                              0                      \n",
            "======================================================================================================================================================\n",
            "Total params: 654,688\n",
            "Trainable params: 654,688\n",
            "Non-trainable params: 0\n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "Model: \"sequential_30\"\n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "Layer (type)                                                       Output Shape                                                Param #                \n",
            "======================================================================================================================================================\n",
            "reshape_13 (Reshape)                                               (None, 10, 32, 32, 16)                                      0                      \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "conv_lst_m2d_52 (ConvLSTM2D)                                       (None, 10, 32, 32, 16)                                      18496                  \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "layer_normalization_102 (LayerNormalization)                       (None, 10, 32, 32, 16)                                      32                     \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "conv_lst_m2d_53 (ConvLSTM2D)                                       (None, 10, 32, 32, 32)                                      55424                  \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "layer_normalization_103 (LayerNormalization)                       (None, 10, 32, 32, 32)                                      64                     \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "conv_lst_m2d_54 (ConvLSTM2D)                                       (None, 10, 32, 32, 64)                                      221440                 \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "layer_normalization_104 (LayerNormalization)                       (None, 10, 32, 32, 64)                                      128                    \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "time_distributed_59 (TimeDistributed)                              (None, 10, 64, 64, 64)                                      102464                 \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "layer_normalization_105 (LayerNormalization)                       (None, 10, 64, 64, 64)                                      128                    \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "time_distributed_60 (TimeDistributed)                              (None, 10, 256, 256, 128)                                   991360                 \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "layer_normalization_106 (LayerNormalization)                       (None, 10, 256, 256, 128)                                   256                    \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "time_distributed_61 (TimeDistributed)                              (None, 10, 256, 256, 1)                                     15489                  \n",
            "======================================================================================================================================================\n",
            "Total params: 1,405,281\n",
            "Trainable params: 1,405,281\n",
            "Non-trainable params: 0\n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "Model: \"sequential_31\"\n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "Layer (type)                                                       Output Shape                                                Param #                \n",
            "======================================================================================================================================================\n",
            "reshape_14 (Reshape)                                               (None, 10, 32, 32, 16)                                      0                      \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "time_distributed_62 (TimeDistributed)                              (None, 10, 16, 16, 16)                                      2320                   \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "layer_normalization_107 (LayerNormalization)                       (None, 10, 16, 16, 16)                                      32                     \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "time_distributed_63 (TimeDistributed)                              (None, 10, 8, 8, 32)                                        4640                   \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "layer_normalization_108 (LayerNormalization)                       (None, 10, 8, 8, 32)                                        64                     \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "time_distributed_64 (TimeDistributed)                              (None, 10, 2, 2, 64)                                        18496                  \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "layer_normalization_109 (LayerNormalization)                       (None, 10, 2, 2, 64)                                        128                    \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "time_distributed_65 (TimeDistributed)                              (None, 10, 1, 1, 128)                                       73856                  \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "layer_normalization_110 (LayerNormalization)                       (None, 10, 1, 1, 128)                                       256                    \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "flatten_14 (Flatten)                                               (None, 1280)                                                0                      \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "dense_21 (Dense)                                                   (None, 512)                                                 655872                 \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "dropout_13 (Dropout)                                               (None, 512)                                                 0                      \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "dense_22 (Dense)                                                   (None, 256)                                                 131328                 \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "dropout_14 (Dropout)                                               (None, 256)                                                 0                      \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "dense_23 (Dense)                                                   (None, 128)                                                 32896                  \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "dropout_15 (Dropout)                                               (None, 128)                                                 0                      \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "dense_24 (Dense)                                                   (None, 64)                                                  8256                   \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "dense_25 (Dense)                                                   (None, 1)                                                   65                     \n",
            "======================================================================================================================================================\n",
            "Total params: 928,209\n",
            "Trainable params: 928,209\n",
            "Non-trainable params: 0\n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "Model: \"sequential_29\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "time_distributed_57 (TimeDis (None, 10, 64, 64, 128)   15616     \n",
            "_________________________________________________________________\n",
            "layer_normalization_97 (Laye (None, 10, 64, 64, 128)   256       \n",
            "_________________________________________________________________\n",
            "time_distributed_58 (TimeDis (None, 10, 32, 32, 64)    204864    \n",
            "_________________________________________________________________\n",
            "layer_normalization_98 (Laye (None, 10, 32, 32, 64)    128       \n",
            "_________________________________________________________________\n",
            "conv_lst_m2d_49 (ConvLSTM2D) (None, 10, 32, 32, 64)    295168    \n",
            "_________________________________________________________________\n",
            "layer_normalization_99 (Laye (None, 10, 32, 32, 64)    128       \n",
            "_________________________________________________________________\n",
            "conv_lst_m2d_50 (ConvLSTM2D) (None, 10, 32, 32, 32)    110720    \n",
            "_________________________________________________________________\n",
            "layer_normalization_100 (Lay (None, 10, 32, 32, 32)    64        \n",
            "_________________________________________________________________\n",
            "conv_lst_m2d_51 (ConvLSTM2D) (None, 10, 32, 32, 16)    27712     \n",
            "_________________________________________________________________\n",
            "layer_normalization_101 (Lay (None, 10, 32, 32, 16)    32        \n",
            "_________________________________________________________________\n",
            "flatten_13 (Flatten)         (None, 163840)            0         \n",
            "=================================================================\n",
            "Total params: 654,688\n",
            "Trainable params: 654,688\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"sequential_30\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "reshape_13 (Reshape)         (None, 10, 32, 32, 16)    0         \n",
            "_________________________________________________________________\n",
            "conv_lst_m2d_52 (ConvLSTM2D) (None, 10, 32, 32, 16)    18496     \n",
            "_________________________________________________________________\n",
            "layer_normalization_102 (Lay (None, 10, 32, 32, 16)    32        \n",
            "_________________________________________________________________\n",
            "conv_lst_m2d_53 (ConvLSTM2D) (None, 10, 32, 32, 32)    55424     \n",
            "_________________________________________________________________\n",
            "layer_normalization_103 (Lay (None, 10, 32, 32, 32)    64        \n",
            "_________________________________________________________________\n",
            "conv_lst_m2d_54 (ConvLSTM2D) (None, 10, 32, 32, 64)    221440    \n",
            "_________________________________________________________________\n",
            "layer_normalization_104 (Lay (None, 10, 32, 32, 64)    128       \n",
            "_________________________________________________________________\n",
            "time_distributed_59 (TimeDis (None, 10, 64, 64, 64)    102464    \n",
            "_________________________________________________________________\n",
            "layer_normalization_105 (Lay (None, 10, 64, 64, 64)    128       \n",
            "_________________________________________________________________\n",
            "time_distributed_60 (TimeDis (None, 10, 256, 256, 128) 991360    \n",
            "_________________________________________________________________\n",
            "layer_normalization_106 (Lay (None, 10, 256, 256, 128) 256       \n",
            "_________________________________________________________________\n",
            "time_distributed_61 (TimeDis (None, 10, 256, 256, 1)   15489     \n",
            "=================================================================\n",
            "Total params: 1,405,281\n",
            "Trainable params: 1,405,281\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"sequential_31\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "reshape_14 (Reshape)         (None, 10, 32, 32, 16)    0         \n",
            "_________________________________________________________________\n",
            "time_distributed_62 (TimeDis (None, 10, 16, 16, 16)    2320      \n",
            "_________________________________________________________________\n",
            "layer_normalization_107 (Lay (None, 10, 16, 16, 16)    32        \n",
            "_________________________________________________________________\n",
            "time_distributed_63 (TimeDis (None, 10, 8, 8, 32)      4640      \n",
            "_________________________________________________________________\n",
            "layer_normalization_108 (Lay (None, 10, 8, 8, 32)      64        \n",
            "_________________________________________________________________\n",
            "time_distributed_64 (TimeDis (None, 10, 2, 2, 64)      18496     \n",
            "_________________________________________________________________\n",
            "layer_normalization_109 (Lay (None, 10, 2, 2, 64)      128       \n",
            "_________________________________________________________________\n",
            "time_distributed_65 (TimeDis (None, 10, 1, 1, 128)     73856     \n",
            "_________________________________________________________________\n",
            "layer_normalization_110 (Lay (None, 10, 1, 1, 128)     256       \n",
            "_________________________________________________________________\n",
            "flatten_14 (Flatten)         (None, 1280)              0         \n",
            "_________________________________________________________________\n",
            "dense_21 (Dense)             (None, 512)               655872    \n",
            "_________________________________________________________________\n",
            "dropout_13 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_22 (Dense)             (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dropout_14 (Dropout)         (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_23 (Dense)             (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dropout_15 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_24 (Dense)             (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_25 (Dense)             (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 928,209\n",
            "Trainable params: 928,209\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"sequential_33\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "sequential_29 (Sequential)   (None, 163840)            654688    \n",
            "_________________________________________________________________\n",
            "sequential_30 (Sequential)   (None, 10, 256, 256, 1)   1405281   \n",
            "=================================================================\n",
            "Total params: 2,059,969\n",
            "Trainable params: 2,059,969\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"sequential_34\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "sequential_29 (Sequential)   (None, 163840)            654688    \n",
            "_________________________________________________________________\n",
            "sequential_31 (Sequential)   (None, 1)                 928209    \n",
            "=================================================================\n",
            "Total params: 1,582,897\n",
            "Trainable params: 1,582,897\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6GvNOR9piRHx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "def reconstruct_batch(model, sequences, epoch, folder_name):\n",
        "\n",
        "    sz = sequences.shape[0]\n",
        "    #InX = Input(shape=sequences.shape[1:]) \n",
        "    #tmpModel = Model(inputs=InX, outputs=model.get_layer(\"convTD5\").output)\n",
        "    reconstructed_sequences = model.predict(sequences,batch_size=conf.BATCH_SIZE)\n",
        "\n",
        "    path = join(conf.run_data,folder_name, str(epoch)+\"_epoch\")\n",
        "    os.makedirs(path, exist_ok=True)\n",
        "    for i in range(0, sz):\n",
        "        #cv2_imshow(np.reshape(reconstructed_sequences[i][2],(256, 256))*256)\n",
        "        if i < 10:\n",
        "            img_num = \"00\"+str(i)\n",
        "        elif i < 100:\n",
        "            img_num = \"0\"+str(i)\n",
        "        else:\n",
        "            img_num = str(i)\n",
        "        print(\"Reconstructing : \"+ str(reconstructed_sequences.shape))\n",
        "        cv2.imwrite(join(path,\"gen_\"+img_num+\".jpg\"), convert_images_back(reconstructed_sequences[i][6]))\n",
        "        \n",
        "def settrainable(model, toset):\n",
        "    for layer in model.layers:\n",
        "        layer.trainable = toset\n",
        "    model.trainable = toset\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def evaluate_gen(sequences, model, test_case_dir, epoch=conf.EPOCHS):\n",
        "\n",
        "    reconstructed_sequences = model.predict(sequences,batch_size=conf.BATCH_SIZE)\n",
        "    \n",
        "    sz = sequences.shape[0]\n",
        "    \n",
        "    print(\"Test size:\"+str(sz))\n",
        "   \n",
        "    os.makedirs(join(conf.image_dir,test_case_dir,\"epoch_\"+str(epoch)), exist_ok=True)\n",
        "    for i in range(0, sz):\n",
        "        #print(\"sz \"+str(i)+\"\\n\")\n",
        "        #cv2_imshow(np.reshape(reconstructed_sequences[i][2],(256, 256))*256)\n",
        "        if i < 10:\n",
        "            img_num = \"00\"+str(i)\n",
        "        elif i < 100:\n",
        "            img_num = \"0\"+str(i)\n",
        "        else:\n",
        "            img_num = str(i)    \n",
        "        \n",
        "        cv2.imwrite(join(conf.image_dir, test_case_dir, \"epoch_\"+str(epoch),\"gen_\"+img_num+\".jpg\"), convert_images_back(reconstructed_sequences[i][6]))\n",
        "\n",
        "\n",
        "def evaluate_dis(sequences, model):\n",
        "    sr = model.predict(sequences,batch_size=conf.BATCH_SIZE)\n",
        "\n",
        "    plt.plot(sr)\n",
        "    plt.ylabel('regularity score Sr(t)')\n",
        "    plt.xlabel('frame t')\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8GzbHa0avadq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1d678e97-63f5-4c54-f2ef-15e2f31fff13"
      },
      "source": [
        "import csv\n",
        "test_cases_dir = \"Test008\"\n",
        "test_cases = get_test_sequences(test_cases_dir, 200)\n",
        "print(\"Test data set loaded\")\n",
        "conf.reconfig(new_name=\"Conv2DLSTM_AAE\", batch_size=4, epochs=100, retrain=0)\n",
        "x_train = get_clips_list(conf.dim1)\n",
        "\n",
        "print(\"Train data set loaded\")\n",
        "\n",
        "batchsize = conf.BATCH_SIZE\n",
        "\n",
        "for epochnumber in range(conf.EPOCHS):\n",
        "    print(\"Epoch \"+str(epochnumber+1))\n",
        "\n",
        "    with open(join(conf.run_data, 'loss_val.csv'), mode='w') as csv_file:\n",
        "        fieldnames = ['epoch_num', 'batch_num', 'ae_loss', 'disc_loss', 'enc_disc_loss']\n",
        "        writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
        "        writer.writeheader()\n",
        "        for i in range(int(len(x_train) / batchsize)):\n",
        "    \n",
        "            settrainable(model_ae, True)\n",
        "            settrainable(model_enc, True)\n",
        "            settrainable(model_dec, True)\n",
        "        \n",
        "            batch = x_train[i*batchsize:i*batchsize+batchsize]\n",
        "            #for(i in range(5)):\n",
        "            ae_loss = model_ae.train_on_batch(batch, batch)\n",
        "            \n",
        "            \n",
        "            settrainable(model_disc, True)\n",
        "            batchpred = model_enc.predict(batch)\n",
        "            fakepred = np.random.standard_normal((batchsize, conf.latent_dim))\n",
        "            discbatch_x = np.concatenate([batchpred, fakepred])\n",
        "            discbatch_y = np.concatenate([np.zeros(batchsize), np.ones(batchsize)])\n",
        "            disc_loss = model_disc.train_on_batch(discbatch_x, discbatch_y)\n",
        "        \n",
        "            settrainable(model_enc_disc, True)\n",
        "            settrainable(model_enc, True)\n",
        "            settrainable(model_disc, False)\n",
        "            enc_disc_loss = model_enc_disc.train_on_batch(batch, np.ones(batchsize))\n",
        "            print(\"ae_loss:\"+str(ae_loss)+\", disc_loss:\"+str(disc_loss)+\", enc_disc_loss:\"+str(enc_disc_loss))\n",
        "            writer.writerow({'epoch_num': epochnumber, 'batch_num': i, 'ae_loss': ae_loss, 'disc_loss': disc_loss, 'enc_disc_loss': enc_disc_loss})\n",
        "\n",
        "    model_enc.save(conf.GEN_MODEL_PATH+str(\"ep\"+str(epochnumber+1)))\n",
        "    model_dec.save(conf.DEC_MODEL_PATH+str(\"ep\"+str(epochnumber+1)))\n",
        "    model_disc.save(conf.DIS_MODEL_PATH+str(\"ep\"+str(epochnumber+1)))\n",
        "    evaluate_gen(test_cases, model_ae, test_cases_dir, epochnumber+1)\n",
        "    evaluate_dis(test_cases, model_enc_disc)\n",
        "    print (\"Reconstruction Loss:\", model_ae.evaluate(x_train, x_train, verbose=0, batch_size=conf.BATCH_SIZE))\n",
        "    print (\"Adverserial Loss:\", model_enc_disc.evaluate(x_train, np.ones(len(x_train)), verbose=0, batch_size=conf.BATCH_SIZE))\n",
        "\n",
        "\n",
        "evaluate_gen(test_cases, model_ae, test_cases_dir)\n",
        "\n",
        "evaluate_dis(test_cases, model_enc_disc)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test case loaded\n",
            "Test data set loaded\n",
            "Configuring train from scratch\n",
            "Train data set loaded\n",
            "Epoch 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:297: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
            "  'Discrepancy between trainable weights and collected trainable'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ae_loss:0.12264384, disc_loss:1.154802, enc_disc_loss:1.310503\n",
            "ae_loss:0.09117317, disc_loss:0.97806185, enc_disc_loss:1.7145442\n",
            "ae_loss:0.08059255, disc_loss:0.87504613, enc_disc_loss:1.8937958\n",
            "ae_loss:0.0748904, disc_loss:1.0354192, enc_disc_loss:1.0646867\n",
            "ae_loss:0.06795651, disc_loss:1.1285233, enc_disc_loss:1.0996192\n",
            "ae_loss:0.058782227, disc_loss:1.0654068, enc_disc_loss:0.61533743\n",
            "ae_loss:0.053156655, disc_loss:0.72032166, enc_disc_loss:1.0705345\n",
            "ae_loss:0.051293857, disc_loss:0.87156427, enc_disc_loss:0.9379612\n",
            "ae_loss:0.04548948, disc_loss:0.6989884, enc_disc_loss:1.0231894\n",
            "ae_loss:0.042495146, disc_loss:0.96873593, enc_disc_loss:0.83441067\n",
            "ae_loss:0.04474374, disc_loss:0.9203682, enc_disc_loss:0.8034548\n",
            "ae_loss:0.04370557, disc_loss:1.2464576, enc_disc_loss:0.7834188\n",
            "ae_loss:0.041212074, disc_loss:1.149419, enc_disc_loss:0.7383918\n",
            "ae_loss:0.04248876, disc_loss:1.0302525, enc_disc_loss:0.66007704\n",
            "ae_loss:0.04097087, disc_loss:1.1522558, enc_disc_loss:0.79224205\n",
            "ae_loss:0.041549306, disc_loss:0.87339973, enc_disc_loss:0.9781834\n",
            "ae_loss:0.039051257, disc_loss:0.9111841, enc_disc_loss:0.46215218\n",
            "ae_loss:0.037232693, disc_loss:1.1240842, enc_disc_loss:0.5785093\n",
            "ae_loss:0.03652606, disc_loss:1.0077007, enc_disc_loss:0.4176141\n",
            "ae_loss:0.037382014, disc_loss:0.9950616, enc_disc_loss:0.8208562\n",
            "ae_loss:0.03456958, disc_loss:0.9568436, enc_disc_loss:0.8219476\n",
            "ae_loss:0.033812575, disc_loss:1.0123062, enc_disc_loss:0.5681727\n",
            "ae_loss:0.03205238, disc_loss:0.83796334, enc_disc_loss:0.7667171\n",
            "ae_loss:0.03213762, disc_loss:0.7861448, enc_disc_loss:0.5891423\n",
            "ae_loss:0.032341503, disc_loss:1.0411811, enc_disc_loss:0.48738694\n",
            "ae_loss:0.03047868, disc_loss:0.86542326, enc_disc_loss:0.26216173\n",
            "ae_loss:0.029443095, disc_loss:0.62137544, enc_disc_loss:0.6304701\n",
            "ae_loss:0.030751148, disc_loss:0.9523421, enc_disc_loss:0.4962747\n",
            "ae_loss:0.030062607, disc_loss:0.7529932, enc_disc_loss:0.4031827\n",
            "ae_loss:0.028724834, disc_loss:0.8617741, enc_disc_loss:0.42134243\n",
            "ae_loss:0.023962704, disc_loss:0.98808587, enc_disc_loss:0.3416927\n",
            "ae_loss:0.023362081, disc_loss:0.70036376, enc_disc_loss:0.5762905\n",
            "ae_loss:0.02458941, disc_loss:1.0672657, enc_disc_loss:0.89785165\n",
            "ae_loss:0.10026002, disc_loss:0.568858, enc_disc_loss:0.60259825\n",
            "ae_loss:0.03750757, disc_loss:0.8657706, enc_disc_loss:0.53440416\n",
            "ae_loss:0.052039087, disc_loss:0.72719157, enc_disc_loss:0.50266474\n",
            "ae_loss:0.03264183, disc_loss:1.1882191, enc_disc_loss:0.83968234\n",
            "ae_loss:0.03464393, disc_loss:0.83064586, enc_disc_loss:0.48196805\n",
            "ae_loss:0.04298959, disc_loss:0.8776764, enc_disc_loss:0.43633628\n",
            "ae_loss:0.032506257, disc_loss:0.8423872, enc_disc_loss:0.41347334\n",
            "ae_loss:0.03155312, disc_loss:0.78092945, enc_disc_loss:0.54181564\n",
            "ae_loss:0.03749007, disc_loss:1.0455637, enc_disc_loss:0.44130048\n",
            "ae_loss:0.038591277, disc_loss:0.93028605, enc_disc_loss:0.48711067\n",
            "ae_loss:0.033749044, disc_loss:0.8154109, enc_disc_loss:0.42704803\n",
            "ae_loss:0.0305533, disc_loss:0.9264719, enc_disc_loss:0.4250906\n",
            "ae_loss:0.03228984, disc_loss:0.7587965, enc_disc_loss:0.6224433\n",
            "ae_loss:0.03418431, disc_loss:0.44516233, enc_disc_loss:0.53245246\n",
            "ae_loss:0.032725938, disc_loss:0.68112963, enc_disc_loss:0.543055\n",
            "ae_loss:0.030164102, disc_loss:0.712157, enc_disc_loss:0.41595918\n",
            "ae_loss:0.029441457, disc_loss:0.6568884, enc_disc_loss:0.73716635\n",
            "ae_loss:0.036841027, disc_loss:0.6314255, enc_disc_loss:0.6950016\n",
            "ae_loss:0.036152005, disc_loss:0.7119896, enc_disc_loss:0.65647846\n",
            "ae_loss:0.033618145, disc_loss:0.57169694, enc_disc_loss:0.54458946\n",
            "ae_loss:0.031697642, disc_loss:0.7065261, enc_disc_loss:0.4357944\n",
            "ae_loss:0.03202337, disc_loss:0.8702156, enc_disc_loss:0.5149157\n",
            "ae_loss:0.032426916, disc_loss:0.90463585, enc_disc_loss:0.4171126\n",
            "ae_loss:0.030767152, disc_loss:0.58286184, enc_disc_loss:0.4576556\n",
            "ae_loss:0.028870117, disc_loss:0.58058923, enc_disc_loss:0.34455568\n",
            "ae_loss:0.02987651, disc_loss:1.042205, enc_disc_loss:0.26950783\n",
            "ae_loss:0.02957252, disc_loss:0.87363577, enc_disc_loss:0.31980032\n",
            "ae_loss:0.022293298, disc_loss:0.7626724, enc_disc_loss:0.27472588\n",
            "ae_loss:0.021091476, disc_loss:1.2438961, enc_disc_loss:0.396295\n",
            "ae_loss:0.019472668, disc_loss:0.7876501, enc_disc_loss:0.34604466\n",
            "ae_loss:0.018226143, disc_loss:0.8422252, enc_disc_loss:0.14896932\n",
            "ae_loss:0.018898267, disc_loss:0.9420616, enc_disc_loss:0.21195474\n",
            "ae_loss:0.018955417, disc_loss:1.0044717, enc_disc_loss:0.3477823\n",
            "ae_loss:0.018409725, disc_loss:1.2311518, enc_disc_loss:0.27787048\n",
            "ae_loss:0.021299977, disc_loss:1.2828064, enc_disc_loss:0.49827605\n",
            "ae_loss:0.02331134, disc_loss:0.9968587, enc_disc_loss:0.328867\n",
            "ae_loss:0.022653013, disc_loss:1.2070104, enc_disc_loss:0.30376023\n",
            "ae_loss:0.02109757, disc_loss:1.0250663, enc_disc_loss:0.2379491\n",
            "ae_loss:0.02031116, disc_loss:1.447129, enc_disc_loss:0.3847214\n",
            "ae_loss:0.019094441, disc_loss:1.5508076, enc_disc_loss:0.2026465\n",
            "ae_loss:0.020635227, disc_loss:1.1736403, enc_disc_loss:0.1519962\n",
            "ae_loss:0.019869266, disc_loss:1.1293813, enc_disc_loss:0.20961618\n",
            "ae_loss:0.019494778, disc_loss:1.055285, enc_disc_loss:0.26246035\n",
            "ae_loss:0.022714889, disc_loss:1.2377334, enc_disc_loss:0.28806627\n",
            "ae_loss:0.020503612, disc_loss:1.3473754, enc_disc_loss:0.20594348\n",
            "ae_loss:0.026384642, disc_loss:1.1681103, enc_disc_loss:0.15279922\n",
            "ae_loss:0.020398255, disc_loss:1.1559798, enc_disc_loss:0.2356087\n",
            "ae_loss:0.014764872, disc_loss:1.0923836, enc_disc_loss:0.09945367\n",
            "ae_loss:0.015604412, disc_loss:1.2714185, enc_disc_loss:0.18985653\n",
            "ae_loss:0.0159616, disc_loss:1.7712514, enc_disc_loss:0.44448262\n",
            "ae_loss:0.014342664, disc_loss:0.9133129, enc_disc_loss:0.19003767\n",
            "ae_loss:0.0265789, disc_loss:1.8483319, enc_disc_loss:0.28319845\n",
            "ae_loss:0.01924767, disc_loss:1.3121703, enc_disc_loss:0.14751624\n",
            "ae_loss:0.017972011, disc_loss:1.1796689, enc_disc_loss:0.19515185\n",
            "ae_loss:0.016623633, disc_loss:1.5234678, enc_disc_loss:0.24122134\n",
            "ae_loss:0.022210805, disc_loss:1.2181747, enc_disc_loss:0.21118855\n",
            "ae_loss:0.016590275, disc_loss:1.4238107, enc_disc_loss:0.3231446\n",
            "ae_loss:0.01864857, disc_loss:1.3408104, enc_disc_loss:0.16938564\n",
            "ae_loss:0.014734045, disc_loss:1.3346047, enc_disc_loss:0.24168657\n",
            "ae_loss:0.013924867, disc_loss:0.88617945, enc_disc_loss:0.27408296\n",
            "ae_loss:0.015082372, disc_loss:1.4050751, enc_disc_loss:0.23055032\n",
            "ae_loss:0.016121771, disc_loss:1.0444994, enc_disc_loss:0.09778336\n",
            "ae_loss:0.0170709, disc_loss:0.9675453, enc_disc_loss:0.45624104\n",
            "ae_loss:0.011154425, disc_loss:1.1204523, enc_disc_loss:0.14871177\n",
            "ae_loss:0.011688699, disc_loss:0.7748711, enc_disc_loss:0.24913687\n",
            "ae_loss:0.013022212, disc_loss:1.5359383, enc_disc_loss:0.41533366\n",
            "ae_loss:0.015994802, disc_loss:0.76591104, enc_disc_loss:0.36511576\n",
            "ae_loss:0.012964073, disc_loss:2.043383, enc_disc_loss:0.25090742\n",
            "ae_loss:0.026641587, disc_loss:1.1119665, enc_disc_loss:0.14513467\n",
            "ae_loss:0.017026793, disc_loss:1.3613763, enc_disc_loss:0.24049565\n",
            "ae_loss:0.020697538, disc_loss:1.5227615, enc_disc_loss:0.111850575\n",
            "ae_loss:0.018127788, disc_loss:1.4618655, enc_disc_loss:0.1659444\n",
            "ae_loss:0.014378083, disc_loss:1.1700197, enc_disc_loss:0.35011616\n",
            "ae_loss:0.018188609, disc_loss:1.2217067, enc_disc_loss:0.27942383\n",
            "ae_loss:0.022213366, disc_loss:1.3554863, enc_disc_loss:0.35202098\n",
            "ae_loss:0.015915152, disc_loss:1.1684006, enc_disc_loss:0.45239705\n",
            "ae_loss:0.023823448, disc_loss:1.1727886, enc_disc_loss:0.19359122\n",
            "ae_loss:0.015999453, disc_loss:0.81213725, enc_disc_loss:0.3487752\n",
            "ae_loss:0.0156150665, disc_loss:1.2759018, enc_disc_loss:0.45305082\n",
            "ae_loss:0.017375994, disc_loss:1.0081626, enc_disc_loss:0.348063\n",
            "ae_loss:0.016878825, disc_loss:1.1899256, enc_disc_loss:0.23061618\n",
            "ae_loss:0.017033463, disc_loss:1.0438827, enc_disc_loss:0.21848926\n",
            "ae_loss:0.017470485, disc_loss:1.3502555, enc_disc_loss:0.222776\n",
            "ae_loss:0.013444382, disc_loss:0.9059663, enc_disc_loss:0.86668086\n",
            "ae_loss:0.019233037, disc_loss:1.2823389, enc_disc_loss:0.29584342\n",
            "ae_loss:0.010699543, disc_loss:0.76359576, enc_disc_loss:0.29623008\n",
            "ae_loss:0.024153693, disc_loss:1.1159269, enc_disc_loss:0.22177479\n",
            "ae_loss:0.023173342, disc_loss:1.0366868, enc_disc_loss:0.34846115\n",
            "ae_loss:0.01353435, disc_loss:1.0026273, enc_disc_loss:0.47114688\n",
            "ae_loss:0.020812413, disc_loss:0.97173834, enc_disc_loss:0.25804046\n",
            "ae_loss:0.012298873, disc_loss:1.0805112, enc_disc_loss:0.39582872\n",
            "ae_loss:0.018871099, disc_loss:0.90887904, enc_disc_loss:0.3617526\n",
            "ae_loss:0.0273271, disc_loss:0.9808734, enc_disc_loss:0.2985737\n",
            "ae_loss:0.012015349, disc_loss:1.0293448, enc_disc_loss:0.32029063\n",
            "ae_loss:0.021372719, disc_loss:0.93926847, enc_disc_loss:0.3267247\n",
            "ae_loss:0.019756591, disc_loss:1.0848374, enc_disc_loss:0.28728646\n",
            "ae_loss:0.01205449, disc_loss:0.84534454, enc_disc_loss:0.5592665\n",
            "ae_loss:0.02125845, disc_loss:0.83151823, enc_disc_loss:0.2345554\n",
            "ae_loss:0.03979449, disc_loss:0.916509, enc_disc_loss:0.19135165\n",
            "ae_loss:0.03457243, disc_loss:0.79804367, enc_disc_loss:0.25418833\n",
            "ae_loss:0.024350021, disc_loss:1.0481335, enc_disc_loss:0.31675625\n",
            "ae_loss:0.020022007, disc_loss:0.8055769, enc_disc_loss:0.34783\n",
            "ae_loss:0.023603115, disc_loss:0.88268447, enc_disc_loss:0.3823253\n",
            "ae_loss:0.02571237, disc_loss:1.0391302, enc_disc_loss:0.30904716\n",
            "ae_loss:0.024319036, disc_loss:0.64930224, enc_disc_loss:0.12925975\n",
            "ae_loss:0.026090425, disc_loss:1.6855782, enc_disc_loss:0.49120957\n",
            "ae_loss:0.02995782, disc_loss:1.315469, enc_disc_loss:0.48480374\n",
            "ae_loss:0.02758522, disc_loss:1.552325, enc_disc_loss:0.15304416\n",
            "ae_loss:0.024938738, disc_loss:1.3121208, enc_disc_loss:0.11829935\n",
            "ae_loss:0.024576616, disc_loss:1.6126338, enc_disc_loss:0.3993348\n",
            "ae_loss:0.021471586, disc_loss:1.3073058, enc_disc_loss:0.3272341\n",
            "ae_loss:0.01857521, disc_loss:0.8818597, enc_disc_loss:0.25824338\n",
            "ae_loss:0.017399395, disc_loss:1.1906793, enc_disc_loss:0.23523962\n",
            "ae_loss:0.014885066, disc_loss:0.9017495, enc_disc_loss:0.489855\n",
            "ae_loss:0.018503096, disc_loss:1.0476466, enc_disc_loss:0.41667515\n",
            "ae_loss:0.014421833, disc_loss:1.0408819, enc_disc_loss:0.3311376\n",
            "ae_loss:0.024529377, disc_loss:1.3204914, enc_disc_loss:0.5635817\n",
            "ae_loss:0.018115375, disc_loss:0.9869121, enc_disc_loss:0.24413435\n",
            "ae_loss:0.018706527, disc_loss:1.0941817, enc_disc_loss:0.24528632\n",
            "ae_loss:0.021569308, disc_loss:0.8005297, enc_disc_loss:0.3183238\n",
            "ae_loss:0.014110565, disc_loss:0.55064106, enc_disc_loss:0.46969616\n",
            "ae_loss:0.030976485, disc_loss:0.9288672, enc_disc_loss:0.21837217\n",
            "ae_loss:0.02238833, disc_loss:0.9764595, enc_disc_loss:0.4751313\n",
            "ae_loss:0.015952453, disc_loss:0.93703777, enc_disc_loss:0.32707688\n",
            "ae_loss:0.027959716, disc_loss:1.0452406, enc_disc_loss:0.21717824\n",
            "ae_loss:0.018298015, disc_loss:0.79029113, enc_disc_loss:0.18016408\n",
            "ae_loss:0.023938855, disc_loss:1.1963185, enc_disc_loss:0.34135753\n",
            "ae_loss:0.018912066, disc_loss:1.3345289, enc_disc_loss:0.28453588\n",
            "ae_loss:0.01975366, disc_loss:1.2867672, enc_disc_loss:0.21107124\n",
            "ae_loss:0.02065287, disc_loss:1.1963298, enc_disc_loss:0.15618679\n",
            "ae_loss:0.015521203, disc_loss:0.8793892, enc_disc_loss:0.1730109\n",
            "ae_loss:0.022554807, disc_loss:1.1619446, enc_disc_loss:0.3345571\n",
            "ae_loss:0.026768127, disc_loss:1.2704399, enc_disc_loss:0.15485728\n",
            "ae_loss:0.017998075, disc_loss:2.047906, enc_disc_loss:0.108007684\n",
            "ae_loss:0.015923692, disc_loss:1.6384857, enc_disc_loss:0.21522838\n",
            "ae_loss:0.02092018, disc_loss:1.4196339, enc_disc_loss:0.115268275\n",
            "ae_loss:0.012801115, disc_loss:2.0629108, enc_disc_loss:0.1950715\n",
            "ae_loss:0.020998355, disc_loss:1.3713934, enc_disc_loss:0.13034032\n",
            "ae_loss:0.027483791, disc_loss:1.6595402, enc_disc_loss:0.11403732\n",
            "ae_loss:0.014838989, disc_loss:1.3275657, enc_disc_loss:0.16229996\n",
            "ae_loss:0.025364399, disc_loss:1.301386, enc_disc_loss:0.21772674\n",
            "ae_loss:0.019316697, disc_loss:1.2493482, enc_disc_loss:0.29167622\n",
            "ae_loss:0.028632635, disc_loss:1.1326491, enc_disc_loss:0.20270056\n",
            "ae_loss:0.030566614, disc_loss:0.9726432, enc_disc_loss:0.2545066\n",
            "ae_loss:0.017993195, disc_loss:1.1699274, enc_disc_loss:0.24960858\n",
            "ae_loss:0.029243726, disc_loss:0.942531, enc_disc_loss:0.45081943\n",
            "ae_loss:0.024465574, disc_loss:0.86587656, enc_disc_loss:0.4928828\n",
            "ae_loss:0.015386911, disc_loss:1.0481192, enc_disc_loss:0.51782525\n",
            "ae_loss:0.022576882, disc_loss:1.0475157, enc_disc_loss:0.56388557\n",
            "ae_loss:0.02133234, disc_loss:1.0185549, enc_disc_loss:0.48920405\n",
            "ae_loss:0.016514987, disc_loss:1.2519075, enc_disc_loss:0.3384565\n",
            "ae_loss:0.016417373, disc_loss:0.9639221, enc_disc_loss:0.4300639\n",
            "ae_loss:0.023129007, disc_loss:0.9855261, enc_disc_loss:0.1575234\n",
            "ae_loss:0.018947836, disc_loss:0.86267537, enc_disc_loss:0.38775158\n",
            "ae_loss:0.014838131, disc_loss:0.92088544, enc_disc_loss:0.2856946\n",
            "ae_loss:0.024305737, disc_loss:1.0448508, enc_disc_loss:0.2959032\n",
            "ae_loss:0.01815553, disc_loss:1.0027764, enc_disc_loss:0.42984638\n",
            "ae_loss:0.015387232, disc_loss:1.2674826, enc_disc_loss:0.1363262\n",
            "ae_loss:0.018263444, disc_loss:1.3156477, enc_disc_loss:0.14948097\n",
            "ae_loss:0.014936984, disc_loss:1.4525075, enc_disc_loss:0.15234062\n",
            "ae_loss:0.013793473, disc_loss:0.88580185, enc_disc_loss:0.21203949\n",
            "ae_loss:0.015169394, disc_loss:0.99302304, enc_disc_loss:0.19946608\n",
            "ae_loss:0.012098196, disc_loss:1.3634121, enc_disc_loss:0.488245\n",
            "ae_loss:0.016201431, disc_loss:1.0856682, enc_disc_loss:0.17308182\n",
            "ae_loss:0.011901597, disc_loss:1.1802157, enc_disc_loss:0.4627002\n",
            "ae_loss:0.034215756, disc_loss:0.96752566, enc_disc_loss:0.5953984\n",
            "ae_loss:0.013213068, disc_loss:0.9883956, enc_disc_loss:0.40077677\n",
            "ae_loss:0.025299916, disc_loss:0.9136147, enc_disc_loss:0.37672555\n",
            "ae_loss:0.016231949, disc_loss:0.58852327, enc_disc_loss:0.24312487\n",
            "ae_loss:0.014768617, disc_loss:1.0727141, enc_disc_loss:0.26058298\n",
            "ae_loss:0.024064202, disc_loss:0.79405224, enc_disc_loss:0.41545996\n",
            "ae_loss:0.012834069, disc_loss:1.5415378, enc_disc_loss:0.2823152\n",
            "ae_loss:0.017164668, disc_loss:0.73638797, enc_disc_loss:0.61891574\n",
            "ae_loss:0.027953412, disc_loss:0.7124938, enc_disc_loss:0.57024205\n",
            "ae_loss:0.022971457, disc_loss:1.1085892, enc_disc_loss:0.6905242\n",
            "ae_loss:0.01422224, disc_loss:0.9583093, enc_disc_loss:0.57470274\n",
            "ae_loss:0.018358719, disc_loss:0.6929008, enc_disc_loss:0.56182384\n",
            "ae_loss:0.028581897, disc_loss:0.9751338, enc_disc_loss:0.18475705\n",
            "ae_loss:0.024828907, disc_loss:0.69797224, enc_disc_loss:0.32032862\n",
            "ae_loss:0.01938195, disc_loss:0.71880203, enc_disc_loss:0.5525123\n",
            "ae_loss:0.019359868, disc_loss:0.9168092, enc_disc_loss:0.14354344\n",
            "ae_loss:0.021356527, disc_loss:0.7419155, enc_disc_loss:0.30338097\n",
            "ae_loss:0.022174934, disc_loss:1.0019556, enc_disc_loss:0.38932896\n",
            "ae_loss:0.020558339, disc_loss:0.6632663, enc_disc_loss:0.2874958\n",
            "ae_loss:0.01673899, disc_loss:0.5459194, enc_disc_loss:0.16330656\n",
            "ae_loss:0.013754373, disc_loss:1.0933387, enc_disc_loss:0.5339838\n",
            "ae_loss:0.013619696, disc_loss:0.92051506, enc_disc_loss:0.3900516\n",
            "ae_loss:0.012309855, disc_loss:1.2299155, enc_disc_loss:0.50982845\n",
            "ae_loss:0.011516225, disc_loss:1.0350044, enc_disc_loss:0.23174934\n",
            "ae_loss:0.011631018, disc_loss:0.9158128, enc_disc_loss:0.43332458\n",
            "ae_loss:0.013831342, disc_loss:0.5889211, enc_disc_loss:0.51861554\n",
            "ae_loss:0.016106876, disc_loss:0.59164494, enc_disc_loss:0.6848697\n",
            "ae_loss:0.014321881, disc_loss:0.8178991, enc_disc_loss:0.4077224\n",
            "ae_loss:0.01226823, disc_loss:0.90245336, enc_disc_loss:0.4522614\n",
            "ae_loss:0.013328636, disc_loss:0.80764365, enc_disc_loss:0.42993534\n",
            "ae_loss:0.014956194, disc_loss:0.77095795, enc_disc_loss:0.34464765\n",
            "ae_loss:0.012178237, disc_loss:0.5864675, enc_disc_loss:0.8515927\n",
            "ae_loss:0.021337496, disc_loss:0.8531568, enc_disc_loss:0.43524534\n",
            "ae_loss:0.024274344, disc_loss:1.1721251, enc_disc_loss:0.32268927\n",
            "ae_loss:0.01722534, disc_loss:0.8419033, enc_disc_loss:0.2782306\n",
            "ae_loss:0.014088246, disc_loss:0.7716426, enc_disc_loss:0.2681747\n",
            "ae_loss:0.019211566, disc_loss:0.5863801, enc_disc_loss:0.4505641\n",
            "ae_loss:0.022203231, disc_loss:0.91437197, enc_disc_loss:0.11535396\n",
            "ae_loss:0.017451236, disc_loss:0.8486697, enc_disc_loss:0.33487564\n",
            "ae_loss:0.013880868, disc_loss:0.58790535, enc_disc_loss:0.266711\n",
            "ae_loss:0.016371222, disc_loss:1.4739753, enc_disc_loss:0.14722756\n",
            "ae_loss:0.018667292, disc_loss:1.7857378, enc_disc_loss:0.4041413\n",
            "ae_loss:0.017399108, disc_loss:1.2472192, enc_disc_loss:0.20691156\n",
            "ae_loss:0.015564837, disc_loss:0.57409495, enc_disc_loss:0.68753976\n",
            "ae_loss:0.0142334, disc_loss:0.7352461, enc_disc_loss:0.16636592\n",
            "ae_loss:0.012597797, disc_loss:1.3069018, enc_disc_loss:0.38531336\n",
            "ae_loss:0.012801116, disc_loss:0.9167732, enc_disc_loss:0.55344594\n",
            "ae_loss:0.01604291, disc_loss:0.7914698, enc_disc_loss:0.48270547\n",
            "ae_loss:0.018708307, disc_loss:0.79708135, enc_disc_loss:0.21694177\n",
            "ae_loss:0.014006831, disc_loss:0.7881863, enc_disc_loss:0.51913905\n",
            "ae_loss:0.013026632, disc_loss:0.72866005, enc_disc_loss:0.39281285\n",
            "ae_loss:0.023785356, disc_loss:0.6012224, enc_disc_loss:0.49689895\n",
            "ae_loss:0.02455179, disc_loss:0.64387757, enc_disc_loss:0.43517008\n",
            "ae_loss:0.01540975, disc_loss:0.7442905, enc_disc_loss:0.26082957\n",
            "ae_loss:0.017619465, disc_loss:0.8226064, enc_disc_loss:0.49955794\n",
            "ae_loss:0.024774803, disc_loss:0.6224565, enc_disc_loss:0.13980359\n",
            "ae_loss:0.017194953, disc_loss:0.7744894, enc_disc_loss:0.22036256\n",
            "ae_loss:0.012991515, disc_loss:0.71011996, enc_disc_loss:0.2588275\n",
            "ae_loss:0.01858441, disc_loss:0.7836588, enc_disc_loss:0.42208463\n",
            "ae_loss:0.023081891, disc_loss:1.0055236, enc_disc_loss:0.31996542\n",
            "ae_loss:0.01803738, disc_loss:1.0523509, enc_disc_loss:0.39423105\n",
            "ae_loss:0.013284368, disc_loss:0.54420304, enc_disc_loss:0.2626781\n",
            "ae_loss:0.013019207, disc_loss:0.8048398, enc_disc_loss:0.3380168\n",
            "ae_loss:0.01622707, disc_loss:0.9233084, enc_disc_loss:0.5057582\n",
            "ae_loss:0.016157694, disc_loss:0.9772722, enc_disc_loss:0.33313623\n",
            "ae_loss:0.012479411, disc_loss:0.7154095, enc_disc_loss:0.3760485\n",
            "ae_loss:0.013907996, disc_loss:0.9962217, enc_disc_loss:0.23677775\n",
            "ae_loss:0.024353672, disc_loss:0.8118495, enc_disc_loss:0.23291738\n",
            "ae_loss:0.028710414, disc_loss:0.89592546, enc_disc_loss:0.34433603\n",
            "ae_loss:0.023133393, disc_loss:0.96058357, enc_disc_loss:0.37062252\n",
            "ae_loss:0.014606667, disc_loss:1.1164634, enc_disc_loss:0.23932548\n",
            "ae_loss:0.015946543, disc_loss:1.2363075, enc_disc_loss:0.23236838\n",
            "ae_loss:0.022467121, disc_loss:0.89787316, enc_disc_loss:0.19423378\n",
            "ae_loss:0.018668279, disc_loss:0.84879404, enc_disc_loss:0.2810951\n",
            "ae_loss:0.014688566, disc_loss:0.7693231, enc_disc_loss:0.24729586\n",
            "ae_loss:0.016793586, disc_loss:1.1283913, enc_disc_loss:0.20919812\n",
            "ae_loss:0.022654697, disc_loss:1.0942353, enc_disc_loss:0.2546596\n",
            "ae_loss:0.026990771, disc_loss:1.0588266, enc_disc_loss:0.56311506\n",
            "ae_loss:0.030300746, disc_loss:0.8463292, enc_disc_loss:0.5449811\n",
            "ae_loss:0.021107454, disc_loss:0.81922865, enc_disc_loss:0.11144376\n",
            "ae_loss:0.018588185, disc_loss:1.2917508, enc_disc_loss:0.30210954\n",
            "ae_loss:0.024315435, disc_loss:0.7701959, enc_disc_loss:0.17838687\n",
            "ae_loss:0.018641258, disc_loss:1.1438807, enc_disc_loss:0.28252187\n",
            "ae_loss:0.018416801, disc_loss:1.0956155, enc_disc_loss:0.27367324\n",
            "ae_loss:0.033355914, disc_loss:1.5798743, enc_disc_loss:0.1392481\n",
            "ae_loss:0.031623207, disc_loss:1.4682574, enc_disc_loss:0.25754496\n",
            "ae_loss:0.023928385, disc_loss:1.0068884, enc_disc_loss:0.10472696\n",
            "ae_loss:0.027616743, disc_loss:1.9652919, enc_disc_loss:0.0536025\n",
            "ae_loss:0.029085478, disc_loss:1.9036287, enc_disc_loss:0.34943926\n",
            "ae_loss:0.021167403, disc_loss:1.5022109, enc_disc_loss:0.13494642\n",
            "ae_loss:0.029275194, disc_loss:1.0418084, enc_disc_loss:0.13792256\n",
            "ae_loss:0.02243787, disc_loss:1.7546263, enc_disc_loss:0.062340036\n",
            "ae_loss:0.030144861, disc_loss:1.3454759, enc_disc_loss:0.12516657\n",
            "ae_loss:0.020691484, disc_loss:2.2723808, enc_disc_loss:0.19872434\n",
            "ae_loss:0.020480767, disc_loss:1.0300534, enc_disc_loss:0.21322337\n",
            "ae_loss:0.020134741, disc_loss:1.0039479, enc_disc_loss:0.24906217\n",
            "ae_loss:0.016998097, disc_loss:0.9316295, enc_disc_loss:0.1751817\n",
            "ae_loss:0.015377944, disc_loss:0.85858953, enc_disc_loss:0.1854834\n",
            "ae_loss:0.015527854, disc_loss:0.65854704, enc_disc_loss:0.24054661\n",
            "ae_loss:0.025462324, disc_loss:0.8146279, enc_disc_loss:0.21025789\n",
            "ae_loss:0.034060664, disc_loss:0.7238228, enc_disc_loss:0.34694755\n",
            "ae_loss:0.028013265, disc_loss:1.1808265, enc_disc_loss:0.26037586\n",
            "ae_loss:0.016505936, disc_loss:1.2012396, enc_disc_loss:0.23203835\n",
            "ae_loss:0.025241047, disc_loss:1.1749712, enc_disc_loss:0.15562765\n",
            "ae_loss:0.024062777, disc_loss:0.67436075, enc_disc_loss:0.2937442\n",
            "ae_loss:0.019360425, disc_loss:0.83621544, enc_disc_loss:0.2867146\n",
            "ae_loss:0.021615049, disc_loss:0.915251, enc_disc_loss:0.24608223\n",
            "ae_loss:0.027723264, disc_loss:0.7852249, enc_disc_loss:0.37276512\n",
            "ae_loss:0.027343249, disc_loss:0.9711686, enc_disc_loss:0.2822876\n",
            "ae_loss:0.017690118, disc_loss:0.89432096, enc_disc_loss:0.2003747\n",
            "ae_loss:0.021309907, disc_loss:1.1525149, enc_disc_loss:0.23135203\n",
            "ae_loss:0.029746514, disc_loss:1.1304835, enc_disc_loss:0.16978058\n",
            "ae_loss:0.016317768, disc_loss:0.9126235, enc_disc_loss:0.3192668\n",
            "ae_loss:0.0145724835, disc_loss:1.0231557, enc_disc_loss:0.40158784\n",
            "ae_loss:0.027343001, disc_loss:0.81591123, enc_disc_loss:0.2961615\n",
            "ae_loss:0.017954106, disc_loss:1.1217026, enc_disc_loss:0.20080715\n",
            "ae_loss:0.01302968, disc_loss:1.0648044, enc_disc_loss:0.3333667\n",
            "ae_loss:0.014706619, disc_loss:0.9374554, enc_disc_loss:0.56578064\n",
            "ae_loss:0.020434173, disc_loss:1.3668275, enc_disc_loss:0.1935846\n",
            "ae_loss:0.020390134, disc_loss:0.8151748, enc_disc_loss:0.5076432\n",
            "ae_loss:0.013400416, disc_loss:0.8529312, enc_disc_loss:0.5201402\n",
            "ae_loss:0.014488094, disc_loss:1.208055, enc_disc_loss:0.20363316\n",
            "ae_loss:0.024341661, disc_loss:0.87463796, enc_disc_loss:0.29155552\n",
            "ae_loss:0.04059396, disc_loss:1.2350305, enc_disc_loss:0.29844746\n",
            "ae_loss:0.014039931, disc_loss:0.8362312, enc_disc_loss:0.20212185\n",
            "ae_loss:0.01180747, disc_loss:1.098391, enc_disc_loss:0.2590505\n",
            "ae_loss:0.014612724, disc_loss:0.71532875, enc_disc_loss:0.20958772\n",
            "ae_loss:0.015521698, disc_loss:0.9789938, enc_disc_loss:0.6022164\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}