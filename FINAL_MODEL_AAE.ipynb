{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FINAL_MODEL_AAE.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyN9+FLEhAFY9S1ywRpm8s6T",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dmbk/Anomaly-Detection-System/blob/master/FINAL_MODEL_AAE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mOpwOqr0OL6R",
        "colab_type": "code",
        "outputId": "e7cd94e4-210a-403b-9d07-2310541af6e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        }
      },
      "source": [
        "!pip install imageio\n",
        "!pip install progress\n",
        "#!pip install tensorflow_datasets\n",
        "!pip install keras-layer-normalization\n",
        "from google.colab import drive\n",
        "#!pip install alive-progress\n",
        "drive.mount('/content/drive', force_remount=True)\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: imageio in /usr/local/lib/python3.6/dist-packages (2.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from imageio) (1.18.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from imageio) (7.0.0)\n",
            "Requirement already satisfied: progress in /usr/local/lib/python3.6/dist-packages (1.5)\n",
            "Requirement already satisfied: keras-layer-normalization in /usr/local/lib/python3.6/dist-packages (0.14.0)\n",
            "Requirement already satisfied: Keras in /usr/local/lib/python3.6/dist-packages (from keras-layer-normalization) (2.3.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from keras-layer-normalization) (1.18.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras->keras-layer-normalization) (2.10.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-layer-normalization) (1.0.8)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-layer-normalization) (1.4.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras->keras-layer-normalization) (3.13)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-layer-normalization) (1.1.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-layer-normalization) (1.12.0)\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-eFt6lxCTi3Q",
        "colab_type": "code",
        "outputId": "58fb2fc8-e7aa-48b9-becf-0e8cea86a61e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "\n",
        "import skimage\n",
        "import glob\n",
        "import imageio\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "from PIL import Image\n",
        "from os.path import join\n",
        "from os import listdir\n",
        "from os.path import isfile, join, isdir\n",
        "\n",
        "#import keras\n",
        "import argparse\n",
        "from os.path import dirname\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\t\n",
        "import statistics\n",
        "import shutil\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import time\n",
        "from progress.bar import IncrementalBar\n",
        "\n",
        "import numpy as np\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Input, Dense, Reshape, Flatten\n",
        "from keras.layers import Conv2DTranspose, ConvLSTM2D, BatchNormalization, TimeDistributed, Conv2D, Dropout, Activation, InputLayer\n",
        "from keras.optimizers import Adam\n",
        "from keras_layer_normalization import LayerNormalization\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "571xSlFJUBaB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Config:\n",
        "    def __init__(self, data_dir_, cwdir_name_, data_set):\n",
        "        self.data_set_name = data_set\n",
        "        self.data_dir = data_dir_\n",
        "        self.data_set_dir = join(self.data_dir, data_set)\n",
        "        self.cwdir_name = cwdir_name_\n",
        "        self.cwdir = join(self.data_dir,self.cwdir_name)\n",
        "        self.run_data = join(self.cwdir, \"training_gan\")\n",
        "        self.image_dir = join(self.run_data,self.data_set_name,\"Test/\")\n",
        "        if not os.path.exists(self.cwdir):\n",
        "            os.mkdir(self.cwdir)\n",
        "            os.mkdir(self.run_data)\n",
        "    \n",
        "        if not os.path.exists(self.run_data):\n",
        "            #shutil.rmtree(self.run_data)\n",
        "            os.mkdir(self.run_data)\n",
        "            os.makedirs(self.image_dir, exist_ok=True)\n",
        "            os.mkdir(self.ref_model_dir)\n",
        "\n",
        "        self.DATASET_PATH = join(self.data_set_dir,\"Train/\")\n",
        "        self.TEST_DIR = join(self.data_set_dir,\"Test/\")\n",
        "        self.BATCH_SIZE = 2\n",
        "        self.EPOCHS = 50\n",
        "        self.GEN_MODEL_PATH = join(self.cwdir,\"model_gen_Conv2DLSTM_AAE\")\n",
        "        self.DIS_MODEL_PATH = join(self.cwdir,\"model_dis_Conv2DLSTM_AAE\")\n",
        "        self.DEC_MODEL_PATH = join(self.cwdir,\"model_dec_Conv2DLSTM_AAE\")\n",
        "\n",
        "        self.retrain = 0\n",
        "        self.dim1 = 10\n",
        "        self.dim2 = 256\n",
        "        self.dim3 = 256\n",
        "        self.dim4 = 1\n",
        "\n",
        "\n",
        "\n",
        "    def reconfig(self, new_name, batch_size = 4, epochs = 5, retrain = 0):\n",
        "        self.cwdir_name = new_name\n",
        "        self.cwdir = join(self.data_dir, self.cwdir_name)\n",
        "        self.run_data = join(self.cwdir, \"training_dir\")\n",
        "        self.image_dir = join(self.run_data,self.data_set_name,\"Test/\")\n",
        "\n",
        "        self.BATCH_SIZE = batch_size\n",
        "        self.EPOCHS = epochs\n",
        "        self.GEN_MODEL_PATH = join(self.cwdir,\"model_gen_Conv2DLSTM_AAE\")\n",
        "        self.DIS_MODEL_PATH = join(self.cwdir,\"model_dis_Conv2DLSTM_AAE\")\n",
        "        self.DEC_MODEL_PATH = join(self.cwdir,\"model_dec_Conv2DLSTM_AAE\")\n",
        "\n",
        "        self.retrain = retrain\n",
        "        if retrain == 0:\n",
        "            print(\"Configuring train from scratch\")\n",
        "            if not os.path.exists(self.cwdir):\n",
        "                os.mkdir(self.cwdir)\n",
        "                os.mkdir(self.run_data)\n",
        "    \n",
        "            if os.path.exists(self.run_data):\n",
        "                shutil.rmtree(self.run_data)\n",
        "                os.mkdir(self.run_data)\n",
        "                os.makedirs(self.image_dir, exist_ok=True)\n",
        "\n",
        "\n",
        "conf = Config(data_dir_=\"/content/drive/My Drive/\", cwdir_name_=\"Conv2DLSTM_AAE\", data_set=\"UCSD_Anomaly_Dataset.v1p2/UCSDped1/\") \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wEre58ljoxbK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_clips_by_stride(stride, frames_list, sequence_size):\n",
        "\n",
        "    clips = []\n",
        "    sz = len(frames_list)\n",
        "    clip = np.zeros(shape=(sequence_size, 256, 256, 1))\n",
        "    cnt = 0\n",
        "    for start in range(0, stride):\n",
        "        for i in range(start, sz, stride):\n",
        "            clip[cnt, :, :, 0] = frames_list[i]\n",
        "            cnt = cnt + 1\n",
        "            if cnt == sequence_size:\n",
        "                clips.append(clip)\n",
        "                cnt = 0\n",
        "    return clips\n",
        "\n",
        "def get_clips_list(seq_size):\n",
        "\n",
        "    clips = []\n",
        "    # loop over the training folders (Train000,Train001,..)\n",
        "    for f in sorted(listdir(conf.DATASET_PATH)):\n",
        "        directory_path = join(conf.DATASET_PATH, f)\n",
        "        if isdir(directory_path):\n",
        "            all_frames = []\n",
        "            # loop over all the images in the folder (0.tif,1.tif,..,199.tif)\n",
        "            for c in sorted(listdir(directory_path)):\n",
        "                img_path = join(directory_path, c)\n",
        "                if str(img_path)[-3:] == \"tif\":\n",
        "                    img = Image.open(img_path).resize((256, 256))\n",
        "                    img = np.array(img, dtype=np.float32)\n",
        "                    img = (img - 127.5)/127.5\n",
        "                    #img = (2*(img - np.amin(img))/(np.amax(img) - np.amin(img)))-1\n",
        "                    #img = np.array(img, dtype=np.float32) / 256.0\n",
        "                    all_frames.append(img)\n",
        "            # get the 32-frames sequences from the list of images after applying data augmentation\n",
        "            for stride in range(1, 3):\n",
        "                clips.extend(get_clips_by_stride(stride=stride, frames_list=all_frames, sequence_size=seq_size))\n",
        "    \n",
        "    #print(np.array(clips).shape)\n",
        "    return np.array(clips)\n",
        "\n",
        "\n",
        "def get_single_test(single_test_path, sz):\n",
        "    test = np.zeros(shape=(sz, conf.dim2, conf.dim3, conf.dim4))\n",
        "    cnt = 0\n",
        "    for f in sorted(listdir(single_test_path)):\n",
        "        if str(join(single_test_path, f))[-3:] == \"tif\":\n",
        "            img = Image.open(join(single_test_path, f)).resize((conf.dim2, conf.dim3))\n",
        "            #cv2_imshow(np.array(img,dtype=np.float32))\n",
        "            #cv2.waitKey(0)\n",
        "            img = np.array(img, dtype=np.float32) / 256\n",
        "            test[cnt, :, :, 0] = img\n",
        "            cnt = cnt + 1\n",
        "    return test\n",
        "\n",
        "def get_test_sequences(test_case_dir, sz):\n",
        "    test = get_single_test(join(conf.TEST_DIR,test_case_dir), sz)\n",
        "    print(\"Test case loaded\")\n",
        "    sz = test.shape[0] - conf.dim1\n",
        "    sequences = np.zeros((sz, conf.dim1, conf.dim2, conf.dim3, conf.dim4))\n",
        "    # apply the sliding window technique to get the sequences\n",
        "    for i in range(0, sz):\n",
        "        clip = np.zeros((conf.dim1, conf.dim2, conf.dim3, conf.dim4))\n",
        "        for j in range(0, conf.dim1):\n",
        "            clip[j] = test[i + j, :, :, :]\n",
        "        sequences[i] = clip\n",
        "    return sequences\n",
        "\n",
        "def convert_images_back(image):\n",
        "    return np.reshape(image,(256, 256))*256.0\n",
        "    #print(image.shape)\n",
        "    #return np.reshape(image[:, :, 0],(image.shape[0], image.shape[1]))*127.5 + 127.5\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0RiNsbLXHTb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_model_enc():\n",
        "    if conf.retrain == 1 and os.path.isfile(conf.GEN_MODEL_PATH+\".hdf5\"):\n",
        "        model_gen=load_model(conf.GEN_MODEL_PATH)\n",
        "        return model_gen\n",
        "    seq = Sequential()\n",
        "    seq.add(TimeDistributed(Conv2D(128, (11, 11), strides=4, padding=\"same\"), batch_input_shape=(None, 10, 256, 256, 1)))\n",
        "    seq.add(LayerNormalization())\n",
        "    seq.add(TimeDistributed(Conv2D(64, (5, 5), strides=2, padding=\"same\")))\n",
        "    seq.add(LayerNormalization())\n",
        "    # # # # #\n",
        "    seq.add(ConvLSTM2D(64, (3, 3), padding=\"same\", return_sequences=True))\n",
        "    seq.add(LayerNormalization())\n",
        "    seq.add(ConvLSTM2D(32, (3, 3), padding=\"same\", return_sequences=True))\n",
        "    seq.add(LayerNormalization())\n",
        "    seq.add(ConvLSTM2D(8, (3, 3), padding=\"same\", return_sequences=True))\n",
        "    seq.add(LayerNormalization())\n",
        "    seq.add(ConvLSTM2D(2, (3, 3), padding=\"same\", return_sequences=True))\n",
        "    seq.add(LayerNormalization())\n",
        "    seq.add(Flatten())\n",
        "    seq.summary(line_length=150)\n",
        "    return  seq\n",
        "\n",
        "def build_model_dec():\n",
        "    if conf.retrain == 1 and os.path.isfile(conf.DEC_MODEL_PATH+\".hdf5\"):\n",
        "        model_gen=load_model(conf.DEC_MODEL_PATH)\n",
        "        return model_gen\n",
        "    seq = Sequential()\n",
        "    seq.add(Reshape((10, 32, 32, 2), input_shape=(20480,)))\n",
        "    seq.add(ConvLSTM2D(2, (3, 3), padding=\"same\", return_sequences=True))\n",
        "    seq.add(LayerNormalization())\n",
        "\n",
        "    seq.add(ConvLSTM2D(8, (3, 3), padding=\"same\", return_sequences=True))\n",
        "    seq.add(LayerNormalization())\n",
        "    seq.add(ConvLSTM2D(32, (3, 3), padding=\"same\", return_sequences=True))\n",
        "    seq.add(LayerNormalization())\n",
        "    seq.add(ConvLSTM2D(64, (3, 3), padding=\"same\", return_sequences=True))\n",
        "    seq.add(LayerNormalization())\n",
        "    # # # # #\n",
        "    seq.add(TimeDistributed(Conv2DTranspose(64, (5, 5), strides=2, padding=\"same\")))\n",
        "    seq.add(LayerNormalization())\n",
        "    seq.add(TimeDistributed(Conv2DTranspose(128, (11, 11), strides=4, padding=\"same\")))\n",
        "    seq.add(LayerNormalization())\n",
        "    seq.add(TimeDistributed(Conv2D(1, (11, 11), activation=\"sigmoid\", padding=\"same\")))\n",
        "    seq.summary(line_length=150)\n",
        "    return seq\n",
        "\n",
        "def build_model_disc():\n",
        "    if conf.retrain == 1 and os.path.isfile(conf.DIS_MODEL_PATH+\".hdf5\"):\n",
        "        model_gen=load_model(conf.DIS_MODEL_PATH)\n",
        "        return model_gen\n",
        "    seq = Sequential()\n",
        "    model = Sequential()\n",
        "    seq.add(Reshape((10, 32, 32, 2), input_shape=(20480,)))\n",
        "    seq.add(TimeDistributed(Conv2D(32, (3, 3), strides=2, padding=\"same\")))\n",
        "    seq.add(LayerNormalization())\n",
        "    seq.add(TimeDistributed(Conv2D(64, (3,3), strides=4, padding=\"same\")))\n",
        "    seq.add(LayerNormalization())\n",
        "    seq.add(TimeDistributed(Conv2D(128, (3,3), strides=4, padding=\"same\")))\n",
        "    seq.add(LayerNormalization())\n",
        "    \n",
        "    seq.add(Flatten())\n",
        "    seq.add(Dense(512, activation=\"relu\"))\n",
        "    seq.add(Dropout(0.4))\n",
        "    seq.add(Dense(256, activation=\"relu\"))\n",
        "    seq.add(Dropout(0.4))\n",
        "    seq.add(Dense(128, activation=\"relu\"))\n",
        "    seq.add(Dropout(0.4))\n",
        "    seq.add(Dense(64, activation=\"relu\"))\n",
        "    #model.add(ke.layers.Dense(32, activation=\"relu\", input_shape=(20480,)))\n",
        "    #model.add(ke.layers.Dense(32, activation=\"relu\"))\n",
        "    seq.add(Dense(1, activation=\"sigmoid\"))\n",
        "    seq.summary(line_length=150)\n",
        "    return seq\n",
        "\n",
        "#build_model_enc()\n",
        "#build_model_dec()\n",
        "#build_model_disc()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0prEtmaLqGVG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b273179d-2655-4c29-b1ea-d800a7c66add"
      },
      "source": [
        "def build_model_aae():\n",
        "    model_enc = build_model_enc()\n",
        "    model_dec = build_model_dec()\n",
        "    model_disc = build_model_disc()\n",
        "    \n",
        "    model_ae = Sequential()\n",
        "    model_ae.add(model_enc)\n",
        "    model_ae.add(model_dec)\n",
        "    \n",
        "    model_enc_disc = Sequential()\n",
        "    model_enc_disc.add(model_enc)\n",
        "    model_enc_disc.add(model_disc)\n",
        "    \n",
        "    return model_enc, model_dec, model_disc, model_ae, model_enc_disc\n",
        "\n",
        "model_enc, model_dec, model_disc, model_ae, model_enc_disc = build_model_aae()\n",
        "\n",
        "model_enc.summary()\n",
        "model_dec.summary()\n",
        "model_disc.summary()\n",
        "model_ae.summary()\n",
        "model_enc_disc.summary()\n",
        "\n",
        "model_disc.compile(optimizer=Adam(lr=1e-4), loss=\"binary_crossentropy\")\n",
        "model_enc_disc.compile(optimizer=Adam(lr=1e-4), loss=\"binary_crossentropy\")\n",
        "model_ae.compile(optimizer=Adam(lr=1e-3), loss=\"mean_squared_error\")\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "Layer (type)                                                       Output Shape                                                Param #                \n",
            "======================================================================================================================================================\n",
            "time_distributed_1 (TimeDistributed)                               (None, 10, 64, 64, 128)                                     15616                  \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "layer_normalization_1 (LayerNormalization)                         (None, 10, 64, 64, 128)                                     256                    \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "time_distributed_2 (TimeDistributed)                               (None, 10, 32, 32, 64)                                      204864                 \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "layer_normalization_2 (LayerNormalization)                         (None, 10, 32, 32, 64)                                      128                    \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "conv_lst_m2d_1 (ConvLSTM2D)                                        (None, 10, 32, 32, 64)                                      295168                 \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "layer_normalization_3 (LayerNormalization)                         (None, 10, 32, 32, 64)                                      128                    \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "conv_lst_m2d_2 (ConvLSTM2D)                                        (None, 10, 32, 32, 32)                                      110720                 \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "layer_normalization_4 (LayerNormalization)                         (None, 10, 32, 32, 32)                                      64                     \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "conv_lst_m2d_3 (ConvLSTM2D)                                        (None, 10, 32, 32, 8)                                       11552                  \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "layer_normalization_5 (LayerNormalization)                         (None, 10, 32, 32, 8)                                       16                     \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "conv_lst_m2d_4 (ConvLSTM2D)                                        (None, 10, 32, 32, 2)                                       728                    \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "layer_normalization_6 (LayerNormalization)                         (None, 10, 32, 32, 2)                                       4                      \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)                                                (None, 20480)                                               0                      \n",
            "======================================================================================================================================================\n",
            "Total params: 639,244\n",
            "Trainable params: 639,244\n",
            "Non-trainable params: 0\n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "Model: \"sequential_2\"\n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "Layer (type)                                                       Output Shape                                                Param #                \n",
            "======================================================================================================================================================\n",
            "reshape_1 (Reshape)                                                (None, 10, 32, 32, 2)                                       0                      \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "conv_lst_m2d_5 (ConvLSTM2D)                                        (None, 10, 32, 32, 2)                                       296                    \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "layer_normalization_7 (LayerNormalization)                         (None, 10, 32, 32, 2)                                       4                      \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "conv_lst_m2d_6 (ConvLSTM2D)                                        (None, 10, 32, 32, 8)                                       2912                   \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "layer_normalization_8 (LayerNormalization)                         (None, 10, 32, 32, 8)                                       16                     \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "conv_lst_m2d_7 (ConvLSTM2D)                                        (None, 10, 32, 32, 32)                                      46208                  \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "layer_normalization_9 (LayerNormalization)                         (None, 10, 32, 32, 32)                                      64                     \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "conv_lst_m2d_8 (ConvLSTM2D)                                        (None, 10, 32, 32, 64)                                      221440                 \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "layer_normalization_10 (LayerNormalization)                        (None, 10, 32, 32, 64)                                      128                    \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "time_distributed_3 (TimeDistributed)                               (None, 10, 64, 64, 64)                                      102464                 \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "layer_normalization_11 (LayerNormalization)                        (None, 10, 64, 64, 64)                                      128                    \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "time_distributed_4 (TimeDistributed)                               (None, 10, 256, 256, 128)                                   991360                 \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "layer_normalization_12 (LayerNormalization)                        (None, 10, 256, 256, 128)                                   256                    \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "time_distributed_5 (TimeDistributed)                               (None, 10, 256, 256, 1)                                     15489                  \n",
            "======================================================================================================================================================\n",
            "Total params: 1,380,765\n",
            "Trainable params: 1,380,765\n",
            "Non-trainable params: 0\n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "Model: \"sequential_3\"\n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "Layer (type)                                                       Output Shape                                                Param #                \n",
            "======================================================================================================================================================\n",
            "reshape_2 (Reshape)                                                (None, 10, 32, 32, 2)                                       0                      \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "time_distributed_6 (TimeDistributed)                               (None, 10, 16, 16, 32)                                      608                    \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "layer_normalization_13 (LayerNormalization)                        (None, 10, 16, 16, 32)                                      64                     \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "time_distributed_7 (TimeDistributed)                               (None, 10, 4, 4, 64)                                        18496                  \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "layer_normalization_14 (LayerNormalization)                        (None, 10, 4, 4, 64)                                        128                    \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "time_distributed_8 (TimeDistributed)                               (None, 10, 1, 1, 128)                                       73856                  \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "layer_normalization_15 (LayerNormalization)                        (None, 10, 1, 1, 128)                                       256                    \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "flatten_2 (Flatten)                                                (None, 1280)                                                0                      \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "dense_1 (Dense)                                                    (None, 512)                                                 655872                 \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)                                                (None, 512)                                                 0                      \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "dense_2 (Dense)                                                    (None, 256)                                                 131328                 \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)                                                (None, 256)                                                 0                      \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "dense_3 (Dense)                                                    (None, 128)                                                 32896                  \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)                                                (None, 128)                                                 0                      \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "dense_4 (Dense)                                                    (None, 64)                                                  8256                   \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "dense_5 (Dense)                                                    (None, 1)                                                   65                     \n",
            "======================================================================================================================================================\n",
            "Total params: 921,825\n",
            "Trainable params: 921,825\n",
            "Non-trainable params: 0\n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "time_distributed_1 (TimeDist (None, 10, 64, 64, 128)   15616     \n",
            "_________________________________________________________________\n",
            "layer_normalization_1 (Layer (None, 10, 64, 64, 128)   256       \n",
            "_________________________________________________________________\n",
            "time_distributed_2 (TimeDist (None, 10, 32, 32, 64)    204864    \n",
            "_________________________________________________________________\n",
            "layer_normalization_2 (Layer (None, 10, 32, 32, 64)    128       \n",
            "_________________________________________________________________\n",
            "conv_lst_m2d_1 (ConvLSTM2D)  (None, 10, 32, 32, 64)    295168    \n",
            "_________________________________________________________________\n",
            "layer_normalization_3 (Layer (None, 10, 32, 32, 64)    128       \n",
            "_________________________________________________________________\n",
            "conv_lst_m2d_2 (ConvLSTM2D)  (None, 10, 32, 32, 32)    110720    \n",
            "_________________________________________________________________\n",
            "layer_normalization_4 (Layer (None, 10, 32, 32, 32)    64        \n",
            "_________________________________________________________________\n",
            "conv_lst_m2d_3 (ConvLSTM2D)  (None, 10, 32, 32, 8)     11552     \n",
            "_________________________________________________________________\n",
            "layer_normalization_5 (Layer (None, 10, 32, 32, 8)     16        \n",
            "_________________________________________________________________\n",
            "conv_lst_m2d_4 (ConvLSTM2D)  (None, 10, 32, 32, 2)     728       \n",
            "_________________________________________________________________\n",
            "layer_normalization_6 (Layer (None, 10, 32, 32, 2)     4         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 20480)             0         \n",
            "=================================================================\n",
            "Total params: 639,244\n",
            "Trainable params: 639,244\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "reshape_1 (Reshape)          (None, 10, 32, 32, 2)     0         \n",
            "_________________________________________________________________\n",
            "conv_lst_m2d_5 (ConvLSTM2D)  (None, 10, 32, 32, 2)     296       \n",
            "_________________________________________________________________\n",
            "layer_normalization_7 (Layer (None, 10, 32, 32, 2)     4         \n",
            "_________________________________________________________________\n",
            "conv_lst_m2d_6 (ConvLSTM2D)  (None, 10, 32, 32, 8)     2912      \n",
            "_________________________________________________________________\n",
            "layer_normalization_8 (Layer (None, 10, 32, 32, 8)     16        \n",
            "_________________________________________________________________\n",
            "conv_lst_m2d_7 (ConvLSTM2D)  (None, 10, 32, 32, 32)    46208     \n",
            "_________________________________________________________________\n",
            "layer_normalization_9 (Layer (None, 10, 32, 32, 32)    64        \n",
            "_________________________________________________________________\n",
            "conv_lst_m2d_8 (ConvLSTM2D)  (None, 10, 32, 32, 64)    221440    \n",
            "_________________________________________________________________\n",
            "layer_normalization_10 (Laye (None, 10, 32, 32, 64)    128       \n",
            "_________________________________________________________________\n",
            "time_distributed_3 (TimeDist (None, 10, 64, 64, 64)    102464    \n",
            "_________________________________________________________________\n",
            "layer_normalization_11 (Laye (None, 10, 64, 64, 64)    128       \n",
            "_________________________________________________________________\n",
            "time_distributed_4 (TimeDist (None, 10, 256, 256, 128) 991360    \n",
            "_________________________________________________________________\n",
            "layer_normalization_12 (Laye (None, 10, 256, 256, 128) 256       \n",
            "_________________________________________________________________\n",
            "time_distributed_5 (TimeDist (None, 10, 256, 256, 1)   15489     \n",
            "=================================================================\n",
            "Total params: 1,380,765\n",
            "Trainable params: 1,380,765\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "reshape_2 (Reshape)          (None, 10, 32, 32, 2)     0         \n",
            "_________________________________________________________________\n",
            "time_distributed_6 (TimeDist (None, 10, 16, 16, 32)    608       \n",
            "_________________________________________________________________\n",
            "layer_normalization_13 (Laye (None, 10, 16, 16, 32)    64        \n",
            "_________________________________________________________________\n",
            "time_distributed_7 (TimeDist (None, 10, 4, 4, 64)      18496     \n",
            "_________________________________________________________________\n",
            "layer_normalization_14 (Laye (None, 10, 4, 4, 64)      128       \n",
            "_________________________________________________________________\n",
            "time_distributed_8 (TimeDist (None, 10, 1, 1, 128)     73856     \n",
            "_________________________________________________________________\n",
            "layer_normalization_15 (Laye (None, 10, 1, 1, 128)     256       \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 1280)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 512)               655872    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 921,825\n",
            "Trainable params: 921,825\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "sequential_1 (Sequential)    (None, 20480)             639244    \n",
            "_________________________________________________________________\n",
            "sequential_2 (Sequential)    (None, 10, 256, 256, 1)   1380765   \n",
            "=================================================================\n",
            "Total params: 2,020,009\n",
            "Trainable params: 2,020,009\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "sequential_1 (Sequential)    (None, 20480)             639244    \n",
            "_________________________________________________________________\n",
            "sequential_3 (Sequential)    (None, 1)                 921825    \n",
            "=================================================================\n",
            "Total params: 1,561,069\n",
            "Trainable params: 1,561,069\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6GvNOR9piRHx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "def reconstruct_batch(model, sequences, epoch, folder_name):\n",
        "\n",
        "    sz = sequences.shape[0]\n",
        "    #InX = Input(shape=sequences.shape[1:]) \n",
        "    #tmpModel = Model(inputs=InX, outputs=model.get_layer(\"convTD5\").output)\n",
        "    reconstructed_sequences = model.predict(sequences,batch_size=conf.BATCH_SIZE)\n",
        "\n",
        "    path = join(conf.run_data,folder_name, str(epoch)+\"_epoch\")\n",
        "    os.makedirs(path, exist_ok=True)\n",
        "    for i in range(0, sz):\n",
        "        #cv2_imshow(np.reshape(reconstructed_sequences[i][2],(256, 256))*256)\n",
        "        if i < 10:\n",
        "            img_num = \"00\"+str(i)\n",
        "        elif i < 100:\n",
        "            img_num = \"0\"+str(i)\n",
        "        else:\n",
        "            img_num = str(i)\n",
        "        print(\"Reconstructing : \"+ str(reconstructed_sequences.shape))\n",
        "        cv2.imwrite(join(path,\"gen_\"+img_num+\".jpg\"), convert_images_back(reconstructed_sequences[i][6]))\n",
        "        \n",
        "def settrainable(model, toset):\n",
        "    for layer in model.layers:\n",
        "        layer.trainable = toset\n",
        "    model.trainable = toset\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def evaluate_gen(sequences, model, test_case_dir, epoch=conf.EPOCHS):\n",
        "\n",
        "    reconstructed_sequences = model.predict(sequences,batch_size=conf.BATCH_SIZE)\n",
        "    \n",
        "    sz = sequences.shape[0]\n",
        "    \n",
        "    print(\"Test size:\"+str(sz))\n",
        "   \n",
        "    os.makedirs(join(conf.image_dir,test_case_dir,\"epoch_\"+str(epoch)), exist_ok=True)\n",
        "    for i in range(0, sz):\n",
        "        #print(\"sz \"+str(i)+\"\\n\")\n",
        "        #cv2_imshow(np.reshape(reconstructed_sequences[i][2],(256, 256))*256)\n",
        "        if i < 10:\n",
        "            img_num = \"00\"+str(i)\n",
        "        elif i < 100:\n",
        "            img_num = \"0\"+str(i)\n",
        "        else:\n",
        "            img_num = str(i)    \n",
        "        \n",
        "        cv2.imwrite(join(conf.image_dir, test_case_dir, \"epoch_\"+str(epoch),\"gen_\"+img_num+\".jpg\"), convert_images_back(reconstructed_sequences[i][6]))\n",
        "\n",
        "\n",
        "def evaluate_dis(sequences, model):\n",
        "    sr = model.predict(sequences,batch_size=conf.BATCH_SIZE)\n",
        "\n",
        "    plt.plot(sr)\n",
        "    plt.ylabel('regularity score Sr(t)')\n",
        "    plt.xlabel('frame t')\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8GzbHa0avadq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3970e5fc-2eff-4be5-aa2a-24f3752071ff"
      },
      "source": [
        "\n",
        "test_cases_dir = \"Test008\"\n",
        "test_cases = get_test_sequences(test_cases_dir, 200)\n",
        "print(\"Test data set loaded\")\n",
        "conf.reconfig(new_name=\"Conv2DLSTM_WGAN_GP\", batch_size=4, epochs=100, retrain=0)\n",
        "x_train = get_clips_list(conf.dim1)\n",
        "\n",
        "print(\"Train data set loaded\")\n",
        "\n",
        "batchsize = conf.BATCH_SIZE\n",
        "j = 0\n",
        "num_batches = int(len(x_train) / batchsize)\n",
        "for epochnumber in range(conf.EPOCHS):\n",
        "    j = j+1\n",
        "    bar = IncrementalBar('Countdown', max = num_batches)\n",
        "    print(\"Epoch \"+str(j))\n",
        "    for i in range(int(len(x_train) / batchsize)):\n",
        "\n",
        "        settrainable(model_ae, True)\n",
        "        settrainable(model_enc, True)\n",
        "        settrainable(model_dec, True)\n",
        "        \n",
        "        batch = x_train[i*batchsize:i*batchsize+batchsize]\n",
        "        model_ae.train_on_batch(batch, batch)\n",
        "        \n",
        "        settrainable(model_disc, True)\n",
        "        batchpred = model_enc.predict(batch)\n",
        "        fakepred = np.random.standard_normal((batchsize,20480))\n",
        "        discbatch_x = np.concatenate([batchpred, fakepred])\n",
        "        discbatch_y = np.concatenate([np.zeros(batchsize), np.ones(batchsize)])\n",
        "        model_disc.train_on_batch(discbatch_x, discbatch_y)\n",
        "        \n",
        "        settrainable(model_enc_disc, True)\n",
        "        settrainable(model_enc, True)\n",
        "        settrainable(model_disc, False)\n",
        "        model_enc_disc.train_on_batch(batch, np.ones(batchsize))\n",
        "        bar.next()\n",
        "        time.sleep(1)\n",
        "    \n",
        "    model_enc.save(conf.GEN_MODEL_PATH)\n",
        "    model_dec.save(conf.DEC_MODEL_PATH)\n",
        "    model_disc.save(conf.DIS_MODEL_PATH) \n",
        "    evaluate_gen(test_cases, model_ae, test_cases_dir, epochnumber)\n",
        "    evaluate_dis(test_cases, model_enc_disc)\n",
        "    print (\"Reconstruction Loss:\", model_ae.evaluate(x_train, x_train, verbose=0, batch_size=conf.BATCH_SIZE))\n",
        "    print (\"Adverserial Loss:\", model_enc_disc.evaluate(x_train, np.ones(len(x_train)), verbose=0, batch_size=conf.BATCH_SIZE))\n",
        "\n",
        "\n",
        "evaluate_gen(test_cases, model_ae, test_cases_dir)\n",
        "\n",
        "evaluate_dis(test_cases, model_enc_disc)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test case loaded\n",
            "Test data set loaded\n",
            "Configuring train from scratch\n",
            "Train data set loaded\n",
            "Epoch 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:297: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
            "  'Discrepancy between trainable weights and collected trainable'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Test size:190\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAX70lEQVR4nO3de7QlZX3m8e8jFzVyU+gwyMUGB41tNIhH1FEEEycBRsHLaGCYCOiSOEoUHZYDy1miEON4yzIsDAxOOoAiiI4XXKCABGXGEaURmmuAxkDoBqGVACJEBX7zR9XBzaHOORu669Sm+/tZa6+ueqv23k/X6e5fV71V75uqQpKkmZ40dABJ0mSyQEiSOlkgJEmdLBCSpE4WCElSpw2HDrC2bLXVVrV48eKhY0jSE8qll176s6pa1LVtnSkQixcvZtmyZUPHkKQnlCQ3z7bNS0ySpE4WCElSJwuEJKmTBUKS1MkCIUnq1FuBSLI0yR1Jrpple5Icl2RFkiuS7Dpj+2ZJViY5vq+MkqTZ9XkGcTKw1xzb9wZ2bl+HAifM2H4scFEvySRJ8+qtQFTVRcCdc+yyH3BqNS4GtkiyDUCSFwNbA+f1lU+SNLch+yC2BW4ZWV8JbJvkScCngSMGSSVJAiazk/pdwDlVtXK+HZMcmmRZkmWrV69egGiStP4YcqiNVcD2I+vbtW0vB3ZP8i5gE2DjJPdW1ZEzP6CqTgJOApiamnJqPElai4YsEGcBhyU5A3gpcHdV3QYcOL1DkoOBqa7iIEnqV28FIsnpwJ7AVklWAkcDGwFU1YnAOcA+wArgPuCQvrJIkh673gpEVR0wz/YC3j3PPifT3C4rSVpgk9hJLUmaABYISVInC4QkqZMFQpLUyQIhSepkgZAkdbJASJI6WSAkSZ0sEJKkThYISVInC4QkqZMFQpLUyQIhSepkgZAkdbJASJI6WSAkSZ0sEJKkThYISVInC4QkqZMFQpLUyQIhSepkgZAkdbJASJI6WSAkSZ0sEJKkThYISVInC4QkqZMFQpLUyQIhSepkgZAkdbJASJI69VYgkixNckeSq2bZniTHJVmR5Ioku7btuyT5QZKr2/Y/7SujJGl2fZ5BnAzsNcf2vYGd29ehwAlt+33AW6vq+e37P5Nkix5zSpI6bNjXB1fVRUkWz7HLfsCpVVXAxUm2SLJNVV0/8hm3JrkDWATc1VdWSdKjDdkHsS1wy8j6yrbtYUl2AzYGbuz6gCSHJlmWZNnq1at7CypJ66OJ7aROsg3weeCQqnqoa5+qOqmqpqpqatGiRQsbUJLWcUMWiFXA9iPr27VtJNkMOBv4YFVdPEA2SVrvDVkgzgLe2t7N9DLg7qq6LcnGwNdo+ie+MmA+SVqv9dZJneR0YE9gqyQrgaOBjQCq6kTgHGAfYAXNnUuHtG99C/AqYMskB7dtB1fV5X1llSQ9Wp93MR0wz/YC3t3R/gXgC33lkiSNZ2I7qSVJw7JASJI6WSAkSZ0sEJKkTnN2Uid5CvBaYHfgmcD9wFXA2VV1df/xJElDmbVAJPkITXH4LvBD4A7gKcBzgP/RFo//WlVXLEBOSdICm+sM4kdVdfQs2/46ye8CO/SQSZI0AWbtg6iqswGSvHnmtiRvrqo7qmpZn+EkScMZp5P6qDHbJEnrkLn6IPamGQpj2yTHjWzaDHig72CSpGHN1QdxK3ApsG/767RfAO/rM5QkaXizFoiqWg4sT3JaVf1mATNJkibArH0QSb6Z5HWzbNspyTFJ3tZfNEnSkOa6xPQO4P3AZ5LcCaymeQ5iMc0UoMdX1Td6TyhJGsRcl5h+CnwA+ECSxcA2NE9SX19V9y1IOknSYOYbamMD4DtV9WrgpgVJJEmaCHM+B1FVDwIPJdl8gfJIkibEODPK3QtcmeR84JfTjVX1nt5SSZIGN06B+Gr7kiStR+YtEFV1CkCSjYDfB1ZV1R19B5MkDWuu5yBOTPL8dnlzYDlwKnBZkgMWKJ8kaSBzdVLvPjIp0CE0t7e+AHgxze2vkqR12FwF4tcjy/8e+Do8/HyEJGkdN1eBuCvJa5O8CHgF8G2AJBsCT12IcJKk4czVSf3nwHHAvwEOHzlz+CPg7L6DSZKGNddQG9cDe3W0nwuc22coSdLwxplRTpK0HrJASJI6WSAkSZ3mLRBJtk7yd0m+1a4vSfL2/qNJkoY0zhnEyTSd0s9s168HDu8rkCRpMoxTILaqqjOBhwCq6gHgwfnelGRpkjuSXDXL9iQ5LsmKJFck2XVk20FJbmhfB435e5EkrUXjFIhfJtkSKIAkLwPuHuN9J9Nxm+yIvYGd29ehwAnt5z8DOBp4KbAbcHSSp4/xfZKktWic4b7fD5wFPDvJ94FFwH+c701VdVE7Vels9gNOraoCLk6yRZJtgD2B86vqToB2Hoq9gNPHyCpJWkvGmXJ0j/b1XCDAdVX1m7Xw3dsCt4ysr2zbZmvvyncozdkHO+yww1qIJEmaNs6UowdU1QNVdXVVXbWWisNaUVUnVdVUVU0tWrRo6DiStE4Zpw/i+0mOT7J7kl2nX2vhu1cB24+sb9e2zdYuSVpA4/RB7NL+esxIWwF/uIbffRZwWJIzaDqk766q25KcC/zVSMf0HwNHreF3SZIeo3GmHH314/ngJKfTdDhvlWQlzZ1JG7WfeSJwDrAPsAK4j2ZSIqrqziTHApe0H3XMdIe1JGnhzFsg2ulGjwZe1TZ9j+Yf7Tlvda2qOaclbe9eevcs25YCS+fLJknqzzh9EEuBXwBvaV/3AH/fZyhJ0vDG6YN4dlW9aWT9I0ku7yuQJGkyjHMGcX+SV06vJHkFcH9/kSRJk2CcM4j/ApzS9kUA/AtwcG+JJEkTYZy7mC4H/iDJZu36Pb2nkiQNbpz5IP4qyRZVdU9V3ZPk6Un+ciHCSZKGM04fxN5Vddf0SlX9C83zC5Kkddg4BWKDJE+eXknyVODJc+wvSVoHjNNJfRpwQZLpZx8OAU7pL5IkaRKM00n98STLgde0TcdW1bn9xpIkDW2coTaeBpxXVd9O8lzguUk2mqRhvyVJa984fRAXAU9Jsi3wbeDPaKYTlSStw8bpg0hV3Zfk7cAJVfWJdW2ojY9882quudXHOyQ9MS155mYc/brnr/XPHecMIkleDhwInN22bbDWk0iSJso4ZxDvpZmw52tVdXWSnYAL+421sPqovJL0RDfOXUwX0fRDTK//BHhPn6EkScMb5xKTJGk9ZIGQJHUaZ7C+LRciiCRpsoxzBnFxki8n2SdJek8kSZoI4xSI5wAn0Twgd0M7/Pdz+o0lSRravAWiGudX1QHAO4CDgB8l+V77fIQkaR00zlhMWwL/meYM4nbgL4CzgF2ALwM79hlQkjSMcR6U+wHweeD1VbVypH1ZkhP7iSVJGto4fRD/vaqOHS0OSd4MzVDgvSWTJA1qnAJxZEfbUWs7iCRpssx6iSnJ3jRzT2+b5LiRTZsBD/QdTJI0rLn6IG4FlgH7ApeOtP8CeF+foSRJw5u1QFTVcmB5ktOqyjMGSVrPzHWJ6cyqegtwWZKaub2qXthrMknSoOa6xPTe9tfXLkQQSdJkmfUupqq6LckGwMlVdfPM1zgfnmSvJNclWZHkUXdDJXlWkguSXJHku0m2G9n2iSRXJ7k2yXGOAyVJC2vO21yr6kHgoSSbP9YPbovLZ4G9gSXAAUmWzNjtU8Cp7eWqY4CPte/9d8ArgBcCvw+8BNjjsWaQJD1+4zxJfS9wZZLzgV9ON1bVfLPK7QasaGegI8kZwH7ANSP7LAHe3y5fCHx9+uOBpwAbAwE2ohnmQ5K0QMYpEF9tX4/VtsAtI+srgZfO2Gc58Ebgb4A3AJsm2bKqfpDkQuA2mgJxfFVdO/MLkhwKHAqwww47PI6IkqTZjDMn9Sk9fv8RwPFJDqaZ93oV8GCSfws8D5jukzg/ye5V9X9mZDuJZihypqamHnWnlSTp8RtnNNedafoGltBc9gGgqnaa562rgO1H1rdr2x5WVbfSnEGQZBPgTVV1V5J3ABdX1b3ttm8BLwceUSAkSf0ZZyymvwdOoBle49XAqcAXxnjfJcDOSXZMsjGwP80w4Q9LslWS6QxHAUvb5X8G9kiyYZKNaDqoH3WJSZLUn3EKxFOr6gIg7S2uHwb+w3xvap++Pgw4l+Yf9zOr6uokxyTZt91tT+C6JNcDWwMfbdu/AtwIXEnTT7G8qr45/m9LkrSmxumk/lX7v/wbkhxGc5lok3E+vKrOAc6Z0fahkeWv0BSDme97EPjzcb5DktSPcc4g3gv8DvAe4MU0M8sd1GcoSdLwxrmL6ZJ28V7gkH7jSJImxVyD9X2T5oG1TlW172zbJElPfHOdQXxqwVJIkibOXPNBfG8hg0iSJss4D8r9Ex2XmsZ4UE6S9AQ2zm2uUyPLTwHeDDyjnziSpEkx722uVfXzkdeqqvoMYzwoJ0l6YhvnEtOuI6tPojmjGOfMQ5L0BDbOP/SfHll+ALgJeEsvaSRJE2OcB+VevRBBJEmTZZxLTO/vaL4buLSqLl/7kSRJk2CcsZimgHfSzBC3Lc0gensBn0vygR6zSZIGNE4fxHbAriOT9xwNnA28CrgU+ER/8SRJQxnnDOJ3gV+NrP8G2Lqq7p/RLklah4xzBnEa8MMk32jXXwd8McnTgGt6SyZJGtQ4dzEd284J/Yq26Z1VtaxdPrC3ZJKkQY1ziQmaITbuqaq/AW5OsmOPmSRJE2DeAtF2Sv834Ki2aSPgC32GkiQNb5wziDcA+wK/BKiqW4FN+wwlSRreOAXi11VVtEN+t53TkqR13DgF4swk/xPYIsk7gO8An+s3liRpaHPexZQkwJeA3wPuAZ4LfKiqzl+AbJKkAc1ZIKqqkpxTVS8ALAqStB4Z5xLTj5O8pPckkqSJMs6T1C8FDkxyM82dTKE5uXhhr8kkSYMap0D8Se8pJEkTZ5yhNm5eiCCSpMky7lAbkqT1jAVCktTJAiFJ6tRrgUiyV5LrkqxIcmTH9mcluSDJFUm+m2S7kW07JDkvybVJrkmyuM+skqRH6q1AJNkA+CywN7AEOCDJkhm7fQo4tb1l9hjgYyPbTgU+WVXPA3YD7ugrqyTp0fo8g9gNWFFVP6mqXwNnAPvN2GcJ8A/t8oXT29tCsuH0kB5VdW9V3ddjVknSDH0WiG2BW0bWV7Zto5YDb2yX3wBsmmRL4DnAXUm+muSyJJ9sz0geIcmhSZYlWbZ69eoefguStP4aupP6CGCPJJcBewCrgAdpns/Yvd3+EmAn4OCZb66qk6pqqqqmFi1atGChJWl90GeBWAVsP7K+Xdv2sKq6tareWFUvAj7Ytt1Fc7ZxeXt56gHg68CuPWaVJM3QZ4G4BNg5yY5JNgb2B84a3SHJVkmmMxwFLB157xZJpk8L/hC4pseskqQZeisQ7f/8DwPOBa4Fzqyqq5Mck2Tfdrc9geuSXA9sDXy0fe+DNJeXLkhyJc0AgU5SJEkLKM1sok98U1NTtWzZsqFjSNITSpJLq2qqa9vQndSSpAllgZAkdbJASJI6WSAkSZ0sEJKkThYISVInC4QkqZMFQpLUyQIhSepkgZAkdbJASJI6WSAkSZ0sEJKkThYISVInC4QkqZMFQpLUyQIhSepkgZAkdbJASJI6WSAkSZ0sEJKkThYISVInC4QkqZMFQpLUyQIhSepkgZAkdbJASJI6WSAkSZ0sEJKkThYISVInC4QkqVOvBSLJXkmuS7IiyZEd25+V5IIkVyT5bpLtZmzfLMnKJMf3mVOS9Gi9FYgkGwCfBfYGlgAHJFkyY7dPAadW1QuBY4CPzdh+LHBRXxklSbPr8wxiN2BFVf2kqn4NnAHsN2OfJcA/tMsXjm5P8mJga+C8HjNKkmbRZ4HYFrhlZH1l2zZqOfDGdvkNwKZJtkzyJODTwBFzfUGSQ5MsS7Js9erVaym2JAmG76Q+AtgjyWXAHsAq4EHgXcA5VbVyrjdX1UlVNVVVU4sWLeo/rSStRzbs8bNXAduPrG/Xtj2sqm6lPYNIsgnwpqq6K8nLgd2TvAvYBNg4yb1V9aiObklSP/osEJcAOyfZkaYw7A/8p9EdkmwF3FlVDwFHAUsBqurAkX0OBqYsDpK0sHq7xFRVDwCHAecC1wJnVtXVSY5Jsm+7257AdUmup+mQ/mhfeSRJj02qaugMa8XU1FQtW7Zs6BiS9ISS5NKqmuraNnQntSRpQlkgJEmd1plLTElWAzevwUdsBfxsLcXpg/nWzKTng8nPaL41M6n5nlVVnc8JrDMFYk0lWTbbdbhJYL41M+n5YPIzmm/NTHq+Ll5ikiR1skBIkjpZIH7rpKEDzMN8a2bS88HkZzTfmpn0fI9iH4QkqZNnEJKkThYISVKn9b5AzDct6gB5tk9yYZJrklyd5L1t+4eTrEpyefvaZ+CcNyW5ss2yrG17RpLzk9zQ/vr0gbI9d+Q4XZ7kniSHD3kMkyxNckeSq0baOo9XGse1fyavSLLrgBk/meQf2xxfS7JF2744yf0jx/LEgfLN+jNNclR7DK9L8icD5fvSSLabklzeti/48Xtcqmq9fQEbADcCOwEb00xgtGTgTNsAu7bLmwLX08y892HgiKGP2UjOm4CtZrR9AjiyXT4S+PgE5NwA+CnwrCGPIfAqYFfgqvmOF7AP8C0gwMuAHw6Y8Y+BDdvlj49kXDy634D5On+m7d+Z5cCTgR3bv+cbLHS+Gds/DXxoqOP3eF7r+xnEONOiLqiquq2qftwu/4JmJNyZM/FNqv2AU9rlU4DXD5hl2h8BN1bVmjxlv8aq6iLgzhnNsx2v/Wjmaq+quhjYIsk2Q2SsqvOqGZkZ4GKaeV0GMcsxnM1+wBlV9auq+idgBc3f997MlS9JgLcAp/eZYW1b3wvEONOiDibJYuBFwA/bpsPaU/2lQ12+GVHAeUkuTXJo27Z1Vd3WLv+UZgj3oe3PI/9STtIxnO14Teqfy7fRnNlM2zHJZUm+l2T3oULR/TOdtGO4O3B7Vd0w0jYpx29W63uBmFhpZtj738DhVXUPcALwbGAX4Daa09UhvbKqdgX2Bt6d5FWjG6s5jx70HuokGwP7Al9umybtGD5sEo7XXJJ8EHgAOK1tug3YoapeBLwf+GKSzQaINrE/0xkO4JH/UZmU4zen9b1AzDst6hCSbERTHE6rqq8CVNXtVfVgNbPvfY6eT5fnU1Wr2l/vAL7W5rl9+lJI++sdwyUEmuL146q6HSbvGDL78ZqoP5dpZnV8LXBgW8hoL938vF2+lOYa/3MWOtscP9OJOYZJNqSZWvlL022Tcvzms74XiIenRW3/t7k/cNaQgdprlX8HXFtVfz3SPnoN+g3AVTPfu1CSPC3JptPLNB2ZV9Ecu4Pa3Q4CvjFMwoc94n9tk3QMW7Mdr7OAt7Z3M70MuHvkUtSCSrIX8AFg36q6b6R9UZIN2uWdgJ2BnwyQb7af6VnA/kmenGba452BHy10vtZrgH+sqpXTDZNy/OY1dC/50C+aO0aup6ngH5yAPK+kudRwBXB5+9oH+DxwZdt+FrDNgBl3orlDZDlw9fRxA7YELgBuAL4DPGPAjE8Dfg5sPtI22DGkKVS3Ab+huR7+9tmOF83dS59t/0xeSTMn+1AZV9Bcy5/+s3hiu++b2p/95cCPgdcNlG/WnynwwfYYXgfsPUS+tv1k4J0z9l3w4/d4Xg61IUnqtL5fYpIkzcICIUnqZIGQJHWyQEiSOlkgJEmdLBDSPJK8J8m1SU6bf+9evn+XhRx5Vpq24dABpCeAdwGvqZEHnaB5QrZ+O5Bdn3YBpoBzFuC7pIf5HIQ0h3ac/rfRPGy1FNicZuyfnYB/Bo6ieVjrae1bDquq/5dkT+AjwF3AC4AzaR7oei/wVOD1VXVjkkXAicAO7fsPr6rvj3z/xjQPqz2VZqiIj1XVw0M2SH2yQEjzSHITzdPMP0vyYeB1NIMV3p/kd4CHqupfk+wMnF5VU22B+DrwPJohoH8C/K+qOjrNJFA7VtXhSb4I/G1V/d8kOwDnVtXzZnz/we33H7Ywv2Op4SUm6bE7q6rub5c3Ao5PsgvwII8ccO2SasdQSnIjcF7bfiXw6nb5NcCSZgguADZLsklV3dvnb0AahwVCeux+ObL8PuB24A9obvr415FtvxpZfmhk/SF++3fvScDLqmr0fdJE8C4mac1sDtxWzXDTf0YzxeljcR7wF9Mr7ZnITL+gmX5WWlAWCGnN/C1wUJLlwO/xyLOLcbwHmGpnRLsGeGfHPhfSXIa6PMmfrllcaXx2UkuSOnkGIUnqZIGQJHWyQEiSOlkgJEmdLBCSpE4WCElSJwuEJKnT/wcOwI1mO/OegAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:297: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
            "  'Discrepancy between trainable weights and collected trainable'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Test size:190\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:297: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
            "  'Discrepancy between trainable weights and collected trainable'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Test size:190\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:297: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
            "  'Discrepancy between trainable weights and collected trainable'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-2b44480ee831>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatchsize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatchsize\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbatchsize\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mmodel_ae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0msettrainable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_disc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1512\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1514\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1516\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3790\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3791\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3792\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3793\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3794\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1603\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1604\u001b[0m     \"\"\"\n\u001b[0;32m-> 1605\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1607\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1643\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1644\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1645\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1647\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}