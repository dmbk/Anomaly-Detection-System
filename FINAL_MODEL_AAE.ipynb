{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FINAL_MODEL_AAE.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPBI7c1tf9+KXNwLczeeJ9C",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dmbk/Anomaly-Detection-System/blob/master/FINAL_MODEL_AAE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mOpwOqr0OL6R",
        "colab_type": "code",
        "outputId": "fc93e425-a6d6-4f9a-812a-e377dcd0e9ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 627
        }
      },
      "source": [
        "!pip install imageio\n",
        "!pip install progress\n",
        "#!pip install tensorflow_datasets\n",
        "!pip install keras-layer-normalization\n",
        "from google.colab import drive\n",
        "#!pip install alive-progress\n",
        "drive.mount('/content/drive', force_remount=True)\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: imageio in /usr/local/lib/python3.6/dist-packages (2.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from imageio) (1.18.3)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from imageio) (7.0.0)\n",
            "Collecting progress\n",
            "  Downloading https://files.pythonhosted.org/packages/38/ef/2e887b3d2b248916fc2121889ce68af8a16aaddbe82f9ae6533c24ff0d2b/progress-1.5.tar.gz\n",
            "Building wheels for collected packages: progress\n",
            "  Building wheel for progress (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for progress: filename=progress-1.5-cp36-none-any.whl size=8074 sha256=795ebbec9b9b228a7404088318aca47830c609969cdfa1e846802645a5c9cbcc\n",
            "  Stored in directory: /root/.cache/pip/wheels/6c/c8/80/32a294e3041f006c661838c05a411c7b7ffc60ff939d14e116\n",
            "Successfully built progress\n",
            "Installing collected packages: progress\n",
            "Successfully installed progress-1.5\n",
            "Collecting keras-layer-normalization\n",
            "  Downloading https://files.pythonhosted.org/packages/a4/0e/d1078df0494bac9ce1a67954e5380b6e7569668f0f3b50a9531c62c1fc4a/keras-layer-normalization-0.14.0.tar.gz\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from keras-layer-normalization) (1.18.3)\n",
            "Requirement already satisfied: Keras in /usr/local/lib/python3.6/dist-packages (from keras-layer-normalization) (2.3.1)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-layer-normalization) (1.4.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras->keras-layer-normalization) (2.10.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-layer-normalization) (1.1.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-layer-normalization) (1.12.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-layer-normalization) (1.0.8)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras->keras-layer-normalization) (3.13)\n",
            "Building wheels for collected packages: keras-layer-normalization\n",
            "  Building wheel for keras-layer-normalization (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-layer-normalization: filename=keras_layer_normalization-0.14.0-cp36-none-any.whl size=5268 sha256=11c660c2539260fe3498d030ddd1782a0ddef65720865320385f11656b87448b\n",
            "  Stored in directory: /root/.cache/pip/wheels/54/80/22/a638a7d406fd155e507aa33d703e3fa2612b9eb7bb4f4fe667\n",
            "Successfully built keras-layer-normalization\n",
            "Installing collected packages: keras-layer-normalization\n",
            "Successfully installed keras-layer-normalization-0.14.0\n",
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-eFt6lxCTi3Q",
        "colab_type": "code",
        "outputId": "da13be58-7bb1-4e8d-9e22-393dc34bd107",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "\n",
        "import skimage\n",
        "import glob\n",
        "import imageio\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "from PIL import Image\n",
        "from os.path import join\n",
        "from os import listdir\n",
        "from os.path import isfile, join, isdir\n",
        "\n",
        "#import keras\n",
        "import argparse\n",
        "from os.path import dirname\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\t\n",
        "import statistics\n",
        "import shutil\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import time\n",
        "from progress.bar import IncrementalBar\n",
        "\n",
        "import numpy as np\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Input, Dense, Reshape, Flatten\n",
        "from keras.layers import Conv2DTranspose, ConvLSTM2D, BatchNormalization, TimeDistributed, Conv2D, Dropout, Activation, InputLayer\n",
        "from keras.optimizers import Adam\n",
        "from keras_layer_normalization import LayerNormalization\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "571xSlFJUBaB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Config:\n",
        "    def __init__(self, data_dir_, cwdir_name_, data_set):\n",
        "        self.data_set_name = data_set\n",
        "        self.data_dir = data_dir_\n",
        "        self.data_set_dir = join(self.data_dir, data_set)\n",
        "        self.cwdir_name = cwdir_name_\n",
        "        self.cwdir = join(self.data_dir,self.cwdir_name)\n",
        "        self.run_data = join(self.cwdir, \"training_dir\")\n",
        "        self.image_dir = join(self.run_data,self.data_set_name,\"Test/\")\n",
        "        if not os.path.exists(self.cwdir):\n",
        "            os.mkdir(self.cwdir)\n",
        "            os.mkdir(self.run_data)\n",
        "    \n",
        "        if not os.path.exists(self.run_data):\n",
        "            #shutil.rmtree(self.run_data)\n",
        "            os.mkdir(self.run_data)\n",
        "            os.makedirs(self.image_dir, exist_ok=True)\n",
        "\n",
        "        self.DATASET_PATH = join(self.data_set_dir,\"Train/\")\n",
        "        self.TEST_DIR = join(self.data_set_dir,\"Test/\")\n",
        "        self.BATCH_SIZE = 2\n",
        "        self.EPOCHS = 50\n",
        "        self.GEN_MODEL_PATH = join(self.cwdir,\"model_gen_Conv2DLSTM_AAE\")\n",
        "        self.DIS_MODEL_PATH = join(self.cwdir,\"model_dis_Conv2DLSTM_AAE\")\n",
        "        self.DEC_MODEL_PATH = join(self.cwdir,\"model_dec_Conv2DLSTM_AAE\")\n",
        "\n",
        "        self.retrain = 0\n",
        "        self.dim1 = 10\n",
        "        self.dim2 = 256\n",
        "        self.dim3 = 256\n",
        "        self.dim4 = 1\n",
        "        self.latent_dim = 163840\n",
        "        self.curr_epoch = 0\n",
        "\n",
        "    def reconfig(self, new_name, batch_size = 4, epochs = 5, retrain = 0, curr_epoch = 0):\n",
        "        self.cwdir_name = new_name\n",
        "        self.cwdir = join(self.data_dir, self.cwdir_name)\n",
        "        self.run_data = join(self.cwdir, \"training_dir\")\n",
        "        self.image_dir = join(self.run_data,self.data_set_name,\"Test/\")\n",
        "\n",
        "        self.BATCH_SIZE = batch_size\n",
        "        self.EPOCHS = epochs\n",
        "        self.GEN_MODEL_PATH = join(self.cwdir,\"model_gen_Conv2DLSTM_AAE\")\n",
        "        self.DIS_MODEL_PATH = join(self.cwdir,\"model_dis_Conv2DLSTM_AAE\")\n",
        "        self.DEC_MODEL_PATH = join(self.cwdir,\"model_dec_Conv2DLSTM_AAE\")\n",
        "\n",
        "        self.retrain = retrain\n",
        "        if retrain == 0:\n",
        "            print(\"Configuring train from scratch\")\n",
        "            if not os.path.exists(self.cwdir):\n",
        "                os.mkdir(self.cwdir)\n",
        "                os.mkdir(self.run_data)\n",
        "    \n",
        "            if os.path.exists(self.run_data):\n",
        "                shutil.rmtree(self.run_data)\n",
        "                os.mkdir(self.run_data)\n",
        "                os.makedirs(self.image_dir, exist_ok=True)\n",
        "\n",
        "        self.curr_epoch = curr_epoch\n",
        "\n",
        "conf = Config(data_dir_=\"/content/drive/My Drive/\", cwdir_name_=\"Conv2DLSTM_AAE\", data_set=\"UCSD_Anomaly_Dataset.v1p2/UCSDped1/\") \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wEre58ljoxbK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_clips_by_stride(stride, frames_list, sequence_size):\n",
        "\n",
        "    clips = []\n",
        "    sz = len(frames_list)\n",
        "    clip = np.zeros(shape=(sequence_size, 256, 256, 1))\n",
        "    cnt = 0\n",
        "    for start in range(0, stride):\n",
        "        for i in range(start, sz, stride):\n",
        "            clip[cnt, :, :, 0] = frames_list[i]\n",
        "            cnt = cnt + 1\n",
        "            if cnt == sequence_size:\n",
        "                clips.append(clip)\n",
        "                cnt = 0\n",
        "    return clips\n",
        "\n",
        "def get_clips_list(seq_size):\n",
        "\n",
        "    clips = []\n",
        "    # loop over the training folders (Train000,Train001,..)\n",
        "    for f in sorted(listdir(conf.DATASET_PATH)):\n",
        "        directory_path = join(conf.DATASET_PATH, f)\n",
        "        if isdir(directory_path):\n",
        "            all_frames = []\n",
        "            # loop over all the images in the folder (0.tif,1.tif,..,199.tif)\n",
        "            for c in sorted(listdir(directory_path)):\n",
        "                img_path = join(directory_path, c)\n",
        "                if str(img_path)[-3:] == \"tif\":\n",
        "                    img = Image.open(img_path).resize((256, 256))\n",
        "\n",
        "                    img = np.array(img, dtype=np.float32) / 256.0\n",
        "                    all_frames.append(img)\n",
        "            # get the 32-frames sequences from the list of images after applying data augmentation\n",
        "            for stride in range(1, 3):\n",
        "                clips.extend(get_clips_by_stride(stride=stride, frames_list=all_frames, sequence_size=seq_size))\n",
        "    \n",
        "    #print(np.array(clips).shape)\n",
        "    return np.array(clips)\n",
        "\n",
        "\n",
        "def get_single_test(single_test_path, sz):\n",
        "    test = np.zeros(shape=(sz, conf.dim2, conf.dim3, conf.dim4))\n",
        "    cnt = 0\n",
        "    for f in sorted(listdir(single_test_path)):\n",
        "        if str(join(single_test_path, f))[-3:] == \"tif\":\n",
        "            img = Image.open(join(single_test_path, f)).resize((conf.dim2, conf.dim3))\n",
        "            #cv2_imshow(np.array(img,dtype=np.float32))\n",
        "            #cv2.waitKey(0)\n",
        "            img = np.array(img, dtype=np.float32) / 256\n",
        "            test[cnt, :, :, 0] = img\n",
        "            cnt = cnt + 1\n",
        "    return test\n",
        "\n",
        "def get_test_sequences(test_case_dir, sz):\n",
        "    test = get_single_test(join(conf.TEST_DIR,test_case_dir), sz)\n",
        "    print(\"Test case loaded\")\n",
        "    sz = test.shape[0] - conf.dim1\n",
        "    sequences = np.zeros((sz, conf.dim1, conf.dim2, conf.dim3, conf.dim4))\n",
        "    # apply the sliding window technique to get the sequences\n",
        "    for i in range(0, sz):\n",
        "        clip = np.zeros((conf.dim1, conf.dim2, conf.dim3, conf.dim4))\n",
        "        for j in range(0, conf.dim1):\n",
        "            clip[j] = test[i + j, :, :, :]\n",
        "        sequences[i] = clip\n",
        "    return sequences\n",
        "\n",
        "def convert_images_back(image):\n",
        "    return np.reshape(image,(256, 256))*256.0\n",
        "    #print(image.shape)\n",
        "    #return np.reshape(image[:, :, 0],(image.shape[0], image.shape[1]))*127.5 + 127.5\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0RiNsbLXHTb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_model_enc(path):\n",
        "    if conf.retrain == 1 and os.path.isfile(path):\n",
        "        model_gen=load_model(path)\n",
        "        return model_gen\n",
        "    seq = Sequential()\n",
        "    seq.add(TimeDistributed(Conv2D(128, (11, 11), strides=4, padding=\"same\"), batch_input_shape=(None, 10, 256, 256, 1)))\n",
        "    seq.add(LayerNormalization())\n",
        "    seq.add(TimeDistributed(Conv2D(64, (5, 5), strides=2, padding=\"same\")))\n",
        "    seq.add(LayerNormalization())\n",
        "    # # # # #\n",
        "    seq.add(ConvLSTM2D(64, (3, 3), padding=\"same\", return_sequences=True))\n",
        "    seq.add(LayerNormalization())\n",
        "    seq.add(ConvLSTM2D(32, (3, 3), padding=\"same\", return_sequences=True))\n",
        "    seq.add(LayerNormalization())\n",
        "    seq.add(ConvLSTM2D(16, (3, 3), padding=\"same\", return_sequences=True))\n",
        "    seq.add(LayerNormalization())\n",
        "    seq.add(Flatten())\n",
        "    seq.summary(line_length=150)\n",
        "    return  seq\n",
        "\n",
        "def build_model_dec():\n",
        "    if conf.retrain == 1 and os.path.isfile(path):\n",
        "        model_gen=load_model(path)\n",
        "        return model_gen\n",
        "    seq = Sequential()\n",
        "    seq.add(Reshape((10, 32, 32, 16), input_shape=(conf.latent_dim,)))\n",
        "    seq.add(ConvLSTM2D(16, (3, 3), padding=\"same\", return_sequences=True))\n",
        "    seq.add(LayerNormalization())\n",
        "    seq.add(ConvLSTM2D(32, (3, 3), padding=\"same\", return_sequences=True))\n",
        "    seq.add(LayerNormalization())\n",
        "    seq.add(ConvLSTM2D(64, (3, 3), padding=\"same\", return_sequences=True))\n",
        "    seq.add(LayerNormalization())\n",
        "    # # # # #\n",
        "    seq.add(TimeDistributed(Conv2DTranspose(64, (5, 5), strides=2, padding=\"same\")))\n",
        "    seq.add(LayerNormalization())\n",
        "    seq.add(TimeDistributed(Conv2DTranspose(128, (11, 11), strides=4, padding=\"same\")))\n",
        "    seq.add(LayerNormalization())\n",
        "    seq.add(TimeDistributed(Conv2D(1, (11, 11), activation=\"sigmoid\", padding=\"same\")))\n",
        "    seq.summary(line_length=150)\n",
        "    return seq\n",
        "\n",
        "def build_model_disc():\n",
        "    if conf.retrain == 1 and os.path.isfile(path):\n",
        "        model_gen=load_model(path)\n",
        "        return model_gen\n",
        "    seq = Sequential()\n",
        "    model = Sequential()\n",
        "    seq.add(Reshape((10, 32, 32, 16), input_shape=(conf.latent_dim,)))\n",
        "    seq.add(TimeDistributed(Conv2D(16, (3, 3), strides=2, padding=\"same\")))\n",
        "    seq.add(LayerNormalization())\n",
        "    seq.add(TimeDistributed(Conv2D(32, (3, 3), strides=2, padding=\"same\")))\n",
        "    seq.add(LayerNormalization())\n",
        "    seq.add(TimeDistributed(Conv2D(64, (3,3), strides=4, padding=\"same\")))\n",
        "    seq.add(LayerNormalization())\n",
        "    seq.add(TimeDistributed(Conv2D(128, (3,3), strides=4, padding=\"same\")))\n",
        "    seq.add(LayerNormalization())\n",
        "    \n",
        "    seq.add(Flatten())\n",
        "    seq.add(Dense(512, activation=\"relu\"))\n",
        "    seq.add(Dropout(0.4))\n",
        "    seq.add(Dense(256, activation=\"relu\"))\n",
        "    seq.add(Dropout(0.4))\n",
        "    seq.add(Dense(128, activation=\"relu\"))\n",
        "    seq.add(Dropout(0.4))\n",
        "    seq.add(Dense(64, activation=\"relu\"))\n",
        "    #model.add(ke.layers.Dense(32, activation=\"relu\", input_shape=(20480,)))\n",
        "    #model.add(ke.layers.Dense(32, activation=\"relu\"))\n",
        "    seq.add(Dense(1, activation=\"sigmoid\"))\n",
        "    seq.summary(line_length=150)\n",
        "    return seq\n",
        "\n",
        "#build_model_enc()\n",
        "#build_model_dec()\n",
        "#build_model_disc()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0prEtmaLqGVG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_model_aae(enc_path, dec_path, disc_path):\n",
        "    model_enc = build_model_enc(enc_path)\n",
        "    model_dec = build_model_dec(dec_path)\n",
        "    model_disc = build_model_disc(disc_path)\n",
        "    \n",
        "    model_ae = Sequential()\n",
        "    model_ae.add(model_enc)\n",
        "    model_ae.add(model_dec)\n",
        "    \n",
        "    model_enc_disc = Sequential()\n",
        "    model_enc_disc.add(model_enc)\n",
        "    model_enc_disc.add(model_disc)\n",
        "    \n",
        "    model_enc.summary()\n",
        "    model_dec.summary()\n",
        "    model_disc.summary()\n",
        "    model_ae.summary()\n",
        "    model_enc_disc.summary()\n",
        "\n",
        "    model_disc.compile(optimizer=Adam(lr=1e-4), loss=\"binary_crossentropy\")\n",
        "    model_enc_disc.compile(optimizer=Adam(lr=1e-4), loss=\"binary_crossentropy\")\n",
        "    model_ae.compile(optimizer=Adam(lr=1e-4, decay=1e-5, epsilon=1e-6), loss=\"mse\")\n",
        "    \n",
        "    return model_enc, model_dec, model_disc, model_ae, model_enc_disc\n",
        "\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6GvNOR9piRHx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "def reconstruct_batch(model, sequences, epoch, folder_name):\n",
        "\n",
        "    sz = sequences.shape[0]\n",
        "    #InX = Input(shape=sequences.shape[1:]) \n",
        "    #tmpModel = Model(inputs=InX, outputs=model.get_layer(\"convTD5\").output)\n",
        "    reconstructed_sequences = model.predict(sequences,batch_size=conf.BATCH_SIZE)\n",
        "\n",
        "    path = join(conf.run_data,folder_name, str(epoch)+\"_epoch\")\n",
        "    os.makedirs(path, exist_ok=True)\n",
        "    for i in range(0, sz):\n",
        "        #cv2_imshow(np.reshape(reconstructed_sequences[i][2],(256, 256))*256)\n",
        "        if i < 10:\n",
        "            img_num = \"00\"+str(i)\n",
        "        elif i < 100:\n",
        "            img_num = \"0\"+str(i)\n",
        "        else:\n",
        "            img_num = str(i)\n",
        "        print(\"Reconstructing : \"+ str(reconstructed_sequences.shape))\n",
        "        cv2.imwrite(join(path,\"gen_\"+img_num+\".jpg\"), convert_images_back(reconstructed_sequences[i][6]))\n",
        "        \n",
        "def settrainable(model, toset):\n",
        "    for layer in model.layers:\n",
        "        layer.trainable = toset\n",
        "    model.trainable = toset\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def evaluate_gen(sequences, model, test_case_dir, epoch=conf.EPOCHS):\n",
        "\n",
        "    reconstructed_sequences = model.predict(sequences,batch_size=conf.BATCH_SIZE)\n",
        "    \n",
        "    sz = sequences.shape[0]\n",
        "    \n",
        "    print(\"Test size:\"+str(sz))\n",
        "   \n",
        "    os.makedirs(join(conf.image_dir,test_case_dir,\"epoch_\"+str(epoch)), exist_ok=True)\n",
        "    for i in range(0, sz):\n",
        "        #print(\"sz \"+str(i)+\"\\n\")\n",
        "        #cv2_imshow(np.reshape(reconstructed_sequences[i][2],(256, 256))*256)\n",
        "        if i < 10:\n",
        "            img_num = \"00\"+str(i)\n",
        "        elif i < 100:\n",
        "            img_num = \"0\"+str(i)\n",
        "        else:\n",
        "            img_num = str(i)    \n",
        "        \n",
        "        cv2.imwrite(join(conf.image_dir, test_case_dir, \"epoch_\"+str(epoch),\"gen_\"+img_num+\".jpg\"), convert_images_back(reconstructed_sequences[i][6]))\n",
        "\n",
        "\n",
        "def evaluate_dis(sequences, model):\n",
        "    sr = model.predict(sequences,batch_size=conf.BATCH_SIZE)\n",
        "\n",
        "    plt.plot(sr)\n",
        "    plt.ylabel('regularity score Sr(t)')\n",
        "    plt.xlabel('frame t')\n",
        "    plt.show()\n",
        "\n",
        "def plot_history(d1_hist, d2_hist, d3_hist, image_name):\n",
        "\t# plot history\n",
        "\tplt.plot(d1_hist, label='ae_loss')\n",
        "\tplt.plot(d2_hist, label='disc_loss')\n",
        "\tplt.plot(d3_hist, label='enc_disc_loss')\n",
        "\tplt.legend()\n",
        "\tplt.savefig(image_name)\n",
        "\tplt.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8GzbHa0avadq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import csv\n",
        "\n",
        "\n",
        "test_cases_dir = \"Test008\"\n",
        "test_cases = get_test_sequences(test_cases_dir, 200)\n",
        "print(\"Test data set loaded\")\n",
        "conf.reconfig(new_name=\"Conv2DLSTM_AAE_1\", batch_size=4, epochs=100, retrain=1, curr_epoch=54)\n",
        "x_train = get_clips_list(conf.dim1)\n",
        "\n",
        "print(\"Train data set loaded\")\n",
        "\n",
        "\n",
        "model_enc, model_dec, model_disc, model_ae, model_enc_disc = build_model_aae(enc_path=conf.GEN_MODEL_PATH+str(\"ep\"+str(conf.curr_epoch+1)), dec_path=conf.DEC_MODEL_PATH+str(\"ep\"+str(conf.curr_epoch+1)), disc_path=conf.DIS_MODEL_PATH+str(\"ep\"+str(conf.curr_epoch+1)))\n",
        "\n",
        "\n",
        "batchsize = conf.BATCH_SIZE\n",
        "\n",
        "\n",
        "for epochnumber in range(conf.curr_epoch, conf.EPOCHS):\n",
        "    print(\"Epoch \"+str(epochnumber+1))\n",
        "    d1_hist, d2_hist, d3_hist = list(), list(), list()\n",
        "    with open(join(conf.run_data, 'loss_val.csv'), mode='a') as csv_file:\n",
        "        fieldnames = ['epoch_num', 'batch_num', 'ae_loss', 'disc_loss', 'enc_disc_loss']\n",
        "        writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
        "        writer.writeheader()\n",
        "        for i in range(int(len(x_train) / batchsize)):\n",
        "    \n",
        "            settrainable(model_ae, True)\n",
        "            settrainable(model_enc, True)\n",
        "            settrainable(model_dec, True)\n",
        "        \n",
        "            batch = x_train[i*batchsize:i*batchsize+batchsize]\n",
        "            ae_loss = model_ae.train_on_batch(batch, batch)\n",
        "            \n",
        "            \n",
        "            settrainable(model_disc, True)\n",
        "            batchpred = model_enc.predict(batch)\n",
        "            fakepred = np.random.standard_normal((batchsize, conf.latent_dim))\n",
        "            discbatch_x = np.concatenate([batchpred, fakepred])\n",
        "            discbatch_y = np.concatenate([np.zeros(batchsize), np.ones(batchsize)])\n",
        "            disc_loss = model_disc.train_on_batch(discbatch_x, discbatch_y)\n",
        "        \n",
        "            settrainable(model_enc_disc, True)\n",
        "            settrainable(model_enc, True)\n",
        "            settrainable(model_disc, False)\n",
        "            enc_disc_loss = model_enc_disc.train_on_batch(batch, np.ones(batchsize))\n",
        "            #print(\"ae_loss:\"+str(ae_loss)+\", disc_loss:\"+str(disc_loss)+\", enc_disc_loss:\"+str(enc_disc_loss))\n",
        "            d1_hist.append(ae_loss)\n",
        "            d2_hist.append(disc_loss)\n",
        "            d3_hist.append(enc_disc_loss)\n",
        "\n",
        "            writer.writerow({'epoch_num': epochnumber, 'batch_num': i, 'ae_loss': ae_loss, 'disc_loss': disc_loss, 'enc_disc_loss': enc_disc_loss})\n",
        "        csv_file.close()\n",
        "    plot_history(d1_hist, d2_hist, d3_hist, join(conf.run_data,\"plot_ep_\"+str(epochnumber+1)))\n",
        "    model_enc.save(conf.GEN_MODEL_PATH+str(\"ep\"+str(epochnumber+1)))\n",
        "    model_dec.save(conf.DEC_MODEL_PATH+str(\"ep\"+str(epochnumber+1)))\n",
        "    model_disc.save(conf.DIS_MODEL_PATH+str(\"ep\"+str(epochnumber+1)))\n",
        "    evaluate_gen(test_cases, model_ae, test_cases_dir, epochnumber+1)\n",
        "    evaluate_dis(test_cases, model_enc_disc)\n",
        "    print (\"Reconstruction Loss:\", model_ae.evaluate(x_train, x_train, verbose=0, batch_size=conf.BATCH_SIZE))\n",
        "    print (\"Adverserial Loss:\", model_enc_disc.evaluate(x_train, np.ones(len(x_train)), verbose=0, batch_size=conf.BATCH_SIZE))\n",
        "\n",
        "\n",
        "evaluate_gen(test_cases, model_ae, test_cases_dir)\n",
        "\n",
        "evaluate_dis(test_cases, model_enc_disc)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZ5GD6ShnpFg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}