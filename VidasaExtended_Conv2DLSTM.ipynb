{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VidasaExtended-Conv3DLSTM",
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNNinNqwMPs9b4I8OeijEz7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dmbk/Anomaly-Detection-System/blob/master/VidasaExtended_Conv2DLSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1mPo2Rl7x8K",
        "colab_type": "code",
        "outputId": "17f872cf-dd64-4514-df9b-378807174c31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "#!pip install keras-layer-normalization\n",
        "!pip install imageio"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: imageio in /usr/local/lib/python3.6/dist-packages (2.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from imageio) (1.17.5)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from imageio) (6.2.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0UHZdNKz8KOS",
        "colab_type": "code",
        "outputId": "edfca69c-5ca0-490f-dae4-3994ee935b53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nge9O3wR8VVZ",
        "colab_type": "code",
        "outputId": "ef8e4e03-fb4d-4e79-d97f-bfdb74fa98d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "import tensorflow as tf\n",
        "import glob\n",
        "import imageio\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "from PIL import Image\n",
        "from tensorflow.keras import layers\n",
        "import time\n",
        "\n",
        "from IPython import display\n",
        "\n",
        "from os.path import join\n",
        "from os import listdir\n",
        "from os.path import isfile, join, isdir\n",
        "\n",
        "#import keras\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.layers import Conv2DTranspose, Conv3DTranspose, ConvLSTM2D, BatchNormalization, LayerNormalization, TimeDistributed, Conv2D, Conv3D, MaxPool3D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import argparse\n",
        "from os.path import dirname\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "\n",
        "tf.keras.backend.set_floatx('float32')\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RdLkLR3r8d1K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Config:\n",
        "    def __init__(self, data_dir):\n",
        "        self.DATASET_PATH = join(data_dir,\"UCSDped1/Train\")\n",
        "        self.TEST_DIR = join(data_dir,\"UCSDped1/Test/\")\n",
        "        self.BATCH_SIZE = 4\n",
        "        self.EPOCHS = 3\n",
        "        self.MODEL_PATH = join(data_dir,\"model_conv3d_lstm.hdf5\")\n",
        "        self.dim1 = 10\n",
        "        self.dim2 = 16\n",
        "        self.dim3 = 256\n",
        "        self.dim4 = 256\n",
        "        self.dim5 = 1\n",
        "\n",
        "conf = Config(data_dir=\"/content/drive/My Drive/UCSD_Anomaly_Dataset.v1p2/\") \n",
        "physical_devices = tf.config.list_physical_devices('GPU') \n",
        "try: \n",
        "  tf.config.experimental.set_memory_growth(physical_devices[0], True) \n",
        "except: \n",
        "  # Invalid device or cannot modify virtual devices once initialized. \n",
        "  pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vncIs43R8uYV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 885
        },
        "outputId": "ab448c82-0841-4328-cca3-3ae00f089fad"
      },
      "source": [
        "def get_model(reload_model=True):\n",
        "    \"\"\"\n",
        "        input dims = (10,16,256,256,1)\n",
        "    \"\"\"\n",
        "    if reload_model == True and os.path.isfile(conf.MODEL_PATH):\n",
        "        model=load_model(conf.MODEL_PATH,custom_objects={'LayerNormalization': LayerNormalization})\n",
        "        return model, True\n",
        "    print(\"Loading model\")\n",
        "    seq = Sequential()\n",
        "    seq.add(TimeDistributed(Conv3D(64, (3, 11, 11), strides=(2,4,4), padding=\"same\"), batch_input_shape=(None, conf.dim1, conf.dim2, conf.dim3, conf.dim4, conf.dim5)))\n",
        "    seq.add(LayerNormalization())\n",
        "    seq.add(TimeDistributed(Conv3D(64, (3, 5, 5), strides=(1,2,2), padding=\"same\")))\n",
        "    seq.add(LayerNormalization())\n",
        "    seq.add(TimeDistributed(Conv3D(32, (3, 3, 3), strides=(1,2,2), padding=\"same\")))\n",
        "    seq.add(LayerNormalization())\n",
        "    # # # # #\n",
        "    seq.add(TimeDistributed(ConvLSTM2D(64, (3, 3), padding=\"same\", return_sequences=True)))\n",
        "    seq.add(LayerNormalization())\n",
        "    seq.add(TimeDistributed(ConvLSTM2D(32, (3, 3), padding=\"same\", return_sequences=True)))\n",
        "    seq.add(LayerNormalization())\n",
        "    seq.add(TimeDistributed(ConvLSTM2D(64, (3, 3), padding=\"same\", return_sequences=True)))\n",
        "    seq.add(LayerNormalization())\n",
        "    # # # # #\n",
        "    seq.add(TimeDistributed(Conv3DTranspose(32, (3, 3, 3), strides=(1,2,2), padding=\"same\")))\n",
        "    seq.add(LayerNormalization())\n",
        "    seq.add(TimeDistributed(Conv3DTranspose(64, (3, 5, 5), strides=(1,2,2), padding=\"same\")))\n",
        "    seq.add(LayerNormalization())\n",
        "    seq.add(TimeDistributed(Conv3DTranspose(64, (3, 11, 11), strides=(2,4,4), padding=\"same\")))\n",
        "    seq.add(LayerNormalization())\n",
        "    seq.add(TimeDistributed(Conv3D(1, (3, 11, 11), activation=\"sigmoid\", padding=\"same\")))\n",
        "    print(seq.summary(line_length=150))\n",
        "    return seq, False\n",
        "\n",
        "def train_v1():\n",
        "    seq, loaded = get_model()\n",
        "    if loaded == True:\n",
        "        return seq\n",
        "\n",
        "    training_set = np.array(get_training_set(conf.dim1))\n",
        "    #np_data.shape()\n",
        "\n",
        "    #dataset = tf.data.Dataset.from_tensor_slices(np_data).batch(conf.BATCH_SIZE)\n",
        "\n",
        "    seq.compile(loss='mse', optimizer=tf.optimizers.Adam(lr=1e-4, decay=1e-5, epsilon=1e-6))\n",
        "    !mkdir training_1\n",
        "    checkpoint_path = \"training_1/cp.ckpt\"\n",
        "    checkpoint_dir = dirname(checkpoint_path)\n",
        "\n",
        "    # Create a callback that saves the model's weights\n",
        "    cp_callback = ModelCheckpoint(filepath=checkpoint_path,save_weights_only=True,verbose=1)\n",
        "\n",
        "    seq.fit(training_set, training_set,\n",
        "            batch_size=conf.BATCH_SIZE, epochs=conf.EPOCHS, shuffle=False, callbacks=[cp_callback], )\n",
        "    seq.save(conf.MODEL_PATH,save_format='h5')\n",
        "    return seq\n",
        "\n",
        "\n",
        "def get_loss(true_clips, pred_clips):\n",
        "    return tf.keras.losses.MSE(y_true=true_clips, y_pred=pred_clips)\n",
        "\n",
        "def get_optimizer():\n",
        "    return tf.optimizers.Adam(1e-4, decay=1e-5, epsilon=1e-6)\n",
        "\n",
        "@tf.function\n",
        "def train_step(clips, model, optimizer):    \n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "        reconstructed_clips = model(clips, training=True)\n",
        "        reconstruction_loss = get_loss(reconstructed_clips, clips)\n",
        "\n",
        "    gradients_of_model = gen_tape.gradient(reconstruction_loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients_of_model, model.trainable_variables))\n",
        "   \n",
        "def train():\n",
        "    model, loaded = get_model()\n",
        "    if loaded == True:\n",
        "        return model\n",
        "    np_data = np.array(get_training_set(conf.dim1))\n",
        "    #np_data.shape()\n",
        "\n",
        "    dataset = tf.data.Dataset.from_tensor_slices(np_data).batch(conf.BATCH_SIZE)\n",
        "    optimizer = get_optimizer()\n",
        "    for epoch in range(conf.EPOCHS):\n",
        "        start = time.time()\n",
        "    \n",
        "        for clips_batch in dataset:\n",
        "            train_step(clips_batch, model, optimizer)\n",
        "\n",
        "        display.clear_output(wait=True)\n",
        "\n",
        "        print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
        "\n",
        "    model.save(conf.MODEL_PATH,save_format='h5')\n",
        "  \n",
        "    display.clear_output(wait=True)\n",
        "\n",
        "\n",
        "get_model()\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading model\n",
            "Model: \"sequential\"\n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "Layer (type)                                                       Output Shape                                                Param #                \n",
            "======================================================================================================================================================\n",
            "time_distributed (TimeDistributed)                                 (None, 10, 8, 64, 64, 64)                                   23296                  \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "layer_normalization (LayerNormalization)                           (None, 10, 8, 64, 64, 64)                                   128                    \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "time_distributed_1 (TimeDistributed)                               (None, 10, 8, 32, 32, 64)                                   307264                 \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "layer_normalization_1 (LayerNormalization)                         (None, 10, 8, 32, 32, 64)                                   128                    \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "time_distributed_2 (TimeDistributed)                               (None, 10, 8, 16, 16, 32)                                   55328                  \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "layer_normalization_2 (LayerNormalization)                         (None, 10, 8, 16, 16, 32)                                   64                     \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "time_distributed_3 (TimeDistributed)                               (None, 10, 8, 16, 16, 64)                                   221440                 \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "layer_normalization_3 (LayerNormalization)                         (None, 10, 8, 16, 16, 64)                                   128                    \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "time_distributed_4 (TimeDistributed)                               (None, 10, 8, 16, 16, 32)                                   110720                 \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "layer_normalization_4 (LayerNormalization)                         (None, 10, 8, 16, 16, 32)                                   64                     \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "time_distributed_5 (TimeDistributed)                               (None, 10, 8, 16, 16, 64)                                   221440                 \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "layer_normalization_5 (LayerNormalization)                         (None, 10, 8, 16, 16, 64)                                   128                    \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "time_distributed_6 (TimeDistributed)                               (None, 10, 8, 32, 32, 32)                                   55328                  \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "layer_normalization_6 (LayerNormalization)                         (None, 10, 8, 32, 32, 32)                                   64                     \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "time_distributed_7 (TimeDistributed)                               (None, 10, 8, 64, 64, 64)                                   153664                 \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "layer_normalization_7 (LayerNormalization)                         (None, 10, 8, 64, 64, 64)                                   128                    \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "time_distributed_8 (TimeDistributed)                               (None, 10, 16, 256, 256, 64)                                1486912                \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "layer_normalization_8 (LayerNormalization)                         (None, 10, 16, 256, 256, 64)                                128                    \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "time_distributed_9 (TimeDistributed)                               (None, 10, 16, 256, 256, 1)                                 23233                  \n",
            "======================================================================================================================================================\n",
            "Total params: 2,659,585\n",
            "Trainable params: 2,659,585\n",
            "Non-trainable params: 0\n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tensorflow.python.keras.engine.sequential.Sequential at 0x7f97a84b99e8>,\n",
              " False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQG-jIK2UibT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_clips_by_stride(stride, frames_list, sequence_size):\n",
        "    \"\"\" For data augmenting purposes.\n",
        "    Parameters\n",
        "    ----------\n",
        "    stride : int\n",
        "        The distance between two consecutive frames\n",
        "    frames_list : list\n",
        "        A list of sorted frames of shape 256 X 256\n",
        "    sequence_size: int\n",
        "        The size of the lstm sequence\n",
        "    Returns\n",
        "    -------\n",
        "    list\n",
        "        A list of clips , 32 frames each\n",
        "    \"\"\"\n",
        "    clips = []\n",
        "    sz = len(frames_list)\n",
        "    clip = np.zeros(shape=(sequence_size, 256, 256, 1))\n",
        "    cnt = 0\n",
        "    for start in range(0, stride):\n",
        "        for i in range(start, sz, stride):\n",
        "            clip[cnt, :, :, 0] = frames_list[i]\n",
        "            cnt = cnt + 1\n",
        "            if cnt == sequence_size:\n",
        "                clips.append(clip)\n",
        "                cnt = 0\n",
        "    return clips\n",
        "\n",
        "def get_clips_list(seq_size):\n",
        "    \"\"\"\n",
        "    seq_size :int \n",
        "        The sequence size of individual clip\n",
        "    Returns\n",
        "    -------\n",
        "    list\n",
        "        A list of training sequences of shape (NUMBER_OF_SEQUENCES,SINGLE_SEQUENCE_SIZE,FRAME_WIDTH,FRAME_HEIGHT,1)\n",
        "    \"\"\"\n",
        "    clips = []\n",
        "    # loop over the training folders (Train000,Train001,..)\n",
        "    for f in sorted(listdir(conf.DATASET_PATH)):\n",
        "        directory_path = join(conf.DATASET_PATH, f)\n",
        "        if isdir(directory_path):\n",
        "            all_frames = []\n",
        "            # loop over all the images in the folder (0.tif,1.tif,..,199.tif)\n",
        "            for c in sorted(listdir(directory_path)):\n",
        "                img_path = join(directory_path, c)\n",
        "                if str(img_path)[-3:] == \"tif\":\n",
        "                    img = Image.open(img_path).resize((256, 256))\n",
        "\n",
        "                    img = np.array(img, dtype=np.float32) / 256.0\n",
        "                    all_frames.append(img)\n",
        "            # get the 32-frames sequences from the list of images after applying data augmentation\n",
        "            for stride in range(1, 3):\n",
        "                clips.extend(get_clips_by_stride(stride=stride, frames_list=all_frames, sequence_size=seq_size))\n",
        "    return clips\n",
        "\n",
        "def get_training_set(clip_seq_size):\n",
        "    \"\"\"\n",
        "    clip_seq_size : int\n",
        "        size of a single clips group\n",
        "    Returns\n",
        "    -------\n",
        "    list\n",
        "        creates list of lists of frames \n",
        "    \"\"\"\n",
        "    #print(\"test0\")\n",
        "    clips_array = []\n",
        "    clips = get_clips_list(conf.dim2)\n",
        "    #print(clips[0])\n",
        "    tmp_clip = []\n",
        "    count = 0\n",
        "    for clip in clips:\n",
        "        tmp_clip.append(clip)\n",
        "        count = count +1\n",
        "        if count == clip_seq_size:\n",
        "            clips_array.append(tmp_clip)\n",
        "            tmp_clip = []\n",
        "            count = 0\n",
        "    return clips_array"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U9GgGhfGy6Z2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_single_test(single_test_path):\n",
        "    sz = 200\n",
        "    test = np.zeros(shape=(sz, conf.dim3, conf.dim4, conf.dim5))\n",
        "    cnt = 0\n",
        "    for f in sorted(listdir(single_test_path)):\n",
        "        if str(join(single_test_path, f))[-3:] == \"tif\":\n",
        "            img = Image.open(join(single_test_path, f)).resize((conf.dim3, conf.dim4))\n",
        "            #cv2_imshow(np.array(img,dtype=np.float32))\n",
        "            #cv2.waitKey(0)\n",
        "            img = np.array(img, dtype=np.float32) / 256\n",
        "            test[cnt, :, :, 0] = img\n",
        "            cnt = cnt + 1\n",
        "    return test\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cpy3WPYmykgv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(test_case_dir, model):\n",
        "\n",
        "    test = get_single_test(join(conf.TEST_DIR,test_case_dir))\n",
        "    print(\"Test case loaded\")\n",
        "    sz = test.shape[0] - conf.dim2\n",
        "    sequences = np.zeros((sz, conf.dim2, conf.dim3, conf.dim4, conf.dim5))\n",
        "    # apply the sliding window technique to get the sequences\n",
        "    for i in range(0, sz):\n",
        "        clip = np.zeros((conf.dim2, conf.dim3, conf.dim4, conf.dim5))\n",
        "        for j in range(0, conf.dim2):\n",
        "            clip[j] = test[i + j, :, :, :]\n",
        "        sequences[i] = clip\n",
        "\n",
        "    sz_10x = sequences.shape[0] - conf.dim1\n",
        "    sequences_10x = np.zeros((sz_10x, conf.dim1, conf.dim2, conf.dim3, conf.dim4, conf.dim5))\n",
        "    count = 0\n",
        "    for k in range(0, sz_10x):\n",
        "        clip_10x = np.zeros((conf.dim1, conf.dim2, conf.dim3, conf.dim4, conf.dim5))\n",
        "        for l in range(0, conf.dim1):\n",
        "            clip_10x[l] = sequences[k + l, :, :, :, :] \n",
        "        sequences_10x[k] = clip_10x\n",
        "\n",
        "    # get the reconstruction cost of all the sequences\n",
        "    reconstructed_sequences_10x = model.predict(sequences_10x,batch_size=conf.BATCH_SIZE)\n",
        "\n",
        "    #reconstruction shape = (sz_10x, 10, 16, 256, 256, 1)\n",
        "    sequences_reconstruction_cost = np.array([np.linalg.norm(np.subtract(sequences_10x[i],reconstructed_sequences[i])) for i in range(0,sz_10x)])\n",
        "    sa = (sequences_reconstruction_cost - np.min(sequences_reconstruction_cost)) / np.max(sequences_reconstruction_cost)\n",
        "    sr = 1.0 - sa\n",
        "    print(sr.shape())\n",
        "    \n",
        "    plt.plot(sr)\n",
        "    plt.ylabel('regularity score Sr(t)')\n",
        "    plt.xlabel('frame t')\n",
        "    plt.show()\n",
        "    sr = sigmoid(sr)\n",
        "    # plot the regularity scores\n",
        "    plt.plot(sr)\n",
        "    plt.ylabel('regularity score Sr(t)')\n",
        "    plt.xlabel('frame t')\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bqgGWUrKk30t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "51247b74-fd5a-49aa-8ca6-e435a701dff3"
      },
      "source": [
        "\n",
        "\n",
        "model = train_v1()\n",
        "print(\"Model Loaded\")\n",
        "evaluate(\"Test001\", model)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading model\n",
            "Model: \"sequential_1\"\n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "Layer (type)                                                       Output Shape                                                Param #                \n",
            "======================================================================================================================================================\n",
            "time_distributed_10 (TimeDistributed)                              (None, 10, 8, 64, 64, 64)                                   23296                  \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "layer_normalization_9 (LayerNormalization)                         (None, 10, 8, 64, 64, 64)                                   128                    \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "time_distributed_11 (TimeDistributed)                              (None, 10, 8, 32, 32, 64)                                   307264                 \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "layer_normalization_10 (LayerNormalization)                        (None, 10, 8, 32, 32, 64)                                   128                    \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "time_distributed_12 (TimeDistributed)                              (None, 10, 8, 16, 16, 32)                                   55328                  \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "layer_normalization_11 (LayerNormalization)                        (None, 10, 8, 16, 16, 32)                                   64                     \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "time_distributed_13 (TimeDistributed)                              (None, 10, 8, 16, 16, 64)                                   221440                 \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "layer_normalization_12 (LayerNormalization)                        (None, 10, 8, 16, 16, 64)                                   128                    \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "time_distributed_14 (TimeDistributed)                              (None, 10, 8, 16, 16, 32)                                   110720                 \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "layer_normalization_13 (LayerNormalization)                        (None, 10, 8, 16, 16, 32)                                   64                     \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "time_distributed_15 (TimeDistributed)                              (None, 10, 8, 16, 16, 64)                                   221440                 \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "layer_normalization_14 (LayerNormalization)                        (None, 10, 8, 16, 16, 64)                                   128                    \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "time_distributed_16 (TimeDistributed)                              (None, 10, 8, 32, 32, 32)                                   55328                  \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "layer_normalization_15 (LayerNormalization)                        (None, 10, 8, 32, 32, 32)                                   64                     \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "time_distributed_17 (TimeDistributed)                              (None, 10, 8, 64, 64, 64)                                   153664                 \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "layer_normalization_16 (LayerNormalization)                        (None, 10, 8, 64, 64, 64)                                   128                    \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "time_distributed_18 (TimeDistributed)                              (None, 10, 16, 256, 256, 64)                                1486912                \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "layer_normalization_17 (LayerNormalization)                        (None, 10, 16, 256, 256, 64)                                128                    \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "time_distributed_19 (TimeDistributed)                              (None, 10, 16, 256, 256, 1)                                 23233                  \n",
            "======================================================================================================================================================\n",
            "Total params: 2,659,585\n",
            "Trainable params: 2,659,585\n",
            "Non-trainable params: 0\n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "None\n",
            "mkdir: cannot create directory ‘training_1’: File exists\n",
            "Train on 81 samples\n",
            "Epoch 1/3\n",
            " 4/81 [>.............................] - ETA: 6:08\n",
            "Epoch 00001: saving model to training_1/cp.ckpt\n",
            " 4/81 [>.............................] - ETA: 6:11"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ResourceExhaustedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-4a0841cf0d3a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_v1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Model Loaded\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Test001\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-4946b78e527f>\u001b[0m in \u001b[0;36mtrain_v1\u001b[0;34m()\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     seq.fit(training_set, training_set,\n\u001b[0;32m---> 53\u001b[0;31m             batch_size=conf.BATCH_SIZE, epochs=conf.EPOCHS, shuffle=False, callbacks=[cp_callback], )\n\u001b[0m\u001b[1;32m     54\u001b[0m     \u001b[0mseq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMODEL_PATH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msave_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mseq\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    127\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 98\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    630\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 632\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    633\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m       \u001b[0mcanon_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2361\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2363\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2365\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1611\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     keras_symbolic_tensors = [\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
            "\u001b[0;31mResourceExhaustedError\u001b[0m:  OOM when allocating tensor with shape[40,16,256,256,64] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node sequential_1/time_distributed_18/conv3d_transpose_5/conv3d_transpose (defined at <ipython-input-5-4946b78e527f>:53) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_distributed_function_13672]\n\nFunction call stack:\ndistributed_function\n"
          ]
        }
      ]
    }
  ]
}