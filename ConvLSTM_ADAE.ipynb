{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ConvLSTM_VanillaGAN.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dmbk/Anomaly-Detection-System/blob/master/ConvLSTM_ADAE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZeDOtMkwIqL0",
        "colab_type": "code",
        "outputId": "f29083be-ac12-42be-d5e2-decd8ab279c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        }
      },
      "source": [
        "!pip install imageio\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: imageio in /usr/local/lib/python3.6/dist-packages (2.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from imageio) (1.18.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from imageio) (7.0.0)\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1qK4WayIRWG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "import tensorflow as tf\n",
        "import skimage\n",
        "import glob\n",
        "import imageio\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "from PIL import Image\n",
        "from tensorflow.keras import layers\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "from IPython import display\n",
        "\n",
        "from os.path import join\n",
        "from os import listdir\n",
        "from os.path import isfile, join, isdir\n",
        "\n",
        "#import keras\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.layers import Input, GaussianNoise, Reshape, LeakyReLU, Conv2DTranspose, Conv3DTranspose, ConvLSTM2D, BatchNormalization, LayerNormalization, TimeDistributed, Conv2D, Conv3D, ZeroPadding3D, MaxPooling2D, MaxPooling3D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.models import Sequential, load_model, Model\n",
        "from keras.optimizers import RMSprop\n",
        "import matplotlib.pyplot as plt\n",
        "import argparse\n",
        "from os.path import dirname\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\t\n",
        "from keras import backend\n",
        "from keras.constraints import Constraint\n",
        "tf.keras.backend.set_floatx('float32')\n",
        "import shutil\n",
        "from matplotlib import pyplot"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27gwZwBqIxav",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Config:\n",
        "    def __init__(self, data_dir_, cwdir_name_):\n",
        "        self.data_dir = data_dir_\n",
        "        self.cwdir_name = cwdir_name_\n",
        "        self.cwdir = join(self.data_dir,self.cwdir_name)\n",
        "        self.run_data = join(self.cwdir, \"training_gan\")\n",
        "        if not os.path.exists(self.cwdir):\n",
        "            os.mkdir(self.cwdir)\n",
        "            os.mkdir(self.run_data)\n",
        "    \n",
        "        if os.path.exists(self.run_data):\n",
        "            shutil.rmtree(self.run_data)\n",
        "            os.mkdir(self.run_data)\n",
        "\n",
        "        self.DATASET_PATH = join(self.data_dir,\"UCSD_Anomaly_Dataset.v1p2/UCSDped1/Train/\")\n",
        "        self.TEST_DIR = join(self.data_dir,\"UCSD_Anomaly_Dataset.v1p2/UCSDped1/Test/\")\n",
        "        self.BATCH_SIZE = 4\n",
        "        self.EPOCHS = 5\n",
        "        self.GEN_MODEL_PATH = join(self.cwdir,\"model_gen_Conv2DLSTM_GAN.hdf5\")\n",
        "        self.DIS_MODEL_PATH = join(self.cwdir,\"model_dis_Conv2DLSTM_GAN.hdf5\")\n",
        "        self.GAN_MODEL_PATH = join(self.cwdir,\"model_combined_Conv2DLSTM_GAN.hdf5\")\n",
        "        self.dim1 = 10\n",
        "        self.dim2 = 256\n",
        "        self.dim3 = 256\n",
        "        self.dim4 = 1\n",
        "        self.n_critic = 5\n",
        "        self.r_alpha = 0.2\n",
        "\n",
        "    def reconfig(self, new_name, batch_size = 4, epochs = 5):\n",
        "        self.cwdir_name = new_name\n",
        "        self.cwdir = join(self.data_dir, self.cwdir_name)\n",
        "        self.run_data = join(self.cwdir, \"training_gan\")\n",
        "        if not os.path.exists(self.cwdir):\n",
        "            os.mkdir(self.cwdir)\n",
        "            os.mkdir(self.run_data)\n",
        "    \n",
        "        if os.path.exists(self.run_data):\n",
        "            shutil.rmtree(self.run_data)\n",
        "            os.mkdir(self.run_data)\n",
        "\n",
        "        self.BATCH_SIZE = 4\n",
        "        self.EPOCHS = 5\n",
        "        self.GEN_MODEL_PATH = join(self.cwdir,\"model_gen_Conv2DLSTM_GAN.hdf5\")\n",
        "        self.DIS_MODEL_PATH = join(self.cwdir,\"model_dis_Conv2DLSTM_GAN.hdf5\")\n",
        "        self.GAN_MODEL_PATH = join(self.cwdir,\"model_combined_Conv2DLSTM_GAN.hdf5\")\n",
        "\n",
        "\n",
        "class ModelContainer:\n",
        "    def __init__(self, y0, y1, y2):\n",
        "        self.generator = y0\n",
        "        self.discriminator = y1\n",
        "        self.gan = y2\n",
        " \n",
        "\n",
        "conf = Config(data_dir_=\"/content/drive/My Drive/\", cwdir_name_=\"Conv2DLSTM_VanillaGAN\") \n",
        "physical_devices = tf.config.list_physical_devices('GPU') \n",
        "try: \n",
        "  tf.config.experimental.set_memory_growth(physical_devices[0], True) \n",
        "except: \n",
        "  # Invalid device or cannot modify virtual devices once initialized. \n",
        "  pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5IyRNft5JKae",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_clips_by_stride(stride, frames_list, sequence_size):\n",
        "    \"\"\" For data augmenting purposes.\n",
        "    Parameters\n",
        "    ----------\n",
        "    stride : int\n",
        "        The distance between two consecutive frames\n",
        "    frames_list : list\n",
        "        A list of sorted frames of shape 256 X 256\n",
        "    sequence_size: int\n",
        "        The size of the lstm sequence\n",
        "    Returns\n",
        "    -------\n",
        "    list\n",
        "        A list of clips , 32 frames each\n",
        "    \"\"\"\n",
        "    clips = []\n",
        "    sz = len(frames_list)\n",
        "    clip = np.zeros(shape=(sequence_size, 256, 256, 1))\n",
        "    cnt = 0\n",
        "    for start in range(0, stride):\n",
        "        for i in range(start, sz, stride):\n",
        "            clip[cnt, :, :, 0] = frames_list[i]\n",
        "            cnt = cnt + 1\n",
        "            if cnt == sequence_size:\n",
        "                clips.append(clip)\n",
        "                cnt = 0\n",
        "    return clips\n",
        "\n",
        "def get_clips_list(seq_size):\n",
        "    \"\"\"\n",
        "    seq_size :int \n",
        "        The sequence size of individual clip\n",
        "    Returns\n",
        "    -------\n",
        "    list\n",
        "        A list of training sequences of shape (NUMBER_OF_SEQUENCES,SINGLE_SEQUENCE_SIZE,FRAME_WIDTH,FRAME_HEIGHT,1)\n",
        "    \"\"\"\n",
        "    clips = []\n",
        "    # loop over the training folders (Train000,Train001,..)\n",
        "    for f in sorted(listdir(conf.DATASET_PATH)):\n",
        "        directory_path = join(conf.DATASET_PATH, f)\n",
        "        if isdir(directory_path):\n",
        "            all_frames = []\n",
        "            # loop over all the images in the folder (0.tif,1.tif,..,199.tif)\n",
        "            for c in sorted(listdir(directory_path)):\n",
        "                img_path = join(directory_path, c)\n",
        "                if str(img_path)[-3:] == \"tif\":\n",
        "                    img = Image.open(img_path).resize((256, 256))\n",
        "\n",
        "                    img = np.array(img, dtype=np.float32) / 256.0\n",
        "                    all_frames.append(img)\n",
        "            # get the 32-frames sequences from the list of images after applying data augmentation\n",
        "            for stride in range(1, 3):\n",
        "                clips.extend(get_clips_by_stride(stride=stride, frames_list=all_frames, sequence_size=seq_size))\n",
        "    return clips\n",
        "\n",
        "\n",
        "def get_single_test(single_test_path, sz):\n",
        "    test = np.zeros(shape=(sz, conf.dim2, conf.dim3, conf.dim4))\n",
        "    cnt = 0\n",
        "    for f in sorted(listdir(single_test_path)):\n",
        "        if str(join(single_test_path, f))[-3:] == \"tif\":\n",
        "            img = Image.open(join(single_test_path, f)).resize((conf.dim2, conf.dim3))\n",
        "            #cv2_imshow(np.array(img,dtype=np.float32))\n",
        "            #cv2.waitKey(0)\n",
        "            img = np.array(img, dtype=np.float32) / 256\n",
        "            test[cnt, :, :, 0] = img\n",
        "            cnt = cnt + 1\n",
        "    return test\n",
        "\n",
        "def evaluate(test_case_dir, model, sz, gen_only):\n",
        "\n",
        "    test = get_single_test(join(conf.TEST_DIR,test_case_dir), sz)\n",
        "    print(\"Test case loaded\")\n",
        "    sz = test.shape[0] - conf.dim1\n",
        "    sequences = np.zeros((sz, conf.dim1, conf.dim2, conf.dim3, conf.dim4))\n",
        "    # apply the sliding window technique to get the sequences\n",
        "    for i in range(0, sz):\n",
        "        clip = np.zeros((conf.dim1, conf.dim2, conf.dim3, conf.dim4))\n",
        "        for j in range(0, conf.dim1):\n",
        "            clip[j] = test[i + j, :, :, :]\n",
        "        sequences[i] = clip\n",
        "\n",
        "    # get the reconstruction cost of all the sequences\n",
        "    reconstructed_sequences, reconstructed_sequences_2 = model.predict(sequences,batch_size=conf.BATCH_SIZE)\n",
        "    \n",
        "    if gen_only == 1:\n",
        "\n",
        "        for i in range(0, sz):\n",
        "            cv2_imshow(np.reshape(reconstructed_sequences[i][0],(256, 256))*256)\n",
        "            cv2.waitKey()\n",
        "            cv2_imshow(np.reshape(reconstructed_sequences_2[i][0],(256, 256))*256)\n",
        "            cv2.waitKey()\n",
        "\n",
        "        #reconstruction_shape = (sz,10, 256, 256, 1)\n",
        "    sequences_reconstruction_cost = np.array([np.linalg.norm(np.subtract(sequences[i],reconstructed_sequences[i])) for i in range(0,sz)])\n",
        "    sa = (sequences_reconstruction_cost - np.min(sequences_reconstruction_cost)) / np.max(sequences_reconstruction_cost)\n",
        "    sr = 1.0 - sa\n",
        "\n",
        "    #print(sr.shape())\n",
        "\n",
        "    plt.plot(sr)\n",
        "    plt.ylabel('regularity score Sr(t)')\n",
        "    plt.xlabel('frame t')\n",
        "    plt.show()\n",
        "\n",
        "    sequences_reconstruction_cost_2 = np.array([np.linalg.norm(np.subtract(sequences[i],reconstructed_sequences_2[i])) for i in range(0,sz)])\n",
        "    sa_2 = (sequences_reconstruction_cost_2 - np.min(sequences_reconstruction_cost_2)) / np.max(sequences_reconstruction_cost_2)\n",
        "    sr_2 = 1.0 - sa_2\n",
        "    \n",
        "    #print(sr.shape())\n",
        "\n",
        "    plt.plot(sr_2)\n",
        "    plt.ylabel('regularity score Sr(t)')\n",
        "    plt.xlabel('frame t')\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QCP4CpApLacO",
        "colab_type": "code",
        "outputId": "cc21ca1c-f63b-4850-ebbf-f19868f3050e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "def get_generator():\n",
        "    #if reload_model == True and os.path.isfile(conf.GEN_MODEL_PATH):\n",
        "    #    model=load_model(conf.GEN_MODEL_PATH,custom_objects={'LayerNormalization': LayerNormalization})\n",
        "    #    return model, True\n",
        "\n",
        "    init = tf.keras.initializers.RandomNormal(stddev=0.02)\n",
        "    \n",
        "    print(\"Loading generator model\")\n",
        "    model = Sequential()\n",
        "    #model.add(TimeDistributed(Conv2D(128, (11, 11), strides=4, activation=\"relu\", kernel_initializer=init, padding=\"same\"), batch_input_shape=(None, conf.dim1, conf.dim2, conf.dim3, conf.dim4)))   \n",
        "    model.add(TimeDistributed(Conv2D(128, (11, 11), strides=4, activation=\"relu\", kernel_initializer=init, padding=\"same\"), batch_input_shape=(None, conf.dim1, conf.dim2, conf.dim3, conf.dim4)))\n",
        "    model.add(LayerNormalization())\n",
        "    model.add(TimeDistributed(Conv2D(64, (5, 5), strides=2, activation=\"relu\", kernel_initializer=init, padding=\"same\")))\n",
        "    model.add(LayerNormalization())\n",
        "\n",
        "    # # # # #\n",
        "    model.add(ConvLSTM2D(64, (3, 3), kernel_initializer=init, padding=\"same\", return_sequences=True))\n",
        "    model.add(LayerNormalization())\n",
        "    model.add(ConvLSTM2D(32, (3, 3), kernel_initializer=init, padding=\"same\", return_sequences=True))\n",
        "    model.add(LayerNormalization())\n",
        "    model.add(ConvLSTM2D(64, (3, 3), kernel_initializer=init, padding=\"same\", return_sequences=True))\n",
        "    model.add(LayerNormalization())\n",
        "    # # # # #\n",
        "\n",
        "    model.add(TimeDistributed(Conv2DTranspose(64, (5, 5), strides=2, activation=\"relu\", kernel_initializer=init, padding=\"same\")))\n",
        "    model.add(LayerNormalization())\n",
        "    model.add(TimeDistributed(Conv2DTranspose(128, (11, 11), strides=4, activation=\"relu\", kernel_initializer=init, padding=\"same\")))\n",
        "    model.add(LayerNormalization())\n",
        "    model.add(TimeDistributed(Conv2D(1, (11, 11), activation=\"tanh\", kernel_initializer=init,  padding=\"same\")))\n",
        "\n",
        "    model.summary(line_length=150)\n",
        "    return model\n",
        "\n",
        "\n",
        "def get_discriminator():\n",
        "\n",
        "    init = tf.keras.initializers.RandomNormal(stddev=0.02)\n",
        "\n",
        "    model = Sequential()\n",
        "\n",
        "    #model.add(GaussianNoise(0.1, input_shape=(conf.dim1, conf.dim2, conf.dim3, conf.dim4)))\n",
        "    model.add(TimeDistributed(Conv2D(16, kernel_size = 5, strides=2,activation=tf.keras.layers.LeakyReLU(alpha=0.1),name=\"conv1\", \n",
        "                    kernel_initializer=init, padding=\"valid\"), batch_input_shape=(None, conf.dim1, conf.dim2, conf.dim3, conf.dim4)))  \n",
        "    model.add(LayerNormalization())\n",
        "\n",
        "    model.add(TimeDistributed(Conv2D(32, kernel_size = 5, strides=2, activation=tf.keras.layers.LeakyReLU(alpha=0.1),name=\"conv2\", \n",
        "                    kernel_initializer=init, padding=\"valid\")))\n",
        "    model.add(LayerNormalization())\n",
        "   \n",
        "    model.add(TimeDistributed(Conv2D(64, kernel_size = 5, strides=2, activation=tf.keras.layers.LeakyReLU(alpha=0.1),name=\"conv3\", \n",
        "                    kernel_initializer=init, padding=\"valid\"))) \n",
        "    \n",
        "    model.add(LayerNormalization())\n",
        "    model.add(Flatten())\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "   \n",
        "    model.summary(line_length=150)\n",
        "    return model\n",
        "\n",
        "\n",
        "def build_model(model, image_dims):\n",
        "    input_img = Input(shape=image_dims)\n",
        "    output = model(input_img)\n",
        "    return Model(input_img,output)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#https://medium.com/analytics-vidhya/implementing-a-gan-in-keras-d6c36bc6ab5f   \n",
        "#https://www.dlology.com/blog/how-to-do-novelty-detection-in-keras-with-generative-adversarial-network/\n",
        "#https://arxiv.org/pdf/1802.09088.pdf\n",
        "get_generator()\n",
        "get_discriminator()"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading generator model\n",
            "Model: \"sequential_26\"\n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "Layer (type)                                                       Output Shape                                                Param #                \n",
            "======================================================================================================================================================\n",
            "time_distributed_94 (TimeDistributed)                              (None, 10, 64, 64, 128)                                     15616                  \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "layer_normalization_119 (LayerNormalization)                       (None, 10, 64, 64, 128)                                     256                    \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "time_distributed_95 (TimeDistributed)                              (None, 10, 32, 32, 64)                                      204864                 \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "layer_normalization_120 (LayerNormalization)                       (None, 10, 32, 32, 64)                                      128                    \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "conv_lst_m2d_42 (ConvLSTM2D)                                       (None, 10, 32, 32, 64)                                      295168                 \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "layer_normalization_121 (LayerNormalization)                       (None, 10, 32, 32, 64)                                      128                    \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "conv_lst_m2d_43 (ConvLSTM2D)                                       (None, 10, 32, 32, 32)                                      110720                 \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "layer_normalization_122 (LayerNormalization)                       (None, 10, 32, 32, 32)                                      64                     \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "conv_lst_m2d_44 (ConvLSTM2D)                                       (None, 10, 32, 32, 64)                                      221440                 \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "layer_normalization_123 (LayerNormalization)                       (None, 10, 32, 32, 64)                                      128                    \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "time_distributed_96 (TimeDistributed)                              (None, 10, 64, 64, 64)                                      102464                 \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "layer_normalization_124 (LayerNormalization)                       (None, 10, 64, 64, 64)                                      128                    \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "time_distributed_97 (TimeDistributed)                              (None, 10, 256, 256, 128)                                   991360                 \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "layer_normalization_125 (LayerNormalization)                       (None, 10, 256, 256, 128)                                   256                    \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "time_distributed_98 (TimeDistributed)                              (None, 10, 256, 256, 1)                                     15489                  \n",
            "======================================================================================================================================================\n",
            "Total params: 1,958,209\n",
            "Trainable params: 1,958,209\n",
            "Non-trainable params: 0\n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "Model: \"sequential_27\"\n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "Layer (type)                                                       Output Shape                                                Param #                \n",
            "======================================================================================================================================================\n",
            "time_distributed_99 (TimeDistributed)                              (None, 10, 126, 126, 16)                                    416                    \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "layer_normalization_126 (LayerNormalization)                       (None, 10, 126, 126, 16)                                    32                     \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "time_distributed_100 (TimeDistributed)                             (None, 10, 61, 61, 32)                                      12832                  \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "layer_normalization_127 (LayerNormalization)                       (None, 10, 61, 61, 32)                                      64                     \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "time_distributed_101 (TimeDistributed)                             (None, 10, 29, 29, 64)                                      51264                  \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "layer_normalization_128 (LayerNormalization)                       (None, 10, 29, 29, 64)                                      128                    \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "flatten_7 (Flatten)                                                (None, 538240)                                              0                      \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "dropout_7 (Dropout)                                                (None, 538240)                                              0                      \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "dense_7 (Dense)                                                    (None, 1)                                                   538241                 \n",
            "======================================================================================================================================================\n",
            "Total params: 602,977\n",
            "Trainable params: 602,977\n",
            "Non-trainable params: 0\n",
            "______________________________________________________________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.engine.sequential.Sequential at 0x7f0eb2fa6cc0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1H9pUAm46jls",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create a line plot of loss for the gan and save to file\n",
        "def plot_history(d1_hist, d2_hist, g_hist, image_name):\n",
        "\t# plot history\n",
        "\tpyplot.plot(d1_hist, label='disc_real')\n",
        "\tpyplot.plot(d2_hist, label='disc_fake')\n",
        "\tpyplot.plot(g_hist, label='gen')\n",
        "\tpyplot.legend()\n",
        "\tpyplot.savefig(image_name)\n",
        "\tpyplot.close()\n",
        " \n",
        "\n",
        "def compile_gan(generator, discriminator):\n",
        "    image_dims = [conf.dim1, conf.dim2, conf.dim3, conf.dim4]\n",
        "    optimizer = tf.keras.optimizers.Adam(lr=1e-4, decay=1e-5, epsilon=1e-6)\n",
        "    built_dis = build_model(discriminator, image_dims)\n",
        "    built_dis.compile(optimizer=optimizer, loss='mse')\n",
        "\n",
        "    built_gen = build_model(generator, image_dims)\n",
        "    img = Input(shape=image_dims, dtype=tf.dtypes.float32)\n",
        "    #gn_layer = GaussianNoise(0.1)(img)\n",
        "    \n",
        "    reconstructed_img = built_gen(img)\n",
        "    \n",
        "    built_dis.trainable = False\n",
        "    validity = built_dis(reconstructed_img)\n",
        "\n",
        "    gan_model = Model(img, [reconstructed_img, validity])\n",
        "    gan_model.compile(loss=['mse', 'mse'],\n",
        "    loss_weights=[1, 1],\n",
        "    optimizer=optimizer)\n",
        "\n",
        "    return ModelContainer(built_gen, built_dis, gan_model)\n",
        "\n",
        "def add_noise(batch_clips):\n",
        "\n",
        "    clips = []\n",
        "    for clip in batch_clips:\n",
        "        lst_noisy = []\n",
        "        sigma = 0.155\n",
        "        for image in clip:\n",
        "            noisy = np.random.normal(image, sigma, 100)\n",
        "\n",
        "            lst_noisy.append(noisy)\n",
        "        clip.append(lst_noisy)\n",
        "    return np.array(clips)\n",
        "    \n",
        "def train_step(models, batch_clips, c1_hist, c2_hist):\n",
        "    \n",
        "    batch_noise_clips = batch_clips# + tf.random.normal(shape=[conf.dim1, conf.dim2, conf.dim3, conf.dim4], stddev=0.1)\n",
        "    \n",
        "    batch_fake_clips = models.generator.predict_on_batch(batch_noise_clips)\n",
        "    \n",
        "    d_loss_real = models.discriminator.train_on_batch(batch_clips, batch_clips))\n",
        "    d_loss_fake = models.discriminator.train_on_batch(batch_fake_clips, batch_fake_clips))\n",
        "    \n",
        "    print(f'\\t\\t\\t\\t Discriminator Loss_Real: {d_loss_real} \\t\\t Loss_Fake: {d_loss_fake}\\n')\n",
        "    c1_hist.append(d_loss_real)\n",
        "    c2_hist.append(d_loss_fake)\n",
        "    models.gan.train_on_batch(batch_noise_clips, [batch_clips,batch_fake_clips])\n",
        "    g_loss = models.gan.train_on_batch(batch_noise_clips, [batch_clips, batch_fake_clips])\n",
        "    return  g_loss\n",
        "    \n",
        "\n",
        "def train():\n",
        "    discriminator = get_generator()\n",
        "    generator = get_generator()\n",
        "    models = compile_gan(generator, discriminator)\n",
        "    models.gan.summary()\n",
        "\n",
        "    train_dataset = tf.data.Dataset.from_tensor_slices(np.array(get_clips_list(conf.dim1))).batch(conf.BATCH_SIZE)\n",
        "    c1_hist, c2_hist, g_hist = list(), list(), list()\n",
        "\n",
        "    for epoch in range(conf.EPOCHS):\n",
        "        print(f'Epoch {epoch+1} started')\n",
        "        for batch in train_dataset:\n",
        "            \n",
        "            [total_weighted_loss, reconstruction_loss, fooling_loss] = train_step(models, batch, c1_hist, c2_hist)\n",
        "            \n",
        "            print(f'Epoch: {epoch} \\t Discriminator Loss: {fooling_loss} \\t\\t Generator Loss: {reconstruction_loss} \\t\\t Total Loss: {total_weighted_loss}')\n",
        "            g_hist.append(reconstruction_loss)\n",
        "\n",
        "        plot_history(c1_hist, c2_hist, g_hist, join(conf.run_data,\"plot_line_plot_loss\"+\"_ep-\"+str(epoch+1)+\".png\"))\n",
        "        models.gan.save(join(conf.run_data,\"gan\"+\"_ep-\"+str(epoch+1)+\".hdf5\"), save_format='h5')\n",
        "    \n",
        "    models.generator.save(conf.GEN_MODEL_PATH,save_format='h5')\n",
        "    models.discriminator.save(conf.DIS_MODEL_PATH,save_format='h5')\n",
        "    models.gan.save(conf.GAN_MODEL_PATH, save_format='h5')\n",
        "    plot_history(c1_hist, c2_hist, g_hist, join(conf.cwdir,\"final_plot.png\"))\n",
        "    return models.gan"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eC7JERZTIi3M",
        "colab_type": "code",
        "outputId": "96386070-6004-4467-f159-da4c57353cca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#!rm training_gan/gan.hdf5 -rf\n",
        "#!mkdir training_gan\n",
        "\n",
        "#if os.path.isfile(conf.GAN_MODEL_PATH):\n",
        "#    model=load_model(conf.GAN_MODEL_PATH, custom_objects={'LeakyReLU': LeakyReLU})\n",
        "#else :\n",
        "    conf.reconfig(\"Conv2DLSTM_ADAE\")\n",
        "    model = train()\n",
        "\n",
        "evaluate(\"Test002\", model, 200, 1)"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading generator model\n",
            "Model: \"sequential_28\"\n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "Layer (type)                                                       Output Shape                                                Param #                \n",
            "======================================================================================================================================================\n",
            "time_distributed_102 (TimeDistributed)                             (None, 10, 64, 64, 128)                                     15616                  \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "layer_normalization_129 (LayerNormalization)                       (None, 10, 64, 64, 128)                                     256                    \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "time_distributed_103 (TimeDistributed)                             (None, 10, 32, 32, 64)                                      204864                 \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "layer_normalization_130 (LayerNormalization)                       (None, 10, 32, 32, 64)                                      128                    \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "conv_lst_m2d_45 (ConvLSTM2D)                                       (None, 10, 32, 32, 64)                                      295168                 \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "layer_normalization_131 (LayerNormalization)                       (None, 10, 32, 32, 64)                                      128                    \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "conv_lst_m2d_46 (ConvLSTM2D)                                       (None, 10, 32, 32, 32)                                      110720                 \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "layer_normalization_132 (LayerNormalization)                       (None, 10, 32, 32, 32)                                      64                     \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "conv_lst_m2d_47 (ConvLSTM2D)                                       (None, 10, 32, 32, 64)                                      221440                 \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "layer_normalization_133 (LayerNormalization)                       (None, 10, 32, 32, 64)                                      128                    \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "time_distributed_104 (TimeDistributed)                             (None, 10, 64, 64, 64)                                      102464                 \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "layer_normalization_134 (LayerNormalization)                       (None, 10, 64, 64, 64)                                      128                    \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "time_distributed_105 (TimeDistributed)                             (None, 10, 256, 256, 128)                                   991360                 \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "layer_normalization_135 (LayerNormalization)                       (None, 10, 256, 256, 128)                                   256                    \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "time_distributed_106 (TimeDistributed)                             (None, 10, 256, 256, 1)                                     15489                  \n",
            "======================================================================================================================================================\n",
            "Total params: 1,958,209\n",
            "Trainable params: 1,958,209\n",
            "Non-trainable params: 0\n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "Loading generator model\n",
            "Model: \"sequential_29\"\n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "Layer (type)                                                       Output Shape                                                Param #                \n",
            "======================================================================================================================================================\n",
            "time_distributed_107 (TimeDistributed)                             (None, 10, 64, 64, 128)                                     15616                  \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "layer_normalization_136 (LayerNormalization)                       (None, 10, 64, 64, 128)                                     256                    \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "time_distributed_108 (TimeDistributed)                             (None, 10, 32, 32, 64)                                      204864                 \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "layer_normalization_137 (LayerNormalization)                       (None, 10, 32, 32, 64)                                      128                    \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "conv_lst_m2d_48 (ConvLSTM2D)                                       (None, 10, 32, 32, 64)                                      295168                 \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "layer_normalization_138 (LayerNormalization)                       (None, 10, 32, 32, 64)                                      128                    \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "conv_lst_m2d_49 (ConvLSTM2D)                                       (None, 10, 32, 32, 32)                                      110720                 \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "layer_normalization_139 (LayerNormalization)                       (None, 10, 32, 32, 32)                                      64                     \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "conv_lst_m2d_50 (ConvLSTM2D)                                       (None, 10, 32, 32, 64)                                      221440                 \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "layer_normalization_140 (LayerNormalization)                       (None, 10, 32, 32, 64)                                      128                    \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "time_distributed_109 (TimeDistributed)                             (None, 10, 64, 64, 64)                                      102464                 \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "layer_normalization_141 (LayerNormalization)                       (None, 10, 64, 64, 64)                                      128                    \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "time_distributed_110 (TimeDistributed)                             (None, 10, 256, 256, 128)                                   991360                 \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "layer_normalization_142 (LayerNormalization)                       (None, 10, 256, 256, 128)                                   256                    \n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "time_distributed_111 (TimeDistributed)                             (None, 10, 256, 256, 1)                                     15489                  \n",
            "======================================================================================================================================================\n",
            "Total params: 1,958,209\n",
            "Trainable params: 1,958,209\n",
            "Non-trainable params: 0\n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "Model: \"model_11\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_12 (InputLayer)        [(None, 10, 256, 256, 1)] 0         \n",
            "_________________________________________________________________\n",
            "model_10 (Model)             (None, 10, 256, 256, 1)   1958209   \n",
            "_________________________________________________________________\n",
            "model_9 (Model)              (None, 10, 256, 256, 1)   1958209   \n",
            "=================================================================\n",
            "Total params: 3,916,418\n",
            "Trainable params: 1,958,209\n",
            "Non-trainable params: 1,958,209\n",
            "_________________________________________________________________\n",
            "Epoch 1 started\n",
            "\t\t\t\t Discriminator Loss_Real: 1.6288135051727295 \t\t Loss_Fake: 0.6957138776779175\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 1.4424748420715332 \t\t Generator Loss: 0.7811902761459351 \t\t Total Loss: 2.223665237426758\n",
            "\t\t\t\t Discriminator Loss_Real: 1.0963704586029053 \t\t Loss_Fake: 0.7538060545921326\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.7234834432601929 \t\t Generator Loss: 0.6126881241798401 \t\t Total Loss: 1.3361716270446777\n",
            "\t\t\t\t Discriminator Loss_Real: 0.4139813780784607 \t\t Loss_Fake: 0.8371750712394714\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.23669497668743134 \t\t Generator Loss: 0.5224269032478333 \t\t Total Loss: 0.7591218948364258\n",
            "\t\t\t\t Discriminator Loss_Real: 0.18783621490001678 \t\t Loss_Fake: 0.9228717684745789\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.12790778279304504 \t\t Generator Loss: 0.47192487120628357 \t\t Total Loss: 0.5998326539993286\n",
            "\t\t\t\t Discriminator Loss_Real: 0.09403904527425766 \t\t Loss_Fake: 0.939309298992157\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.070784792304039 \t\t Generator Loss: 0.4565553069114685 \t\t Total Loss: 0.5273401141166687\n",
            "\t\t\t\t Discriminator Loss_Real: 0.049023084342479706 \t\t Loss_Fake: 0.9484532475471497\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.03391115739941597 \t\t Generator Loss: 0.4112842082977295 \t\t Total Loss: 0.44519537687301636\n",
            "\t\t\t\t Discriminator Loss_Real: 0.030629441142082214 \t\t Loss_Fake: 0.9621663093566895\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.035207003355026245 \t\t Generator Loss: 0.39645442366600037 \t\t Total Loss: 0.4316614270210266\n",
            "\t\t\t\t Discriminator Loss_Real: 0.04907950013875961 \t\t Loss_Fake: 0.9752163887023926\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.0116847213357687 \t\t Generator Loss: 0.38769856095314026 \t\t Total Loss: 0.3993832767009735\n",
            "\t\t\t\t Discriminator Loss_Real: 0.013743569143116474 \t\t Loss_Fake: 0.9800052642822266\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.008993270806968212 \t\t Generator Loss: 0.382035493850708 \t\t Total Loss: 0.3910287618637085\n",
            "\t\t\t\t Discriminator Loss_Real: 0.009953049942851067 \t\t Loss_Fake: 0.9799359440803528\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.0116728525608778 \t\t Generator Loss: 0.3808065950870514 \t\t Total Loss: 0.39247944951057434\n",
            "\t\t\t\t Discriminator Loss_Real: 0.013704800978302956 \t\t Loss_Fake: 0.9774478077888489\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.010656704194843769 \t\t Generator Loss: 0.38404935598373413 \t\t Total Loss: 0.3947060704231262\n",
            "\t\t\t\t Discriminator Loss_Real: 0.016191456466913223 \t\t Loss_Fake: 0.9783239364624023\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.009294649586081505 \t\t Generator Loss: 0.3789084255695343 \t\t Total Loss: 0.38820308446884155\n",
            "\t\t\t\t Discriminator Loss_Real: 0.011054540053009987 \t\t Loss_Fake: 0.9718096852302551\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.031292837113142014 \t\t Generator Loss: 0.37446802854537964 \t\t Total Loss: 0.40576085448265076\n",
            "\t\t\t\t Discriminator Loss_Real: 0.02913697622716427 \t\t Loss_Fake: 0.9720532298088074\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.017973069101572037 \t\t Generator Loss: 0.36975356936454773 \t\t Total Loss: 0.38772663474082947\n",
            "\t\t\t\t Discriminator Loss_Real: 0.02345755137503147 \t\t Loss_Fake: 0.9789029359817505\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.008149144239723682 \t\t Generator Loss: 0.3658042848110199 \t\t Total Loss: 0.3739534318447113\n",
            "\t\t\t\t Discriminator Loss_Real: 0.008677233941853046 \t\t Loss_Fake: 0.9758528470993042\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.021325230598449707 \t\t Generator Loss: 0.36214005947113037 \t\t Total Loss: 0.3834652900695801\n",
            "\t\t\t\t Discriminator Loss_Real: 0.020934496074914932 \t\t Loss_Fake: 0.9776070713996887\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.008833655156195164 \t\t Generator Loss: 0.35601186752319336 \t\t Total Loss: 0.36484551429748535\n",
            "\t\t\t\t Discriminator Loss_Real: 0.008226653560996056 \t\t Loss_Fake: 0.9732843637466431\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.026665229350328445 \t\t Generator Loss: 0.3524357080459595 \t\t Total Loss: 0.3791009485721588\n",
            "\t\t\t\t Discriminator Loss_Real: 0.02508786879479885 \t\t Loss_Fake: 0.9723593592643738\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.019592123106122017 \t\t Generator Loss: 0.34578755497932434 \t\t Total Loss: 0.3653796911239624\n",
            "\t\t\t\t Discriminator Loss_Real: 0.017817193642258644 \t\t Loss_Fake: 0.9774948954582214\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.007146832533180714 \t\t Generator Loss: 0.34373465180397034 \t\t Total Loss: 0.3508814871311188\n",
            "\t\t\t\t Discriminator Loss_Real: 0.007019451353698969 \t\t Loss_Fake: 0.978571891784668\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.008362256921827793 \t\t Generator Loss: 0.3376123011112213 \t\t Total Loss: 0.34597456455230713\n",
            "\t\t\t\t Discriminator Loss_Real: 0.007075388915836811 \t\t Loss_Fake: 0.9636057615280151\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.06552398949861526 \t\t Generator Loss: 0.3379814624786377 \t\t Total Loss: 0.40350544452667236\n",
            "\t\t\t\t Discriminator Loss_Real: 0.05604579299688339 \t\t Loss_Fake: 0.9660600423812866\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.027911672368645668 \t\t Generator Loss: 0.33501163125038147 \t\t Total Loss: 0.3629232943058014\n",
            "\t\t\t\t Discriminator Loss_Real: 0.03182482719421387 \t\t Loss_Fake: 0.9781668782234192\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.017253603786230087 \t\t Generator Loss: 0.3357955813407898 \t\t Total Loss: 0.3530491888523102\n",
            "\t\t\t\t Discriminator Loss_Real: 0.02139141783118248 \t\t Loss_Fake: 0.9894720911979675\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.00211653346195817 \t\t Generator Loss: 0.32529303431510925 \t\t Total Loss: 0.327409565448761\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0021288583520799875 \t\t Loss_Fake: 0.9922733306884766\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.0020389282144606113 \t\t Generator Loss: 0.3204628825187683 \t\t Total Loss: 0.3225018084049225\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0021967615466564894 \t\t Loss_Fake: 0.9918987154960632\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.003080998547375202 \t\t Generator Loss: 0.31660932302474976 \t\t Total Loss: 0.3196903169155121\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0031079724431037903 \t\t Loss_Fake: 0.9876187443733215\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.01310807280242443 \t\t Generator Loss: 0.319565087556839 \t\t Total Loss: 0.33267316222190857\n",
            "\t\t\t\t Discriminator Loss_Real: 0.012034018523991108 \t\t Loss_Fake: 0.9877697229385376\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.003764732973650098 \t\t Generator Loss: 0.31268277764320374 \t\t Total Loss: 0.31644749641418457\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0031766542233526707 \t\t Loss_Fake: 0.9882122874259949\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.004854811821132898 \t\t Generator Loss: 0.31364598870277405 \t\t Total Loss: 0.3185007870197296\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00412305723875761 \t\t Loss_Fake: 0.9829791188240051\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.02511787973344326 \t\t Generator Loss: 0.3230434060096741 \t\t Total Loss: 0.3481612801551819\n",
            "\t\t\t\t Discriminator Loss_Real: 0.021137595176696777 \t\t Loss_Fake: 0.9849531054496765\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.007557596080005169 \t\t Generator Loss: 0.31688398122787476 \t\t Total Loss: 0.3244415819644928\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0043800161220133305 \t\t Loss_Fake: 0.9799335598945618\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.025604084134101868 \t\t Generator Loss: 0.32125648856163025 \t\t Total Loss: 0.3468605875968933\n",
            "\t\t\t\t Discriminator Loss_Real: 0.01909484900534153 \t\t Loss_Fake: 0.9864166975021362\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.006619391031563282 \t\t Generator Loss: 0.31646624207496643 \t\t Total Loss: 0.32308563590049744\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0055279722437262535 \t\t Loss_Fake: 0.987824559211731\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.004986179061233997 \t\t Generator Loss: 0.31607306003570557 \t\t Total Loss: 0.3210592269897461\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00339699350297451 \t\t Loss_Fake: 0.9872034788131714\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.01293096225708723 \t\t Generator Loss: 0.308810830116272 \t\t Total Loss: 0.3217417895793915\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00814267061650753 \t\t Loss_Fake: 0.9882881045341492\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.004202437587082386 \t\t Generator Loss: 0.30864131450653076 \t\t Total Loss: 0.3128437399864197\n",
            "\t\t\t\t Discriminator Loss_Real: 0.002196942688897252 \t\t Loss_Fake: 0.987557590007782\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.006219145841896534 \t\t Generator Loss: 0.3016708195209503 \t\t Total Loss: 0.3078899681568146\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0031638015061616898 \t\t Loss_Fake: 0.9793494343757629\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.04135870188474655 \t\t Generator Loss: 0.30327343940734863 \t\t Total Loss: 0.3446321487426758\n",
            "\t\t\t\t Discriminator Loss_Real: 0.023618243634700775 \t\t Loss_Fake: 0.981122612953186\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.01859966106712818 \t\t Generator Loss: 0.299323707818985 \t\t Total Loss: 0.317923367023468\n",
            "\t\t\t\t Discriminator Loss_Real: 0.011021566577255726 \t\t Loss_Fake: 0.9828298687934875\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.008918830193579197 \t\t Generator Loss: 0.30189886689186096 \t\t Total Loss: 0.310817688703537\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0056062014773488045 \t\t Loss_Fake: 0.9837819337844849\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.013608584180474281 \t\t Generator Loss: 0.29580166935920715 \t\t Total Loss: 0.3094102442264557\n",
            "\t\t\t\t Discriminator Loss_Real: 0.007004042621701956 \t\t Loss_Fake: 0.9845458269119263\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.008186480030417442 \t\t Generator Loss: 0.2955321669578552 \t\t Total Loss: 0.3037186563014984\n",
            "\t\t\t\t Discriminator Loss_Real: 0.002600926673039794 \t\t Loss_Fake: 0.9768136739730835\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.02997683919966221 \t\t Generator Loss: 0.320241242647171 \t\t Total Loss: 0.3502180874347687\n",
            "\t\t\t\t Discriminator Loss_Real: 0.016500288620591164 \t\t Loss_Fake: 0.9803704023361206\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.020266495645046234 \t\t Generator Loss: 0.31105726957321167 \t\t Total Loss: 0.3313237726688385\n",
            "\t\t\t\t Discriminator Loss_Real: 0.004873410798609257 \t\t Loss_Fake: 0.9648452997207642\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.037031110376119614 \t\t Generator Loss: 0.32747840881347656 \t\t Total Loss: 0.3645095229148865\n",
            "\t\t\t\t Discriminator Loss_Real: 0.009616242721676826 \t\t Loss_Fake: 0.9700492024421692\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.07935032248497009 \t\t Generator Loss: 0.36049798130989075 \t\t Total Loss: 0.43984830379486084\n",
            "\t\t\t\t Discriminator Loss_Real: 0.05000844597816467 \t\t Loss_Fake: 0.9880595207214355\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.0026221568696200848 \t\t Generator Loss: 0.3416932225227356 \t\t Total Loss: 0.34431537985801697\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0017918288940563798 \t\t Loss_Fake: 0.9880599975585938\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.013055195100605488 \t\t Generator Loss: 0.33423614501953125 \t\t Total Loss: 0.34729135036468506\n",
            "\t\t\t\t Discriminator Loss_Real: 0.009736469015479088 \t\t Loss_Fake: 0.9931379556655884\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.0012189591070637107 \t\t Generator Loss: 0.33384785056114197 \t\t Total Loss: 0.3350667953491211\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00106678600423038 \t\t Loss_Fake: 0.9945783615112305\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.0016600328963249922 \t\t Generator Loss: 0.3048810362815857 \t\t Total Loss: 0.3065410554409027\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0012312941253185272 \t\t Loss_Fake: 0.9911072850227356\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.013151733204722404 \t\t Generator Loss: 0.30835169553756714 \t\t Total Loss: 0.3215034306049347\n",
            "\t\t\t\t Discriminator Loss_Real: 0.010115930810570717 \t\t Loss_Fake: 0.9914531707763672\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.0023030792362987995 \t\t Generator Loss: 0.30429592728614807 \t\t Total Loss: 0.3065990209579468\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0014598359121009707 \t\t Loss_Fake: 0.9917299151420593\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.003378169145435095 \t\t Generator Loss: 0.2957794964313507 \t\t Total Loss: 0.29915767908096313\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0017342644277960062 \t\t Loss_Fake: 0.9817511439323425\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.03892224654555321 \t\t Generator Loss: 0.29572194814682007 \t\t Total Loss: 0.3346441984176636\n",
            "\t\t\t\t Discriminator Loss_Real: 0.016904884949326515 \t\t Loss_Fake: 0.9931083917617798\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.0029923184774816036 \t\t Generator Loss: 0.29146623611450195 \t\t Total Loss: 0.2944585680961609\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0013941362267360091 \t\t Loss_Fake: 0.9922135472297668\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.002821333007887006 \t\t Generator Loss: 0.28738051652908325 \t\t Total Loss: 0.2902018427848816\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0013269500341266394 \t\t Loss_Fake: 0.9932171702384949\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.005279436241835356 \t\t Generator Loss: 0.28031450510025024 \t\t Total Loss: 0.2855939269065857\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0015603143256157637 \t\t Loss_Fake: 0.9864431619644165\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.010013153776526451 \t\t Generator Loss: 0.2858826816082001 \t\t Total Loss: 0.29589584469795227\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0030909511260688305 \t\t Loss_Fake: 0.9842960238456726\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.021058224141597748 \t\t Generator Loss: 0.2958599328994751 \t\t Total Loss: 0.31691816449165344\n",
            "\t\t\t\t Discriminator Loss_Real: 0.009254306554794312 \t\t Loss_Fake: 0.9868295788764954\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.021187614649534225 \t\t Generator Loss: 0.2784484624862671 \t\t Total Loss: 0.2996360659599304\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0016852263361215591 \t\t Loss_Fake: 0.9869768023490906\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.008210701867938042 \t\t Generator Loss: 0.29635652899742126 \t\t Total Loss: 0.30456721782684326\n",
            "\t\t\t\t Discriminator Loss_Real: 0.002036145655438304 \t\t Loss_Fake: 0.9804431200027466\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.01366516388952732 \t\t Generator Loss: 0.3037572503089905 \t\t Total Loss: 0.31742241978645325\n",
            "\t\t\t\t Discriminator Loss_Real: 0.003705818671733141 \t\t Loss_Fake: 0.9704272150993347\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.0814405083656311 \t\t Generator Loss: 0.3207671642303467 \t\t Total Loss: 0.4022076725959778\n",
            "\t\t\t\t Discriminator Loss_Real: 0.03835764154791832 \t\t Loss_Fake: 0.9909483194351196\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.0016035328153520823 \t\t Generator Loss: 0.34428244829177856 \t\t Total Loss: 0.3458859920501709\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0012801013654097915 \t\t Loss_Fake: 0.9926545023918152\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.0147247314453125 \t\t Generator Loss: 0.32940158247947693 \t\t Total Loss: 0.34412631392478943\n",
            "\t\t\t\t Discriminator Loss_Real: 0.000744755263440311 \t\t Loss_Fake: 0.9940475225448608\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.00856203492730856 \t\t Generator Loss: 0.32729649543762207 \t\t Total Loss: 0.3358585238456726\n",
            "\t\t\t\t Discriminator Loss_Real: 0.004370896611362696 \t\t Loss_Fake: 0.9915663003921509\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.002990249777212739 \t\t Generator Loss: 0.31903454661369324 \t\t Total Loss: 0.32202479243278503\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0008728057146072388 \t\t Loss_Fake: 0.9945892095565796\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.0026526611763983965 \t\t Generator Loss: 0.3192136585712433 \t\t Total Loss: 0.32186633348464966\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0008042043773457408 \t\t Loss_Fake: 0.9916521906852722\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.009265956468880177 \t\t Generator Loss: 0.3092329800128937 \t\t Total Loss: 0.3184989392757416\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0036744337994605303 \t\t Loss_Fake: 0.9889436960220337\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.011720106936991215 \t\t Generator Loss: 0.3047176003456116 \t\t Total Loss: 0.3164377212524414\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0019007741939276457 \t\t Loss_Fake: 0.9893549680709839\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.01095755584537983 \t\t Generator Loss: 0.30675244331359863 \t\t Total Loss: 0.3177100121974945\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00288779241964221 \t\t Loss_Fake: 0.9854943156242371\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.010381476953625679 \t\t Generator Loss: 0.3052327632904053 \t\t Total Loss: 0.315614253282547\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0021561062894761562 \t\t Loss_Fake: 0.9862281084060669\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.022018352523446083 \t\t Generator Loss: 0.2950682044029236 \t\t Total Loss: 0.3170865476131439\n",
            "\t\t\t\t Discriminator Loss_Real: 0.003868917003273964 \t\t Loss_Fake: 0.9888824224472046\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.011045778170228004 \t\t Generator Loss: 0.32065868377685547 \t\t Total Loss: 0.3317044675350189\n",
            "\t\t\t\t Discriminator Loss_Real: 0.015212981030344963 \t\t Loss_Fake: 0.9941749572753906\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.014118331484496593 \t\t Generator Loss: 0.30897340178489685 \t\t Total Loss: 0.3230917453765869\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0012500621378421783 \t\t Loss_Fake: 0.9952943921089172\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.0017531246412545443 \t\t Generator Loss: 0.32116013765335083 \t\t Total Loss: 0.322913259267807\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0010132293682545424 \t\t Loss_Fake: 0.9950340986251831\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.004536387976258993 \t\t Generator Loss: 0.29781603813171387 \t\t Total Loss: 0.3023524284362793\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0009891799418255687 \t\t Loss_Fake: 0.9934270977973938\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.0025228403974324465 \t\t Generator Loss: 0.3056819438934326 \t\t Total Loss: 0.3082047700881958\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0009573170100338757 \t\t Loss_Fake: 0.9944469332695007\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.008002568036317825 \t\t Generator Loss: 0.2922359108924866 \t\t Total Loss: 0.3002384901046753\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0009091222891584039 \t\t Loss_Fake: 0.9934483766555786\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.005888325162231922 \t\t Generator Loss: 0.3029451072216034 \t\t Total Loss: 0.30883342027664185\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0009093554690480232 \t\t Loss_Fake: 0.9925345182418823\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.004743620287626982 \t\t Generator Loss: 0.2915870249271393 \t\t Total Loss: 0.29633063077926636\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0009750634199008346 \t\t Loss_Fake: 0.9904072880744934\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.0014584728050976992 \t\t Generator Loss: 0.3322123885154724 \t\t Total Loss: 0.33367085456848145\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0011506397277116776 \t\t Loss_Fake: 0.9947441220283508\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.005688696168363094 \t\t Generator Loss: 0.3237140476703644 \t\t Total Loss: 0.32940274477005005\n",
            "\t\t\t\t Discriminator Loss_Real: 0.001624222146347165 \t\t Loss_Fake: 0.980229377746582\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.003854030277580023 \t\t Generator Loss: 0.34627610445022583 \t\t Total Loss: 0.3501301407814026\n",
            "\t\t\t\t Discriminator Loss_Real: 0.003002660581842065 \t\t Loss_Fake: 0.9919648170471191\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.014787319116294384 \t\t Generator Loss: 0.345994770526886 \t\t Total Loss: 0.36078208684921265\n",
            "\t\t\t\t Discriminator Loss_Real: 0.008764422498643398 \t\t Loss_Fake: 0.9873372912406921\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.005840029567480087 \t\t Generator Loss: 0.35829323530197144 \t\t Total Loss: 0.3641332685947418\n",
            "\t\t\t\t Discriminator Loss_Real: 0.007992653176188469 \t\t Loss_Fake: 0.9900916218757629\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.00483133178204298 \t\t Generator Loss: 0.36054906249046326 \t\t Total Loss: 0.3653804063796997\n",
            "\t\t\t\t Discriminator Loss_Real: 0.004347541369497776 \t\t Loss_Fake: 0.9912530779838562\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.0018646239768713713 \t\t Generator Loss: 0.3828868865966797 \t\t Total Loss: 0.38475149869918823\n",
            "\t\t\t\t Discriminator Loss_Real: 0.01086425967514515 \t\t Loss_Fake: 0.9963630437850952\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.0008888871525414288 \t\t Generator Loss: 0.360065758228302 \t\t Total Loss: 0.3609546422958374\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0007731523364782333 \t\t Loss_Fake: 0.9928407669067383\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.004891646094620228 \t\t Generator Loss: 0.3497810363769531 \t\t Total Loss: 0.3546726703643799\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0005856809439137578 \t\t Loss_Fake: 0.9962931871414185\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.000911206123419106 \t\t Generator Loss: 0.3523697257041931 \t\t Total Loss: 0.3532809317111969\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0006053311517462134 \t\t Loss_Fake: 0.9959912300109863\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.002351765288040042 \t\t Generator Loss: 0.34505394101142883 \t\t Total Loss: 0.34740570187568665\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0007284317980520427 \t\t Loss_Fake: 0.994857132434845\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.0039938888512551785 \t\t Generator Loss: 0.3408840298652649 \t\t Total Loss: 0.3448779284954071\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0009691820596344769 \t\t Loss_Fake: 0.9922992587089539\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.001843228004872799 \t\t Generator Loss: 0.3575488030910492 \t\t Total Loss: 0.3593920171260834\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0013405387289822102 \t\t Loss_Fake: 0.9943784475326538\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.00611870689317584 \t\t Generator Loss: 0.3431827127933502 \t\t Total Loss: 0.34930142760276794\n",
            "\t\t\t\t Discriminator Loss_Real: 0.002043022308498621 \t\t Loss_Fake: 0.9837645292282104\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.004684661515057087 \t\t Generator Loss: 0.3537084460258484 \t\t Total Loss: 0.3583931028842926\n",
            "\t\t\t\t Discriminator Loss_Real: 0.003322939621284604 \t\t Loss_Fake: 0.9913979768753052\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.012530012056231499 \t\t Generator Loss: 0.36831170320510864 \t\t Total Loss: 0.3808417022228241\n",
            "\t\t\t\t Discriminator Loss_Real: 0.007240878883749247 \t\t Loss_Fake: 0.9910442233085632\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.006834688130766153 \t\t Generator Loss: 0.3593622148036957 \t\t Total Loss: 0.3661969006061554\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0023677474819123745 \t\t Loss_Fake: 0.9887587428092957\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.0028363277669996023 \t\t Generator Loss: 0.38688284158706665 \t\t Total Loss: 0.389719158411026\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0027849790640175343 \t\t Loss_Fake: 0.9913023710250854\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.010228164494037628 \t\t Generator Loss: 0.40643972158432007 \t\t Total Loss: 0.4166678786277771\n",
            "\t\t\t\t Discriminator Loss_Real: 0.010478241369128227 \t\t Loss_Fake: 0.9914647936820984\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.009864059276878834 \t\t Generator Loss: 0.394008070230484 \t\t Total Loss: 0.40387213230133057\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0014934152131900191 \t\t Loss_Fake: 0.9921126365661621\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.0035207285545766354 \t\t Generator Loss: 0.39515239000320435 \t\t Total Loss: 0.3986731171607971\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0014443574473261833 \t\t Loss_Fake: 0.9848092794418335\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.05094391107559204 \t\t Generator Loss: 0.37461522221565247 \t\t Total Loss: 0.4255591332912445\n",
            "\t\t\t\t Discriminator Loss_Real: 0.017932120710611343 \t\t Loss_Fake: 0.9899787902832031\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.01689109578728676 \t\t Generator Loss: 0.3557268977165222 \t\t Total Loss: 0.3726179897785187\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0009097030269913375 \t\t Loss_Fake: 0.9931536912918091\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.007514134049415588 \t\t Generator Loss: 0.3588595688343048 \t\t Total Loss: 0.3663737177848816\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0008521111449226737 \t\t Loss_Fake: 0.9922795295715332\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.0061869132332503796 \t\t Generator Loss: 0.3551921248435974 \t\t Total Loss: 0.3613790273666382\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0008203433826565742 \t\t Loss_Fake: 0.9925152063369751\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.009563992731273174 \t\t Generator Loss: 0.3523150086402893 \t\t Total Loss: 0.36187899112701416\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0008691083639860153 \t\t Loss_Fake: 0.988994300365448\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.004345416557043791 \t\t Generator Loss: 0.3825948238372803 \t\t Total Loss: 0.38694024085998535\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0012112727854400873 \t\t Loss_Fake: 0.9914838671684265\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.015839364379644394 \t\t Generator Loss: 0.388502836227417 \t\t Total Loss: 0.4043422043323517\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0027912124060094357 \t\t Loss_Fake: 0.9813822507858276\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.08543888479471207 \t\t Generator Loss: 0.4238714575767517 \t\t Total Loss: 0.5093103647232056\n",
            "\t\t\t\t Discriminator Loss_Real: 0.02638329192996025 \t\t Loss_Fake: 0.9923185110092163\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.0013501750072464347 \t\t Generator Loss: 0.43920260667800903 \t\t Total Loss: 0.4405527710914612\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0011386170517653227 \t\t Loss_Fake: 0.9961286783218384\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.001041086041368544 \t\t Generator Loss: 0.44069963693618774 \t\t Total Loss: 0.4417407214641571\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0009427001932635903 \t\t Loss_Fake: 0.9963658452033997\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.0011273275595158339 \t\t Generator Loss: 0.44106507301330566 \t\t Total Loss: 0.442192405462265\n",
            "\t\t\t\t Discriminator Loss_Real: 0.001031722640618682 \t\t Loss_Fake: 0.9961093664169312\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.0013761536683887243 \t\t Generator Loss: 0.4410075545310974 \t\t Total Loss: 0.44238370656967163\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0012821909040212631 \t\t Loss_Fake: 0.9956457018852234\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.001761304447427392 \t\t Generator Loss: 0.44041672348976135 \t\t Total Loss: 0.44217804074287415\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0016577241476625204 \t\t Loss_Fake: 0.9950367212295532\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.002182596130296588 \t\t Generator Loss: 0.44010862708091736 \t\t Total Loss: 0.4422912299633026\n",
            "\t\t\t\t Discriminator Loss_Real: 0.002078881487250328 \t\t Loss_Fake: 0.9942768812179565\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.0026107504963874817 \t\t Generator Loss: 0.43990883231163025 \t\t Total Loss: 0.44251957535743713\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0024967268109321594 \t\t Loss_Fake: 0.9929754137992859\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.004151791799813509 \t\t Generator Loss: 0.4397122859954834 \t\t Total Loss: 0.4438640773296356\n",
            "\t\t\t\t Discriminator Loss_Real: 0.004013139754533768 \t\t Loss_Fake: 0.9912713766098022\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.006175736431032419 \t\t Generator Loss: 0.4394262433052063 \t\t Total Loss: 0.4456019699573517\n",
            "\t\t\t\t Discriminator Loss_Real: 0.005974875763058662 \t\t Loss_Fake: 0.9929177165031433\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.002366742119193077 \t\t Generator Loss: 0.43851786851882935 \t\t Total Loss: 0.44088461995124817\n",
            "\t\t\t\t Discriminator Loss_Real: 0.002199736190959811 \t\t Loss_Fake: 0.9936798214912415\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.0025049704127013683 \t\t Generator Loss: 0.4379991590976715 \t\t Total Loss: 0.44050413370132446\n",
            "\t\t\t\t Discriminator Loss_Real: 0.002310218056663871 \t\t Loss_Fake: 0.993367075920105\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.0027378506492823362 \t\t Generator Loss: 0.437220960855484 \t\t Total Loss: 0.4399588108062744\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0025292520876973867 \t\t Loss_Fake: 0.9928991198539734\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.0030861373525112867 \t\t Generator Loss: 0.4349508285522461 \t\t Total Loss: 0.4380369782447815\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0028519576881080866 \t\t Loss_Fake: 0.992424488067627\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.0034878302831202745 \t\t Generator Loss: 0.4368966221809387 \t\t Total Loss: 0.4403844475746155\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0031191520392894745 \t\t Loss_Fake: 0.9919992685317993\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.003595010843127966 \t\t Generator Loss: 0.43378978967666626 \t\t Total Loss: 0.43738481402397156\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0032454163301736116 \t\t Loss_Fake: 0.9916308522224426\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.003636858193203807 \t\t Generator Loss: 0.4349856972694397 \t\t Total Loss: 0.4386225640773773\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0032548054587095976 \t\t Loss_Fake: 0.9912726283073425\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.0036880571860820055 \t\t Generator Loss: 0.43221959471702576 \t\t Total Loss: 0.43590766191482544\n",
            "\t\t\t\t Discriminator Loss_Real: 0.003253164468333125 \t\t Loss_Fake: 0.990706741809845\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.003895787987858057 \t\t Generator Loss: 0.4325043559074402 \t\t Total Loss: 0.4364001452922821\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0034636978525668383 \t\t Loss_Fake: 0.9887420535087585\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.008682937361299992 \t\t Generator Loss: 0.43300238251686096 \t\t Total Loss: 0.4416853189468384\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00930771790444851 \t\t Loss_Fake: 0.9904524683952332\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.0036819037050008774 \t\t Generator Loss: 0.42501217126846313 \t\t Total Loss: 0.42869406938552856\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0030547459609806538 \t\t Loss_Fake: 0.9907869100570679\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.004132065922021866 \t\t Generator Loss: 0.42400088906288147 \t\t Total Loss: 0.42813295125961304\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0034190737642347813 \t\t Loss_Fake: 0.9903095364570618\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.00471284706145525 \t\t Generator Loss: 0.42138299345970154 \t\t Total Loss: 0.4260958433151245\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00393284298479557 \t\t Loss_Fake: 0.989591121673584\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.005189645104110241 \t\t Generator Loss: 0.4220733642578125 \t\t Total Loss: 0.4272630214691162\n",
            "\t\t\t\t Discriminator Loss_Real: 0.004283006768673658 \t\t Loss_Fake: 0.9888861775398254\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.005295452196151018 \t\t Generator Loss: 0.42152461409568787 \t\t Total Loss: 0.4268200695514679\n",
            "\t\t\t\t Discriminator Loss_Real: 0.004620866850018501 \t\t Loss_Fake: 0.9879786372184753\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.006207706406712532 \t\t Generator Loss: 0.41987746953964233 \t\t Total Loss: 0.4260851740837097\n",
            "\t\t\t\t Discriminator Loss_Real: 0.005526072345674038 \t\t Loss_Fake: 0.9873932600021362\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.005817378405481577 \t\t Generator Loss: 0.42072510719299316 \t\t Total Loss: 0.4265424907207489\n",
            "\t\t\t\t Discriminator Loss_Real: 0.004859731532633305 \t\t Loss_Fake: 0.9869391322135925\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.0066580637358129025 \t\t Generator Loss: 0.4202337861061096 \t\t Total Loss: 0.42689186334609985\n",
            "\t\t\t\t Discriminator Loss_Real: 0.005768632981926203 \t\t Loss_Fake: 0.9869171380996704\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.005372578743845224 \t\t Generator Loss: 0.41896024346351624 \t\t Total Loss: 0.4243328273296356\n",
            "\t\t\t\t Discriminator Loss_Real: 0.004186446778476238 \t\t Loss_Fake: 0.9851792454719543\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.01822291687130928 \t\t Generator Loss: 0.41903582215309143 \t\t Total Loss: 0.4372587502002716\n",
            "\t\t\t\t Discriminator Loss_Real: 0.016207288950681686 \t\t Loss_Fake: 0.9891349077224731\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.0050155529752373695 \t\t Generator Loss: 0.4173366129398346 \t\t Total Loss: 0.4223521649837494\n",
            "\t\t\t\t Discriminator Loss_Real: 0.003774904413148761 \t\t Loss_Fake: 0.989409327507019\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.00523788807913661 \t\t Generator Loss: 0.4165824055671692 \t\t Total Loss: 0.4218202829360962\n",
            "\t\t\t\t Discriminator Loss_Real: 0.003764687804505229 \t\t Loss_Fake: 0.98956298828125\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.004533256404101849 \t\t Generator Loss: 0.41647475957870483 \t\t Total Loss: 0.42100802063941956\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0033414606004953384 \t\t Loss_Fake: 0.9896026849746704\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.0043367319740355015 \t\t Generator Loss: 0.4164627492427826 \t\t Total Loss: 0.42079949378967285\n",
            "\t\t\t\t Discriminator Loss_Real: 0.003185560926795006 \t\t Loss_Fake: 0.9883496165275574\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.007410191930830479 \t\t Generator Loss: 0.41649848222732544 \t\t Total Loss: 0.42390868067741394\n",
            "\t\t\t\t Discriminator Loss_Real: 0.006476609501987696 \t\t Loss_Fake: 0.9892009496688843\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.004280181135982275 \t\t Generator Loss: 0.41637763381004333 \t\t Total Loss: 0.42065781354904175\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0028475397266447544 \t\t Loss_Fake: 0.9897761344909668\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.005040106363594532 \t\t Generator Loss: 0.4158833622932434 \t\t Total Loss: 0.42092347145080566\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0031519955955445766 \t\t Loss_Fake: 0.9892183542251587\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.005472016055136919 \t\t Generator Loss: 0.41588273644447327 \t\t Total Loss: 0.421354740858078\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00344446930103004 \t\t Loss_Fake: 0.9886581301689148\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.005696360487490892 \t\t Generator Loss: 0.4159729480743408 \t\t Total Loss: 0.4216693043708801\n",
            "\t\t\t\t Discriminator Loss_Real: 0.003634237451478839 \t\t Loss_Fake: 0.9875549077987671\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.0065538943745195866 \t\t Generator Loss: 0.41585788130760193 \t\t Total Loss: 0.4224117696285248\n",
            "\t\t\t\t Discriminator Loss_Real: 0.004244398791342974 \t\t Loss_Fake: 0.984205424785614\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.03080832026898861 \t\t Generator Loss: 0.4042278230190277 \t\t Total Loss: 0.43503615260124207\n",
            "\t\t\t\t Discriminator Loss_Real: 0.027485419064760208 \t\t Loss_Fake: 0.9898110628128052\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.0034000002779066563 \t\t Generator Loss: 0.40373483300209045 \t\t Total Loss: 0.4071348309516907\n",
            "\t\t\t\t Discriminator Loss_Real: 0.002057210775092244 \t\t Loss_Fake: 0.9916642904281616\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.0030219550244510174 \t\t Generator Loss: 0.4037604331970215 \t\t Total Loss: 0.4067823886871338\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0017030624439939857 \t\t Loss_Fake: 0.9924171566963196\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.002987164305523038 \t\t Generator Loss: 0.4041646420955658 \t\t Total Loss: 0.40715181827545166\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0017231631791219115 \t\t Loss_Fake: 0.9921751022338867\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.003639817237854004 \t\t Generator Loss: 0.4037091135978699 \t\t Total Loss: 0.4073489308357239\n",
            "\t\t\t\t Discriminator Loss_Real: 0.001888458849862218 \t\t Loss_Fake: 0.991355299949646\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.004195448011159897 \t\t Generator Loss: 0.40374332666397095 \t\t Total Loss: 0.40793877840042114\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0022570565342903137 \t\t Loss_Fake: 0.9903855323791504\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.00549718551337719 \t\t Generator Loss: 0.4035798907279968 \t\t Total Loss: 0.40907707810401917\n",
            "\t\t\t\t Discriminator Loss_Real: 0.002937138080596924 \t\t Loss_Fake: 0.9891685247421265\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.00669009517878294 \t\t Generator Loss: 0.4035579562187195 \t\t Total Loss: 0.4102480411529541\n",
            "\t\t\t\t Discriminator Loss_Real: 0.003638423979282379 \t\t Loss_Fake: 0.9884881973266602\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.006703728344291449 \t\t Generator Loss: 0.40392762422561646 \t\t Total Loss: 0.41063135862350464\n",
            "\t\t\t\t Discriminator Loss_Real: 0.003941429778933525 \t\t Loss_Fake: 0.9879654049873352\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.0066489302553236485 \t\t Generator Loss: 0.4036845564842224 \t\t Total Loss: 0.4103334844112396\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0039506107568740845 \t\t Loss_Fake: 0.9874075651168823\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.006425057537853718 \t\t Generator Loss: 0.4068845808506012 \t\t Total Loss: 0.41330963373184204\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0041777631267905235 \t\t Loss_Fake: 0.9860160946846008\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.009878292679786682 \t\t Generator Loss: 0.4067540764808655 \t\t Total Loss: 0.41663235425949097\n",
            "\t\t\t\t Discriminator Loss_Real: 0.007625597063452005 \t\t Loss_Fake: 0.9865869283676147\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.006573277525603771 \t\t Generator Loss: 0.4067491888999939 \t\t Total Loss: 0.41332247853279114\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0036283310037106276 \t\t Loss_Fake: 0.9874001741409302\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.007226309273391962 \t\t Generator Loss: 0.4068521559238434 \t\t Total Loss: 0.4140784740447998\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0037623229436576366 \t\t Loss_Fake: 0.9872275590896606\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.007561203092336655 \t\t Generator Loss: 0.40667977929115295 \t\t Total Loss: 0.4142409861087799\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0037438205908983946 \t\t Loss_Fake: 0.9870265126228333\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.007077218499034643 \t\t Generator Loss: 0.4064182639122009 \t\t Total Loss: 0.4134954810142517\n",
            "\t\t\t\t Discriminator Loss_Real: 0.003535669296979904 \t\t Loss_Fake: 0.9868177175521851\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.0072374953888356686 \t\t Generator Loss: 0.40529489517211914 \t\t Total Loss: 0.41253238916397095\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0035423077642917633 \t\t Loss_Fake: 0.986302375793457\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.008040761575102806 \t\t Generator Loss: 0.40326204895973206 \t\t Total Loss: 0.4113028049468994\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0038280622102320194 \t\t Loss_Fake: 0.9857263565063477\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.008514289744198322 \t\t Generator Loss: 0.4031293988227844 \t\t Total Loss: 0.4116436839103699\n",
            "\t\t\t\t Discriminator Loss_Real: 0.004095372743904591 \t\t Loss_Fake: 0.9852892160415649\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.009045712649822235 \t\t Generator Loss: 0.4043601155281067 \t\t Total Loss: 0.4134058356285095\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0041275667026638985 \t\t Loss_Fake: 0.9848729968070984\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.009352998808026314 \t\t Generator Loss: 0.4076681137084961 \t\t Total Loss: 0.41702112555503845\n",
            "\t\t\t\t Discriminator Loss_Real: 0.004022842273116112 \t\t Loss_Fake: 0.9847350120544434\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.009640149772167206 \t\t Generator Loss: 0.4080675542354584 \t\t Total Loss: 0.4177077114582062\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0037664626725018024 \t\t Loss_Fake: 0.9846188426017761\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.009234080091118813 \t\t Generator Loss: 0.40778160095214844 \t\t Total Loss: 0.4170156717300415\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0035339822061359882 \t\t Loss_Fake: 0.984285831451416\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.009889972396194935 \t\t Generator Loss: 0.406931072473526 \t\t Total Loss: 0.41682103276252747\n",
            "\t\t\t\t Discriminator Loss_Real: 0.003675181418657303 \t\t Loss_Fake: 0.9833759069442749\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.011268870905041695 \t\t Generator Loss: 0.40707793831825256 \t\t Total Loss: 0.4183468222618103\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0042252978309988976 \t\t Loss_Fake: 0.9819672703742981\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.014092354103922844 \t\t Generator Loss: 0.4073360562324524 \t\t Total Loss: 0.4214284121990204\n",
            "\t\t\t\t Discriminator Loss_Real: 0.006255061831325293 \t\t Loss_Fake: 0.9809539914131165\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.013206462375819683 \t\t Generator Loss: 0.4071950316429138 \t\t Total Loss: 0.4204014837741852\n",
            "\t\t\t\t Discriminator Loss_Real: 0.005228598602116108 \t\t Loss_Fake: 0.981463611125946\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.012172622606158257 \t\t Generator Loss: 0.4077736735343933 \t\t Total Loss: 0.4199462831020355\n",
            "\t\t\t\t Discriminator Loss_Real: 0.004348442889750004 \t\t Loss_Fake: 0.9799410700798035\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.02382921427488327 \t\t Generator Loss: 0.40774407982826233 \t\t Total Loss: 0.4315733015537262\n",
            "\t\t\t\t Discriminator Loss_Real: 0.011269320733845234 \t\t Loss_Fake: 0.9839587211608887\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.008481990545988083 \t\t Generator Loss: 0.4079245626926422 \t\t Total Loss: 0.4164065420627594\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0022915280424058437 \t\t Loss_Fake: 0.9851250648498535\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.010621531866490841 \t\t Generator Loss: 0.41771286725997925 \t\t Total Loss: 0.42833438515663147\n",
            "\t\t\t\t Discriminator Loss_Real: 0.002377917058765888 \t\t Loss_Fake: 0.9841327667236328\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.01446609664708376 \t\t Generator Loss: 0.4184997081756592 \t\t Total Loss: 0.43296581506729126\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0030360971577465534 \t\t Loss_Fake: 0.983504593372345\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.014165282249450684 \t\t Generator Loss: 0.4183853268623352 \t\t Total Loss: 0.4325506091117859\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0029204341117292643 \t\t Loss_Fake: 0.9832143783569336\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.01191643811762333 \t\t Generator Loss: 0.4184783101081848 \t\t Total Loss: 0.4303947389125824\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0027387358713895082 \t\t Loss_Fake: 0.9831043481826782\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.013615521602332592 \t\t Generator Loss: 0.4194110929965973 \t\t Total Loss: 0.43302661180496216\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0033672458957880735 \t\t Loss_Fake: 0.9818814396858215\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.01730463281273842 \t\t Generator Loss: 0.4187648892402649 \t\t Total Loss: 0.436069518327713\n",
            "\t\t\t\t Discriminator Loss_Real: 0.003942173905670643 \t\t Loss_Fake: 0.9815425872802734\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.01457285601645708 \t\t Generator Loss: 0.4190158247947693 \t\t Total Loss: 0.4335886836051941\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00325353373773396 \t\t Loss_Fake: 0.9822565317153931\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.014137649908661842 \t\t Generator Loss: 0.41974949836730957 \t\t Total Loss: 0.43388715386390686\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0029085904825478792 \t\t Loss_Fake: 0.981498122215271\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.01741751655936241 \t\t Generator Loss: 0.419750839471817 \t\t Total Loss: 0.4371683597564697\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0030186905059963465 \t\t Loss_Fake: 0.9812939763069153\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.014939757995307446 \t\t Generator Loss: 0.42006832361221313 \t\t Total Loss: 0.43500807881355286\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0026532902847975492 \t\t Loss_Fake: 0.981671154499054\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.01672051101922989 \t\t Generator Loss: 0.42424720525741577 \t\t Total Loss: 0.44096770882606506\n",
            "\t\t\t\t Discriminator Loss_Real: 0.002801872557029128 \t\t Loss_Fake: 0.9806147813796997\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.018093015998601913 \t\t Generator Loss: 0.4243241846561432 \t\t Total Loss: 0.4424172043800354\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0028711012564599514 \t\t Loss_Fake: 0.9806265830993652\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.017160475254058838 \t\t Generator Loss: 0.42481908202171326 \t\t Total Loss: 0.4419795572757721\n",
            "\t\t\t\t Discriminator Loss_Real: 0.002708002459257841 \t\t Loss_Fake: 0.9799162745475769\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.01903911679983139 \t\t Generator Loss: 0.42508944869041443 \t\t Total Loss: 0.4441285729408264\n",
            "\t\t\t\t Discriminator Loss_Real: 0.002796490676701069 \t\t Loss_Fake: 0.9794297218322754\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.018601085990667343 \t\t Generator Loss: 0.42541271448135376 \t\t Total Loss: 0.4440138041973114\n",
            "\t\t\t\t Discriminator Loss_Real: 0.002801683731377125 \t\t Loss_Fake: 0.9785500764846802\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.023099157959222794 \t\t Generator Loss: 0.42632991075515747 \t\t Total Loss: 0.44942906498908997\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0035898066125810146 \t\t Loss_Fake: 0.9754385948181152\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.03295200318098068 \t\t Generator Loss: 0.42777642607688904 \t\t Total Loss: 0.4607284367084503\n",
            "\t\t\t\t Discriminator Loss_Real: 0.010687889531254768 \t\t Loss_Fake: 0.9827693700790405\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.017952008172869682 \t\t Generator Loss: 0.42768439650535583 \t\t Total Loss: 0.4456363916397095\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0021182463970035315 \t\t Loss_Fake: 0.9809175729751587\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.026838725432753563 \t\t Generator Loss: 0.4269788861274719 \t\t Total Loss: 0.45381760597229004\n",
            "\t\t\t\t Discriminator Loss_Real: 0.002584232483059168 \t\t Loss_Fake: 0.9794934988021851\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.015289406292140484 \t\t Generator Loss: 0.42796868085861206 \t\t Total Loss: 0.4432580769062042\n",
            "\t\t\t\t Discriminator Loss_Real: 0.002545819850638509 \t\t Loss_Fake: 0.9787122011184692\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.0359533354640007 \t\t Generator Loss: 0.4248381555080414 \t\t Total Loss: 0.4607914984226227\n",
            "\t\t\t\t Discriminator Loss_Real: 0.009443214163184166 \t\t Loss_Fake: 0.9813094139099121\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.024139460176229477 \t\t Generator Loss: 0.42243894934654236 \t\t Total Loss: 0.44657841324806213\n",
            "\t\t\t\t Discriminator Loss_Real: 0.001639459514990449 \t\t Loss_Fake: 0.9819733500480652\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.01425344031304121 \t\t Generator Loss: 0.422050803899765 \t\t Total Loss: 0.4363042414188385\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0009975587017834187 \t\t Loss_Fake: 0.9823325276374817\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.02163836732506752 \t\t Generator Loss: 0.4215555787086487 \t\t Total Loss: 0.4431939423084259\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0014969240874052048 \t\t Loss_Fake: 0.98139488697052\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.027186661958694458 \t\t Generator Loss: 0.42245155572891235 \t\t Total Loss: 0.4496382176876068\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0020522833801805973 \t\t Loss_Fake: 0.9799930453300476\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.015258116647601128 \t\t Generator Loss: 0.4204801023006439 \t\t Total Loss: 0.435738205909729\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0013132081367075443 \t\t Loss_Fake: 0.9822145700454712\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.0202613677829504 \t\t Generator Loss: 0.4204477369785309 \t\t Total Loss: 0.44070911407470703\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0016352121019735932 \t\t Loss_Fake: 0.979460597038269\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.029384490102529526 \t\t Generator Loss: 0.4208165109157562 \t\t Total Loss: 0.45020100474357605\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0025081404019147158 \t\t Loss_Fake: 0.9788565635681152\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.018856141716241837 \t\t Generator Loss: 0.4203527867794037 \t\t Total Loss: 0.4392089247703552\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0015706000849604607 \t\t Loss_Fake: 0.9803920984268188\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.020889144390821457 \t\t Generator Loss: 0.4200940728187561 \t\t Total Loss: 0.44098320603370667\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0016190602909773588 \t\t Loss_Fake: 0.9780485033988953\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.028121313080191612 \t\t Generator Loss: 0.41590356826782227 \t\t Total Loss: 0.4440248906612396\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0021360605023801327 \t\t Loss_Fake: 0.9762412309646606\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.024835776537656784 \t\t Generator Loss: 0.41657084226608276 \t\t Total Loss: 0.44140660762786865\n",
            "\t\t\t\t Discriminator Loss_Real: 0.002598646329715848 \t\t Loss_Fake: 0.9699371457099915\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.08466030657291412 \t\t Generator Loss: 0.41594967246055603 \t\t Total Loss: 0.5006099939346313\n",
            "\t\t\t\t Discriminator Loss_Real: 0.05102856829762459 \t\t Loss_Fake: 0.9724776148796082\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.010105530731379986 \t\t Generator Loss: 0.4155349135398865 \t\t Total Loss: 0.42564043402671814\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0009429492056369781 \t\t Loss_Fake: 0.9867332577705383\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.01644684001803398 \t\t Generator Loss: 0.4155914783477783 \t\t Total Loss: 0.4320383071899414\n",
            "\t\t\t\t Discriminator Loss_Real: 0.000991456676274538 \t\t Loss_Fake: 0.9836864471435547\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.03592614829540253 \t\t Generator Loss: 0.4141330122947693 \t\t Total Loss: 0.450059175491333\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0029472263995558023 \t\t Loss_Fake: 0.9839648008346558\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.03239605575799942 \t\t Generator Loss: 0.4135751724243164 \t\t Total Loss: 0.44597122073173523\n",
            "\t\t\t\t Discriminator Loss_Real: 0.002076429082080722 \t\t Loss_Fake: 0.9821603894233704\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.01735902763903141 \t\t Generator Loss: 0.41319194436073303 \t\t Total Loss: 0.4305509626865387\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0010296065593138337 \t\t Loss_Fake: 0.9825030565261841\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.021558990702033043 \t\t Generator Loss: 0.4097267985343933 \t\t Total Loss: 0.4312857985496521\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0012539050076156855 \t\t Loss_Fake: 0.979975700378418\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.02945612743496895 \t\t Generator Loss: 0.41311612725257874 \t\t Total Loss: 0.4425722658634186\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0018491607625037432 \t\t Loss_Fake: 0.9795311689376831\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.019896939396858215 \t\t Generator Loss: 0.40949177742004395 \t\t Total Loss: 0.42938870191574097\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0012353742495179176 \t\t Loss_Fake: 0.9808558225631714\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.02260272577404976 \t\t Generator Loss: 0.4083224833011627 \t\t Total Loss: 0.4309252202510834\n",
            "\t\t\t\t Discriminator Loss_Real: 0.001283052726648748 \t\t Loss_Fake: 0.9787586331367493\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.03131451457738876 \t\t Generator Loss: 0.40992259979248047 \t\t Total Loss: 0.44123712182044983\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0018136914586648345 \t\t Loss_Fake: 0.9784847497940063\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.020786026492714882 \t\t Generator Loss: 0.40900760889053345 \t\t Total Loss: 0.4297936260700226\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0012284473050385714 \t\t Loss_Fake: 0.9805773496627808\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.02008737623691559 \t\t Generator Loss: 0.41044455766677856 \t\t Total Loss: 0.43053191900253296\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0013299104757606983 \t\t Loss_Fake: 0.9778342247009277\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.03021942637860775 \t\t Generator Loss: 0.4097939133644104 \t\t Total Loss: 0.4400133490562439\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0020510784815996885 \t\t Loss_Fake: 0.9773540496826172\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.020714832469820976 \t\t Generator Loss: 0.4094208776950836 \t\t Total Loss: 0.43013569712638855\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0014619999565184116 \t\t Loss_Fake: 0.9784553647041321\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.0204039104282856 \t\t Generator Loss: 0.4089256227016449 \t\t Total Loss: 0.4293295443058014\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0014545792946591973 \t\t Loss_Fake: 0.9764194488525391\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.028783489018678665 \t\t Generator Loss: 0.4081938862800598 \t\t Total Loss: 0.4369773864746094\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0019279478583484888 \t\t Loss_Fake: 0.9759324789047241\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.023303160443902016 \t\t Generator Loss: 0.40823525190353394 \t\t Total Loss: 0.4315384030342102\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0014501772820949554 \t\t Loss_Fake: 0.9753677248954773\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.02577146515250206 \t\t Generator Loss: 0.41613951325416565 \t\t Total Loss: 0.441910982131958\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0019295761594548821 \t\t Loss_Fake: 0.9681777954101562\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.05870983004570007 \t\t Generator Loss: 0.4186810851097107 \t\t Total Loss: 0.47739091515541077\n",
            "\t\t\t\t Discriminator Loss_Real: 0.014303037896752357 \t\t Loss_Fake: 0.9766748547554016\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.021360088139772415 \t\t Generator Loss: 0.4178057610988617 \t\t Total Loss: 0.439165860414505\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0010530657600611448 \t\t Loss_Fake: 0.9763965606689453\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.029442567378282547 \t\t Generator Loss: 0.4165283143520355 \t\t Total Loss: 0.44597089290618896\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0013290338683873415 \t\t Loss_Fake: 0.9755498170852661\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.03143744915723801 \t\t Generator Loss: 0.4207324981689453 \t\t Total Loss: 0.4521699547767639\n",
            "\t\t\t\t Discriminator Loss_Real: 0.001855670241639018 \t\t Loss_Fake: 0.9717742800712585\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.051822226494550705 \t\t Generator Loss: 0.420564740896225 \t\t Total Loss: 0.4723869562149048\n",
            "\t\t\t\t Discriminator Loss_Real: 0.006246132310479879 \t\t Loss_Fake: 0.9700581431388855\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.057699054479599 \t\t Generator Loss: 0.42632025480270386 \t\t Total Loss: 0.48401930928230286\n",
            "\t\t\t\t Discriminator Loss_Real: 0.006605344824492931 \t\t Loss_Fake: 0.9710999727249146\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.05798565223813057 \t\t Generator Loss: 0.4283429682254791 \t\t Total Loss: 0.4863286316394806\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0028219795785844326 \t\t Loss_Fake: 0.965643584728241\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.042143285274505615 \t\t Generator Loss: 0.4259072244167328 \t\t Total Loss: 0.4680505096912384\n",
            "\t\t\t\t Discriminator Loss_Real: 0.001033260952681303 \t\t Loss_Fake: 0.9696918725967407\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.09639470279216766 \t\t Generator Loss: 0.42472800612449646 \t\t Total Loss: 0.5211226940155029\n",
            "\t\t\t\t Discriminator Loss_Real: 0.02096116915345192 \t\t Loss_Fake: 0.9682387113571167\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.016349518671631813 \t\t Generator Loss: 0.41852402687072754 \t\t Total Loss: 0.4348735511302948\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00039377855136990547 \t\t Loss_Fake: 0.9815605878829956\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.036263395100831985 \t\t Generator Loss: 0.41985297203063965 \t\t Total Loss: 0.45611637830734253\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0007889391854405403 \t\t Loss_Fake: 0.980514645576477\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.06529947370290756 \t\t Generator Loss: 0.41638293862342834 \t\t Total Loss: 0.4816824197769165\n",
            "\t\t\t\t Discriminator Loss_Real: 0.006429496221244335 \t\t Loss_Fake: 0.9783228039741516\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.05643322318792343 \t\t Generator Loss: 0.4163234233856201 \t\t Total Loss: 0.47275665402412415\n",
            "\t\t\t\t Discriminator Loss_Real: 0.002693729242309928 \t\t Loss_Fake: 0.9673005938529968\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.1036527156829834 \t\t Generator Loss: 0.41868895292282104 \t\t Total Loss: 0.5223416686058044\n",
            "\t\t\t\t Discriminator Loss_Real: 0.019468728452920914 \t\t Loss_Fake: 0.9739810824394226\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.0022919464390724897 \t\t Generator Loss: 0.4138881266117096 \t\t Total Loss: 0.4161800742149353\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00020109470642637461 \t\t Loss_Fake: 0.9979866743087769\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.00025366255431436 \t\t Generator Loss: 0.41236376762390137 \t\t Total Loss: 0.41261744499206543\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0002895650686696172 \t\t Loss_Fake: 0.9988416433334351\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.0003046714118681848 \t\t Generator Loss: 0.411304235458374 \t\t Total Loss: 0.41160890460014343\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0004241286660544574 \t\t Loss_Fake: 0.9985968470573425\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.00047850474948063493 \t\t Generator Loss: 0.40935808420181274 \t\t Total Loss: 0.4098365902900696\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0006111494149081409 \t\t Loss_Fake: 0.9976764917373657\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.001702967332676053 \t\t Generator Loss: 0.40738701820373535 \t\t Total Loss: 0.40908998250961304\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0015088632935658097 \t\t Loss_Fake: 0.9931963682174683\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.04793093726038933 \t\t Generator Loss: 0.41107988357543945 \t\t Total Loss: 0.4590108096599579\n",
            "\t\t\t\t Discriminator Loss_Real: 0.04606753587722778 \t\t Loss_Fake: 0.993542492389679\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.0007353979744948447 \t\t Generator Loss: 0.40992575883865356 \t\t Total Loss: 0.41066116094589233\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0003714321064762771 \t\t Loss_Fake: 0.9978452920913696\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.0006820333073846996 \t\t Generator Loss: 0.4085778295993805 \t\t Total Loss: 0.4092598557472229\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00029019018984399736 \t\t Loss_Fake: 0.9959920048713684\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.010623148642480373 \t\t Generator Loss: 0.40825003385543823 \t\t Total Loss: 0.4188731908798218\n",
            "\t\t\t\t Discriminator Loss_Real: 0.003142033936455846 \t\t Loss_Fake: 0.9953648447990417\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.003533559385687113 \t\t Generator Loss: 0.4065348505973816 \t\t Total Loss: 0.41006842255592346\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00039151767850853503 \t\t Loss_Fake: 0.9949043393135071\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.006057601422071457 \t\t Generator Loss: 0.40589842200279236 \t\t Total Loss: 0.4119560122489929\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0005319262854754925 \t\t Loss_Fake: 0.9945885539054871\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.011109324172139168 \t\t Generator Loss: 0.40511569380760193 \t\t Total Loss: 0.41622501611709595\n",
            "\t\t\t\t Discriminator Loss_Real: 0.001434694742783904 \t\t Loss_Fake: 0.9949566125869751\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.004185495898127556 \t\t Generator Loss: 0.40158289670944214 \t\t Total Loss: 0.40576839447021484\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0005584746832028031 \t\t Loss_Fake: 0.9938116073608398\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.017528057098388672 \t\t Generator Loss: 0.405371755361557 \t\t Total Loss: 0.4228998124599457\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0023194458335638046 \t\t Loss_Fake: 0.9939392805099487\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.005286757834255695 \t\t Generator Loss: 0.4046964645385742 \t\t Total Loss: 0.40998321771621704\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0006803273572586477 \t\t Loss_Fake: 0.9922374486923218\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.013066927902400494 \t\t Generator Loss: 0.3999297022819519 \t\t Total Loss: 0.4129966199398041\n",
            "\t\t\t\t Discriminator Loss_Real: 0.001156509737484157 \t\t Loss_Fake: 0.9911447763442993\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.024361860007047653 \t\t Generator Loss: 0.3983302712440491 \t\t Total Loss: 0.42269212007522583\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00348443235270679 \t\t Loss_Fake: 0.9940407872200012\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.003645270364359021 \t\t Generator Loss: 0.3950587213039398 \t\t Total Loss: 0.39870399236679077\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0014824416721239686 \t\t Loss_Fake: 0.9931951761245728\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.010831483639776707 \t\t Generator Loss: 0.39807915687561035 \t\t Total Loss: 0.4089106321334839\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0021111448295414448 \t\t Loss_Fake: 0.9898903965950012\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.023872073739767075 \t\t Generator Loss: 0.4019445776939392 \t\t Total Loss: 0.4258166551589966\n",
            "\t\t\t\t Discriminator Loss_Real: 0.005314665846526623 \t\t Loss_Fake: 0.991710364818573\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.008235071785748005 \t\t Generator Loss: 0.3942502737045288 \t\t Total Loss: 0.40248534083366394\n",
            "\t\t\t\t Discriminator Loss_Real: 0.005639476235955954 \t\t Loss_Fake: 0.990750789642334\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.008850855752825737 \t\t Generator Loss: 0.39594656229019165 \t\t Total Loss: 0.40479740500450134\n",
            "\t\t\t\t Discriminator Loss_Real: 0.006193749140948057 \t\t Loss_Fake: 0.993278980255127\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.002048765541985631 \t\t Generator Loss: 0.39473599195480347 \t\t Total Loss: 0.3967847526073456\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0014121872372925282 \t\t Loss_Fake: 0.9925563931465149\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.008405134081840515 \t\t Generator Loss: 0.39805659651756287 \t\t Total Loss: 0.4064617156982422\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0027382411062717438 \t\t Loss_Fake: 0.984950065612793\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.06314501166343689 \t\t Generator Loss: 0.4002005457878113 \t\t Total Loss: 0.46334555745124817\n",
            "\t\t\t\t Discriminator Loss_Real: 0.057004522532224655 \t\t Loss_Fake: 0.9887480735778809\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.07136789709329605 \t\t Generator Loss: 0.38401564955711365 \t\t Total Loss: 0.4553835391998291\n",
            "\t\t\t\t Discriminator Loss_Real: 0.06167110800743103 \t\t Loss_Fake: 0.9857832789421082\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.06897224485874176 \t\t Generator Loss: 0.382592111825943 \t\t Total Loss: 0.45156437158584595\n",
            "\t\t\t\t Discriminator Loss_Real: 0.06048084422945976 \t\t Loss_Fake: 0.984630286693573\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.07199149578809738 \t\t Generator Loss: 0.37511929869651794 \t\t Total Loss: 0.4471108019351959\n",
            "\t\t\t\t Discriminator Loss_Real: 0.059249550104141235 \t\t Loss_Fake: 0.9792425036430359\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.09839663654565811 \t\t Generator Loss: 0.3773941397666931 \t\t Total Loss: 0.47579076886177063\n",
            "\t\t\t\t Discriminator Loss_Real: 0.062471985816955566 \t\t Loss_Fake: 0.9832255244255066\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.004178022965788841 \t\t Generator Loss: 0.38605695962905884 \t\t Total Loss: 0.39023497700691223\n",
            "\t\t\t\t Discriminator Loss_Real: 0.001527602900750935 \t\t Loss_Fake: 0.9912129640579224\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.011262976564466953 \t\t Generator Loss: 0.3751985728740692 \t\t Total Loss: 0.3864615559577942\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0029327457305043936 \t\t Loss_Fake: 0.9873180389404297\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.03155020996928215 \t\t Generator Loss: 0.38490980863571167 \t\t Total Loss: 0.4164600074291229\n",
            "\t\t\t\t Discriminator Loss_Real: 0.013951510190963745 \t\t Loss_Fake: 0.995034396648407\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.003284173086285591 \t\t Generator Loss: 0.38384053111076355 \t\t Total Loss: 0.3871247172355652\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0008401898667216301 \t\t Loss_Fake: 0.9934478998184204\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.007342605385929346 \t\t Generator Loss: 0.37502676248550415 \t\t Total Loss: 0.38236936926841736\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0009564150823280215 \t\t Loss_Fake: 0.9920781850814819\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.008764246478676796 \t\t Generator Loss: 0.379229873418808 \t\t Total Loss: 0.38799411058425903\n",
            "\t\t\t\t Discriminator Loss_Real: 0.001265329890884459 \t\t Loss_Fake: 0.9902969598770142\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.017633486539125443 \t\t Generator Loss: 0.38662785291671753 \t\t Total Loss: 0.40426135063171387\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0017238107975572348 \t\t Loss_Fake: 0.9834849238395691\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.03330528363585472 \t\t Generator Loss: 0.4102846086025238 \t\t Total Loss: 0.4435898959636688\n",
            "\t\t\t\t Discriminator Loss_Real: 0.006002321839332581 \t\t Loss_Fake: 0.9447634816169739\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.7518371343612671 \t\t Generator Loss: 0.43037018179893494 \t\t Total Loss: 1.1822073459625244\n",
            "\t\t\t\t Discriminator Loss_Real: 0.6433552503585815 \t\t Loss_Fake: 0.9681301116943359\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.2086612433195114 \t\t Generator Loss: 0.43347588181495667 \t\t Total Loss: 0.6421371102333069\n",
            "\t\t\t\t Discriminator Loss_Real: 0.17342612147331238 \t\t Loss_Fake: 0.9834683537483215\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.006224976386874914 \t\t Generator Loss: 0.43255504965782166 \t\t Total Loss: 0.4387800395488739\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0046930196695029736 \t\t Loss_Fake: 0.9987845420837402\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 9.353642963105813e-05 \t\t Generator Loss: 0.43254750967025757 \t\t Total Loss: 0.43264105916023254\n",
            "\t\t\t\t Discriminator Loss_Real: 8.282998169306666e-05 \t\t Loss_Fake: 0.9996894001960754\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 2.2740823624189943e-05 \t\t Generator Loss: 0.42997732758522034 \t\t Total Loss: 0.43000006675720215\n",
            "\t\t\t\t Discriminator Loss_Real: 1.996830542339012e-05 \t\t Loss_Fake: 0.999836266040802\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 1.3680581105290912e-05 \t\t Generator Loss: 0.4307485520839691 \t\t Total Loss: 0.43076223134994507\n",
            "\t\t\t\t Discriminator Loss_Real: 1.2216010873089544e-05 \t\t Loss_Fake: 0.9998811483383179\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 1.0760030818346422e-05 \t\t Generator Loss: 0.42857280373573303 \t\t Total Loss: 0.428583562374115\n",
            "\t\t\t\t Discriminator Loss_Real: 9.637693437980488e-06 \t\t Loss_Fake: 0.9998995661735535\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 9.184474038193002e-06 \t\t Generator Loss: 0.42792797088623047 \t\t Total Loss: 0.4279371500015259\n",
            "\t\t\t\t Discriminator Loss_Real: 8.516306479577906e-06 \t\t Loss_Fake: 0.9999086260795593\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 8.259513379016425e-06 \t\t Generator Loss: 0.4273627698421478 \t\t Total Loss: 0.4273710250854492\n",
            "\t\t\t\t Discriminator Loss_Real: 7.705185453232843e-06 \t\t Loss_Fake: 0.9999130368232727\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 7.589839697175194e-06 \t\t Generator Loss: 0.42764806747436523 \t\t Total Loss: 0.4276556670665741\n",
            "\t\t\t\t Discriminator Loss_Real: 7.18051296644262e-06 \t\t Loss_Fake: 0.9999145269393921\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 7.3191122282878496e-06 \t\t Generator Loss: 0.4265812337398529 \t\t Total Loss: 0.4265885651111603\n",
            "\t\t\t\t Discriminator Loss_Real: 6.872452559036901e-06 \t\t Loss_Fake: 0.9999138116836548\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 7.14652696842677e-06 \t\t Generator Loss: 0.4254552721977234 \t\t Total Loss: 0.42546242475509644\n",
            "\t\t\t\t Discriminator Loss_Real: 6.770897016394883e-06 \t\t Loss_Fake: 0.9999111294746399\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 7.247871508297976e-06 \t\t Generator Loss: 0.4253029227256775 \t\t Total Loss: 0.4253101646900177\n",
            "\t\t\t\t Discriminator Loss_Real: 6.876415227452526e-06 \t\t Loss_Fake: 0.9999063611030579\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 7.593768714286853e-06 \t\t Generator Loss: 0.42514950037002563 \t\t Total Loss: 0.4251570999622345\n",
            "\t\t\t\t Discriminator Loss_Real: 7.269575235113734e-06 \t\t Loss_Fake: 0.9998992085456848\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 8.28347765491344e-06 \t\t Generator Loss: 0.42491379380226135 \t\t Total Loss: 0.42492207884788513\n",
            "\t\t\t\t Discriminator Loss_Real: 8.024042472243309e-06 \t\t Loss_Fake: 0.9998893737792969\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 9.484049769525882e-06 \t\t Generator Loss: 0.4248388409614563 \t\t Total Loss: 0.4248483180999756\n",
            "\t\t\t\t Discriminator Loss_Real: 9.296732059738133e-06 \t\t Loss_Fake: 0.9998757243156433\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 1.1485887625894975e-05 \t\t Generator Loss: 0.42439502477645874 \t\t Total Loss: 0.424406498670578\n",
            "\t\t\t\t Discriminator Loss_Real: 1.1422313946241047e-05 \t\t Loss_Fake: 0.9998575448989868\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 1.489992700953735e-05 \t\t Generator Loss: 0.42354756593704224 \t\t Total Loss: 0.4235624670982361\n",
            "\t\t\t\t Discriminator Loss_Real: 1.483375126554165e-05 \t\t Loss_Fake: 0.9998325109481812\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 2.0827341359108686e-05 \t\t Generator Loss: 0.4260646402835846 \t\t Total Loss: 0.4260854721069336\n",
            "\t\t\t\t Discriminator Loss_Real: 2.1054491298855282e-05 \t\t Loss_Fake: 0.9997989535331726\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 3.178118640789762e-05 \t\t Generator Loss: 0.4260343611240387 \t\t Total Loss: 0.426066130399704\n",
            "\t\t\t\t Discriminator Loss_Real: 3.2340947655029595e-05 \t\t Loss_Fake: 0.9997531175613403\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 5.2195071475580335e-05 \t\t Generator Loss: 0.4269726276397705 \t\t Total Loss: 0.42702481150627136\n",
            "\t\t\t\t Discriminator Loss_Real: 5.300943666952662e-05 \t\t Loss_Fake: 0.9996965527534485\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 8.748564141569659e-05 \t\t Generator Loss: 0.4256521165370941 \t\t Total Loss: 0.4257396161556244\n",
            "\t\t\t\t Discriminator Loss_Real: 8.900508692022413e-05 \t\t Loss_Fake: 0.9996360540390015\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.00013934608432464302 \t\t Generator Loss: 0.4261942505836487 \t\t Total Loss: 0.42633360624313354\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00014218340220395476 \t\t Loss_Fake: 0.9995844960212708\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.00019527963013388216 \t\t Generator Loss: 0.42539292573928833 \t\t Total Loss: 0.4255881905555725\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0001980844244826585 \t\t Loss_Fake: 0.9995549917221069\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.00022460092441178858 \t\t Generator Loss: 0.42416200041770935 \t\t Total Loss: 0.424386590719223\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0002279978507431224 \t\t Loss_Fake: 0.9995500445365906\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.00021372742776293308 \t\t Generator Loss: 0.4239334464073181 \t\t Total Loss: 0.42414718866348267\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00021712659508921206 \t\t Loss_Fake: 0.9995638728141785\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.00017701982869766653 \t\t Generator Loss: 0.4242030680179596 \t\t Total Loss: 0.4243800938129425\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00017969663895200938 \t\t Loss_Fake: 0.9995914697647095\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.00013709333143197 \t\t Generator Loss: 0.4241310656070709 \t\t Total Loss: 0.4242681562900543\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00014030507009010762 \t\t Loss_Fake: 0.9996218681335449\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.00010898255277425051 \t\t Generator Loss: 0.40485209226608276 \t\t Total Loss: 0.40496107935905457\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00011120217095594853 \t\t Loss_Fake: 0.999646008014679\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 9.225333633366972e-05 \t\t Generator Loss: 0.4043894410133362 \t\t Total Loss: 0.4044817090034485\n",
            "\t\t\t\t Discriminator Loss_Real: 9.453866368858144e-05 \t\t Loss_Fake: 0.9996600151062012\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 8.604606409789994e-05 \t\t Generator Loss: 0.40410226583480835 \t\t Total Loss: 0.4041883051395416\n",
            "\t\t\t\t Discriminator Loss_Real: 8.791770233074203e-05 \t\t Loss_Fake: 0.9996620416641235\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 8.70390358613804e-05 \t\t Generator Loss: 0.40375199913978577 \t\t Total Loss: 0.4038390517234802\n",
            "\t\t\t\t Discriminator Loss_Real: 8.90834053279832e-05 \t\t Loss_Fake: 0.9996554255485535\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 9.455631516175345e-05 \t\t Generator Loss: 0.40361863374710083 \t\t Total Loss: 0.403713196516037\n",
            "\t\t\t\t Discriminator Loss_Real: 9.630634303903207e-05 \t\t Loss_Fake: 0.9996406435966492\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.00010698659025365487 \t\t Generator Loss: 0.40420475602149963 \t\t Total Loss: 0.40431174635887146\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00010893277067225426 \t\t Loss_Fake: 0.9996235966682434\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.00012241177319083363 \t\t Generator Loss: 0.4041052758693695 \t\t Total Loss: 0.40422767400741577\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00012457201955839992 \t\t Loss_Fake: 0.9996057748794556\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.00013752272934652865 \t\t Generator Loss: 0.4040498733520508 \t\t Total Loss: 0.4041873812675476\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00013970627333037555 \t\t Loss_Fake: 0.9995927810668945\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.00014777228352613747 \t\t Generator Loss: 0.4039309620857239 \t\t Total Loss: 0.40407872200012207\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00015016864927019924 \t\t Loss_Fake: 0.999584972858429\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.0001510968868387863 \t\t Generator Loss: 0.4037989675998688 \t\t Total Loss: 0.4039500653743744\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0001531322195660323 \t\t Loss_Fake: 0.9995841979980469\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.0001469432609155774 \t\t Generator Loss: 0.3963415026664734 \t\t Total Loss: 0.3964884579181671\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0001489481219323352 \t\t Loss_Fake: 0.9995878338813782\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.0001388679229421541 \t\t Generator Loss: 0.39612630009651184 \t\t Total Loss: 0.3962651789188385\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0001403971400577575 \t\t Loss_Fake: 0.9995942115783691\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.00012957365834154189 \t\t Generator Loss: 0.39587709307670593 \t\t Total Loss: 0.39600667357444763\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00013101173681207 \t\t Loss_Fake: 0.9995999336242676\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.00012241906370036304 \t\t Generator Loss: 0.39554455876350403 \t\t Total Loss: 0.3956669867038727\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00012342361151240766 \t\t Loss_Fake: 0.9996035695075989\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.00011792057193815708 \t\t Generator Loss: 0.39451050758361816 \t\t Total Loss: 0.3946284353733063\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00011914123024325818 \t\t Loss_Fake: 0.9996036291122437\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.00011526448361109942 \t\t Generator Loss: 0.3927423357963562 \t\t Total Loss: 0.3928576111793518\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00011802903463831171 \t\t Loss_Fake: 0.9996010661125183\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.0001186149165732786 \t\t Generator Loss: 0.39194339513778687 \t\t Total Loss: 0.3920620083808899\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00011992764484602958 \t\t Loss_Fake: 0.999592661857605\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.00012234633322805166 \t\t Generator Loss: 0.3923127055168152 \t\t Total Loss: 0.3924350440502167\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00012403252185322344 \t\t Loss_Fake: 0.9995832443237305\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.00012561636685859412 \t\t Generator Loss: 0.39292407035827637 \t\t Total Loss: 0.3930496871471405\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0001292616070713848 \t\t Loss_Fake: 0.9995716214179993\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.00013240946282166988 \t\t Generator Loss: 0.39140981435775757 \t\t Total Loss: 0.3915422260761261\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0001359634770778939 \t\t Loss_Fake: 0.9995598793029785\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.00013492682774085552 \t\t Generator Loss: 0.40546512603759766 \t\t Total Loss: 0.40560004115104675\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0001397479500155896 \t\t Loss_Fake: 0.9995473623275757\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.00013803550973534584 \t\t Generator Loss: 0.4055563807487488 \t\t Total Loss: 0.4056944251060486\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00014187581837177277 \t\t Loss_Fake: 0.9995322227478027\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.00013867356756236404 \t\t Generator Loss: 0.4052456021308899 \t\t Total Loss: 0.40538427233695984\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00014295759319793433 \t\t Loss_Fake: 0.9995134472846985\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.00014102141722105443 \t\t Generator Loss: 0.4054436683654785 \t\t Total Loss: 0.4055846929550171\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00014458646182902157 \t\t Loss_Fake: 0.9994871020317078\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.00014612250379286706 \t\t Generator Loss: 0.4055759012699127 \t\t Total Loss: 0.4057220220565796\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0001485124375903979 \t\t Loss_Fake: 0.9994493722915649\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.00016147081623785198 \t\t Generator Loss: 0.4053436815738678 \t\t Total Loss: 0.40550515055656433\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00016167611465789378 \t\t Loss_Fake: 0.9993985891342163\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.0001910971332108602 \t\t Generator Loss: 0.4051826000213623 \t\t Total Loss: 0.4053736925125122\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0001900184724945575 \t\t Loss_Fake: 0.9993389844894409\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.00024516499252058566 \t\t Generator Loss: 0.40475955605506897 \t\t Total Loss: 0.40500470995903015\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00023841443180572242 \t\t Loss_Fake: 0.9992850422859192\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.00030432065250352025 \t\t Generator Loss: 0.40446537733078003 \t\t Total Loss: 0.4047696888446808\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00029514572815969586 \t\t Loss_Fake: 0.9992520213127136\n",
            "\n",
            "Epoch: 0 \t Discriminator Loss: 0.00034239242086187005 \t\t Generator Loss: 0.4041305184364319 \t\t Total Loss: 0.4044729173183441\n",
            "Epoch 2 started\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00032750144600868225 \t\t Loss_Fake: 0.9992427825927734\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0003331502084620297 \t\t Generator Loss: 0.3980081379413605 \t\t Total Loss: 0.3983412981033325\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0003184503293596208 \t\t Loss_Fake: 0.9992542266845703\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0002922483254224062 \t\t Generator Loss: 0.3977304995059967 \t\t Total Loss: 0.39802274107933044\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0002803879033308476 \t\t Loss_Fake: 0.9992793202400208\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.00025038429885171354 \t\t Generator Loss: 0.3975129723548889 \t\t Total Loss: 0.39776337146759033\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00024066815967671573 \t\t Loss_Fake: 0.9993085861206055\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0002206777426181361 \t\t Generator Loss: 0.39726918935775757 \t\t Total Loss: 0.39748987555503845\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00021415870287455618 \t\t Loss_Fake: 0.9993278384208679\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0002081739075947553 \t\t Generator Loss: 0.39714565873146057 \t\t Total Loss: 0.3973538279533386\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00020271346147637814 \t\t Loss_Fake: 0.9993356466293335\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0002062791318167001 \t\t Generator Loss: 0.3964402675628662 \t\t Total Loss: 0.39664655923843384\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00020129485346842557 \t\t Loss_Fake: 0.99932861328125\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.00021471097716130316 \t\t Generator Loss: 0.39632874727249146 \t\t Total Loss: 0.3965434730052948\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00020824841340072453 \t\t Loss_Fake: 0.9993128776550293\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.00023022163077257574 \t\t Generator Loss: 0.39619019627571106 \t\t Total Loss: 0.396420419216156\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00022196622740011662 \t\t Loss_Fake: 0.9992903470993042\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0002511073253117502 \t\t Generator Loss: 0.39612144231796265 \t\t Total Loss: 0.39637255668640137\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0002402552345301956 \t\t Loss_Fake: 0.9992685317993164\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.00027224307996220887 \t\t Generator Loss: 0.3960978388786316 \t\t Total Loss: 0.3963700830936432\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00025948291295208037 \t\t Loss_Fake: 0.9992526173591614\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0002858609950635582 \t\t Generator Loss: 0.4058057367801666 \t\t Total Loss: 0.4060916006565094\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0002714080910664052 \t\t Loss_Fake: 0.999245285987854\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.00028695756918750703 \t\t Generator Loss: 0.40570420026779175 \t\t Total Loss: 0.40599116683006287\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00027224532095715404 \t\t Loss_Fake: 0.9992481470108032\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.00027764480910263956 \t\t Generator Loss: 0.40561652183532715 \t\t Total Loss: 0.4058941602706909\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0002633878611959517 \t\t Loss_Fake: 0.9992562532424927\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.00026383218937553465 \t\t Generator Loss: 0.4055562913417816 \t\t Total Loss: 0.4058201313018799\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0002506239397916943 \t\t Loss_Fake: 0.9992666244506836\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0002520745911169797 \t\t Generator Loss: 0.40549927949905396 \t\t Total Loss: 0.4057513475418091\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00024158056476153433 \t\t Loss_Fake: 0.9992740750312805\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0002454267523717135 \t\t Generator Loss: 0.40444955229759216 \t\t Total Loss: 0.40469497442245483\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00023495953064411879 \t\t Loss_Fake: 0.9992772936820984\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0002440381358610466 \t\t Generator Loss: 0.404327929019928 \t\t Total Loss: 0.4045719802379608\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00023351472918875515 \t\t Loss_Fake: 0.9992750883102417\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0002480756666045636 \t\t Generator Loss: 0.4041568338871002 \t\t Total Loss: 0.4044049084186554\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00023656990379095078 \t\t Loss_Fake: 0.9992691278457642\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0002548683260101825 \t\t Generator Loss: 0.403917133808136 \t\t Total Loss: 0.40417200326919556\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00024261372163891792 \t\t Loss_Fake: 0.999261200428009\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.00026333387359045446 \t\t Generator Loss: 0.40352219343185425 \t\t Total Loss: 0.4037855267524719\n",
            "\t\t\t\t Discriminator Loss_Real: 0.000246415933361277 \t\t Loss_Fake: 0.9992538690567017\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.00027041262364946306 \t\t Generator Loss: 0.39718759059906006 \t\t Total Loss: 0.397458016872406\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00025261874543502927 \t\t Loss_Fake: 0.9992483258247375\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0002738002222031355 \t\t Generator Loss: 0.3938813805580139 \t\t Total Loss: 0.3941551744937897\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0002561185974627733 \t\t Loss_Fake: 0.9992494583129883\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.00027444600709713995 \t\t Generator Loss: 0.3936770558357239 \t\t Total Loss: 0.39395150542259216\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00025619627558626235 \t\t Loss_Fake: 0.9992477297782898\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.00027100901934318244 \t\t Generator Loss: 0.3954268991947174 \t\t Total Loss: 0.3956979215145111\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0002534749801270664 \t\t Loss_Fake: 0.999250590801239\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0002652822877280414 \t\t Generator Loss: 0.39384016394615173 \t\t Total Loss: 0.3941054344177246\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0002499374095350504 \t\t Loss_Fake: 0.9992559552192688\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.00026374400476925075 \t\t Generator Loss: 0.39331871271133423 \t\t Total Loss: 0.39358246326446533\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0002462400880176574 \t\t Loss_Fake: 0.9992567300796509\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0002602951426524669 \t\t Generator Loss: 0.3925284743309021 \t\t Total Loss: 0.39278876781463623\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00024403170391451567 \t\t Loss_Fake: 0.9992595911026001\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0002605181944090873 \t\t Generator Loss: 0.3920581042766571 \t\t Total Loss: 0.39231863617897034\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00024373340420424938 \t\t Loss_Fake: 0.9992570877075195\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.00026124768191948533 \t\t Generator Loss: 0.39199334383010864 \t\t Total Loss: 0.3922545909881592\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00024512497475370765 \t\t Loss_Fake: 0.9992556571960449\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0002641203172970563 \t\t Generator Loss: 0.391498327255249 \t\t Total Loss: 0.3917624354362488\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00024832069175317883 \t\t Loss_Fake: 0.9992523193359375\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0002661989419721067 \t\t Generator Loss: 0.4043264389038086 \t\t Total Loss: 0.4045926332473755\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0002506642194930464 \t\t Loss_Fake: 0.9992507100105286\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0002685493673197925 \t\t Generator Loss: 0.40367943048477173 \t\t Total Loss: 0.40394797921180725\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0002522302092984319 \t\t Loss_Fake: 0.9992486834526062\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0002686627267394215 \t\t Generator Loss: 0.40260982513427734 \t\t Total Loss: 0.4028784930706024\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0002526518073864281 \t\t Loss_Fake: 0.999250054359436\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.00026596320094540715 \t\t Generator Loss: 0.39910224080085754 \t\t Total Loss: 0.39936819672584534\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00025204828125424683 \t\t Loss_Fake: 0.9992515444755554\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0002673088456504047 \t\t Generator Loss: 0.3938518166542053 \t\t Total Loss: 0.39411911368370056\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00025085522793233395 \t\t Loss_Fake: 0.9992450475692749\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0002672018017619848 \t\t Generator Loss: 0.3904067873954773 \t\t Total Loss: 0.39067399501800537\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0002494178188499063 \t\t Loss_Fake: 0.9992530941963196\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.00026272059767507017 \t\t Generator Loss: 0.3928651511669159 \t\t Total Loss: 0.3931278586387634\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00024827412562444806 \t\t Loss_Fake: 0.9992485046386719\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.00026988802710548043 \t\t Generator Loss: 0.3871729075908661 \t\t Total Loss: 0.38744279742240906\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00024782796390354633 \t\t Loss_Fake: 0.9992486834526062\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.00026678500580601394 \t\t Generator Loss: 0.38720786571502686 \t\t Total Loss: 0.3874746561050415\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0002480059920344502 \t\t Loss_Fake: 0.9992465972900391\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.000278150022495538 \t\t Generator Loss: 0.3877536654472351 \t\t Total Loss: 0.38803181052207947\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0002486728481017053 \t\t Loss_Fake: 0.9992384910583496\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.00027233516448177397 \t\t Generator Loss: 0.39155763387680054 \t\t Total Loss: 0.3918299674987793\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00024922654847614467 \t\t Loss_Fake: 0.9992415308952332\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.00028382643358781934 \t\t Generator Loss: 0.389265239238739 \t\t Total Loss: 0.3895490765571594\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0002494636573828757 \t\t Loss_Fake: 0.9992316961288452\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0002762179938144982 \t\t Generator Loss: 0.3870822489261627 \t\t Total Loss: 0.3873584568500519\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00024920894065871835 \t\t Loss_Fake: 0.9992384910583496\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.00028399532311595976 \t\t Generator Loss: 0.3874630331993103 \t\t Total Loss: 0.38774701952934265\n",
            "\t\t\t\t Discriminator Loss_Real: 0.000248586613452062 \t\t Loss_Fake: 0.9992321133613586\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.000277753482805565 \t\t Generator Loss: 0.38624170422554016 \t\t Total Loss: 0.3865194618701935\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0002480176626704633 \t\t Loss_Fake: 0.9992371797561646\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0002811752201523632 \t\t Generator Loss: 0.38328367471694946 \t\t Total Loss: 0.38356485962867737\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0002473322383593768 \t\t Loss_Fake: 0.9992321729660034\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0002793657477013767 \t\t Generator Loss: 0.38140538334846497 \t\t Total Loss: 0.3816847503185272\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00024687961558811367 \t\t Loss_Fake: 0.9992362260818481\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.00028264799038879573 \t\t Generator Loss: 0.38171592354774475 \t\t Total Loss: 0.38199856877326965\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00024676136672496796 \t\t Loss_Fake: 0.9992302656173706\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0002784244134090841 \t\t Generator Loss: 0.38066571950912476 \t\t Total Loss: 0.3809441328048706\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00024690842838026583 \t\t Loss_Fake: 0.9992354512214661\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.00028086098609492183 \t\t Generator Loss: 0.37891989946365356 \t\t Total Loss: 0.3792007565498352\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0002471586922183633 \t\t Loss_Fake: 0.9992311596870422\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.00027864836738444865 \t\t Generator Loss: 0.35900023579597473 \t\t Total Loss: 0.3592788875102997\n",
            "\t\t\t\t Discriminator Loss_Real: 0.000247719552135095 \t\t Loss_Fake: 0.9992358088493347\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.00028001583996228874 \t\t Generator Loss: 0.3579626679420471 \t\t Total Loss: 0.3582426905632019\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00024839359684847295 \t\t Loss_Fake: 0.9992313385009766\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0002803799288813025 \t\t Generator Loss: 0.3570675253868103 \t\t Total Loss: 0.35734790563583374\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00024906796170398593 \t\t Loss_Fake: 0.9992339015007019\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0002804111281875521 \t\t Generator Loss: 0.35821375250816345 \t\t Total Loss: 0.3584941625595093\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0002495907829143107 \t\t Loss_Fake: 0.9992303848266602\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.000280478794593364 \t\t Generator Loss: 0.35776883363723755 \t\t Total Loss: 0.35804930329322815\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00024868588661774993 \t\t Loss_Fake: 0.9992326498031616\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.00027961720479652286 \t\t Generator Loss: 0.35566532611846924 \t\t Total Loss: 0.3559449315071106\n",
            "\t\t\t\t Discriminator Loss_Real: 0.000249023869400844 \t\t Loss_Fake: 0.9992294311523438\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0002815453917719424 \t\t Generator Loss: 0.35677915811538696 \t\t Total Loss: 0.3570607006549835\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00024932477390393615 \t\t Loss_Fake: 0.9992308616638184\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0002803115639835596 \t\t Generator Loss: 0.35721293091773987 \t\t Total Loss: 0.35749325156211853\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00024955629487521946 \t\t Loss_Fake: 0.9992283582687378\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0002821316011250019 \t\t Generator Loss: 0.35057729482650757 \t\t Total Loss: 0.3508594334125519\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0002497359237167984 \t\t Loss_Fake: 0.9992328882217407\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.00027928961208090186 \t\t Generator Loss: 0.35327282547950745 \t\t Total Loss: 0.35355210304260254\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0002503201540093869 \t\t Loss_Fake: 0.9992290735244751\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0002862958062905818 \t\t Generator Loss: 0.3501959443092346 \t\t Total Loss: 0.3504822254180908\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00025056040612980723 \t\t Loss_Fake: 0.9992228746414185\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0002863020054064691 \t\t Generator Loss: 0.350288450717926 \t\t Total Loss: 0.3505747616291046\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0002503583091311157 \t\t Loss_Fake: 0.9992243647575378\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.00028358554118312895 \t\t Generator Loss: 0.3490692973136902 \t\t Total Loss: 0.3493528962135315\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0002497173845767975 \t\t Loss_Fake: 0.9992267489433289\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0002803663373924792 \t\t Generator Loss: 0.34427598118782043 \t\t Total Loss: 0.34455636143684387\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00024916528491303325 \t\t Loss_Fake: 0.9992172122001648\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.00028563887462951243 \t\t Generator Loss: 0.3379027545452118 \t\t Total Loss: 0.33818838000297546\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0002485938312020153 \t\t Loss_Fake: 0.9992281794548035\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0002893027849495411 \t\t Generator Loss: 0.33662477135658264 \t\t Total Loss: 0.3369140625\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0002483174321241677 \t\t Loss_Fake: 0.999214768409729\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.00028636149363592267 \t\t Generator Loss: 0.33863693475723267 \t\t Total Loss: 0.33892330527305603\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0002483088173903525 \t\t Loss_Fake: 0.9992238879203796\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.00028121902141720057 \t\t Generator Loss: 0.33830663561820984 \t\t Total Loss: 0.33858785033226013\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0002485134173184633 \t\t Loss_Fake: 0.999220073223114\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.00029145641019567847 \t\t Generator Loss: 0.3348422348499298 \t\t Total Loss: 0.33513370156288147\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0002492032654117793 \t\t Loss_Fake: 0.999210000038147\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.00029402674408629537 \t\t Generator Loss: 0.32665711641311646 \t\t Total Loss: 0.32695114612579346\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00024946159101091325 \t\t Loss_Fake: 0.999219536781311\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0002933992655016482 \t\t Generator Loss: 0.3174411356449127 \t\t Total Loss: 0.3177345395088196\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00024929491337388754 \t\t Loss_Fake: 0.9992101788520813\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.00027784102712757885 \t\t Generator Loss: 0.3286318778991699 \t\t Total Loss: 0.3289097249507904\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0002488726458977908 \t\t Loss_Fake: 0.9992265701293945\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.00029833504231646657 \t\t Generator Loss: 0.3321835398674011 \t\t Total Loss: 0.33248186111450195\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0002488369937054813 \t\t Loss_Fake: 0.999215304851532\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0002889682655222714 \t\t Generator Loss: 0.329617977142334 \t\t Total Loss: 0.3299069404602051\n",
            "\t\t\t\t Discriminator Loss_Real: 0.000249494391027838 \t\t Loss_Fake: 0.9992084503173828\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0003038280992768705 \t\t Generator Loss: 0.3248388171195984 \t\t Total Loss: 0.32514265179634094\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0002499288530088961 \t\t Loss_Fake: 0.9992192983627319\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.00029189075576141477 \t\t Generator Loss: 0.3224374055862427 \t\t Total Loss: 0.32272928953170776\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0002501937560737133 \t\t Loss_Fake: 0.9991989135742188\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.00028822413878515363 \t\t Generator Loss: 0.31786414980888367 \t\t Total Loss: 0.31815236806869507\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0002498704707249999 \t\t Loss_Fake: 0.9992162585258484\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.00029746690415777266 \t\t Generator Loss: 0.3145340383052826 \t\t Total Loss: 0.3148314952850342\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0002491924969945103 \t\t Loss_Fake: 0.9991944432258606\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.00029750989051535726 \t\t Generator Loss: 0.31435251235961914 \t\t Total Loss: 0.3146500289440155\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00024839938851073384 \t\t Loss_Fake: 0.9992161989212036\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0002918555401265621 \t\t Generator Loss: 0.31140655279159546 \t\t Total Loss: 0.31169840693473816\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0002485621371306479 \t\t Loss_Fake: 0.9991987943649292\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0003120366600342095 \t\t Generator Loss: 0.31771355867385864 \t\t Total Loss: 0.3180255889892578\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0002486367884557694 \t\t Loss_Fake: 0.9991986155509949\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0002995868562720716 \t\t Generator Loss: 0.31715840101242065 \t\t Total Loss: 0.31745797395706177\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0002485254663042724 \t\t Loss_Fake: 0.9992055892944336\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0003107892407570034 \t\t Generator Loss: 0.3141644597053528 \t\t Total Loss: 0.31447523832321167\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00024866106105037034 \t\t Loss_Fake: 0.9991801977157593\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0003057173453271389 \t\t Generator Loss: 0.3131914734840393 \t\t Total Loss: 0.3134971857070923\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00024795468198135495 \t\t Loss_Fake: 0.999198317527771\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0003128546813968569 \t\t Generator Loss: 0.31007081270217896 \t\t Total Loss: 0.310383677482605\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0002468716411385685 \t\t Loss_Fake: 0.999188244342804\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.00030787388095632195 \t\t Generator Loss: 0.3122408986091614 \t\t Total Loss: 0.31254878640174866\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00024618461611680686 \t\t Loss_Fake: 0.9991894960403442\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.00030798997613601387 \t\t Generator Loss: 0.3079180419445038 \t\t Total Loss: 0.3082260191440582\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00024599162861704826 \t\t Loss_Fake: 0.9991949200630188\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0003126495867036283 \t\t Generator Loss: 0.30615490674972534 \t\t Total Loss: 0.30646756291389465\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00024674428277648985 \t\t Loss_Fake: 0.9991868734359741\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.00028609653236344457 \t\t Generator Loss: 0.30249276757240295 \t\t Total Loss: 0.30277886986732483\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00024814842618070543 \t\t Loss_Fake: 0.9992178678512573\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0002897225203923881 \t\t Generator Loss: 0.29730668663978577 \t\t Total Loss: 0.29759639501571655\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00024928711354732513 \t\t Loss_Fake: 0.9991840124130249\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0003186400863341987 \t\t Generator Loss: 0.2964068651199341 \t\t Total Loss: 0.2967255115509033\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0002525893796700984 \t\t Loss_Fake: 0.9991839528083801\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0003033685206901282 \t\t Generator Loss: 0.29414063692092896 \t\t Total Loss: 0.2944439947605133\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0002542318543419242 \t\t Loss_Fake: 0.9991966485977173\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0003039817383978516 \t\t Generator Loss: 0.2905053198337555 \t\t Total Loss: 0.29080930352211\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0002547968178987503 \t\t Loss_Fake: 0.9991710782051086\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.00032124159042723477 \t\t Generator Loss: 0.28611496090888977 \t\t Total Loss: 0.28643620014190674\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0002537993132136762 \t\t Loss_Fake: 0.999176025390625\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.00030950078507885337 \t\t Generator Loss: 0.28452855348587036 \t\t Total Loss: 0.2848380506038666\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00025130569702014327 \t\t Loss_Fake: 0.9991837739944458\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.00031690375180915 \t\t Generator Loss: 0.2840043902397156 \t\t Total Loss: 0.28432130813598633\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00024937771377153695 \t\t Loss_Fake: 0.999169647693634\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0003145353402942419 \t\t Generator Loss: 0.28316864371299744 \t\t Total Loss: 0.2834831774234772\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0002484586730133742 \t\t Loss_Fake: 0.9991742968559265\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0003194515884388238 \t\t Generator Loss: 0.2831347584724426 \t\t Total Loss: 0.28345420956611633\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00024860812118276954 \t\t Loss_Fake: 0.9991663694381714\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0003314394853077829 \t\t Generator Loss: 0.28098443150520325 \t\t Total Loss: 0.2813158631324768\n",
            "\t\t\t\t Discriminator Loss_Real: 0.000249657838139683 \t\t Loss_Fake: 0.9991599321365356\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0003208678972441703 \t\t Generator Loss: 0.28010615706443787 \t\t Total Loss: 0.2804270386695862\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0002499965485185385 \t\t Loss_Fake: 0.9991530179977417\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.00033639007597230375 \t\t Generator Loss: 0.28923481702804565 \t\t Total Loss: 0.28957119584083557\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0002510045887902379 \t\t Loss_Fake: 0.9991475939750671\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0003377427055966109 \t\t Generator Loss: 0.2887340486049652 \t\t Total Loss: 0.28907179832458496\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00025139848003163934 \t\t Loss_Fake: 0.9991461634635925\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.00033941626315936446 \t\t Generator Loss: 0.28732067346572876 \t\t Total Loss: 0.2876600921154022\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00025138320052064955 \t\t Loss_Fake: 0.9991316795349121\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0003556226729415357 \t\t Generator Loss: 0.28450194001197815 \t\t Total Loss: 0.2848575711250305\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0002508301695343107 \t\t Loss_Fake: 0.9991259574890137\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0003485998313408345 \t\t Generator Loss: 0.28264954686164856 \t\t Total Loss: 0.28299814462661743\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0002494722721166909 \t\t Loss_Fake: 0.9991253614425659\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.00034123403020203114 \t\t Generator Loss: 0.28431135416030884 \t\t Total Loss: 0.28465259075164795\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00024869065964594483 \t\t Loss_Fake: 0.9991135597229004\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0003625821555033326 \t\t Generator Loss: 0.2807829976081848 \t\t Total Loss: 0.2811455726623535\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00024917288101278245 \t\t Loss_Fake: 0.9991024732589722\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.00036841866676695645 \t\t Generator Loss: 0.28221026062965393 \t\t Total Loss: 0.2825786769390106\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00025060249026864767 \t\t Loss_Fake: 0.9990838766098022\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0003668450517579913 \t\t Generator Loss: 0.27872419357299805 \t\t Total Loss: 0.2790910303592682\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0002527252654545009 \t\t Loss_Fake: 0.9990673065185547\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0003665135591290891 \t\t Generator Loss: 0.27959513664245605 \t\t Total Loss: 0.27996164560317993\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0002559286658652127 \t\t Loss_Fake: 0.9990406036376953\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.00039704152732156217 \t\t Generator Loss: 0.27748945355415344 \t\t Total Loss: 0.2778865098953247\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00026048964355140924 \t\t Loss_Fake: 0.9990145564079285\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0004107850545551628 \t\t Generator Loss: 0.27379703521728516 \t\t Total Loss: 0.27420783042907715\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00026842072838917375 \t\t Loss_Fake: 0.99896240234375\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0004062805383000523 \t\t Generator Loss: 0.27237361669540405 \t\t Total Loss: 0.2727799117565155\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00028342107543721795 \t\t Loss_Fake: 0.9989005923271179\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.000469857215648517 \t\t Generator Loss: 0.27064695954322815 \t\t Total Loss: 0.27111682295799255\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00031226553255692124 \t\t Loss_Fake: 0.9988252520561218\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0005477546947076917 \t\t Generator Loss: 0.272066205739975 \t\t Total Loss: 0.2726139724254608\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0003607060352806002 \t\t Loss_Fake: 0.9987813830375671\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.000650272995699197 \t\t Generator Loss: 0.2695634663105011 \t\t Total Loss: 0.2702137529850006\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0004172310291323811 \t\t Loss_Fake: 0.9987527132034302\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0006493477267213166 \t\t Generator Loss: 0.269391804933548 \t\t Total Loss: 0.2700411379337311\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0004424590733833611 \t\t Loss_Fake: 0.9987404942512512\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0006393241928890347 \t\t Generator Loss: 0.26944562792778015 \t\t Total Loss: 0.270084947347641\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00041544350096955895 \t\t Loss_Fake: 0.9987574815750122\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0005855251802131534 \t\t Generator Loss: 0.2678883671760559 \t\t Total Loss: 0.26847389340400696\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00036420958349481225 \t\t Loss_Fake: 0.9988045692443848\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0005431938916444778 \t\t Generator Loss: 0.2670474648475647 \t\t Total Loss: 0.2675906717777252\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0003243726387154311 \t\t Loss_Fake: 0.9987978935241699\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0005128443008288741 \t\t Generator Loss: 0.2665140628814697 \t\t Total Loss: 0.2670269012451172\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00030497877742163837 \t\t Loss_Fake: 0.9987996220588684\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0005183916073292494 \t\t Generator Loss: 0.26182350516319275 \t\t Total Loss: 0.2623418867588043\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0002978683914989233 \t\t Loss_Fake: 0.998803973197937\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0005480552208609879 \t\t Generator Loss: 0.2610127627849579 \t\t Total Loss: 0.2615608274936676\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00029843777883797884 \t\t Loss_Fake: 0.9988151788711548\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0006251974846236408 \t\t Generator Loss: 0.25844985246658325 \t\t Total Loss: 0.2590750455856323\n",
            "\t\t\t\t Discriminator Loss_Real: 0.000307292997604236 \t\t Loss_Fake: 0.9987611770629883\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0005991898360662162 \t\t Generator Loss: 0.2570542097091675 \t\t Total Loss: 0.2576533854007721\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0003216327750124037 \t\t Loss_Fake: 0.9987088441848755\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0005795371253043413 \t\t Generator Loss: 0.2562885582447052 \t\t Total Loss: 0.2568680942058563\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0003316054353490472 \t\t Loss_Fake: 0.998731255531311\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.000667394429910928 \t\t Generator Loss: 0.2555146813392639 \t\t Total Loss: 0.25618207454681396\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0003337679081596434 \t\t Loss_Fake: 0.9987472295761108\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0007394448621198535 \t\t Generator Loss: 0.2506760060787201 \t\t Total Loss: 0.2514154613018036\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0003326800942886621 \t\t Loss_Fake: 0.9987003207206726\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.00063962338026613 \t\t Generator Loss: 0.2473568171262741 \t\t Total Loss: 0.24799643456935883\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0003248917346354574 \t\t Loss_Fake: 0.9986764788627625\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0005994935636408627 \t\t Generator Loss: 0.2483406811952591 \t\t Total Loss: 0.24894016981124878\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0003068335063289851 \t\t Loss_Fake: 0.9987045526504517\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0007163884001784027 \t\t Generator Loss: 0.24339208006858826 \t\t Total Loss: 0.24410846829414368\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00028752934304066 \t\t Loss_Fake: 0.99876868724823\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0007142223184928298 \t\t Generator Loss: 0.23992948234081268 \t\t Total Loss: 0.240643709897995\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00028146454133093357 \t\t Loss_Fake: 0.9986960291862488\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0006084123742766678 \t\t Generator Loss: 0.24254615604877472 \t\t Total Loss: 0.24315457046031952\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0002846443676389754 \t\t Loss_Fake: 0.9986521601676941\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0006666487897746265 \t\t Generator Loss: 0.2395515739917755 \t\t Total Loss: 0.24021822214126587\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0002808207063935697 \t\t Loss_Fake: 0.9987133741378784\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0007927360129542649 \t\t Generator Loss: 0.24036884307861328 \t\t Total Loss: 0.24116158485412598\n",
            "\t\t\t\t Discriminator Loss_Real: 0.000276084610959515 \t\t Loss_Fake: 0.9987085461616516\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0008318446343764663 \t\t Generator Loss: 0.2381562888622284 \t\t Total Loss: 0.23898813128471375\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0002812436723615974 \t\t Loss_Fake: 0.9986467361450195\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0006544826319441199 \t\t Generator Loss: 0.2402859479188919 \t\t Total Loss: 0.24094043672084808\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00028400158043950796 \t\t Loss_Fake: 0.9986327886581421\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0008052689954638481 \t\t Generator Loss: 0.23759377002716064 \t\t Total Loss: 0.23839904367923737\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00027403986314311624 \t\t Loss_Fake: 0.9986698031425476\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0008496392401866615 \t\t Generator Loss: 0.23840081691741943 \t\t Total Loss: 0.23925045132637024\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0002619583101477474 \t\t Loss_Fake: 0.9986858367919922\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0007806818466633558 \t\t Generator Loss: 0.2374786138534546 \t\t Total Loss: 0.23825930058956146\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00026123313000425696 \t\t Loss_Fake: 0.998633086681366\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0007042744546197355 \t\t Generator Loss: 0.23786397278308868 \t\t Total Loss: 0.2385682463645935\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0002593372482806444 \t\t Loss_Fake: 0.9986363649368286\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0007652002386748791 \t\t Generator Loss: 0.23629207909107208 \t\t Total Loss: 0.23705728352069855\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00025204854318872094 \t\t Loss_Fake: 0.9986665844917297\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0009053424000740051 \t\t Generator Loss: 0.23666568100452423 \t\t Total Loss: 0.23757103085517883\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0002483546850271523 \t\t Loss_Fake: 0.9986523389816284\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0008450059103779495 \t\t Generator Loss: 0.23611478507518768 \t\t Total Loss: 0.2369597852230072\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0002511048805899918 \t\t Loss_Fake: 0.9986171722412109\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0008071468910202384 \t\t Generator Loss: 0.23670554161071777 \t\t Total Loss: 0.23751269280910492\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00025125202955678105 \t\t Loss_Fake: 0.9986053705215454\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.000847028277348727 \t\t Generator Loss: 0.23605096340179443 \t\t Total Loss: 0.23689799010753632\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0002404108818154782 \t\t Loss_Fake: 0.9986394643783569\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0008954368531703949 \t\t Generator Loss: 0.23616568744182587 \t\t Total Loss: 0.23706112802028656\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00022941327188163996 \t\t Loss_Fake: 0.998637855052948\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0009088602964766324 \t\t Generator Loss: 0.2358960211277008 \t\t Total Loss: 0.23680488765239716\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0002266744413645938 \t\t Loss_Fake: 0.9986168146133423\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0008336192113347352 \t\t Generator Loss: 0.23601320385932922 \t\t Total Loss: 0.23684681951999664\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00022763021115679294 \t\t Loss_Fake: 0.9985980987548828\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0008795382454991341 \t\t Generator Loss: 0.23591434955596924 \t\t Total Loss: 0.2367938905954361\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00022546897525899112 \t\t Loss_Fake: 0.9986055493354797\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0009199032792821527 \t\t Generator Loss: 0.2285897433757782 \t\t Total Loss: 0.2295096516609192\n",
            "\t\t\t\t Discriminator Loss_Real: 0.000218229804886505 \t\t Loss_Fake: 0.9986225962638855\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0009799732360988855 \t\t Generator Loss: 0.22858913242816925 \t\t Total Loss: 0.22956910729408264\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00021446503524202853 \t\t Loss_Fake: 0.998607337474823\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0009601974743418396 \t\t Generator Loss: 0.2283473014831543 \t\t Total Loss: 0.22930750250816345\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00021506065968424082 \t\t Loss_Fake: 0.9985911250114441\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0009189735283143818 \t\t Generator Loss: 0.22827720642089844 \t\t Total Loss: 0.22919617593288422\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0002140748838428408 \t\t Loss_Fake: 0.9985822439193726\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0009151247213594615 \t\t Generator Loss: 0.22746577858924866 \t\t Total Loss: 0.22838090360164642\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0002062146959360689 \t\t Loss_Fake: 0.9985898733139038\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0008433664334006608 \t\t Generator Loss: 0.2239467203617096 \t\t Total Loss: 0.2247900813817978\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0001980280940188095 \t\t Loss_Fake: 0.9986793398857117\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.000669128552544862 \t\t Generator Loss: 0.22553908824920654 \t\t Total Loss: 0.22620820999145508\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00020302156917750835 \t\t Loss_Fake: 0.9985653758049011\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0010247731115669012 \t\t Generator Loss: 0.22524888813495636 \t\t Total Loss: 0.22627365589141846\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00021294548059813678 \t\t Loss_Fake: 0.9985672831535339\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0009993354324251413 \t\t Generator Loss: 0.22340555489063263 \t\t Total Loss: 0.22440488636493683\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00020978758402634412 \t\t Loss_Fake: 0.998630166053772\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0007675507804378867 \t\t Generator Loss: 0.22444505989551544 \t\t Total Loss: 0.22521260380744934\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0002102275175275281 \t\t Loss_Fake: 0.9985707402229309\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0011495858198031783 \t\t Generator Loss: 0.2257022112607956 \t\t Total Loss: 0.22685179114341736\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00021807248413097113 \t\t Loss_Fake: 0.9985650777816772\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0010866100201383233 \t\t Generator Loss: 0.2247125655412674 \t\t Total Loss: 0.22579917311668396\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00022134007303975523 \t\t Loss_Fake: 0.998609721660614\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.001099220709875226 \t\t Generator Loss: 0.2242744415998459 \t\t Total Loss: 0.22537365555763245\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00022862968035042286 \t\t Loss_Fake: 0.9985404014587402\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0011965015437453985 \t\t Generator Loss: 0.22419866919517517 \t\t Total Loss: 0.22539517283439636\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00022731073840986937 \t\t Loss_Fake: 0.9985354542732239\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0008598670247010887 \t\t Generator Loss: 0.22347411513328552 \t\t Total Loss: 0.2243339866399765\n",
            "\t\t\t\t Discriminator Loss_Real: 0.000206509925192222 \t\t Loss_Fake: 0.9985482096672058\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0009236796759068966 \t\t Generator Loss: 0.21986636519432068 \t\t Total Loss: 0.2207900434732437\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00018500290752854198 \t\t Loss_Fake: 0.9985672831535339\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0009153448045253754 \t\t Generator Loss: 0.21912434697151184 \t\t Total Loss: 0.22003969550132751\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0001749983202898875 \t\t Loss_Fake: 0.998550295829773\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0008604516042396426 \t\t Generator Loss: 0.220939040184021 \t\t Total Loss: 0.22179949283599854\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00017540341650601476 \t\t Loss_Fake: 0.9985135793685913\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0009280092199333012 \t\t Generator Loss: 0.21932721138000488 \t\t Total Loss: 0.22025522589683533\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00017524762370157987 \t\t Loss_Fake: 0.9985175132751465\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.001017949660308659 \t\t Generator Loss: 0.21495354175567627 \t\t Total Loss: 0.21597148478031158\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00017311969713773578 \t\t Loss_Fake: 0.9984917640686035\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0010196302318945527 \t\t Generator Loss: 0.21871888637542725 \t\t Total Loss: 0.21973851323127747\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00017135990492533892 \t\t Loss_Fake: 0.9984726905822754\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0009315459756180644 \t\t Generator Loss: 0.21766021847724915 \t\t Total Loss: 0.21859176456928253\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00016917979519348592 \t\t Loss_Fake: 0.9984709024429321\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0011965399608016014 \t\t Generator Loss: 0.21615929901599884 \t\t Total Loss: 0.21735583245754242\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00017551668861415237 \t\t Loss_Fake: 0.9984161257743835\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0011684934142977 \t\t Generator Loss: 0.21669915318489075 \t\t Total Loss: 0.2178676426410675\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00019537137995939702 \t\t Loss_Fake: 0.9983350038528442\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0014168014749884605 \t\t Generator Loss: 0.2167636603116989 \t\t Total Loss: 0.21818046271800995\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00022930656268727034 \t\t Loss_Fake: 0.9982479810714722\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0016672654310241342 \t\t Generator Loss: 0.2153993546962738 \t\t Total Loss: 0.21706661581993103\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0002764000673778355 \t\t Loss_Fake: 0.9981896281242371\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0017757993191480637 \t\t Generator Loss: 0.21525995433330536 \t\t Total Loss: 0.21703575551509857\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00032963193370960653 \t\t Loss_Fake: 0.9981416463851929\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0017283910419791937 \t\t Generator Loss: 0.21557101607322693 \t\t Total Loss: 0.21729940176010132\n",
            "\t\t\t\t Discriminator Loss_Real: 0.000347409542882815 \t\t Loss_Fake: 0.9981414079666138\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0014712412375956774 \t\t Generator Loss: 0.2154107391834259 \t\t Total Loss: 0.21688197553157806\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00030309017165564 \t\t Loss_Fake: 0.9981633424758911\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0014195868279784918 \t\t Generator Loss: 0.2146962434053421 \t\t Total Loss: 0.2161158323287964\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00023742104531265795 \t\t Loss_Fake: 0.9981853365898132\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0014235626440495253 \t\t Generator Loss: 0.2195623219013214 \t\t Total Loss: 0.22098588943481445\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0001955668703885749 \t\t Loss_Fake: 0.9982190132141113\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0016567569691687822 \t\t Generator Loss: 0.21997582912445068 \t\t Total Loss: 0.22163258492946625\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00018332245235797018 \t\t Loss_Fake: 0.9982015490531921\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0019774597603827715 \t\t Generator Loss: 0.2210720032453537 \t\t Total Loss: 0.22304946184158325\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00019326286565046757 \t\t Loss_Fake: 0.9981971979141235\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0024144721683114767 \t\t Generator Loss: 0.22236911952495575 \t\t Total Loss: 0.22478358447551727\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00021747413848061115 \t\t Loss_Fake: 0.9981576204299927\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0026574688963592052 \t\t Generator Loss: 0.2214702069759369 \t\t Total Loss: 0.22412768006324768\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00024179750471375883 \t\t Loss_Fake: 0.9981234669685364\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.00214576767757535 \t\t Generator Loss: 0.21922926604747772 \t\t Total Loss: 0.22137503325939178\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0002380113146500662 \t\t Loss_Fake: 0.9981180429458618\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0014848577557131648 \t\t Generator Loss: 0.22027187049388885 \t\t Total Loss: 0.2217567265033722\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00019850837998092175 \t\t Loss_Fake: 0.9981077909469604\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0009427696350030601 \t\t Generator Loss: 0.22113151848316193 \t\t Total Loss: 0.22207428514957428\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0001504595420556143 \t\t Loss_Fake: 0.9981564283370972\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0009490781230852008 \t\t Generator Loss: 0.21918673813343048 \t\t Total Loss: 0.22013582289218903\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00012034891551593319 \t\t Loss_Fake: 0.9982508420944214\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0012174941366538405 \t\t Generator Loss: 0.2188439816236496 \t\t Total Loss: 0.22006148099899292\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00011340695346007124 \t\t Loss_Fake: 0.9982753992080688\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.00169193500187248 \t\t Generator Loss: 0.2214973419904709 \t\t Total Loss: 0.22318927943706512\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00013225941802375019 \t\t Loss_Fake: 0.9981085658073425\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0021958076395094395 \t\t Generator Loss: 0.22079212963581085 \t\t Total Loss: 0.22298793494701385\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00017662273603491485 \t\t Loss_Fake: 0.9981023073196411\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0021316136699169874 \t\t Generator Loss: 0.2205958366394043 \t\t Total Loss: 0.2227274477481842\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00020766284433193505 \t\t Loss_Fake: 0.998119056224823\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0016730257775634527 \t\t Generator Loss: 0.2201303243637085 \t\t Total Loss: 0.22180335223674774\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00018120754975825548 \t\t Loss_Fake: 0.9980798959732056\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0009417319670319557 \t\t Generator Loss: 0.2140340358018875 \t\t Total Loss: 0.2149757742881775\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00013826217036694288 \t\t Loss_Fake: 0.9985449910163879\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0005880238022655249 \t\t Generator Loss: 0.21552777290344238 \t\t Total Loss: 0.216115802526474\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00012838441762141883 \t\t Loss_Fake: 0.9980940818786621\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0011254765558987856 \t\t Generator Loss: 0.2154511958360672 \t\t Total Loss: 0.21657666563987732\n",
            "\t\t\t\t Discriminator Loss_Real: 0.000142423712532036 \t\t Loss_Fake: 0.9981309771537781\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0012791412882506847 \t\t Generator Loss: 0.21097874641418457 \t\t Total Loss: 0.21225789189338684\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00016780559963081032 \t\t Loss_Fake: 0.9981178045272827\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0019811023958027363 \t\t Generator Loss: 0.21046534180641174 \t\t Total Loss: 0.2124464511871338\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00021558106527663767 \t\t Loss_Fake: 0.9980689287185669\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0015844667796045542 \t\t Generator Loss: 0.2126276046037674 \t\t Total Loss: 0.2142120748758316\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00023533326748292893 \t\t Loss_Fake: 0.9980608224868774\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0011173966340720654 \t\t Generator Loss: 0.21489110589027405 \t\t Total Loss: 0.2160084992647171\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00018808463937602937 \t\t Loss_Fake: 0.9980627298355103\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0007993971230462193 \t\t Generator Loss: 0.21296286582946777 \t\t Total Loss: 0.21376226842403412\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00013317886623553932 \t\t Loss_Fake: 0.9981791377067566\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0008591970545239747 \t\t Generator Loss: 0.2101876437664032 \t\t Total Loss: 0.21104684472084045\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00010886879317695275 \t\t Loss_Fake: 0.9981797933578491\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0009412679937668145 \t\t Generator Loss: 0.2096727341413498 \t\t Total Loss: 0.21061399579048157\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00011260584142291918 \t\t Loss_Fake: 0.9981595277786255\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0013880905462428927 \t\t Generator Loss: 0.20975211262702942 \t\t Total Loss: 0.2111402004957199\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00014211153029464185 \t\t Loss_Fake: 0.9980567693710327\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0017201686277985573 \t\t Generator Loss: 0.2100287675857544 \t\t Total Loss: 0.21174894273281097\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00018584572535473853 \t\t Loss_Fake: 0.998050332069397\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.002049866132438183 \t\t Generator Loss: 0.2095297873020172 \t\t Total Loss: 0.21157965064048767\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00020409573335200548 \t\t Loss_Fake: 0.9980484843254089\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.001908391946926713 \t\t Generator Loss: 0.2092759907245636 \t\t Total Loss: 0.21118438243865967\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0001831053086789325 \t\t Loss_Fake: 0.9980714917182922\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.001713326433673501 \t\t Generator Loss: 0.20917189121246338 \t\t Total Loss: 0.2108852118253708\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00015453816740773618 \t\t Loss_Fake: 0.9980789422988892\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0015808293828740716 \t\t Generator Loss: 0.2091856300830841 \t\t Total Loss: 0.21076646447181702\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00014093084610067308 \t\t Loss_Fake: 0.9980891942977905\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0014906346332281828 \t\t Generator Loss: 0.20711474120616913 \t\t Total Loss: 0.20860537886619568\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00013832448166795075 \t\t Loss_Fake: 0.998063862323761\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.00155750778503716 \t\t Generator Loss: 0.20708218216896057 \t\t Total Loss: 0.2086396962404251\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0001416154409525916 \t\t Loss_Fake: 0.9980519413948059\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0015613866271451116 \t\t Generator Loss: 0.20711550116539001 \t\t Total Loss: 0.20867688953876495\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00013816879072692245 \t\t Loss_Fake: 0.9980543851852417\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0014617843553423882 \t\t Generator Loss: 0.2072458565235138 \t\t Total Loss: 0.20870764553546906\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00012614301522262394 \t\t Loss_Fake: 0.9980549812316895\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0012870443752035499 \t\t Generator Loss: 0.2075452357530594 \t\t Total Loss: 0.2088322788476944\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00011019732482964173 \t\t Loss_Fake: 0.9980605840682983\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0010741462465375662 \t\t Generator Loss: 0.20802155137062073 \t\t Total Loss: 0.20909570157527924\n",
            "\t\t\t\t Discriminator Loss_Real: 9.766289440449327e-05 \t\t Loss_Fake: 0.9980577230453491\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0009106793440878391 \t\t Generator Loss: 0.20918893814086914 \t\t Total Loss: 0.21009962260723114\n",
            "\t\t\t\t Discriminator Loss_Real: 8.955552766565233e-05 \t\t Loss_Fake: 0.9980531930923462\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0007159111555665731 \t\t Generator Loss: 0.21123436093330383 \t\t Total Loss: 0.21195027232170105\n",
            "\t\t\t\t Discriminator Loss_Real: 8.364493260160089e-05 \t\t Loss_Fake: 0.9980506896972656\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0007014851435087621 \t\t Generator Loss: 0.21090468764305115 \t\t Total Loss: 0.21160617470741272\n",
            "\t\t\t\t Discriminator Loss_Real: 7.835791620891541e-05 \t\t Loss_Fake: 0.9980524778366089\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0008440309902653098 \t\t Generator Loss: 0.2069079428911209 \t\t Total Loss: 0.20775197446346283\n",
            "\t\t\t\t Discriminator Loss_Real: 7.473890582332388e-05 \t\t Loss_Fake: 0.9980951547622681\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0013734335079789162 \t\t Generator Loss: 0.199596107006073 \t\t Total Loss: 0.20096954703330994\n",
            "\t\t\t\t Discriminator Loss_Real: 8.220706513384357e-05 \t\t Loss_Fake: 0.9981659650802612\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.001857902156189084 \t\t Generator Loss: 0.1995256245136261 \t\t Total Loss: 0.2013835310935974\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00011474033817648888 \t\t Loss_Fake: 0.9980305433273315\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0020045689307153225 \t\t Generator Loss: 0.20288817584514618 \t\t Total Loss: 0.20489273965358734\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0001593380147824064 \t\t Loss_Fake: 0.9980391263961792\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0018104889895766973 \t\t Generator Loss: 0.19994506239891052 \t\t Total Loss: 0.201755553483963\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0001557061477797106 \t\t Loss_Fake: 0.9980044364929199\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0016199242090806365 \t\t Generator Loss: 0.1998608112335205 \t\t Total Loss: 0.20148073136806488\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00012674255413003266 \t\t Loss_Fake: 0.9980366826057434\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0012809569016098976 \t\t Generator Loss: 0.20111703872680664 \t\t Total Loss: 0.20239800214767456\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00010604968701954931 \t\t Loss_Fake: 0.9980589151382446\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0014228845247998834 \t\t Generator Loss: 0.20096468925476074 \t\t Total Loss: 0.20238757133483887\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00010221459524473175 \t\t Loss_Fake: 0.998050332069397\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0018855066737160087 \t\t Generator Loss: 0.20035597681999207 \t\t Total Loss: 0.20224148035049438\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00011362871009623632 \t\t Loss_Fake: 0.9980337023735046\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0023099223617464304 \t\t Generator Loss: 0.19993969798088074 \t\t Total Loss: 0.20224961638450623\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00013797497376799583 \t\t Loss_Fake: 0.9980067014694214\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0023457661736756563 \t\t Generator Loss: 0.19962330162525177 \t\t Total Loss: 0.20196907222270966\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0001511137670604512 \t\t Loss_Fake: 0.9980137944221497\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0018067049095407128 \t\t Generator Loss: 0.2049175202846527 \t\t Total Loss: 0.20672422647476196\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00013151676103007048 \t\t Loss_Fake: 0.9980053901672363\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0013998487265780568 \t\t Generator Loss: 0.20526954531669617 \t\t Total Loss: 0.2066693902015686\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00010082217340823263 \t\t Loss_Fake: 0.9980226755142212\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.001122860936447978 \t\t Generator Loss: 0.20497313141822815 \t\t Total Loss: 0.20609599351882935\n",
            "\t\t\t\t Discriminator Loss_Real: 8.138340490404516e-05 \t\t Loss_Fake: 0.998051643371582\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0012008951744064689 \t\t Generator Loss: 0.20445311069488525 \t\t Total Loss: 0.20565401017665863\n",
            "\t\t\t\t Discriminator Loss_Real: 7.580751844216138e-05 \t\t Loss_Fake: 0.9980262517929077\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0013475383166223764 \t\t Generator Loss: 0.20429754257202148 \t\t Total Loss: 0.20564508438110352\n",
            "\t\t\t\t Discriminator Loss_Real: 8.06391763035208e-05 \t\t Loss_Fake: 0.9980022311210632\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0016003610799089074 \t\t Generator Loss: 0.20475979149341583 \t\t Total Loss: 0.20636014640331268\n",
            "\t\t\t\t Discriminator Loss_Real: 8.973795047495514e-05 \t\t Loss_Fake: 0.9979920387268066\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0016762251034379005 \t\t Generator Loss: 0.20475773513317108 \t\t Total Loss: 0.206433966755867\n",
            "\t\t\t\t Discriminator Loss_Real: 9.543159831082448e-05 \t\t Loss_Fake: 0.9979793429374695\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0015868585323914886 \t\t Generator Loss: 0.20473241806030273 \t\t Total Loss: 0.20631927251815796\n",
            "\t\t\t\t Discriminator Loss_Real: 9.377981768921018e-05 \t\t Loss_Fake: 0.9979718327522278\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.001478178077377379 \t\t Generator Loss: 0.2047264277935028 \t\t Total Loss: 0.2062046080827713\n",
            "\t\t\t\t Discriminator Loss_Real: 8.998256816994399e-05 \t\t Loss_Fake: 0.9979692697525024\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0013675381196662784 \t\t Generator Loss: 0.20492276549339294 \t\t Total Loss: 0.20629030466079712\n",
            "\t\t\t\t Discriminator Loss_Real: 8.621070446679369e-05 \t\t Loss_Fake: 0.9979493021965027\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0013979712966829538 \t\t Generator Loss: 0.2013850212097168 \t\t Total Loss: 0.2027829885482788\n",
            "\t\t\t\t Discriminator Loss_Real: 8.833425818011165e-05 \t\t Loss_Fake: 0.9979292750358582\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0013039216864854097 \t\t Generator Loss: 0.20198814570903778 \t\t Total Loss: 0.20329207181930542\n",
            "\t\t\t\t Discriminator Loss_Real: 8.996015094453469e-05 \t\t Loss_Fake: 0.9979062080383301\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0011669460218399763 \t\t Generator Loss: 0.20306019484996796 \t\t Total Loss: 0.20422713458538055\n",
            "\t\t\t\t Discriminator Loss_Real: 8.849659934639931e-05 \t\t Loss_Fake: 0.9978739619255066\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0009770540054887533 \t\t Generator Loss: 0.20430347323417664 \t\t Total Loss: 0.20528052747249603\n",
            "\t\t\t\t Discriminator Loss_Real: 8.394840551773086e-05 \t\t Loss_Fake: 0.9978238344192505\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0009092615800909698 \t\t Generator Loss: 0.2040276974439621 \t\t Total Loss: 0.20493696630001068\n",
            "\t\t\t\t Discriminator Loss_Real: 8.124769374262542e-05 \t\t Loss_Fake: 0.9977666139602661\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0010375333949923515 \t\t Generator Loss: 0.2021230012178421 \t\t Total Loss: 0.20316053926944733\n",
            "\t\t\t\t Discriminator Loss_Real: 8.58387429616414e-05 \t\t Loss_Fake: 0.9977019429206848\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.001458331593312323 \t\t Generator Loss: 0.20073452591896057 \t\t Total Loss: 0.20219285786151886\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00010812420077854767 \t\t Loss_Fake: 0.9976245164871216\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0021920485887676477 \t\t Generator Loss: 0.2004745751619339 \t\t Total Loss: 0.20266662538051605\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00016196075011976063 \t\t Loss_Fake: 0.9975606799125671\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0028402828611433506 \t\t Generator Loss: 0.2006082534790039 \t\t Total Loss: 0.20344853401184082\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00023779363255016506 \t\t Loss_Fake: 0.9975516200065613\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.002950055059045553 \t\t Generator Loss: 0.20074105262756348 \t\t Total Loss: 0.20369111001491547\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00026650598738342524 \t\t Loss_Fake: 0.9975441098213196\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.002526137512177229 \t\t Generator Loss: 0.20440857112407684 \t\t Total Loss: 0.20693470537662506\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00021642199135385454 \t\t Loss_Fake: 0.9975331425666809\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.002016599988564849 \t\t Generator Loss: 0.20455756783485413 \t\t Total Loss: 0.20657417178153992\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00015624430670868605 \t\t Loss_Fake: 0.9975584745407104\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0018245894461870193 \t\t Generator Loss: 0.20446369051933289 \t\t Total Loss: 0.20628827810287476\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00012366539158392698 \t\t Loss_Fake: 0.9975848197937012\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.001878908253274858 \t\t Generator Loss: 0.20438280701637268 \t\t Total Loss: 0.20626170933246613\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00011530077608767897 \t\t Loss_Fake: 0.9975602030754089\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.002160797594115138 \t\t Generator Loss: 0.2042917013168335 \t\t Total Loss: 0.20645250380039215\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00011966629244852811 \t\t Loss_Fake: 0.9975296258926392\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0022166285198181868 \t\t Generator Loss: 0.2046385556459427 \t\t Total Loss: 0.2068551778793335\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00012589558900799602 \t\t Loss_Fake: 0.997495174407959\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.002189903985708952 \t\t Generator Loss: 0.20485131442546844 \t\t Total Loss: 0.20704121887683868\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00012399167462717742 \t\t Loss_Fake: 0.9974600076675415\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0019246125593781471 \t\t Generator Loss: 0.20520368218421936 \t\t Total Loss: 0.20712830126285553\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00011523302237037569 \t\t Loss_Fake: 0.9974199533462524\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0017226652707904577 \t\t Generator Loss: 0.2056160271167755 \t\t Total Loss: 0.20733869075775146\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00010594588093226776 \t\t Loss_Fake: 0.9973508715629578\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.001466668676584959 \t\t Generator Loss: 0.20666806399822235 \t\t Total Loss: 0.208134725689888\n",
            "\t\t\t\t Discriminator Loss_Real: 9.762313857208937e-05 \t\t Loss_Fake: 0.9971965551376343\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0012351702898740768 \t\t Generator Loss: 0.20484237372875214 \t\t Total Loss: 0.20607754588127136\n",
            "\t\t\t\t Discriminator Loss_Real: 9.041318844538182e-05 \t\t Loss_Fake: 0.9969975352287292\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.000997080816887319 \t\t Generator Loss: 0.2073957920074463 \t\t Total Loss: 0.20839287340641022\n",
            "\t\t\t\t Discriminator Loss_Real: 8.256492583313957e-05 \t\t Loss_Fake: 0.9967138171195984\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0007868724642321467 \t\t Generator Loss: 0.2086453139781952 \t\t Total Loss: 0.2094321846961975\n",
            "\t\t\t\t Discriminator Loss_Real: 7.701097638346255e-05 \t\t Loss_Fake: 0.9965949058532715\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0012432639487087727 \t\t Generator Loss: 0.20561666786670685 \t\t Total Loss: 0.20685993134975433\n",
            "\t\t\t\t Discriminator Loss_Real: 7.814344280632213e-05 \t\t Loss_Fake: 0.9963647723197937\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.001001345575787127 \t\t Generator Loss: 0.20805302262306213 \t\t Total Loss: 0.2090543657541275\n",
            "\t\t\t\t Discriminator Loss_Real: 8.921663538785651e-05 \t\t Loss_Fake: 0.9962601661682129\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.001278794719837606 \t\t Generator Loss: 0.21233220398426056 \t\t Total Loss: 0.21361099183559418\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00011250875104451552 \t\t Loss_Fake: 0.9955934286117554\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0002247592929052189 \t\t Generator Loss: 0.2706011235713959 \t\t Total Loss: 0.27082589268684387\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00016082078218460083 \t\t Loss_Fake: 0.9988647699356079\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0016689397161826491 \t\t Generator Loss: 0.26247039437294006 \t\t Total Loss: 0.264139324426651\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0002891494077630341 \t\t Loss_Fake: 0.9956768155097961\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0022834069095551968 \t\t Generator Loss: 0.2734364867210388 \t\t Total Loss: 0.27571988105773926\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0005923046846874058 \t\t Loss_Fake: 0.9965227246284485\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0007608774467371404 \t\t Generator Loss: 0.2902096211910248 \t\t Total Loss: 0.29097050428390503\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00118454999756068 \t\t Loss_Fake: 0.9932821989059448\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.011188012547791004 \t\t Generator Loss: 0.2929247319698334 \t\t Total Loss: 0.3041127324104309\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0071174330078065395 \t\t Loss_Fake: 0.9994930028915405\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 5.8696565247373655e-05 \t\t Generator Loss: 0.31422993540763855 \t\t Total Loss: 0.3142886459827423\n",
            "\t\t\t\t Discriminator Loss_Real: 5.6011456763371825e-05 \t\t Loss_Fake: 0.9997879862785339\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 3.749065945157781e-05 \t\t Generator Loss: 0.3221171498298645 \t\t Total Loss: 0.3221546411514282\n",
            "\t\t\t\t Discriminator Loss_Real: 3.187268157489598e-05 \t\t Loss_Fake: 0.9998636245727539\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 2.7153530027135275e-05 \t\t Generator Loss: 0.31214576959609985 \t\t Total Loss: 0.31217291951179504\n",
            "\t\t\t\t Discriminator Loss_Real: 2.4894219677662477e-05 \t\t Loss_Fake: 0.9998911619186401\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 2.3159203919931315e-05 \t\t Generator Loss: 0.3113388419151306 \t\t Total Loss: 0.31136199831962585\n",
            "\t\t\t\t Discriminator Loss_Real: 2.1393225324572995e-05 \t\t Loss_Fake: 0.9998998641967773\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 2.1544889023061842e-05 \t\t Generator Loss: 0.29785075783729553 \t\t Total Loss: 0.29787230491638184\n",
            "\t\t\t\t Discriminator Loss_Real: 1.9914356016670354e-05 \t\t Loss_Fake: 0.9999014735221863\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 2.042818596237339e-05 \t\t Generator Loss: 0.29407545924186707 \t\t Total Loss: 0.29409587383270264\n",
            "\t\t\t\t Discriminator Loss_Real: 1.9216393411625177e-05 \t\t Loss_Fake: 0.9999035596847534\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 2.0454859622986987e-05 \t\t Generator Loss: 0.2869749069213867 \t\t Total Loss: 0.2869953513145447\n",
            "\t\t\t\t Discriminator Loss_Real: 1.910309038066771e-05 \t\t Loss_Fake: 0.9999000430107117\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 2.099995981552638e-05 \t\t Generator Loss: 0.28351688385009766 \t\t Total Loss: 0.283537894487381\n",
            "\t\t\t\t Discriminator Loss_Real: 1.9526976757333614e-05 \t\t Loss_Fake: 0.9998947978019714\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 2.1949546862742864e-05 \t\t Generator Loss: 0.2819282114505768 \t\t Total Loss: 0.2819501757621765\n",
            "\t\t\t\t Discriminator Loss_Real: 2.0639736248995177e-05 \t\t Loss_Fake: 0.9998880624771118\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 2.3556412998004816e-05 \t\t Generator Loss: 0.279500275850296 \t\t Total Loss: 0.2795238196849823\n",
            "\t\t\t\t Discriminator Loss_Real: 2.2423590053222142e-05 \t\t Loss_Fake: 0.9998750686645508\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 2.6960118702845648e-05 \t\t Generator Loss: 0.2790054976940155 \t\t Total Loss: 0.27903246879577637\n",
            "\t\t\t\t Discriminator Loss_Real: 2.529434277676046e-05 \t\t Loss_Fake: 0.9998587369918823\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 3.121502959402278e-05 \t\t Generator Loss: 0.2807370126247406 \t\t Total Loss: 0.2807682156562805\n",
            "\t\t\t\t Discriminator Loss_Real: 2.994278838741593e-05 \t\t Loss_Fake: 0.9998350143432617\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 3.947303048335016e-05 \t\t Generator Loss: 0.27637749910354614 \t\t Total Loss: 0.27641695737838745\n",
            "\t\t\t\t Discriminator Loss_Real: 3.779533290071413e-05 \t\t Loss_Fake: 0.9998000860214233\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 5.3434388973983005e-05 \t\t Generator Loss: 0.27612948417663574 \t\t Total Loss: 0.2761829197406769\n",
            "\t\t\t\t Discriminator Loss_Real: 5.176984268473461e-05 \t\t Loss_Fake: 0.9997529983520508\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 7.952751911943778e-05 \t\t Generator Loss: 0.2759370803833008 \t\t Total Loss: 0.27601662278175354\n",
            "\t\t\t\t Discriminator Loss_Real: 7.816547440597787e-05 \t\t Loss_Fake: 0.9996905326843262\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.00012659543426707387 \t\t Generator Loss: 0.2725697457790375 \t\t Total Loss: 0.2726963460445404\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00012523148325271904 \t\t Loss_Fake: 0.9996263384819031\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.00019004667410627007 \t\t Generator Loss: 0.27152201533317566 \t\t Total Loss: 0.271712064743042\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00018973680562339723 \t\t Loss_Fake: 0.9995807409286499\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0002366456901654601 \t\t Generator Loss: 0.2721237540245056 \t\t Total Loss: 0.2723604142665863\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00023636603145860136 \t\t Loss_Fake: 0.9995670318603516\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.00022931804414838552 \t\t Generator Loss: 0.27181166410446167 \t\t Total Loss: 0.272040992975235\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00022948342666495591 \t\t Loss_Fake: 0.9995824098587036\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0001829760440159589 \t\t Generator Loss: 0.2700587213039398 \t\t Total Loss: 0.27024170756340027\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00018161910702474415 \t\t Loss_Fake: 0.9996167421340942\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.00013469552504830062 \t\t Generator Loss: 0.26955950260162354 \t\t Total Loss: 0.2696942090988159\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00013300179853104055 \t\t Loss_Fake: 0.9996522665023804\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.00010407411173218861 \t\t Generator Loss: 0.26942920684814453 \t\t Total Loss: 0.26953327655792236\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00010184964776271954 \t\t Loss_Fake: 0.9996762275695801\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 8.920203981688246e-05 \t\t Generator Loss: 0.26906970143318176 \t\t Total Loss: 0.26915889978408813\n",
            "\t\t\t\t Discriminator Loss_Real: 8.723820064915344e-05 \t\t Loss_Fake: 0.9996840357780457\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 8.719010656932369e-05 \t\t Generator Loss: 0.26874327659606934 \t\t Total Loss: 0.26883047819137573\n",
            "\t\t\t\t Discriminator Loss_Real: 8.493586210533977e-05 \t\t Loss_Fake: 0.9996768236160278\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 9.465383482165635e-05 \t\t Generator Loss: 0.26881617307662964 \t\t Total Loss: 0.26891082525253296\n",
            "\t\t\t\t Discriminator Loss_Real: 9.256346675101668e-05 \t\t Loss_Fake: 0.9996585845947266\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.00011104003351647407 \t\t Generator Loss: 0.2686071991920471 \t\t Total Loss: 0.26871824264526367\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0001088244971469976 \t\t Loss_Fake: 0.9996334314346313\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.00013304462481755763 \t\t Generator Loss: 0.2682749330997467 \t\t Total Loss: 0.2684079706668854\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00013061767094768584 \t\t Loss_Fake: 0.9996103048324585\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.00015293426986318082 \t\t Generator Loss: 0.26804524660110474 \t\t Total Loss: 0.2681981921195984\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0001505346444901079 \t\t Loss_Fake: 0.9995952844619751\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0001620638940948993 \t\t Generator Loss: 0.2679707705974579 \t\t Total Loss: 0.2681328356266022\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00015942846948746592 \t\t Loss_Fake: 0.9995920062065125\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0001564938429510221 \t\t Generator Loss: 0.2706223428249359 \t\t Total Loss: 0.2707788348197937\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00015394091315101832 \t\t Loss_Fake: 0.9995988607406616\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0001422589848516509 \t\t Generator Loss: 0.270378053188324 \t\t Total Loss: 0.27052029967308044\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0001395627623423934 \t\t Loss_Fake: 0.9996106028556824\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.00012724666157737374 \t\t Generator Loss: 0.2702099680900574 \t\t Total Loss: 0.27033722400665283\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00012470588262658566 \t\t Loss_Fake: 0.9996215105056763\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.00011736425949493423 \t\t Generator Loss: 0.2701657712459564 \t\t Total Loss: 0.27028313279151917\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0001147332732216455 \t\t Loss_Fake: 0.9996268153190613\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.00011388459097361192 \t\t Generator Loss: 0.2701207995414734 \t\t Total Loss: 0.2702346742153168\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00011117946996819228 \t\t Loss_Fake: 0.9996255040168762\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.00011662172619253397 \t\t Generator Loss: 0.270119845867157 \t\t Total Loss: 0.27023646235466003\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00011377667397027835 \t\t Loss_Fake: 0.9996183514595032\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0001239144039573148 \t\t Generator Loss: 0.2700386941432953 \t\t Total Loss: 0.2701626121997833\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0001208046087413095 \t\t Loss_Fake: 0.9996083974838257\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.00013280613347887993 \t\t Generator Loss: 0.2700163424015045 \t\t Total Loss: 0.2701491415500641\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00012959651940036565 \t\t Loss_Fake: 0.9995986223220825\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.00014041690155863762 \t\t Generator Loss: 0.27000051736831665 \t\t Total Loss: 0.27014094591140747\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00013682626013178378 \t\t Loss_Fake: 0.999592125415802\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.00014346337411552668 \t\t Generator Loss: 0.2699500620365143 \t\t Total Loss: 0.27009353041648865\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00013993764878250659 \t\t Loss_Fake: 0.9995898008346558\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0001421074994141236 \t\t Generator Loss: 0.2588433623313904 \t\t Total Loss: 0.2589854598045349\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00013823961489833891 \t\t Loss_Fake: 0.999591052532196\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.00013746958575211465 \t\t Generator Loss: 0.2587864100933075 \t\t Total Loss: 0.25892388820648193\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00013361281889956445 \t\t Loss_Fake: 0.9995940923690796\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.00013253824727144092 \t\t Generator Loss: 0.2587284445762634 \t\t Total Loss: 0.2588609755039215\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00012869530473835766 \t\t Loss_Fake: 0.9995962977409363\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.00012945826165378094 \t\t Generator Loss: 0.2586621940135956 \t\t Total Loss: 0.25879165530204773\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0001255268871318549 \t\t Loss_Fake: 0.9995962381362915\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.00012893122038803995 \t\t Generator Loss: 0.2585766315460205 \t\t Total Loss: 0.2587055563926697\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0001251453359145671 \t\t Loss_Fake: 0.9995932579040527\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0001310377410845831 \t\t Generator Loss: 0.2588772177696228 \t\t Total Loss: 0.2590082585811615\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0001271248038392514 \t\t Loss_Fake: 0.999588131904602\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.00013471051352098584 \t\t Generator Loss: 0.2585141062736511 \t\t Total Loss: 0.2586488127708435\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00013070066052023321 \t\t Loss_Fake: 0.9995818138122559\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0001385251962346956 \t\t Generator Loss: 0.25725308060646057 \t\t Total Loss: 0.2573916018009186\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00013458114699460566 \t\t Loss_Fake: 0.9995757937431335\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.00014064038987271488 \t\t Generator Loss: 0.2542606294155121 \t\t Total Loss: 0.2544012665748596\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00013755355030298233 \t\t Loss_Fake: 0.9995718002319336\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0001420633343514055 \t\t Generator Loss: 0.2545331120491028 \t\t Total Loss: 0.2546751797199249\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00013861853221897036 \t\t Loss_Fake: 0.9995654821395874\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.00014363700756803155 \t\t Generator Loss: 0.252098947763443 \t\t Total Loss: 0.2522425949573517\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00013864212087355554 \t\t Loss_Fake: 0.9995616674423218\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0001430401171091944 \t\t Generator Loss: 0.2507091760635376 \t\t Total Loss: 0.25085222721099854\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00013804339687339962 \t\t Loss_Fake: 0.9995566606521606\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.00014198983262758702 \t\t Generator Loss: 0.25161728262901306 \t\t Total Loss: 0.25175926089286804\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00013784770271740854 \t\t Loss_Fake: 0.9995497465133667\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.00014470136375166476 \t\t Generator Loss: 0.2505037188529968 \t\t Total Loss: 0.2506484091281891\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00013887981185689569 \t\t Loss_Fake: 0.9995393753051758\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.00014755813754163682 \t\t Generator Loss: 0.24969482421875 \t\t Total Loss: 0.24984237551689148\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0001418035535607487 \t\t Loss_Fake: 0.9995236396789551\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0001520501245977357 \t\t Generator Loss: 0.25013694167137146 \t\t Total Loss: 0.2502889931201935\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00014654984988737851 \t\t Loss_Fake: 0.999504566192627\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.00016110991418827325 \t\t Generator Loss: 0.250078946352005 \t\t Total Loss: 0.2502400577068329\n",
            "\t\t\t\t Discriminator Loss_Real: 0.000153587810928002 \t\t Loss_Fake: 0.9994775652885437\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0001713789824862033 \t\t Generator Loss: 0.2490708827972412 \t\t Total Loss: 0.24924226105213165\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00016391405370086432 \t\t Loss_Fake: 0.9994378089904785\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.00018855722737498581 \t\t Generator Loss: 0.24906103312969208 \t\t Total Loss: 0.24924959242343903\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00018046176410280168 \t\t Loss_Fake: 0.9993890523910522\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.00022118387278169394 \t\t Generator Loss: 0.24780365824699402 \t\t Total Loss: 0.2480248361825943\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00020885918638668954 \t\t Loss_Fake: 0.9993289113044739\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.00027226621750742197 \t\t Generator Loss: 0.2537379860877991 \t\t Total Loss: 0.25401026010513306\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00025661851395852864 \t\t Loss_Fake: 0.9992650151252747\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0003329417377244681 \t\t Generator Loss: 0.2522885203361511 \t\t Total Loss: 0.25262147188186646\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0003154966689180583 \t\t Loss_Fake: 0.9992260932922363\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.00037525390507653356 \t\t Generator Loss: 0.25318142771720886 \t\t Total Loss: 0.25355666875839233\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0003502666368149221 \t\t Loss_Fake: 0.9992225766181946\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.00036238113534636796 \t\t Generator Loss: 0.25219160318374634 \t\t Total Loss: 0.2525539696216583\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0003347715537529439 \t\t Loss_Fake: 0.9992380142211914\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0003099210443906486 \t\t Generator Loss: 0.25131604075431824 \t\t Total Loss: 0.2516259551048279\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0002883635461330414 \t\t Loss_Fake: 0.9992650747299194\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0002657418081071228 \t\t Generator Loss: 0.251634806394577 \t\t Total Loss: 0.2519005537033081\n",
            "\t\t\t\t Discriminator Loss_Real: 0.000245546514634043 \t\t Loss_Fake: 0.9992977380752563\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.00024352122272830456 \t\t Generator Loss: 0.25205525755882263 \t\t Total Loss: 0.2522987723350525\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0002212438266724348 \t\t Loss_Fake: 0.999313473701477\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0002342137013329193 \t\t Generator Loss: 0.25123894214630127 \t\t Total Loss: 0.25147315859794617\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00021347124129533768 \t\t Loss_Fake: 0.9993070363998413\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.00023851396690588444 \t\t Generator Loss: 0.2509700357913971 \t\t Total Loss: 0.2512085437774658\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00021715377806685865 \t\t Loss_Fake: 0.9992952346801758\n",
            "\n",
            "Epoch: 1 \t Discriminator Loss: 0.0002562002628110349 \t\t Generator Loss: 0.250975638628006 \t\t Total Loss: 0.251231849193573\n",
            "Epoch 3 started\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00022829514637123793 \t\t Loss_Fake: 0.999274730682373\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.0002770760911516845 \t\t Generator Loss: 0.24860236048698425 \t\t Total Loss: 0.24887943267822266\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00024567003129050136 \t\t Loss_Fake: 0.9992451667785645\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.00030162776238285005 \t\t Generator Loss: 0.2483806312084198 \t\t Total Loss: 0.24868226051330566\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0002648193622007966 \t\t Loss_Fake: 0.9992274045944214\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.0003245135594625026 \t\t Generator Loss: 0.24823269248008728 \t\t Total Loss: 0.2485572099685669\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00027852007769979537 \t\t Loss_Fake: 0.9992163777351379\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.0003271414607297629 \t\t Generator Loss: 0.24824829399585724 \t\t Total Loss: 0.24857543408870697\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00027988720103167 \t\t Loss_Fake: 0.9992141723632812\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.00031689403112977743 \t\t Generator Loss: 0.2482583075761795 \t\t Total Loss: 0.24857519567012787\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0002702007768675685 \t\t Loss_Fake: 0.9992244839668274\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.00030361750395968556 \t\t Generator Loss: 0.24798119068145752 \t\t Total Loss: 0.24828480184078217\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0002552604419179261 \t\t Loss_Fake: 0.9992325901985168\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.0002895974030252546 \t\t Generator Loss: 0.2478698492050171 \t\t Total Loss: 0.24815945327281952\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00024395268701482564 \t\t Loss_Fake: 0.9992340207099915\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.000285496556898579 \t\t Generator Loss: 0.2478751391172409 \t\t Total Loss: 0.24816063046455383\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0002394683688180521 \t\t Loss_Fake: 0.9992328882217407\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.00029336835723370314 \t\t Generator Loss: 0.24787887930870056 \t\t Total Loss: 0.24817225337028503\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00024139457673300058 \t\t Loss_Fake: 0.9992241859436035\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.00030211606645025313 \t\t Generator Loss: 0.24780838191509247 \t\t Total Loss: 0.24811050295829773\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00024835707154124975 \t\t Loss_Fake: 0.9992130994796753\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.0003066026256419718 \t\t Generator Loss: 0.2555544078350067 \t\t Total Loss: 0.2558610141277313\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00025587709387764335 \t\t Loss_Fake: 0.9992018938064575\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.0003234847681596875 \t\t Generator Loss: 0.25535687804222107 \t\t Total Loss: 0.2556803524494171\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0002615453558973968 \t\t Loss_Fake: 0.9991981387138367\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.0003305293503217399 \t\t Generator Loss: 0.25536465644836426 \t\t Total Loss: 0.2556951940059662\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0002628230722621083 \t\t Loss_Fake: 0.9991914629936218\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.00032511522294953465 \t\t Generator Loss: 0.25533607602119446 \t\t Total Loss: 0.2556611895561218\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0002591725788079202 \t\t Loss_Fake: 0.9991894960403442\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.0003224521642550826 \t\t Generator Loss: 0.2552209794521332 \t\t Total Loss: 0.25554344058036804\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00025238218950107694 \t\t Loss_Fake: 0.9991937875747681\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.000323557440424338 \t\t Generator Loss: 0.255155086517334 \t\t Total Loss: 0.2554786503314972\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00024677766487002373 \t\t Loss_Fake: 0.9991930723190308\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.0003197726036887616 \t\t Generator Loss: 0.2550574839115143 \t\t Total Loss: 0.25537726283073425\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0002446836151648313 \t\t Loss_Fake: 0.9991856813430786\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.00032152258791029453 \t\t Generator Loss: 0.2550381124019623 \t\t Total Loss: 0.2553596496582031\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0002461036783643067 \t\t Loss_Fake: 0.9991795420646667\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.000333121424773708 \t\t Generator Loss: 0.25491514801979065 \t\t Total Loss: 0.2552482783794403\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0002495967491995543 \t\t Loss_Fake: 0.9991728067398071\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.0003420374705456197 \t\t Generator Loss: 0.2547752857208252 \t\t Total Loss: 0.2551173269748688\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0002533012884669006 \t\t Loss_Fake: 0.9991620779037476\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.0003461455926299095 \t\t Generator Loss: 0.25015729665756226 \t\t Total Loss: 0.25050345063209534\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0002557365223765373 \t\t Loss_Fake: 0.9991540908813477\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.0003492735559120774 \t\t Generator Loss: 0.24906936287879944 \t\t Total Loss: 0.24941863119602203\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00025542828370817006 \t\t Loss_Fake: 0.9991508722305298\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.0003461005981080234 \t\t Generator Loss: 0.24613304436206818 \t\t Total Loss: 0.24647913873195648\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0002530398778617382 \t\t Loss_Fake: 0.9991565942764282\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.0003428655327297747 \t\t Generator Loss: 0.24564337730407715 \t\t Total Loss: 0.2459862381219864\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0002511804341338575 \t\t Loss_Fake: 0.999130368232727\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.00034014059929177165 \t\t Generator Loss: 0.2473468780517578 \t\t Total Loss: 0.24768701195716858\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00025033106794580817 \t\t Loss_Fake: 0.9991288185119629\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.00035227861371822655 \t\t Generator Loss: 0.24671611189842224 \t\t Total Loss: 0.247068390250206\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0002501978015061468 \t\t Loss_Fake: 0.9991313815116882\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.00036771525628864765 \t\t Generator Loss: 0.24564671516418457 \t\t Total Loss: 0.24601443111896515\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0002536386309657246 \t\t Loss_Fake: 0.9990917444229126\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.0003498596197459847 \t\t Generator Loss: 0.24614587426185608 \t\t Total Loss: 0.24649573862552643\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0002593323588371277 \t\t Loss_Fake: 0.9990681409835815\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.0003669023572001606 \t\t Generator Loss: 0.24543742835521698 \t\t Total Loss: 0.2458043247461319\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00026514774071983993 \t\t Loss_Fake: 0.9990439414978027\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.00040355889359489083 \t\t Generator Loss: 0.24575869739055634 \t\t Total Loss: 0.24616225063800812\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00027215437148697674 \t\t Loss_Fake: 0.998995304107666\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.0004155679198447615 \t\t Generator Loss: 0.25088196992874146 \t\t Total Loss: 0.2512975335121155\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00028799514984712005 \t\t Loss_Fake: 0.9989164471626282\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.0004388350644148886 \t\t Generator Loss: 0.2510530352592468 \t\t Total Loss: 0.25149187445640564\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0003201941435690969 \t\t Loss_Fake: 0.9988166093826294\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.0005166848422959447 \t\t Generator Loss: 0.2506250739097595 \t\t Total Loss: 0.251141756772995\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00038525115814991295 \t\t Loss_Fake: 0.9987310171127319\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.0006318733212538064 \t\t Generator Loss: 0.2507724165916443 \t\t Total Loss: 0.2514042854309082\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0004772600659634918 \t\t Loss_Fake: 0.9986518621444702\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.0006830894853919744 \t\t Generator Loss: 0.250501424074173 \t\t Total Loss: 0.25118452310562134\n",
            "\t\t\t\t Discriminator Loss_Real: 0.000521805661264807 \t\t Loss_Fake: 0.9985979199409485\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.0006451158551499248 \t\t Generator Loss: 0.25067138671875 \t\t Total Loss: 0.25131648778915405\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0004915502504445612 \t\t Loss_Fake: 0.9985702633857727\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.0006449843640439212 \t\t Generator Loss: 0.25038689374923706 \t\t Total Loss: 0.25103187561035156\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00046444195322692394 \t\t Loss_Fake: 0.9985524415969849\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.0006928496295586228 \t\t Generator Loss: 0.25036925077438354 \t\t Total Loss: 0.2510620951652527\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00048753758892416954 \t\t Loss_Fake: 0.9985305070877075\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.0007353556575253606 \t\t Generator Loss: 0.250177800655365 \t\t Total Loss: 0.250913143157959\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00052422727458179 \t\t Loss_Fake: 0.9985097646713257\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.0007295323302969337 \t\t Generator Loss: 0.25003188848495483 \t\t Total Loss: 0.2507614195346832\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0005179680301807821 \t\t Loss_Fake: 0.9985048174858093\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.0007063407683745027 \t\t Generator Loss: 0.2521599233150482 \t\t Total Loss: 0.252866268157959\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00047576409997418523 \t\t Loss_Fake: 0.9985136985778809\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.0006923866458237171 \t\t Generator Loss: 0.25091156363487244 \t\t Total Loss: 0.25160396099090576\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0004502000811044127 \t\t Loss_Fake: 0.9984956979751587\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.0007404973148368299 \t\t Generator Loss: 0.24552187323570251 \t\t Total Loss: 0.24626237154006958\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00045434036292135715 \t\t Loss_Fake: 0.9984406232833862\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.0006908939103595912 \t\t Generator Loss: 0.24218440055847168 \t\t Total Loss: 0.24287529289722443\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00045550675713457167 \t\t Loss_Fake: 0.9985111355781555\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.0006510274251922965 \t\t Generator Loss: 0.24512889981269836 \t\t Total Loss: 0.24577993154525757\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0004423736536409706 \t\t Loss_Fake: 0.9984632730484009\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.0007270206115208566 \t\t Generator Loss: 0.24389073252677917 \t\t Total Loss: 0.244617760181427\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0004327287897467613 \t\t Loss_Fake: 0.9984537363052368\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.0007529560243710876 \t\t Generator Loss: 0.24340543150901794 \t\t Total Loss: 0.24415838718414307\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00043375222594477236 \t\t Loss_Fake: 0.9984807968139648\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.0007343210163526237 \t\t Generator Loss: 0.2426106482744217 \t\t Total Loss: 0.2433449625968933\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0004504320677369833 \t\t Loss_Fake: 0.9984172582626343\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.000765583070460707 \t\t Generator Loss: 0.24108919501304626 \t\t Total Loss: 0.24185477197170258\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0004682740254793316 \t\t Loss_Fake: 0.9983669519424438\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.0007691941573284566 \t\t Generator Loss: 0.24106788635253906 \t\t Total Loss: 0.24183708429336548\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0004670995404012501 \t\t Loss_Fake: 0.9984186887741089\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.0007543224492110312 \t\t Generator Loss: 0.23161105811595917 \t\t Total Loss: 0.23236538469791412\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0004524342657532543 \t\t Loss_Fake: 0.9984349012374878\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.0007790527306497097 \t\t Generator Loss: 0.23022779822349548 \t\t Total Loss: 0.23100684583187103\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00044291038648225367 \t\t Loss_Fake: 0.9984137415885925\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.0007400932954624295 \t\t Generator Loss: 0.22841250896453857 \t\t Total Loss: 0.2291526049375534\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0004382189945317805 \t\t Loss_Fake: 0.9983946084976196\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.0007395296124741435 \t\t Generator Loss: 0.2300586700439453 \t\t Total Loss: 0.23079819977283478\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00043244403786957264 \t\t Loss_Fake: 0.998400092124939\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.0008343541994690895 \t\t Generator Loss: 0.22692017257213593 \t\t Total Loss: 0.22775453329086304\n",
            "\t\t\t\t Discriminator Loss_Real: 0.000427369202952832 \t\t Loss_Fake: 0.9984146356582642\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.0007917706971056759 \t\t Generator Loss: 0.22705450654029846 \t\t Total Loss: 0.22784627974033356\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00042972894152626395 \t\t Loss_Fake: 0.998360276222229\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.0007993035251274705 \t\t Generator Loss: 0.2267363965511322 \t\t Total Loss: 0.2275356948375702\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0004330943920649588 \t\t Loss_Fake: 0.9983493089675903\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.0008522855932824314 \t\t Generator Loss: 0.2252258062362671 \t\t Total Loss: 0.2260780930519104\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0004281486035324633 \t\t Loss_Fake: 0.998365044593811\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.0008612864767201245 \t\t Generator Loss: 0.22525222599506378 \t\t Total Loss: 0.22611351311206818\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00041974923806264997 \t\t Loss_Fake: 0.9983434677124023\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.0008354156161658466 \t\t Generator Loss: 0.2256985902786255 \t\t Total Loss: 0.22653400897979736\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0004103922692593187 \t\t Loss_Fake: 0.9983298182487488\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.0009334001806564629 \t\t Generator Loss: 0.22171175479888916 \t\t Total Loss: 0.22264514863491058\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0003977221786044538 \t\t Loss_Fake: 0.998358428478241\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.0009416810353286564 \t\t Generator Loss: 0.22119025886058807 \t\t Total Loss: 0.22213193774223328\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00038979193777777255 \t\t Loss_Fake: 0.998343288898468\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.000905728607904166 \t\t Generator Loss: 0.22098323702812195 \t\t Total Loss: 0.2218889594078064\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0003908760263584554 \t\t Loss_Fake: 0.9982967376708984\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.0008707338129170239 \t\t Generator Loss: 0.22145268321037292 \t\t Total Loss: 0.22232341766357422\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00038852920988574624 \t\t Loss_Fake: 0.9982932806015015\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.0009003413724713027 \t\t Generator Loss: 0.22088448703289032 \t\t Total Loss: 0.2217848300933838\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00037738707032985985 \t\t Loss_Fake: 0.9983118772506714\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.0009695285698398948 \t\t Generator Loss: 0.22075524926185608 \t\t Total Loss: 0.22172477841377258\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0003666067204903811 \t\t Loss_Fake: 0.9983288645744324\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.0009812803473323584 \t\t Generator Loss: 0.22088608145713806 \t\t Total Loss: 0.2218673676252365\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00036702441866509616 \t\t Loss_Fake: 0.9983009099960327\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.0009970625396817923 \t\t Generator Loss: 0.22080016136169434 \t\t Total Loss: 0.22179722785949707\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00037517931195907295 \t\t Loss_Fake: 0.9982627630233765\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.0009927849750965834 \t\t Generator Loss: 0.2208116352558136 \t\t Total Loss: 0.2218044251203537\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00037534197326749563 \t\t Loss_Fake: 0.9982587099075317\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.0010077198967337608 \t\t Generator Loss: 0.22060294449329376 \t\t Total Loss: 0.2216106653213501\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00036130729131400585 \t\t Loss_Fake: 0.9982743263244629\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.000990836531855166 \t\t Generator Loss: 0.2208062708377838 \t\t Total Loss: 0.22179710865020752\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00034510233672335744 \t\t Loss_Fake: 0.9982824325561523\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.0010061466600745916 \t\t Generator Loss: 0.2208356410264969 \t\t Total Loss: 0.22184178233146667\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00033821846591308713 \t\t Loss_Fake: 0.9982719421386719\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.0010556012857705355 \t\t Generator Loss: 0.22079050540924072 \t\t Total Loss: 0.2218461036682129\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0003407556505408138 \t\t Loss_Fake: 0.9982500076293945\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.0010929267155006528 \t\t Generator Loss: 0.22073158621788025 \t\t Total Loss: 0.221824511885643\n",
            "\t\t\t\t Discriminator Loss_Real: 0.000344729982316494 \t\t Loss_Fake: 0.9982337951660156\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.0011069010943174362 \t\t Generator Loss: 0.2207171618938446 \t\t Total Loss: 0.2218240648508072\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00034090763074345887 \t\t Loss_Fake: 0.998226523399353\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.0011011087335646152 \t\t Generator Loss: 0.22116979956626892 \t\t Total Loss: 0.2222709059715271\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0003291772154625505 \t\t Loss_Fake: 0.9982287287712097\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.0010831494582816958 \t\t Generator Loss: 0.22115764021873474 \t\t Total Loss: 0.22224079072475433\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00031425192719325423 \t\t Loss_Fake: 0.9982374310493469\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.0011027985019609332 \t\t Generator Loss: 0.22111161053180695 \t\t Total Loss: 0.22221441566944122\n",
            "\t\t\t\t Discriminator Loss_Real: 0.000304290879284963 \t\t Loss_Fake: 0.9982351064682007\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.0011371274013072252 \t\t Generator Loss: 0.22109496593475342 \t\t Total Loss: 0.22223208844661713\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00030231711571104825 \t\t Loss_Fake: 0.9982274174690247\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.0011746162781491876 \t\t Generator Loss: 0.22109857201576233 \t\t Total Loss: 0.22227318584918976\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0003060828894376755 \t\t Loss_Fake: 0.9982005953788757\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.0013688411563634872 \t\t Generator Loss: 0.2243366688489914 \t\t Total Loss: 0.22570550441741943\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00030425965087488294 \t\t Loss_Fake: 0.9982115626335144\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.0013678927207365632 \t\t Generator Loss: 0.22444915771484375 \t\t Total Loss: 0.22581705451011658\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0002962324651889503 \t\t Loss_Fake: 0.9982089996337891\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.0013580857776105404 \t\t Generator Loss: 0.2243284285068512 \t\t Total Loss: 0.22568652033805847\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00028941044001840055 \t\t Loss_Fake: 0.9981929063796997\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.001306445337831974 \t\t Generator Loss: 0.22428829967975616 \t\t Total Loss: 0.22559474408626556\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00028107623802497983 \t\t Loss_Fake: 0.9981822967529297\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.0012434383388608694 \t\t Generator Loss: 0.2244141846895218 \t\t Total Loss: 0.2256576269865036\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00026673648972064257 \t\t Loss_Fake: 0.9981812238693237\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.0011719256872311234 \t\t Generator Loss: 0.224624902009964 \t\t Total Loss: 0.22579683363437653\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0002496927627362311 \t\t Loss_Fake: 0.998190701007843\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.0011716142762452364 \t\t Generator Loss: 0.2245291769504547 \t\t Total Loss: 0.22570079565048218\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00023821371723897755 \t\t Loss_Fake: 0.9981956481933594\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.0012501736637204885 \t\t Generator Loss: 0.2244350165128708 \t\t Total Loss: 0.22568519413471222\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00023665853950660676 \t\t Loss_Fake: 0.9981884956359863\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.0013693124055862427 \t\t Generator Loss: 0.22440938651561737 \t\t Total Loss: 0.2257786989212036\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00024312769528478384 \t\t Loss_Fake: 0.9981729388237\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.001464157016016543 \t\t Generator Loss: 0.22441038489341736 \t\t Total Loss: 0.22587454319000244\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0002503083669580519 \t\t Loss_Fake: 0.9981578588485718\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.00152097106911242 \t\t Generator Loss: 0.2226661890745163 \t\t Total Loss: 0.22418716549873352\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0002505247830413282 \t\t Loss_Fake: 0.9981549978256226\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.0014689706731587648 \t\t Generator Loss: 0.22270309925079346 \t\t Total Loss: 0.22417207062244415\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00024104109616018832 \t\t Loss_Fake: 0.998156726360321\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.0014108642935752869 \t\t Generator Loss: 0.22271659970283508 \t\t Total Loss: 0.22412747144699097\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00022797883138991892 \t\t Loss_Fake: 0.9981597661972046\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.0013702232390642166 \t\t Generator Loss: 0.22273114323616028 \t\t Total Loss: 0.22410136461257935\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00021666567772626877 \t\t Loss_Fake: 0.9981609582901001\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.0013415893772616982 \t\t Generator Loss: 0.22275491058826447 \t\t Total Loss: 0.22409650683403015\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00020949395548086613 \t\t Loss_Fake: 0.9981580972671509\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.001319864415563643 \t\t Generator Loss: 0.22308699786663055 \t\t Total Loss: 0.2244068682193756\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00020671411766670644 \t\t Loss_Fake: 0.9981502294540405\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.0013396890135481954 \t\t Generator Loss: 0.22311536967754364 \t\t Total Loss: 0.2244550585746765\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00020659351139329374 \t\t Loss_Fake: 0.998142421245575\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.0013866761000826955 \t\t Generator Loss: 0.22310392558574677 \t\t Total Loss: 0.22449059784412384\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00020586742903105915 \t\t Loss_Fake: 0.9981377720832825\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.0014184101019054651 \t\t Generator Loss: 0.2230869084596634 \t\t Total Loss: 0.22450532019138336\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0002021571563091129 \t\t Loss_Fake: 0.9981368184089661\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.001417201361618936 \t\t Generator Loss: 0.22307559847831726 \t\t Total Loss: 0.22449280321598053\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0001969658478628844 \t\t Loss_Fake: 0.9981304407119751\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.0015053664101287723 \t\t Generator Loss: 0.2301335632801056 \t\t Total Loss: 0.23163892328739166\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00018894829554483294 \t\t Loss_Fake: 0.9981377720832825\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.0015451173530891538 \t\t Generator Loss: 0.23010139167308807 \t\t Total Loss: 0.23164650797843933\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00018256792100146413 \t\t Loss_Fake: 0.9981411099433899\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.0016101797809824347 \t\t Generator Loss: 0.23009678721427917 \t\t Total Loss: 0.23170696198940277\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00018157507292926311 \t\t Loss_Fake: 0.9981335401535034\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.0016626527067273855 \t\t Generator Loss: 0.2300972044467926 \t\t Total Loss: 0.23175986111164093\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00018493153038434684 \t\t Loss_Fake: 0.9981219172477722\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.0016901663038879633 \t\t Generator Loss: 0.23008981347084045 \t\t Total Loss: 0.23177997767925262\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00018787333101499826 \t\t Loss_Fake: 0.9981139898300171\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.0016997780185192823 \t\t Generator Loss: 0.23032605648040771 \t\t Total Loss: 0.23202583193778992\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00018731878662947565 \t\t Loss_Fake: 0.9981093406677246\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.0016591763123869896 \t\t Generator Loss: 0.23030154407024384 \t\t Total Loss: 0.2319607138633728\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00018163819913752377 \t\t Loss_Fake: 0.9981074333190918\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.00159669597633183 \t\t Generator Loss: 0.23025746643543243 \t\t Total Loss: 0.2318541556596756\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0001733697426971048 \t\t Loss_Fake: 0.9981071352958679\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.0015350750181823969 \t\t Generator Loss: 0.23019056022167206 \t\t Total Loss: 0.23172563314437866\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00016598423826508224 \t\t Loss_Fake: 0.9981058239936829\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.0015039381105452776 \t\t Generator Loss: 0.23010997474193573 \t\t Total Loss: 0.2316139191389084\n",
            "\t\t\t\t Discriminator Loss_Real: 0.000161217205459252 \t\t Loss_Fake: 0.9981082677841187\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.001455687452107668 \t\t Generator Loss: 0.22923894226551056 \t\t Total Loss: 0.23069463670253754\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00016152477473951876 \t\t Loss_Fake: 0.9980924725532532\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.0014466434950008988 \t\t Generator Loss: 0.22942745685577393 \t\t Total Loss: 0.23087410628795624\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00016385862545575947 \t\t Loss_Fake: 0.9980777502059937\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.0014030449092388153 \t\t Generator Loss: 0.22964343428611755 \t\t Total Loss: 0.23104648292064667\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0001633879728615284 \t\t Loss_Fake: 0.9980657696723938\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.0013258627150207758 \t\t Generator Loss: 0.22983244061470032 \t\t Total Loss: 0.2311583012342453\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00015846324095036834 \t\t Loss_Fake: 0.998054027557373\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.0012533292174339294 \t\t Generator Loss: 0.2298981249332428 \t\t Total Loss: 0.23115146160125732\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00015096779679879546 \t\t Loss_Fake: 0.9980436563491821\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.001209648442454636 \t\t Generator Loss: 0.22973346710205078 \t\t Total Loss: 0.23094311356544495\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00014485044812317938 \t\t Loss_Fake: 0.9980254173278809\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.001202311716042459 \t\t Generator Loss: 0.22909343242645264 \t\t Total Loss: 0.23029574751853943\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0001419967011315748 \t\t Loss_Fake: 0.9980087280273438\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.0012114157434552908 \t\t Generator Loss: 0.22631585597991943 \t\t Total Loss: 0.22752727568149567\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00014299950271379203 \t\t Loss_Fake: 0.9980184435844421\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.0010513371089473367 \t\t Generator Loss: 0.2277545928955078 \t\t Total Loss: 0.22880592942237854\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0001494521420681849 \t\t Loss_Fake: 0.9979788661003113\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.0018423579167574644 \t\t Generator Loss: 0.22464826703071594 \t\t Total Loss: 0.22649063169956207\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00015997717855498195 \t\t Loss_Fake: 0.9979570508003235\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.0020853953901678324 \t\t Generator Loss: 0.22366853058338165 \t\t Total Loss: 0.22575393319129944\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00016953394515439868 \t\t Loss_Fake: 0.9979844093322754\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.001947983168065548 \t\t Generator Loss: 0.22424869239330292 \t\t Total Loss: 0.22619667649269104\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00017961372213903815 \t\t Loss_Fake: 0.997877299785614\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.0023694306146353483 \t\t Generator Loss: 0.22424927353858948 \t\t Total Loss: 0.2266187071800232\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00018132946570403874 \t\t Loss_Fake: 0.9978354573249817\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.0019711540080606937 \t\t Generator Loss: 0.2239414006471634 \t\t Total Loss: 0.22591255605220795\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00016714356024749577 \t\t Loss_Fake: 0.997813880443573\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.0021728291176259518 \t\t Generator Loss: 0.2232663929462433 \t\t Total Loss: 0.22543922066688538\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00015535025158897042 \t\t Loss_Fake: 0.9977346658706665\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.0020022201351821423 \t\t Generator Loss: 0.22342407703399658 \t\t Total Loss: 0.2254263013601303\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00015194722800515592 \t\t Loss_Fake: 0.9976984858512878\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.0019110755529254675 \t\t Generator Loss: 0.22395381331443787 \t\t Total Loss: 0.22586488723754883\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0001574707421241328 \t\t Loss_Fake: 0.9976047277450562\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.002269245684146881 \t\t Generator Loss: 0.22401821613311768 \t\t Total Loss: 0.22628745436668396\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00016805942868813872 \t\t Loss_Fake: 0.9975748062133789\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.0023307488299906254 \t\t Generator Loss: 0.22385427355766296 \t\t Total Loss: 0.22618502378463745\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0001765721244737506 \t\t Loss_Fake: 0.9975515604019165\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.002769241575151682 \t\t Generator Loss: 0.22330594062805176 \t\t Total Loss: 0.2260751873254776\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00017782037321012467 \t\t Loss_Fake: 0.9975073933601379\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.002664162777364254 \t\t Generator Loss: 0.22070078551769257 \t\t Total Loss: 0.2233649492263794\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00017291615949943662 \t\t Loss_Fake: 0.9974480867385864\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.002817736240103841 \t\t Generator Loss: 0.2206559181213379 \t\t Total Loss: 0.2234736531972885\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0001719407446216792 \t\t Loss_Fake: 0.9973691701889038\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.0027989365626126528 \t\t Generator Loss: 0.22077491879463196 \t\t Total Loss: 0.22357384860515594\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00017670152010396123 \t\t Loss_Fake: 0.9973106384277344\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.002790143247693777 \t\t Generator Loss: 0.22086720168590546 \t\t Total Loss: 0.22365733981132507\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00018452826770953834 \t\t Loss_Fake: 0.9972790479660034\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.0027812239713966846 \t\t Generator Loss: 0.22095239162445068 \t\t Total Loss: 0.22373361885547638\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00019035451987292618 \t\t Loss_Fake: 0.9972648620605469\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.002794594271108508 \t\t Generator Loss: 0.22081010043621063 \t\t Total Loss: 0.2236046940088272\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00018646482203621417 \t\t Loss_Fake: 0.9972373843193054\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.002740937052294612 \t\t Generator Loss: 0.22078223526477814 \t\t Total Loss: 0.22352316975593567\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00017160989227704704 \t\t Loss_Fake: 0.9971967935562134\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.002740247407928109 \t\t Generator Loss: 0.2206561118364334 \t\t Total Loss: 0.22339636087417603\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00015685305697843432 \t\t Loss_Fake: 0.9971616864204407\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.0026685185730457306 \t\t Generator Loss: 0.220606729388237 \t\t Total Loss: 0.22327524423599243\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00014898872177582234 \t\t Loss_Fake: 0.9971254467964172\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.0027545045595616102 \t\t Generator Loss: 0.22037816047668457 \t\t Total Loss: 0.2231326699256897\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0001477164914831519 \t\t Loss_Fake: 0.9970839619636536\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.0026739020831882954 \t\t Generator Loss: 0.2194766253232956 \t\t Total Loss: 0.2221505343914032\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0001496752811362967 \t\t Loss_Fake: 0.9969862699508667\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.0027118995785713196 \t\t Generator Loss: 0.21786737442016602 \t\t Total Loss: 0.22057926654815674\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00015366592560894787 \t\t Loss_Fake: 0.9968581199645996\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.002464630175381899 \t\t Generator Loss: 0.21909324824810028 \t\t Total Loss: 0.2215578854084015\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00015761500981170684 \t\t Loss_Fake: 0.9967902898788452\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.0036296751350164413 \t\t Generator Loss: 0.2157081812620163 \t\t Total Loss: 0.2193378508090973\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00016532459994778037 \t\t Loss_Fake: 0.9967082738876343\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.003670755075290799 \t\t Generator Loss: 0.21741196513175964 \t\t Total Loss: 0.22108271718025208\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00017546609160490334 \t\t Loss_Fake: 0.996679425239563\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.0038226074539124966 \t\t Generator Loss: 0.2162996232509613 \t\t Total Loss: 0.22012223303318024\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00017952648340724409 \t\t Loss_Fake: 0.9966670274734497\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.004682556726038456 \t\t Generator Loss: 0.21528594195842743 \t\t Total Loss: 0.2199684977531433\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00018557743169367313 \t\t Loss_Fake: 0.9965771436691284\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.0051515968516469 \t\t Generator Loss: 0.21595044434070587 \t\t Total Loss: 0.2211020439863205\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00019759214774239808 \t\t Loss_Fake: 0.9964345693588257\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.004764082841575146 \t\t Generator Loss: 0.21682798862457275 \t\t Total Loss: 0.22159206867218018\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0002073076757369563 \t\t Loss_Fake: 0.9963079690933228\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.005366545636206865 \t\t Generator Loss: 0.21551470458507538 \t\t Total Loss: 0.22088125348091125\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00020405510440468788 \t\t Loss_Fake: 0.9963012933731079\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.004520541522651911 \t\t Generator Loss: 0.2101254016160965 \t\t Total Loss: 0.21464593708515167\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00018799382087308913 \t\t Loss_Fake: 0.9963414072990417\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.0043341731652617455 \t\t Generator Loss: 0.21005801856517792 \t\t Total Loss: 0.21439218521118164\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0001642324059503153 \t\t Loss_Fake: 0.9963667988777161\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.0035872075241059065 \t\t Generator Loss: 0.21062032878398895 \t\t Total Loss: 0.21420753002166748\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00013737197150476277 \t\t Loss_Fake: 0.9963399171829224\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.003399650799110532 \t\t Generator Loss: 0.21045449376106262 \t\t Total Loss: 0.21385414898395538\n",
            "\t\t\t\t Discriminator Loss_Real: 0.000121362078061793 \t\t Loss_Fake: 0.99627685546875\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.0032593205105513334 \t\t Generator Loss: 0.21047767996788025 \t\t Total Loss: 0.21373699605464935\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00012095668353140354 \t\t Loss_Fake: 0.996211051940918\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.0033676275052130222 \t\t Generator Loss: 0.21071770787239075 \t\t Total Loss: 0.21408534049987793\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00013153332110960037 \t\t Loss_Fake: 0.9961423873901367\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.003147569252178073 \t\t Generator Loss: 0.21173405647277832 \t\t Total Loss: 0.21488162875175476\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00013861180923413485 \t\t Loss_Fake: 0.9959778785705566\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.0023062746040523052 \t\t Generator Loss: 0.21616312861442566 \t\t Total Loss: 0.21846939623355865\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0001296724221901968 \t\t Loss_Fake: 0.9948949813842773\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.00035666051553562284 \t\t Generator Loss: 0.34390750527381897 \t\t Total Loss: 0.3442641794681549\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0001156531143351458 \t\t Loss_Fake: 0.9983916282653809\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.00042173266410827637 \t\t Generator Loss: 0.36093926429748535 \t\t Total Loss: 0.36136099696159363\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00015484483446925879 \t\t Loss_Fake: 0.997707188129425\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.002096232259646058 \t\t Generator Loss: 0.3509190082550049 \t\t Total Loss: 0.3530152440071106\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0003995304577983916 \t\t Loss_Fake: 0.996562659740448\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.003455857513472438 \t\t Generator Loss: 0.35203519463539124 \t\t Total Loss: 0.355491042137146\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0008235462009906769 \t\t Loss_Fake: 0.9961223602294922\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.004097603727132082 \t\t Generator Loss: 0.3367423415184021 \t\t Total Loss: 0.3408399522304535\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0009367324528284371 \t\t Loss_Fake: 0.995897114276886\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.003959560766816139 \t\t Generator Loss: 0.3295387923717499 \t\t Total Loss: 0.33349835872650146\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0006829071207903326 \t\t Loss_Fake: 0.995937168598175\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.003864038037136197 \t\t Generator Loss: 0.32232850790023804 \t\t Total Loss: 0.32619255781173706\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0003788755857385695 \t\t Loss_Fake: 0.9961534738540649\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.0029960982501506805 \t\t Generator Loss: 0.31883296370506287 \t\t Total Loss: 0.32182905077934265\n",
            "\t\t\t\t Discriminator Loss_Real: 0.000254217506153509 \t\t Loss_Fake: 0.9961323738098145\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.003247438697144389 \t\t Generator Loss: 0.3088230490684509 \t\t Total Loss: 0.31207048892974854\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00019230238103773445 \t\t Loss_Fake: 0.9957987666130066\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.0035429950803518295 \t\t Generator Loss: 0.3049059212207794 \t\t Total Loss: 0.3084489107131958\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00018226230167783797 \t\t Loss_Fake: 0.9957106709480286\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.0057334029115736485 \t\t Generator Loss: 0.3034899830818176 \t\t Total Loss: 0.30922338366508484\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00018562554032541811 \t\t Loss_Fake: 0.9956905245780945\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.0041086263954639435 \t\t Generator Loss: 0.3026580512523651 \t\t Total Loss: 0.30676668882369995\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00016343625611625612 \t\t Loss_Fake: 0.9955790638923645\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.004435402806848288 \t\t Generator Loss: 0.3002646565437317 \t\t Total Loss: 0.3047000467777252\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00013530375144910067 \t\t Loss_Fake: 0.9950979351997375\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.006132698152214289 \t\t Generator Loss: 0.30072590708732605 \t\t Total Loss: 0.3068585991859436\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00011848695430671796 \t\t Loss_Fake: 0.9940520524978638\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.0028881256002932787 \t\t Generator Loss: 0.34433093667030334 \t\t Total Loss: 0.3472190499305725\n",
            "\t\t\t\t Discriminator Loss_Real: 0.00040826728218235075 \t\t Loss_Fake: 0.9875525236129761\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.07197824865579605 \t\t Generator Loss: 0.33135488629341125 \t\t Total Loss: 0.4033331274986267\n",
            "\t\t\t\t Discriminator Loss_Real: 0.06003997474908829 \t\t Loss_Fake: 0.9956046342849731\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.08006374537944794 \t\t Generator Loss: 0.45611485838890076 \t\t Total Loss: 0.5361785888671875\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0695246011018753 \t\t Loss_Fake: 0.9879335165023804\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 2.4803433418273926 \t\t Generator Loss: 0.4435066282749176 \t\t Total Loss: 2.9238500595092773\n",
            "\t\t\t\t Discriminator Loss_Real: 1.486220121383667 \t\t Loss_Fake: 0.9989666938781738\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.06256244331598282 \t\t Generator Loss: 0.44967523217201233 \t\t Total Loss: 0.5122376680374146\n",
            "\t\t\t\t Discriminator Loss_Real: 0.06255888193845749 \t\t Loss_Fake: 0.999535858631134\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.06261536478996277 \t\t Generator Loss: 0.44788044691085815 \t\t Total Loss: 0.5104957818984985\n",
            "\t\t\t\t Discriminator Loss_Real: 0.062615767121315 \t\t Loss_Fake: 0.9995056390762329\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.06272111088037491 \t\t Generator Loss: 0.44688719511032104 \t\t Total Loss: 0.5096083283424377\n",
            "\t\t\t\t Discriminator Loss_Real: 0.06272250413894653 \t\t Loss_Fake: 0.9994515180587769\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.06281118839979172 \t\t Generator Loss: 0.44865351915359497 \t\t Total Loss: 0.5114647150039673\n",
            "\t\t\t\t Discriminator Loss_Real: 0.06281308084726334 \t\t Loss_Fake: 0.9994438886642456\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.06279048323631287 \t\t Generator Loss: 0.45669469237327576 \t\t Total Loss: 0.5194851756095886\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0627918690443039 \t\t Loss_Fake: 0.9994782209396362\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.0627116784453392 \t\t Generator Loss: 0.45760875940322876 \t\t Total Loss: 0.5203204154968262\n",
            "\t\t\t\t Discriminator Loss_Real: 0.06271262466907501 \t\t Loss_Fake: 0.9995285272598267\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.06265763938426971 \t\t Generator Loss: 0.4564507007598877 \t\t Total Loss: 0.5191083550453186\n",
            "\t\t\t\t Discriminator Loss_Real: 0.06265836209058762 \t\t Loss_Fake: 0.999557614326477\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.0626382976770401 \t\t Generator Loss: 0.45584583282470703 \t\t Total Loss: 0.5184841156005859\n",
            "\t\t\t\t Discriminator Loss_Real: 0.06263899058103561 \t\t Loss_Fake: 0.9995477795600891\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.06264401972293854 \t\t Generator Loss: 0.455655038356781 \t\t Total Loss: 0.5182990431785583\n",
            "\t\t\t\t Discriminator Loss_Real: 0.06264480948448181 \t\t Loss_Fake: 0.9994977712631226\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.06267373263835907 \t\t Generator Loss: 0.45214590430259705 \t\t Total Loss: 0.5148196220397949\n",
            "\t\t\t\t Discriminator Loss_Real: 0.06267442554235458 \t\t Loss_Fake: 0.9994037747383118\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.06273402273654938 \t\t Generator Loss: 0.45350486040115356 \t\t Total Loss: 0.5162388682365417\n",
            "\t\t\t\t Discriminator Loss_Real: 0.06273455917835236 \t\t Loss_Fake: 0.9992648959159851\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.0628342553973198 \t\t Generator Loss: 0.45147910714149475 \t\t Total Loss: 0.5143133401870728\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0628354623913765 \t\t Loss_Fake: 0.9990798830986023\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.06297619640827179 \t\t Generator Loss: 0.4524129033088684 \t\t Total Loss: 0.515389084815979\n",
            "\t\t\t\t Discriminator Loss_Real: 0.06297757476568222 \t\t Loss_Fake: 0.9988384246826172\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.0631391629576683 \t\t Generator Loss: 0.4501093327999115 \t\t Total Loss: 0.5132485032081604\n",
            "\t\t\t\t Discriminator Loss_Real: 0.06314045190811157 \t\t Loss_Fake: 0.9984076619148254\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.0633789449930191 \t\t Generator Loss: 0.4539884030818939 \t\t Total Loss: 0.5173673629760742\n",
            "\t\t\t\t Discriminator Loss_Real: 0.06337995827198029 \t\t Loss_Fake: 0.9965701103210449\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.07438183575868607 \t\t Generator Loss: 0.45431584119796753 \t\t Total Loss: 0.528697669506073\n",
            "\t\t\t\t Discriminator Loss_Real: 0.07439447939395905 \t\t Loss_Fake: 0.9996832013130188\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.0625055581331253 \t\t Generator Loss: 0.45333346724510193 \t\t Total Loss: 0.5158390402793884\n",
            "\t\t\t\t Discriminator Loss_Real: 0.06250559538602829 \t\t Loss_Fake: 0.9999761581420898\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.06250035017728806 \t\t Generator Loss: 0.45359620451927185 \t\t Total Loss: 0.5160965323448181\n",
            "\t\t\t\t Discriminator Loss_Real: 0.06250036507844925 \t\t Loss_Fake: 0.9999879598617554\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.06249825283885002 \t\t Generator Loss: 0.45357856154441833 \t\t Total Loss: 0.5160768032073975\n",
            "\t\t\t\t Discriminator Loss_Real: 0.06249826028943062 \t\t Loss_Fake: 0.9999892115592957\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.06249416619539261 \t\t Generator Loss: 0.453373521566391 \t\t Total Loss: 0.5158677101135254\n",
            "\t\t\t\t Discriminator Loss_Real: 0.06249416992068291 \t\t Loss_Fake: 0.9999880790710449\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.06248657777905464 \t\t Generator Loss: 0.4535442292690277 \t\t Total Loss: 0.5160307884216309\n",
            "\t\t\t\t Discriminator Loss_Real: 0.06248658150434494 \t\t Loss_Fake: 0.999984085559845\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.06247394159436226 \t\t Generator Loss: 0.45357745885849 \t\t Total Loss: 0.5160514116287231\n",
            "\t\t\t\t Discriminator Loss_Real: 0.06247394531965256 \t\t Loss_Fake: 0.9999769330024719\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.062453895807266235 \t\t Generator Loss: 0.45321449637413025 \t\t Total Loss: 0.5156683921813965\n",
            "\t\t\t\t Discriminator Loss_Real: 0.06245392560958862 \t\t Loss_Fake: 0.9999651908874512\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.062421709299087524 \t\t Generator Loss: 0.4532119631767273 \t\t Total Loss: 0.5156337022781372\n",
            "\t\t\t\t Discriminator Loss_Real: 0.06242178753018379 \t\t Loss_Fake: 0.9999451637268066\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.062365204095840454 \t\t Generator Loss: 0.4517056941986084 \t\t Total Loss: 0.5140708684921265\n",
            "\t\t\t\t Discriminator Loss_Real: 0.06236536428332329 \t\t Loss_Fake: 0.999907374382019\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.062247537076473236 \t\t Generator Loss: 0.451547235250473 \t\t Total Loss: 0.5137947797775269\n",
            "\t\t\t\t Discriminator Loss_Real: 0.062247831374406815 \t\t Loss_Fake: 0.9998221397399902\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.061939436942338943 \t\t Generator Loss: 0.4514644145965576 \t\t Total Loss: 0.5134038329124451\n",
            "\t\t\t\t Discriminator Loss_Real: 0.06194010376930237 \t\t Loss_Fake: 0.9996182322502136\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.06114540621638298 \t\t Generator Loss: 0.4515206813812256 \t\t Total Loss: 0.5126661062240601\n",
            "\t\t\t\t Discriminator Loss_Real: 0.06114637851715088 \t\t Loss_Fake: 0.9995943307876587\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.06057901307940483 \t\t Generator Loss: 0.4514857232570648 \t\t Total Loss: 0.5120647549629211\n",
            "\t\t\t\t Discriminator Loss_Real: 0.06057925149798393 \t\t Loss_Fake: 0.9998343586921692\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.06047378107905388 \t\t Generator Loss: 0.45167970657348633 \t\t Total Loss: 0.5121535062789917\n",
            "\t\t\t\t Discriminator Loss_Real: 0.06047404557466507 \t\t Loss_Fake: 0.9998911619186401\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.060352958738803864 \t\t Generator Loss: 0.45166945457458496 \t\t Total Loss: 0.5120224356651306\n",
            "\t\t\t\t Discriminator Loss_Real: 0.06035355478525162 \t\t Loss_Fake: 0.9998207092285156\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.059961654245853424 \t\t Generator Loss: 0.4516645073890686 \t\t Total Loss: 0.5116261839866638\n",
            "\t\t\t\t Discriminator Loss_Real: 0.05996343493461609 \t\t Loss_Fake: 0.9994532465934753\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.05798874422907829 \t\t Generator Loss: 0.45162028074264526 \t\t Total Loss: 0.509609043598175\n",
            "\t\t\t\t Discriminator Loss_Real: 0.057998232543468475 \t\t Loss_Fake: 0.9945462942123413\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 0.001931249862536788 \t\t Generator Loss: 0.4515940248966217 \t\t Total Loss: 0.45352527499198914\n",
            "\t\t\t\t Discriminator Loss_Real: 0.0019345429027453065 \t\t Loss_Fake: 0.9999061822891235\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 3.777284618422527e-08 \t\t Generator Loss: 0.4475758969783783 \t\t Total Loss: 0.4475759267807007\n",
            "\t\t\t\t Discriminator Loss_Real: 3.8050217199270264e-08 \t\t Loss_Fake: 0.9999984502792358\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 2.1539580785656653e-08 \t\t Generator Loss: 0.4475594162940979 \t\t Total Loss: 0.4475594460964203\n",
            "\t\t\t\t Discriminator Loss_Real: 2.1705263364424354e-08 \t\t Loss_Fake: 0.9999988675117493\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 1.4106094070598374e-08 \t\t Generator Loss: 0.44752630591392517 \t\t Total Loss: 0.44752630591392517\n",
            "\t\t\t\t Discriminator Loss_Real: 1.4215362220681982e-08 \t\t Loss_Fake: 0.9999990463256836\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 1.0011950379862355e-08 \t\t Generator Loss: 0.4475111961364746 \t\t Total Loss: 0.4475111961364746\n",
            "\t\t\t\t Discriminator Loss_Real: 1.0086706581091676e-08 \t\t Loss_Fake: 0.9999991655349731\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 7.485533970452707e-09 \t\t Generator Loss: 0.4475036561489105 \t\t Total Loss: 0.4475036561489105\n",
            "\t\t\t\t Discriminator Loss_Real: 7.544446845031416e-09 \t\t Loss_Fake: 0.9999992251396179\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 5.856632512291071e-09 \t\t Generator Loss: 0.4471066892147064 \t\t Total Loss: 0.4471066892147064\n",
            "\t\t\t\t Discriminator Loss_Real: 5.903770805559816e-09 \t\t Loss_Fake: 0.9999993443489075\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 4.8072577030211505e-09 \t\t Generator Loss: 0.44708800315856934 \t\t Total Loss: 0.44708800315856934\n",
            "\t\t\t\t Discriminator Loss_Real: 4.845853940338429e-09 \t\t Loss_Fake: 0.9999993443489075\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 4.101493367159037e-09 \t\t Generator Loss: 0.4470781683921814 \t\t Total Loss: 0.4470781683921814\n",
            "\t\t\t\t Discriminator Loss_Real: 4.134768971653102e-09 \t\t Loss_Fake: 0.9999994039535522\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 3.608959131540246e-09 \t\t Generator Loss: 0.4470670223236084 \t\t Total Loss: 0.4470670223236084\n",
            "\t\t\t\t Discriminator Loss_Real: 3.6382648005428564e-09 \t\t Loss_Fake: 0.9999996423721313\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 3.259100767039058e-09 \t\t Generator Loss: 0.447049617767334 \t\t Total Loss: 0.447049617767334\n",
            "\t\t\t\t Discriminator Loss_Real: 3.2852944809036444e-09 \t\t Loss_Fake: 0.9999996423721313\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 3.003761239739333e-09 \t\t Generator Loss: 0.4454166889190674 \t\t Total Loss: 0.4454166889190674\n",
            "\t\t\t\t Discriminator Loss_Real: 3.028461037501984e-09 \t\t Loss_Fake: 0.9999996423721313\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 2.8158351206286625e-09 \t\t Generator Loss: 0.4453994333744049 \t\t Total Loss: 0.4453994333744049\n",
            "\t\t\t\t Discriminator Loss_Real: 2.839306123547658e-09 \t\t Loss_Fake: 0.9999996423721313\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 2.6758288917960726e-09 \t\t Generator Loss: 0.44537630677223206 \t\t Total Loss: 0.44537630677223206\n",
            "\t\t\t\t Discriminator Loss_Real: 2.6981576972673338e-09 \t\t Loss_Fake: 0.9999996423721313\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 2.5704331996223573e-09 \t\t Generator Loss: 0.4453446865081787 \t\t Total Loss: 0.4453446865081787\n",
            "\t\t\t\t Discriminator Loss_Real: 2.5919886237346645e-09 \t\t Loss_Fake: 0.9999996423721313\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 2.4903390460906394e-09 \t\t Generator Loss: 0.4453010559082031 \t\t Total Loss: 0.4453010559082031\n",
            "\t\t\t\t Discriminator Loss_Real: 2.5116988489060077e-09 \t\t Loss_Fake: 0.9999996423721313\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 2.4296444856020116e-09 \t\t Generator Loss: 0.4452579915523529 \t\t Total Loss: 0.4452579915523529\n",
            "\t\t\t\t Discriminator Loss_Real: 2.4505530937801723e-09 \t\t Loss_Fake: 0.9999996423721313\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 2.383752306656106e-09 \t\t Generator Loss: 0.44513601064682007 \t\t Total Loss: 0.44513601064682007\n",
            "\t\t\t\t Discriminator Loss_Real: 2.404506149744634e-09 \t\t Loss_Fake: 0.9999996423721313\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 2.3490298595163495e-09 \t\t Generator Loss: 0.4448699355125427 \t\t Total Loss: 0.4448699355125427\n",
            "\t\t\t\t Discriminator Loss_Real: 2.3698714102238227e-09 \t\t Loss_Fake: 0.9999996423721313\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 2.322819048217184e-09 \t\t Generator Loss: 0.4440702795982361 \t\t Total Loss: 0.4440702795982361\n",
            "\t\t\t\t Discriminator Loss_Real: 2.3441182328554078e-09 \t\t Loss_Fake: 0.9999996423721313\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 2.301712598296035e-09 \t\t Generator Loss: 0.4409535825252533 \t\t Total Loss: 0.4409535825252533\n",
            "\t\t\t\t Discriminator Loss_Real: 2.3254691505769642e-09 \t\t Loss_Fake: 0.9999996423721313\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 2.2855390913179008e-09 \t\t Generator Loss: 0.45020604133605957 \t\t Total Loss: 0.45020604133605957\n",
            "\t\t\t\t Discriminator Loss_Real: 2.312517510816292e-09 \t\t Loss_Fake: 0.9999996423721313\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 2.2823893885970392e-09 \t\t Generator Loss: 0.4491654932498932 \t\t Total Loss: 0.4491654932498932\n",
            "\t\t\t\t Discriminator Loss_Real: 2.304073598580203e-09 \t\t Loss_Fake: 0.9999996423721313\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 2.277159349972635e-09 \t\t Generator Loss: 0.44903987646102905 \t\t Total Loss: 0.44903987646102905\n",
            "\t\t\t\t Discriminator Loss_Real: 2.299192836119346e-09 \t\t Loss_Fake: 0.9999996423721313\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 2.272240173795126e-09 \t\t Generator Loss: 0.4486989974975586 \t\t Total Loss: 0.4486989974975586\n",
            "\t\t\t\t Discriminator Loss_Real: 2.297202650325403e-09 \t\t Loss_Fake: 0.9999996423721313\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 2.2747521644106428e-09 \t\t Generator Loss: 0.4475974142551422 \t\t Total Loss: 0.4475974142551422\n",
            "\t\t\t\t Discriminator Loss_Real: 2.297992685029726e-09 \t\t Loss_Fake: 0.9999996423721313\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 2.2775454855405997e-09 \t\t Generator Loss: 0.4488404393196106 \t\t Total Loss: 0.4488404393196106\n",
            "\t\t\t\t Discriminator Loss_Real: 2.300246437769715e-09 \t\t Loss_Fake: 0.9999996423721313\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 2.2794059972852665e-09 \t\t Generator Loss: 0.4482702612876892 \t\t Total Loss: 0.4482702612876892\n",
            "\t\t\t\t Discriminator Loss_Real: 2.304073154490993e-09 \t\t Loss_Fake: 0.9999996423721313\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 2.2851849301730454e-09 \t\t Generator Loss: 0.44788694381713867 \t\t Total Loss: 0.44788694381713867\n",
            "\t\t\t\t Discriminator Loss_Real: 2.3091426548660365e-09 \t\t Loss_Fake: 0.9999996423721313\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 2.2918043018904655e-09 \t\t Generator Loss: 0.44839709997177124 \t\t Total Loss: 0.44839709997177124\n",
            "\t\t\t\t Discriminator Loss_Real: 2.3152624262223753e-09 \t\t Loss_Fake: 0.9999996423721313\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 2.2972475033355977e-09 \t\t Generator Loss: 0.4480317533016205 \t\t Total Loss: 0.4480317533016205\n",
            "\t\t\t\t Discriminator Loss_Real: 2.3216266686887366e-09 \t\t Loss_Fake: 0.9999996423721313\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 2.3053869924183346e-09 \t\t Generator Loss: 0.4422033727169037 \t\t Total Loss: 0.4422033727169037\n",
            "\t\t\t\t Discriminator Loss_Real: 2.329284543023391e-09 \t\t Loss_Fake: 0.9999996423721313\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 2.3139437033137256e-09 \t\t Generator Loss: 0.4424512982368469 \t\t Total Loss: 0.4424512982368469\n",
            "\t\t\t\t Discriminator Loss_Real: 2.3375401614345037e-09 \t\t Loss_Fake: 0.9999996423721313\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 2.321433045793242e-09 \t\t Generator Loss: 0.44225674867630005 \t\t Total Loss: 0.44225674867630005\n",
            "\t\t\t\t Discriminator Loss_Real: 2.346285388199476e-09 \t\t Loss_Fake: 0.9999996423721313\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 2.3309589813891307e-09 \t\t Generator Loss: 0.4421234726905823 \t\t Total Loss: 0.4421234726905823\n",
            "\t\t\t\t Discriminator Loss_Real: 2.355455164249065e-09 \t\t Loss_Fake: 0.9999996423721313\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 2.340456495275589e-09 \t\t Generator Loss: 0.44224482774734497 \t\t Total Loss: 0.44224482774734497\n",
            "\t\t\t\t Discriminator Loss_Real: 2.3650268410335684e-09 \t\t Loss_Fake: 0.9999996423721313\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 2.3494297618498194e-09 \t\t Generator Loss: 0.44211268424987793 \t\t Total Loss: 0.44211268424987793\n",
            "\t\t\t\t Discriminator Loss_Real: 2.3748361055453415e-09 \t\t Loss_Fake: 0.9999996423721313\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 2.3596478104792595e-09 \t\t Generator Loss: 0.44201964139938354 \t\t Total Loss: 0.44201964139938354\n",
            "\t\t\t\t Discriminator Loss_Real: 2.38492514625932e-09 \t\t Loss_Fake: 0.9999996423721313\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 2.3699855411507542e-09 \t\t Generator Loss: 0.4420798718929291 \t\t Total Loss: 0.4420798718929291\n",
            "\t\t\t\t Discriminator Loss_Real: 2.3952317906861254e-09 \t\t Loss_Fake: 0.9999996423721313\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 2.379902941385126e-09 \t\t Generator Loss: 0.442055881023407 \t\t Total Loss: 0.442055881023407\n",
            "\t\t\t\t Discriminator Loss_Real: 2.405749821576819e-09 \t\t Loss_Fake: 0.9999996423721313\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 2.390665887475052e-09 \t\t Generator Loss: 0.4419947564601898 \t\t Total Loss: 0.4419947564601898\n",
            "\t\t\t\t Discriminator Loss_Real: 2.4159705347415183e-09 \t\t Loss_Fake: 0.9999996423721313\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 2.4015165411839234e-09 \t\t Generator Loss: 0.4478299617767334 \t\t Total Loss: 0.4478299617767334\n",
            "\t\t\t\t Discriminator Loss_Real: 2.4268278497885376e-09 \t\t Loss_Fake: 0.9999996423721313\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 2.4119926056442864e-09 \t\t Generator Loss: 0.4478331506252289 \t\t Total Loss: 0.4478331506252289\n",
            "\t\t\t\t Discriminator Loss_Real: 2.437841484237424e-09 \t\t Loss_Fake: 0.9999996423721313\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 2.423329314993339e-09 \t\t Generator Loss: 0.4477969706058502 \t\t Total Loss: 0.4477969706058502\n",
            "\t\t\t\t Discriminator Loss_Real: 2.4489881234046607e-09 \t\t Loss_Fake: 0.9999996423721313\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 2.4344490867633795e-09 \t\t Generator Loss: 0.44780007004737854 \t\t Total Loss: 0.44780007004737854\n",
            "\t\t\t\t Discriminator Loss_Real: 2.4602553327923715e-09 \t\t Loss_Fake: 0.9999996423721313\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 2.445509572623905e-09 \t\t Generator Loss: 0.44780826568603516 \t\t Total Loss: 0.44780826568603516\n",
            "\t\t\t\t Discriminator Loss_Real: 2.4717767832527215e-09 \t\t Loss_Fake: 0.9999996423721313\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 2.457155812152223e-09 \t\t Generator Loss: 0.4475632607936859 \t\t Total Loss: 0.4475632607936859\n",
            "\t\t\t\t Discriminator Loss_Real: 2.4832960132670223e-09 \t\t Loss_Fake: 0.9999996423721313\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 2.4686577226873396e-09 \t\t Generator Loss: 0.44755691289901733 \t\t Total Loss: 0.44755691289901733\n",
            "\t\t\t\t Discriminator Loss_Real: 2.4949406984831057e-09 \t\t Loss_Fake: 0.9999996423721313\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 2.4801356524051243e-09 \t\t Generator Loss: 0.447562038898468 \t\t Total Loss: 0.447562038898468\n",
            "\t\t\t\t Discriminator Loss_Real: 2.5066761999426035e-09 \t\t Loss_Fake: 0.9999996423721313\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 2.4920026042707377e-09 \t\t Generator Loss: 0.44755253195762634 \t\t Total Loss: 0.44755253195762634\n",
            "\t\t\t\t Discriminator Loss_Real: 2.5185347141132297e-09 \t\t Loss_Fake: 0.9999996423721313\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 2.50379916799659e-09 \t\t Generator Loss: 0.4475440979003906 \t\t Total Loss: 0.4475440979003906\n",
            "\t\t\t\t Discriminator Loss_Real: 2.5306026163463002e-09 \t\t Loss_Fake: 0.9999996423721313\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 2.51571963261199e-09 \t\t Generator Loss: 0.44135475158691406 \t\t Total Loss: 0.44135475158691406\n",
            "\t\t\t\t Discriminator Loss_Real: 2.542682064898827e-09 \t\t Loss_Fake: 0.9999996423721313\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 2.527843045996292e-09 \t\t Generator Loss: 0.44135135412216187 \t\t Total Loss: 0.44135135412216187\n",
            "\t\t\t\t Discriminator Loss_Real: 2.554860767389755e-09 \t\t Loss_Fake: 0.9999996423721313\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 2.539859211836415e-09 \t\t Generator Loss: 0.44134530425071716 \t\t Total Loss: 0.44134530425071716\n",
            "\t\t\t\t Discriminator Loss_Real: 2.567154711030639e-09 \t\t Loss_Fake: 0.9999996423721313\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 2.552106526110265e-09 \t\t Generator Loss: 0.4413447976112366 \t\t Total Loss: 0.4413447976112366\n",
            "\t\t\t\t Discriminator Loss_Real: 2.5795512392789988e-09 \t\t Loss_Fake: 0.9999996423721313\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 2.564460421794479e-09 \t\t Generator Loss: 0.44134360551834106 \t\t Total Loss: 0.44134360551834106\n",
            "\t\t\t\t Discriminator Loss_Real: 2.591596715006972e-09 \t\t Loss_Fake: 0.9999996423721313\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 2.576900248740799e-09 \t\t Generator Loss: 0.4417252540588379 \t\t Total Loss: 0.4417252540588379\n",
            "\t\t\t\t Discriminator Loss_Real: 2.604204407674615e-09 \t\t Loss_Fake: 0.9999996423721313\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 2.58939514274914e-09 \t\t Generator Loss: 0.44172343611717224 \t\t Total Loss: 0.44172343611717224\n",
            "\t\t\t\t Discriminator Loss_Real: 2.6169331146519426e-09 \t\t Loss_Fake: 0.9999996423721313\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 2.602172699539551e-09 \t\t Generator Loss: 0.44172248244285583 \t\t Total Loss: 0.44172248244285583\n",
            "\t\t\t\t Discriminator Loss_Real: 2.6297493072036104e-09 \t\t Loss_Fake: 0.9999996423721313\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 2.6148743170750777e-09 \t\t Generator Loss: 0.4417196810245514 \t\t Total Loss: 0.4417196810245514\n",
            "\t\t\t\t Discriminator Loss_Real: 2.6426754118347162e-09 \t\t Loss_Fake: 0.9999996423721313\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 2.6278172970961577e-09 \t\t Generator Loss: 0.44171738624572754 \t\t Total Loss: 0.44171738624572754\n",
            "\t\t\t\t Discriminator Loss_Real: 2.6569062505643615e-09 \t\t Loss_Fake: 0.9999996423721313\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 2.6411020037642174e-09 \t\t Generator Loss: 0.4310375154018402 \t\t Total Loss: 0.4310375154018402\n",
            "\t\t\t\t Discriminator Loss_Real: 2.6700766042608848e-09 \t\t Loss_Fake: 0.9999996423721313\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 2.654132469359638e-09 \t\t Generator Loss: 0.43103504180908203 \t\t Total Loss: 0.43103504180908203\n",
            "\t\t\t\t Discriminator Loss_Real: 2.6833260058367614e-09 \t\t Loss_Fake: 0.9999996423721313\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 2.667312148929568e-09 \t\t Generator Loss: 0.4310339093208313 \t\t Total Loss: 0.4310339093208313\n",
            "\t\t\t\t Discriminator Loss_Real: 2.6967215127626787e-09 \t\t Loss_Fake: 0.9999996423721313\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 2.680859534365254e-09 \t\t Generator Loss: 0.4310317635536194 \t\t Total Loss: 0.4310317635536194\n",
            "\t\t\t\t Discriminator Loss_Real: 2.7101929589434803e-09 \t\t Loss_Fake: 0.9999996423721313\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 2.6940867314806383e-09 \t\t Generator Loss: 0.43102899193763733 \t\t Total Loss: 0.43102899193763733\n",
            "\t\t\t\t Discriminator Loss_Real: 2.723127723314178e-09 \t\t Loss_Fake: 0.9999996423721313\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 2.707857493788879e-09 \t\t Generator Loss: 0.43029022216796875 \t\t Total Loss: 0.43029022216796875\n",
            "\t\t\t\t Discriminator Loss_Real: 2.736850523987755e-09 \t\t Loss_Fake: 0.9999996423721313\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 2.7214628328664503e-09 \t\t Generator Loss: 0.43028849363327026 \t\t Total Loss: 0.43028849363327026\n",
            "\t\t\t\t Discriminator Loss_Real: 2.750691674435757e-09 \t\t Loss_Fake: 0.9999996423721313\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 2.7352637932409607e-09 \t\t Generator Loss: 0.4302859306335449 \t\t Total Loss: 0.4302859306335449\n",
            "\t\t\t\t Discriminator Loss_Real: 2.7646458455876655e-09 \t\t Loss_Fake: 0.9999996423721313\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 2.7492050858057837e-09 \t\t Generator Loss: 0.43028339743614197 \t\t Total Loss: 0.43028339743614197\n",
            "\t\t\t\t Discriminator Loss_Real: 2.778718366513999e-09 \t\t Loss_Fake: 0.9999996423721313\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 2.7631847920872588e-09 \t\t Generator Loss: 0.43028169870376587 \t\t Total Loss: 0.43028169870376587\n",
            "\t\t\t\t Discriminator Loss_Real: 2.793518971699882e-09 \t\t Loss_Fake: 0.9999996423721313\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 2.77710121565633e-09 \t\t Generator Loss: 0.44305962324142456 \t\t Total Loss: 0.44305962324142456\n",
            "\t\t\t\t Discriminator Loss_Real: 2.8078526170816076e-09 \t\t Loss_Fake: 0.9999996423721313\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 2.7913882316710215e-09 \t\t Generator Loss: 0.44305720925331116 \t\t Total Loss: 0.44305720925331116\n",
            "\t\t\t\t Discriminator Loss_Real: 2.8222828518664755e-09 \t\t Loss_Fake: 0.9999996423721313\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 2.806011867306779e-09 \t\t Generator Loss: 0.4430583119392395 \t\t Total Loss: 0.4430583119392395\n",
            "\t\t\t\t Discriminator Loss_Real: 2.83684142843299e-09 \t\t Loss_Fake: 0.9999996423721313\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 2.82025558462351e-09 \t\t Generator Loss: 0.4430573880672455 \t\t Total Loss: 0.4430573880672455\n",
            "\t\t\t\t Discriminator Loss_Real: 2.8515312333610154e-09 \t\t Loss_Fake: 0.9999996423721313\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 2.835278456458923e-09 \t\t Generator Loss: 0.44305357336997986 \t\t Total Loss: 0.44305357336997986\n",
            "\t\t\t\t Discriminator Loss_Real: 2.866110904164998e-09 \t\t Loss_Fake: 0.9999996423721313\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 2.8498454707204246e-09 \t\t Generator Loss: 0.4423544406890869 \t\t Total Loss: 0.4423544406890869\n",
            "\t\t\t\t Discriminator Loss_Real: 2.8810698271541924e-09 \t\t Loss_Fake: 0.9999996423721313\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 2.8649567163085976e-09 \t\t Generator Loss: 0.4423521161079407 \t\t Total Loss: 0.4423521161079407\n",
            "\t\t\t\t Discriminator Loss_Real: 2.8961362197321705e-09 \t\t Loss_Fake: 0.9999996423721313\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 2.8799758133857267e-09 \t\t Generator Loss: 0.44235020875930786 \t\t Total Loss: 0.44235020875930786\n",
            "\t\t\t\t Discriminator Loss_Real: 2.9113302879579805e-09 \t\t Loss_Fake: 0.9999996423721313\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 2.895148565329464e-09 \t\t Generator Loss: 0.44234809279441833 \t\t Total Loss: 0.44234809279441833\n",
            "\t\t\t\t Discriminator Loss_Real: 2.926674236292115e-09 \t\t Loss_Fake: 0.9999996423721313\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 2.9105389209860277e-09 \t\t Generator Loss: 0.44234639406204224 \t\t Total Loss: 0.44234639406204224\n",
            "\t\t\t\t Discriminator Loss_Real: 2.9408417923093566e-09 \t\t Loss_Fake: 0.9999996423721313\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 2.925922393259839e-09 \t\t Generator Loss: 0.4413357675075531 \t\t Total Loss: 0.4413357675075531\n",
            "\t\t\t\t Discriminator Loss_Real: 2.9564473091880927e-09 \t\t Loss_Fake: 0.9999996423721313\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 2.9415907487617687e-09 \t\t Generator Loss: 0.4413347840309143 \t\t Total Loss: 0.4413347840309143\n",
            "\t\t\t\t Discriminator Loss_Real: 2.97219715506003e-09 \t\t Loss_Fake: 0.9999996423721313\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 2.957216915788763e-09 \t\t Generator Loss: 0.44133320450782776 \t\t Total Loss: 0.44133320450782776\n",
            "\t\t\t\t Discriminator Loss_Real: 2.9880602436804793e-09 \t\t Loss_Fake: 0.9999996423721313\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 2.9731697104296018e-09 \t\t Generator Loss: 0.44133123755455017 \t\t Total Loss: 0.44133123755455017\n",
            "\t\t\t\t Discriminator Loss_Real: 3.004092974379091e-09 \t\t Loss_Fake: 0.9999996423721313\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 2.989059222358037e-09 \t\t Generator Loss: 0.4413292407989502 \t\t Total Loss: 0.4413292407989502\n",
            "\t\t\t\t Discriminator Loss_Real: 3.020141248200048e-09 \t\t Loss_Fake: 0.9999996423721313\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 3.0052418331649733e-09 \t\t Generator Loss: 0.4414342939853668 \t\t Total Loss: 0.4414342939853668\n",
            "\t\t\t\t Discriminator Loss_Real: 3.036465967554136e-09 \t\t Loss_Fake: 0.9999996423721313\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 3.021503491851263e-09 \t\t Generator Loss: 0.44143253564834595 \t\t Total Loss: 0.44143253564834595\n",
            "\t\t\t\t Discriminator Loss_Real: 3.0529121453071184e-09 \t\t Loss_Fake: 0.9999996423721313\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 3.0379609938790963e-09 \t\t Generator Loss: 0.4414308965206146 \t\t Total Loss: 0.4414308965206146\n",
            "\t\t\t\t Discriminator Loss_Real: 3.0695219699339304e-09 \t\t Loss_Fake: 0.9999996423721313\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 3.054569486238279e-09 \t\t Generator Loss: 0.4414291977882385 \t\t Total Loss: 0.4414291977882385\n",
            "\t\t\t\t Discriminator Loss_Real: 3.0862765676431536e-09 \t\t Loss_Fake: 0.9999996423721313\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 3.0712521414955063e-09 \t\t Generator Loss: 0.4414275586605072 \t\t Total Loss: 0.4414275586605072\n",
            "\t\t\t\t Discriminator Loss_Real: 3.1029281366556916e-09 \t\t Loss_Fake: 0.9999996423721313\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 3.0880844548164532e-09 \t\t Generator Loss: 0.4461115300655365 \t\t Total Loss: 0.4461115300655365\n",
            "\t\t\t\t Discriminator Loss_Real: 3.119984270938403e-09 \t\t Loss_Fake: 0.9999996423721313\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 3.10510972489908e-09 \t\t Generator Loss: 0.44611018896102905 \t\t Total Loss: 0.44611018896102905\n",
            "\t\t\t\t Discriminator Loss_Real: 3.1371782949207727e-09 \t\t Loss_Fake: 0.9999996423721313\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 3.1223899021881607e-09 \t\t Generator Loss: 0.4461088180541992 \t\t Total Loss: 0.4461088180541992\n",
            "\t\t\t\t Discriminator Loss_Real: 3.1545561718360204e-09 \t\t Loss_Fake: 0.9999996423721313\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 3.1396705235664513e-09 \t\t Generator Loss: 0.44610723853111267 \t\t Total Loss: 0.44610723853111267\n",
            "\t\t\t\t Discriminator Loss_Real: 3.172085483171827e-09 \t\t Loss_Fake: 0.9999996423721313\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 3.157291317279487e-09 \t\t Generator Loss: 0.44610556960105896 \t\t Total Loss: 0.44610556960105896\n",
            "\t\t\t\t Discriminator Loss_Real: 3.1902847030806925e-09 \t\t Loss_Fake: 0.9999996423721313\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 3.1748979001378075e-09 \t\t Generator Loss: 0.44619911909103394 \t\t Total Loss: 0.44619911909103394\n",
            "\t\t\t\t Discriminator Loss_Real: 3.2081417522533684e-09 \t\t Loss_Fake: 0.9999996423721313\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 3.1928102384171098e-09 \t\t Generator Loss: 0.4461976885795593 \t\t Total Loss: 0.4461976885795593\n",
            "\t\t\t\t Discriminator Loss_Real: 3.2261666671473677e-09 \t\t Loss_Fake: 0.9999996423721313\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 3.21080273479879e-09 \t\t Generator Loss: 0.44619613885879517 \t\t Total Loss: 0.44619613885879517\n",
            "\t\t\t\t Discriminator Loss_Real: 3.2443476793986292e-09 \t\t Loss_Fake: 0.9999996423721313\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 3.229009504224223e-09 \t\t Generator Loss: 0.446194589138031 \t\t Total Loss: 0.446194589138031\n",
            "\t\t\t\t Discriminator Loss_Real: 3.262709213913695e-09 \t\t Loss_Fake: 0.9999996423721313\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 3.2473184141679212e-09 \t\t Generator Loss: 0.446193128824234 \t\t Total Loss: 0.446193128824234\n",
            "\t\t\t\t Discriminator Loss_Real: 3.280339999633952e-09 \t\t Loss_Fake: 0.9999996423721313\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 3.2662708093766923e-09 \t\t Generator Loss: 0.42877206206321716 \t\t Total Loss: 0.42877206206321716\n",
            "\t\t\t\t Discriminator Loss_Real: 3.2990334908333807e-09 \t\t Loss_Fake: 0.9999996423721313\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 3.2848579412103618e-09 \t\t Generator Loss: 0.42876943945884705 \t\t Total Loss: 0.42876943945884705\n",
            "\t\t\t\t Discriminator Loss_Real: 3.3179077263412182e-09 \t\t Loss_Fake: 0.9999996423721313\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 3.303422646538934e-09 \t\t Generator Loss: 0.42877131700515747 \t\t Total Loss: 0.42877131700515747\n",
            "\t\t\t\t Discriminator Loss_Real: 3.336964926603514e-09 \t\t Loss_Fake: 0.9999996423721313\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 3.3228642060123548e-09 \t\t Generator Loss: 0.4287714958190918 \t\t Total Loss: 0.4287714958190918\n",
            "\t\t\t\t Discriminator Loss_Real: 3.35619843028212e-09 \t\t Loss_Fake: 0.9999996423721313\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 3.341614318586039e-09 \t\t Generator Loss: 0.4287686347961426 \t\t Total Loss: 0.4287686347961426\n",
            "\t\t\t\t Discriminator Loss_Real: 3.375706159047809e-09 \t\t Loss_Fake: 0.9999996423721313\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 3.3613130057119633e-09 \t\t Generator Loss: 0.42944031953811646 \t\t Total Loss: 0.42944031953811646\n",
            "\t\t\t\t Discriminator Loss_Real: 3.3953084788151955e-09 \t\t Loss_Fake: 0.9999996423721313\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 3.3806000221403565e-09 \t\t Generator Loss: 0.4294382929801941 \t\t Total Loss: 0.4294382929801941\n",
            "\t\t\t\t Discriminator Loss_Real: 3.41509509560467e-09 \t\t Loss_Fake: 0.9999996423721313\n",
            "\n",
            "Epoch: 2 \t Discriminator Loss: 3.4004763449502207e-09 \t\t Generator Loss: 0.42943620681762695 \t\t Total Loss: 0.42943620681762695\n",
            "\t\t\t\t Discriminator Loss_Real: 3.4350879918321198e-09 \t\t Loss_Fake: 0.9999996423721313\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-77-32028262b5ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mconf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreconfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Conv2DLSTM_ADAE\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Test002\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-76-e2f02ed020f5>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0;34m[\u001b[0m\u001b[0mtotal_weighted_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreconstruction_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfooling_loss\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc1_hist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc2_hist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Epoch: {epoch} \\t Discriminator Loss: {fooling_loss} \\t\\t Generator Loss: {reconstruction_loss} \\t\\t Total Loss: {total_weighted_loss}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-76-e2f02ed020f5>\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(models, batch_clips, c1_hist, c2_hist)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mc2_hist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_loss_fake\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_noise_clips\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_clips\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     \u001b[0mg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_noise_clips\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_clips\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m     \u001b[0;32mreturn\u001b[0m  \u001b[0mg_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1076\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1077\u001b[0m           \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreset_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1078\u001b[0;31m           standalone=True)\n\u001b[0m\u001b[1;32m   1079\u001b[0m       outputs = (outputs['total_loss'] + outputs['output_losses'] +\n\u001b[1;32m   1080\u001b[0m                  outputs['metrics'])\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(model, x, y, sample_weight, class_weight, reset_metrics, standalone)\u001b[0m\n\u001b[1;32m    431\u001b[0m       \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m       \u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 433\u001b[0;31m       output_loss_metrics=model._output_loss_metrics)\n\u001b[0m\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    597\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2361\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2363\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2365\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1611\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}